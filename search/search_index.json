{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ethereum Proof-of-Stake Consensus Specifications","text":"<p>This repository hosts the current Ethereum proof-of-stake specifications. Discussions about design rationale and proposed changes can be brought up and discussed as issues. Solidified, agreed-upon changes to the specifications can be made through pull requests.</p>"},{"location":"#specifications","title":"Specifications","text":"<p>Core specifications for Ethereum proof-of-stake clients can be found in specs. These are divided into features. Features are researched and developed in parallel, and then consolidated into sequential upgrades when ready.</p>"},{"location":"#stable-specifications","title":"Stable Specifications","text":"Seq. Code Name Fork Epoch Links 0 Phase0 <code>0</code> Specs, Tests 1 Altair <code>74240</code> Specs, Tests 2 Bellatrix <code>144896</code> Specs, Tests 3 Capella <code>194048</code> Specs, Tests 4 Deneb <code>269568</code> Specs, Tests 5 Electra <code>364032</code> Specs, Tests"},{"location":"#in-development-specifications","title":"In-development Specifications","text":"Seq. Code Name Fork Epoch Links 6 Fulu TBD Specs, Tests 7 Gloas TBD Specs, Tests"},{"location":"#accompanying-documents","title":"Accompanying documents","text":"<ul> <li>SimpleSerialize (SSZ) spec</li> <li>Merkle proof formats</li> <li>General test format</li> </ul>"},{"location":"#external-specifications","title":"External specifications","text":"<p>Additional specifications and standards outside of requisite client functionality can be found in the following repositories:</p> <ul> <li>Beacon APIs</li> <li>Engine APIs</li> <li>Beacon Metrics</li> <li>Builder Specs</li> </ul>"},{"location":"#reference-tests","title":"Reference tests","text":"<p>Reference tests built from the executable Python spec are available in the Ethereum Proof-of-Stake Consensus Spec Tests repository. Compressed tarballs are available for each release here. Nightly reference tests are available here.</p>"},{"location":"#contributors","title":"Contributors","text":""},{"location":"#installation-and-usage","title":"Installation and usage","text":"<p>Clone the repository with:</p> <pre><code>git clone https://github.com/ethereum/consensus-specs.git\n</code></pre> <p>Switch to the directory:</p> <pre><code>cd consensus-specs\n</code></pre> <p>View the help output:</p> <pre><code>make help\n</code></pre>"},{"location":"#design-goals","title":"Design goals","text":"<p>The following are the broad design goals for the Ethereum proof-of-stake consensus specifications:</p> <ul> <li>Minimize complexity, even at the cost of some losses in efficiency.</li> <li>Remain live through major network partitions and when very large portions of   nodes go offline.</li> <li>Select components that are quantum secure or easily swappable for   quantum-secure alternatives.</li> <li>Utilize crypto and design techniques that allow for a large participation of   validators.</li> <li>Minimize hardware requirements such that a consumer laptop can participate.</li> </ul>"},{"location":"#useful-resources","title":"Useful resources","text":"<ul> <li>Design Rationale</li> <li>Phase0 Onboarding Document</li> <li>Combining GHOST and Casper paper</li> <li>Specifications viewer (mkdocs)</li> <li>Specifications viewer (jtraglia)</li> <li>The Eth2 Book</li> <li>PySpec Tests</li> </ul>"},{"location":"docs/new-feature/","title":"How to add a new feature proposal in consensus-specs","text":"<ul> <li>A. Make it executable for linter checks</li> <li>1. Create a folder under <code>./specs/_features</code></li> <li>2. Choose the \"previous fork\" to extend: usually, use the scheduled or the latest mainnet fork version.</li> <li>3. Write down your proposed <code>beacon-chain.md</code> change</li> <li>4. Add <code>fork.md</code></li> <li>5. Make it executable</li> <li>B: Make it executable for pytest and test generator</li> <li>1. [Optional] Add <code>light-client/*</code> docs if you updated the content of <code>BeaconBlock</code></li> <li>2. Add the mainnet and minimal presets and update the configs</li> <li>3. Update <code>context.py</code></li> <li>4. Update <code>constants.py</code></li> <li>5. Update <code>genesis.py</code>:</li> <li>6. Update CI configurations</li> <li>Others</li> <li>Bonus</li> <li>Need help?</li> </ul>"},{"location":"docs/new-feature/#a-make-it-executable-for-linter-checks","title":"A. Make it executable for linter checks","text":""},{"location":"docs/new-feature/#1-create-a-folder-under-specs_features","title":"1. Create a folder under <code>./specs/_features</code>","text":"<p>For example, if it's an <code>EIP-9999</code> CL spec, you can create a <code>./specs/_features/eip9999</code> folder.</p>"},{"location":"docs/new-feature/#2-choose-the-previous-fork-to-extend-usually-use-the-scheduled-or-the-latest-mainnet-fork-version","title":"2. Choose the \"previous fork\" to extend: usually, use the scheduled or the latest mainnet fork version.","text":"<p>For example, if the latest fork is Capella, use <code>./specs/capella</code> content as your \"previous fork\".</p>"},{"location":"docs/new-feature/#3-write-down-your-proposed-beacon-chainmd-change","title":"3. Write down your proposed <code>beacon-chain.md</code> change","text":"<ul> <li>Make a copy of the latest fork content and then edit it.</li> <li>Tips:</li> <li>The differences between \"Constants\", \"Configurations\", and \"Presets\":<ul> <li>Constants: The constant that should never be changed.</li> <li>Configurations: The settings that we may change for different networks.</li> <li>Presets: The settings that we may change for testing.</li> </ul> </li> <li>Readability and simplicity are more important than efficiency and     optimization.<ul> <li>Use simple Python rather than the fancy Python dark magic.</li> </ul> </li> </ul>"},{"location":"docs/new-feature/#4-add-forkmd","title":"4. Add <code>fork.md</code>","text":"<p>You can refer to the previous fork's <code>fork.md</code> file.</p>"},{"location":"docs/new-feature/#5-make-it-executable","title":"5. Make it executable","text":"<ul> <li>Update Pyspec   <code>constants.py</code>   with the new feature name.</li> <li>Update helpers for   <code>setup.py</code>   for building the spec:</li> <li>Update     <code>pysetup/constants.py</code>     with the new feature name as Pyspec <code>constants.py</code> defined.</li> <li>Update     <code>pysetup/spec_builders/__init__.py</code>.     Implement a new <code>&lt;FEATURE_NAME&gt;SpecBuilder</code> in     <code>pysetup/spec_builders/&lt;FEATURE_NAME&gt;.py</code> with the new feature name. e.g.,     <code>EIP9999SpecBuilder</code>. Append it to the <code>spec_builders</code> list.</li> <li>Update     <code>pysetup/md_doc_paths.py</code>:     add the path of the new markdown files in <code>get_md_doc_paths</code> function if     needed.</li> <li>Update <code>PREVIOUS_FORK_OF</code> setting in both   <code>test/helpers/constants.py</code>   and   <code>pysetup/md_doc_paths.py</code>.</li> <li>NOTE: since these two modules (the pyspec itself and the spec builder tool)     must be separate, the fork sequence setting has to be defined again.</li> </ul>"},{"location":"docs/new-feature/#b-make-it-executable-for-pytest-and-test-generator","title":"B: Make it executable for pytest and test generator","text":""},{"location":"docs/new-feature/#1-optional-add-light-client-docs-if-you-updated-the-content-of-beaconblock","title":"1. [Optional] Add <code>light-client/*</code> docs if you updated the content of <code>BeaconBlock</code>","text":"<ul> <li>You can refer to the previous fork's <code>light-client/*</code> file.</li> <li>Add the path of the new markdown files in   <code>pysetup/md_doc_paths.py</code>'s   <code>get_md_doc_paths</code> function.</li> </ul>"},{"location":"docs/new-feature/#2-add-the-mainnet-and-minimal-presets-and-update-the-configs","title":"2. Add the mainnet and minimal presets and update the configs","text":"<ul> <li>Add presets: <code>presets/mainnet/&lt;new-feature-name&gt;.yaml</code> and   <code>presets/minimal/&lt;new-feature-name&gt;.yaml</code></li> <li>Update configs: <code>configs/mainnet.yaml</code> and <code>configs/minimal.yaml</code></li> </ul>"},{"location":"docs/new-feature/#3-update-contextpy","title":"3. Update <code>context.py</code>","text":"<ul> <li>[Optional] Add <code>with_&lt;new-feature-name&gt;_and_later</code> decorator for writing   pytest cases. e.g., <code>with_capella_and_later</code>.</li> </ul>"},{"location":"docs/new-feature/#4-update-constantspy","title":"4. Update <code>constants.py</code>","text":"<ul> <li>Add <code>&lt;NEW_FEATURE&gt;</code> to <code>ALL_PHASES</code> and <code>TESTGEN_FORKS</code></li> </ul>"},{"location":"docs/new-feature/#5-update-genesispy","title":"5. Update <code>genesis.py</code>:","text":"<p>We use <code>create_genesis_state</code> to create the default <code>state</code> in tests.</p> <ul> <li>If the given feature changes <code>BeaconState</code> fields, you have to set the initial   values by adding:</li> </ul> <pre><code>def create_genesis_state(spec, validator_balances, activation_threshold):\n    ...\n\n    if is_post_eip9999(spec):\n        state.new_field = value\n\n    return state\n</code></pre> <ul> <li>If the given feature changes <code>ExecutionPayload</code> fields, you have to set the   initial values by updating <code>get_sample_genesis_execution_payload_header</code>   helper.</li> </ul>"},{"location":"docs/new-feature/#6-update-ci-configurations","title":"6. Update CI configurations","text":"<ul> <li>Update   GitHub Actions config</li> <li>Update <code>pyspec-tests.strategy.matrix.version</code> list by adding new feature to     it</li> </ul>"},{"location":"docs/new-feature/#others","title":"Others","text":""},{"location":"docs/new-feature/#bonus","title":"Bonus","text":"<ul> <li>Add <code>validator.md</code> if honest validator behavior changes with the new feature.</li> </ul>"},{"location":"docs/new-feature/#need-help","title":"Need help?","text":"<p>You can tag spec elves for cleaning up your PR. \ud83e\uddda</p>"},{"location":"docs/release/","title":"Release Procedure","text":"<ul> <li>Introduction</li> <li>Bump the Version</li> <li>Tag the Release</li> <li>Make an Announcement</li> </ul>"},{"location":"docs/release/#introduction","title":"Introduction","text":"<p>This document describes the necessary steps to produce a consensus-specs release.</p>"},{"location":"docs/release/#bump-the-version","title":"Bump the Version","text":"<p>Next, update the <code>VERSION.txt</code> file which contains the eth2spec version.</p> <p>[!TIP] Click on the following link to open the GitHub editor for this file:</p> <ul> <li>https://github.com/ethereum/consensus-specs/edit/master/tests/core/pyspec/eth2spec/VERSION.txt</li> </ul> <p>Next, change the version to the appropriate value and click the \"Commit changes...\" button.</p> <p>For the commit message, put \"Bump version to \\\" (e.g., \"Bump version to 1.5.0-alpha.10\"). <p>Next, click the \"Propose changes\" button and proceed to make the PR.</p>"},{"location":"docs/release/#tag-the-release","title":"Tag the Release","text":"<p>Next, tag the latest commit to master. This will trigger the automated release process.</p> <pre><code>git clone git@github.com:ethereum/consensus-specs.git\ncd consensus-specs\ngit tag &lt;version&gt;\ngit push origin &lt;version&gt;\n</code></pre> <p>Approximately 12 hours later, the releases for consensus-specs and consensus-spec-tests will be available on GitHub.</p>"},{"location":"docs/release/#make-an-announcement","title":"Make an Announcement","text":"<p>[!IMPORTANT] In order to do this, you must be granted the appropriate access.</p> <p>Finally, make an announcement to the Eth R&amp;D server on Discord. This should be posted in the <code>#announcements</code> channel. This will notify client developers of the new release and they will begin to incorporate the new reference tests into their client.</p> <p>Use the following template for your announcement:</p> <pre><code>Consensus layer specs &lt;version&gt; -- &lt;release-name&gt; -- released!\n\nhttps://github.com/ethereum/consensus-specs/releases/tag/&lt;version&gt;\n\nTest vectors: https://github.com/ethereum/consensus-spec-tests/releases/tag/&lt;version&gt;\n</code></pre>"},{"location":"fork_choice/safe-block/","title":"Fork Choice -- Safe Block","text":"<ul> <li>Introduction</li> <li><code>get_safe_beacon_block_root</code></li> <li><code>get_safe_execution_block_hash</code></li> </ul>"},{"location":"fork_choice/safe-block/#introduction","title":"Introduction","text":"<p>Under honest majority and certain network synchronicity assumptions there exists a block that is safe from re-orgs. Normally this block is pretty close to the head of canonical chain which makes it valuable to expose a safe block to users.</p> <p>This section describes an algorithm to find a safe block.</p>"},{"location":"fork_choice/safe-block/#get_safe_beacon_block_root","title":"<code>get_safe_beacon_block_root</code>","text":"<pre><code>def get_safe_beacon_block_root(store: Store) -&gt; Root:\n    # Use most recent justified block as a stopgap\n    return store.justified_checkpoint.root\n</code></pre> <p>Note: Currently safe block algorithm simply returns <code>store.justified_checkpoint.root</code> and is meant to be improved in the future.</p>"},{"location":"fork_choice/safe-block/#get_safe_execution_block_hash","title":"<code>get_safe_execution_block_hash</code>","text":"<pre><code>def get_safe_execution_block_hash(store: Store) -&gt; Hash32:\n    safe_block_root = get_safe_beacon_block_root(store)\n    safe_block = store.blocks[safe_block_root]\n\n    # Return Hash32() if no payload is yet justified\n    if compute_epoch_at_slot(safe_block.slot) &gt;= BELLATRIX_FORK_EPOCH:\n        return safe_block.body.execution_payload.block_hash\n    else:\n        return Hash32()\n</code></pre> <p>Note: This helper uses beacon block container extended in Bellatrix.</p>"},{"location":"light-client/","title":"Light client specifications","text":""},{"location":"specs/altair/","title":"Index","text":""},{"location":"specs/altair/#core","title":"Core","text":"<ul> <li>Beacon Chain</li> <li>BLS</li> <li>Fork</li> <li>P2P Interface</li> <li>Validator</li> </ul>"},{"location":"specs/altair/#light-client","title":"Light Client","text":"<ul> <li>Full Node</li> <li>Light Client</li> <li>P2P Interface</li> <li>Sync Protocol</li> </ul>"},{"location":"specs/altair/beacon-chain/","title":"Altair -- The Beacon Chain","text":"<ul> <li>Introduction</li> <li>Custom types</li> <li>Constants</li> <li>Participation flag indices</li> <li>Incentivization weights</li> <li>Domain types</li> <li>Misc</li> <li>Preset</li> <li>Rewards and penalties</li> <li>Sync committee</li> <li>Configuration</li> <li>Inactivity penalties</li> <li>Containers</li> <li>Modified containers<ul> <li><code>BeaconBlockBody</code></li> <li><code>BeaconState</code></li> </ul> </li> <li>New containers<ul> <li><code>SyncAggregate</code></li> <li><code>SyncCommittee</code></li> </ul> </li> <li>Helper functions</li> <li>Crypto</li> <li>Misc<ul> <li><code>add_flag</code></li> <li><code>has_flag</code></li> <li><code>get_index_for_new_validator</code></li> <li><code>set_or_append_list</code></li> </ul> </li> <li>Beacon state accessors<ul> <li><code>get_next_sync_committee_indices</code></li> <li><code>get_next_sync_committee</code></li> <li><code>get_base_reward_per_increment</code></li> <li><code>get_base_reward</code></li> <li><code>get_unslashed_participating_indices</code></li> <li><code>get_attestation_participation_flag_indices</code></li> <li><code>get_flag_index_deltas</code></li> <li>Modified <code>get_inactivity_penalty_deltas</code></li> </ul> </li> <li>Beacon state mutators<ul> <li>Modified <code>slash_validator</code></li> </ul> </li> <li>Block processing<ul> <li>Modified <code>process_attestation</code></li> <li>Modified <code>add_validator_to_registry</code></li> <li>Sync aggregate processing</li> </ul> </li> <li>Epoch processing<ul> <li>Justification and finalization</li> <li>Inactivity scores</li> <li>Rewards and penalties</li> <li>Slashings</li> <li>Participation flags updates</li> <li>Sync committee updates</li> </ul> </li> </ul>"},{"location":"specs/altair/beacon-chain/#introduction","title":"Introduction","text":"<p>Altair is the first beacon chain hard fork. Its main features are:</p> <ul> <li>sync committees to support light clients</li> <li>incentive accounting reforms to reduce spec complexity</li> <li>penalty parameter updates towards their planned maximally punitive values</li> </ul>"},{"location":"specs/altair/beacon-chain/#custom-types","title":"Custom types","text":"Name SSZ equivalent Description <code>ParticipationFlags</code> <code>uint8</code> a succinct representation of 8 boolean participation flags"},{"location":"specs/altair/beacon-chain/#constants","title":"Constants","text":""},{"location":"specs/altair/beacon-chain/#participation-flag-indices","title":"Participation flag indices","text":"Name Value <code>TIMELY_SOURCE_FLAG_INDEX</code> <code>0</code> <code>TIMELY_TARGET_FLAG_INDEX</code> <code>1</code> <code>TIMELY_HEAD_FLAG_INDEX</code> <code>2</code>"},{"location":"specs/altair/beacon-chain/#incentivization-weights","title":"Incentivization weights","text":"Name Value <code>TIMELY_SOURCE_WEIGHT</code> <code>uint64(14)</code> <code>TIMELY_TARGET_WEIGHT</code> <code>uint64(26)</code> <code>TIMELY_HEAD_WEIGHT</code> <code>uint64(14)</code> <code>SYNC_REWARD_WEIGHT</code> <code>uint64(2)</code> <code>PROPOSER_WEIGHT</code> <code>uint64(8)</code> <code>WEIGHT_DENOMINATOR</code> <code>uint64(64)</code> <p>Note: The sum of the weights equal <code>WEIGHT_DENOMINATOR</code>.</p>"},{"location":"specs/altair/beacon-chain/#domain-types","title":"Domain types","text":"Name Value <code>DOMAIN_SYNC_COMMITTEE</code> <code>DomainType('0x07000000')</code> <code>DOMAIN_SYNC_COMMITTEE_SELECTION_PROOF</code> <code>DomainType('0x08000000')</code> <code>DOMAIN_CONTRIBUTION_AND_PROOF</code> <code>DomainType('0x09000000')</code>"},{"location":"specs/altair/beacon-chain/#misc","title":"Misc","text":"Name Value <code>PARTICIPATION_FLAG_WEIGHTS</code> <code>[TIMELY_SOURCE_WEIGHT, TIMELY_TARGET_WEIGHT, TIMELY_HEAD_WEIGHT]</code>"},{"location":"specs/altair/beacon-chain/#preset","title":"Preset","text":""},{"location":"specs/altair/beacon-chain/#rewards-and-penalties","title":"Rewards and penalties","text":"<p>This patch updates a few configuration values to move penalty parameters closer to their final, maximum security values.</p> <p>Note: The spec does not override previous configuration values but instead creates new values and replaces usage throughout.</p> Name Value <code>INACTIVITY_PENALTY_QUOTIENT_ALTAIR</code> <code>uint64(3 * 2**24)</code> (= 50,331,648) <code>MIN_SLASHING_PENALTY_QUOTIENT_ALTAIR</code> <code>uint64(2**6)</code> (= 64) <code>PROPORTIONAL_SLASHING_MULTIPLIER_ALTAIR</code> <code>uint64(2)</code>"},{"location":"specs/altair/beacon-chain/#sync-committee","title":"Sync committee","text":"Name Value Unit Duration <code>SYNC_COMMITTEE_SIZE</code> <code>uint64(2**9)</code> (= 512) validators <code>EPOCHS_PER_SYNC_COMMITTEE_PERIOD</code> <code>uint64(2**8)</code> (= 256) epochs ~27 hours"},{"location":"specs/altair/beacon-chain/#configuration","title":"Configuration","text":""},{"location":"specs/altair/beacon-chain/#inactivity-penalties","title":"Inactivity penalties","text":"Name Value Description <code>INACTIVITY_SCORE_BIAS</code> <code>uint64(2**2)</code> (= 4) score points per inactive epoch <code>INACTIVITY_SCORE_RECOVERY_RATE</code> <code>uint64(2**4)</code> (= 16) score points per leak-free epoch"},{"location":"specs/altair/beacon-chain/#containers","title":"Containers","text":""},{"location":"specs/altair/beacon-chain/#modified-containers","title":"Modified containers","text":""},{"location":"specs/altair/beacon-chain/#beaconblockbody","title":"<code>BeaconBlockBody</code>","text":"<pre><code>class BeaconBlockBody(Container):\n    randao_reveal: BLSSignature\n    eth1_data: Eth1Data\n    graffiti: Bytes32\n    proposer_slashings: List[ProposerSlashing, MAX_PROPOSER_SLASHINGS]\n    attester_slashings: List[AttesterSlashing, MAX_ATTESTER_SLASHINGS]\n    attestations: List[Attestation, MAX_ATTESTATIONS]\n    deposits: List[Deposit, MAX_DEPOSITS]\n    voluntary_exits: List[SignedVoluntaryExit, MAX_VOLUNTARY_EXITS]\n    # [New in Altair]\n    sync_aggregate: SyncAggregate\n</code></pre>"},{"location":"specs/altair/beacon-chain/#beaconstate","title":"<code>BeaconState</code>","text":"<pre><code>class BeaconState(Container):\n    genesis_time: uint64\n    genesis_validators_root: Root\n    slot: Slot\n    fork: Fork\n    latest_block_header: BeaconBlockHeader\n    block_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    state_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    historical_roots: List[Root, HISTORICAL_ROOTS_LIMIT]\n    eth1_data: Eth1Data\n    eth1_data_votes: List[Eth1Data, EPOCHS_PER_ETH1_VOTING_PERIOD * SLOTS_PER_EPOCH]\n    eth1_deposit_index: uint64\n    validators: List[Validator, VALIDATOR_REGISTRY_LIMIT]\n    balances: List[Gwei, VALIDATOR_REGISTRY_LIMIT]\n    randao_mixes: Vector[Bytes32, EPOCHS_PER_HISTORICAL_VECTOR]\n    slashings: Vector[Gwei, EPOCHS_PER_SLASHINGS_VECTOR]\n    # [Modified in Altair]\n    previous_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    # [Modified in Altair]\n    current_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    justification_bits: Bitvector[JUSTIFICATION_BITS_LENGTH]\n    previous_justified_checkpoint: Checkpoint\n    current_justified_checkpoint: Checkpoint\n    finalized_checkpoint: Checkpoint\n    # [New in Altair]\n    inactivity_scores: List[uint64, VALIDATOR_REGISTRY_LIMIT]\n    # [New in Altair]\n    current_sync_committee: SyncCommittee\n    # [New in Altair]\n    next_sync_committee: SyncCommittee\n</code></pre>"},{"location":"specs/altair/beacon-chain/#new-containers","title":"New containers","text":""},{"location":"specs/altair/beacon-chain/#syncaggregate","title":"<code>SyncAggregate</code>","text":"<pre><code>class SyncAggregate(Container):\n    sync_committee_bits: Bitvector[SYNC_COMMITTEE_SIZE]\n    sync_committee_signature: BLSSignature\n</code></pre>"},{"location":"specs/altair/beacon-chain/#synccommittee","title":"<code>SyncCommittee</code>","text":"<pre><code>class SyncCommittee(Container):\n    pubkeys: Vector[BLSPubkey, SYNC_COMMITTEE_SIZE]\n    aggregate_pubkey: BLSPubkey\n</code></pre>"},{"location":"specs/altair/beacon-chain/#helper-functions","title":"Helper functions","text":""},{"location":"specs/altair/beacon-chain/#crypto","title":"Crypto","text":"<p>Refer to the definitions in the phase 0 document regarding BLS signatures and the extensions defined in the Altair BLS document. This specification assumes knowledge of the functionality described in those documents.</p>"},{"location":"specs/altair/beacon-chain/#misc_1","title":"Misc","text":""},{"location":"specs/altair/beacon-chain/#add_flag","title":"<code>add_flag</code>","text":"<pre><code>def add_flag(flags: ParticipationFlags, flag_index: int) -&gt; ParticipationFlags:\n    \"\"\"\n    Return a new ``ParticipationFlags`` adding ``flag_index`` to ``flags``.\n    \"\"\"\n    flag = ParticipationFlags(2**flag_index)\n    return flags | flag\n</code></pre>"},{"location":"specs/altair/beacon-chain/#has_flag","title":"<code>has_flag</code>","text":"<pre><code>def has_flag(flags: ParticipationFlags, flag_index: int) -&gt; bool:\n    \"\"\"\n    Return whether ``flags`` has ``flag_index`` set.\n    \"\"\"\n    flag = ParticipationFlags(2**flag_index)\n    return flags &amp; flag == flag\n</code></pre>"},{"location":"specs/altair/beacon-chain/#get_index_for_new_validator","title":"<code>get_index_for_new_validator</code>","text":"<pre><code>def get_index_for_new_validator(state: BeaconState) -&gt; ValidatorIndex:\n    return ValidatorIndex(len(state.validators))\n</code></pre>"},{"location":"specs/altair/beacon-chain/#set_or_append_list","title":"<code>set_or_append_list</code>","text":"<pre><code>def set_or_append_list(list: List, index: ValidatorIndex, value: Any) -&gt; None:\n    if index == len(list):\n        list.append(value)\n    else:\n        list[index] = value\n</code></pre>"},{"location":"specs/altair/beacon-chain/#beacon-state-accessors","title":"Beacon state accessors","text":""},{"location":"specs/altair/beacon-chain/#get_next_sync_committee_indices","title":"<code>get_next_sync_committee_indices</code>","text":"<pre><code>def get_next_sync_committee_indices(state: BeaconState) -&gt; Sequence[ValidatorIndex]:\n    \"\"\"\n    Return the sync committee indices, with possible duplicates, for the next sync committee.\n    \"\"\"\n    epoch = Epoch(get_current_epoch(state) + 1)\n\n    MAX_RANDOM_BYTE = 2**8 - 1\n    active_validator_indices = get_active_validator_indices(state, epoch)\n    active_validator_count = uint64(len(active_validator_indices))\n    seed = get_seed(state, epoch, DOMAIN_SYNC_COMMITTEE)\n    i = 0\n    sync_committee_indices: List[ValidatorIndex] = []\n    while len(sync_committee_indices) &lt; SYNC_COMMITTEE_SIZE:\n        shuffled_index = compute_shuffled_index(\n            uint64(i % active_validator_count), active_validator_count, seed\n        )\n        candidate_index = active_validator_indices[shuffled_index]\n        random_byte = hash(seed + uint_to_bytes(uint64(i // 32)))[i % 32]\n        effective_balance = state.validators[candidate_index].effective_balance\n        if effective_balance * MAX_RANDOM_BYTE &gt;= MAX_EFFECTIVE_BALANCE * random_byte:\n            sync_committee_indices.append(candidate_index)\n        i += 1\n    return sync_committee_indices\n</code></pre>"},{"location":"specs/altair/beacon-chain/#get_next_sync_committee","title":"<code>get_next_sync_committee</code>","text":"<p>Note: The function <code>get_next_sync_committee</code> should only be called at sync committee period boundaries and when upgrading state to Altair.</p> <pre><code>def get_next_sync_committee(state: BeaconState) -&gt; SyncCommittee:\n    \"\"\"\n    Return the next sync committee, with possible pubkey duplicates.\n    \"\"\"\n    indices = get_next_sync_committee_indices(state)\n    pubkeys = [state.validators[index].pubkey for index in indices]\n    aggregate_pubkey = eth_aggregate_pubkeys(pubkeys)\n    return SyncCommittee(pubkeys=pubkeys, aggregate_pubkey=aggregate_pubkey)\n</code></pre>"},{"location":"specs/altair/beacon-chain/#get_base_reward_per_increment","title":"<code>get_base_reward_per_increment</code>","text":"<pre><code>def get_base_reward_per_increment(state: BeaconState) -&gt; Gwei:\n    return Gwei(\n        EFFECTIVE_BALANCE_INCREMENT\n        * BASE_REWARD_FACTOR\n        // integer_squareroot(get_total_active_balance(state))\n    )\n</code></pre>"},{"location":"specs/altair/beacon-chain/#get_base_reward","title":"<code>get_base_reward</code>","text":"<p>Note: The function <code>get_base_reward</code> is modified with the removal of <code>BASE_REWARDS_PER_EPOCH</code> and the use of increment based accounting.</p> <p>Note: On average an optimally performing validator earns one base reward per epoch.</p> <pre><code>def get_base_reward(state: BeaconState, index: ValidatorIndex) -&gt; Gwei:\n    \"\"\"\n    Return the base reward for the validator defined by ``index`` with respect to the current ``state``.\n    \"\"\"\n    increments = state.validators[index].effective_balance // EFFECTIVE_BALANCE_INCREMENT\n    return Gwei(increments * get_base_reward_per_increment(state))\n</code></pre>"},{"location":"specs/altair/beacon-chain/#get_unslashed_participating_indices","title":"<code>get_unslashed_participating_indices</code>","text":"<pre><code>def get_unslashed_participating_indices(\n    state: BeaconState, flag_index: int, epoch: Epoch\n) -&gt; Set[ValidatorIndex]:\n    \"\"\"\n    Return the set of validator indices that are both active and unslashed for the given ``flag_index`` and ``epoch``.\n    \"\"\"\n    assert epoch in (get_previous_epoch(state), get_current_epoch(state))\n    if epoch == get_current_epoch(state):\n        epoch_participation = state.current_epoch_participation\n    else:\n        epoch_participation = state.previous_epoch_participation\n    active_validator_indices = get_active_validator_indices(state, epoch)\n    participating_indices = [\n        i for i in active_validator_indices if has_flag(epoch_participation[i], flag_index)\n    ]\n    return set(filter(lambda index: not state.validators[index].slashed, participating_indices))\n</code></pre>"},{"location":"specs/altair/beacon-chain/#get_attestation_participation_flag_indices","title":"<code>get_attestation_participation_flag_indices</code>","text":"<pre><code>def get_attestation_participation_flag_indices(\n    state: BeaconState, data: AttestationData, inclusion_delay: uint64\n) -&gt; Sequence[int]:\n    \"\"\"\n    Return the flag indices that are satisfied by an attestation.\n    \"\"\"\n    if data.target.epoch == get_current_epoch(state):\n        justified_checkpoint = state.current_justified_checkpoint\n    else:\n        justified_checkpoint = state.previous_justified_checkpoint\n\n    # Matching roots\n    is_matching_source = data.source == justified_checkpoint\n    is_matching_target = is_matching_source and data.target.root == get_block_root(\n        state, data.target.epoch\n    )\n    is_matching_head = is_matching_target and data.beacon_block_root == get_block_root_at_slot(\n        state, data.slot\n    )\n    assert is_matching_source\n\n    participation_flag_indices = []\n    if is_matching_source and inclusion_delay &lt;= integer_squareroot(SLOTS_PER_EPOCH):\n        participation_flag_indices.append(TIMELY_SOURCE_FLAG_INDEX)\n    if is_matching_target and inclusion_delay &lt;= SLOTS_PER_EPOCH:\n        participation_flag_indices.append(TIMELY_TARGET_FLAG_INDEX)\n    if is_matching_head and inclusion_delay == MIN_ATTESTATION_INCLUSION_DELAY:\n        participation_flag_indices.append(TIMELY_HEAD_FLAG_INDEX)\n\n    return participation_flag_indices\n</code></pre>"},{"location":"specs/altair/beacon-chain/#get_flag_index_deltas","title":"<code>get_flag_index_deltas</code>","text":"<pre><code>def get_flag_index_deltas(\n    state: BeaconState, flag_index: int\n) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:\n    \"\"\"\n    Return the deltas for a given ``flag_index`` by scanning through the participation flags.\n    \"\"\"\n    rewards = [Gwei(0)] * len(state.validators)\n    penalties = [Gwei(0)] * len(state.validators)\n    previous_epoch = get_previous_epoch(state)\n    unslashed_participating_indices = get_unslashed_participating_indices(\n        state, flag_index, previous_epoch\n    )\n    weight = PARTICIPATION_FLAG_WEIGHTS[flag_index]\n    unslashed_participating_balance = get_total_balance(state, unslashed_participating_indices)\n    unslashed_participating_increments = (\n        unslashed_participating_balance // EFFECTIVE_BALANCE_INCREMENT\n    )\n    active_increments = get_total_active_balance(state) // EFFECTIVE_BALANCE_INCREMENT\n    for index in get_eligible_validator_indices(state):\n        base_reward = get_base_reward(state, index)\n        if index in unslashed_participating_indices:\n            if not is_in_inactivity_leak(state):\n                reward_numerator = base_reward * weight * unslashed_participating_increments\n                rewards[index] += Gwei(reward_numerator // (active_increments * WEIGHT_DENOMINATOR))\n        elif flag_index != TIMELY_HEAD_FLAG_INDEX:\n            penalties[index] += Gwei(base_reward * weight // WEIGHT_DENOMINATOR)\n    return rewards, penalties\n</code></pre>"},{"location":"specs/altair/beacon-chain/#modified-get_inactivity_penalty_deltas","title":"Modified <code>get_inactivity_penalty_deltas</code>","text":"<pre><code>def get_inactivity_penalty_deltas(state: BeaconState) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:\n    \"\"\"\n    Return the inactivity penalty deltas by considering timely target participation flags and inactivity scores.\n    \"\"\"\n    rewards = [Gwei(0) for _ in range(len(state.validators))]\n    penalties = [Gwei(0) for _ in range(len(state.validators))]\n    previous_epoch = get_previous_epoch(state)\n    matching_target_indices = get_unslashed_participating_indices(\n        state, TIMELY_TARGET_FLAG_INDEX, previous_epoch\n    )\n    for index in get_eligible_validator_indices(state):\n        if index not in matching_target_indices:\n            penalty_numerator = (\n                state.validators[index].effective_balance * state.inactivity_scores[index]\n            )\n            penalty_denominator = INACTIVITY_SCORE_BIAS * INACTIVITY_PENALTY_QUOTIENT_ALTAIR\n            penalties[index] += Gwei(penalty_numerator // penalty_denominator)\n    return rewards, penalties\n</code></pre>"},{"location":"specs/altair/beacon-chain/#beacon-state-mutators","title":"Beacon state mutators","text":""},{"location":"specs/altair/beacon-chain/#modified-slash_validator","title":"Modified <code>slash_validator</code>","text":"<p>Note: The function <code>slash_validator</code> is modified to use <code>MIN_SLASHING_PENALTY_QUOTIENT_ALTAIR</code> and use <code>PROPOSER_WEIGHT</code> when calculating the proposer reward.</p> <pre><code>def slash_validator(\n    state: BeaconState, slashed_index: ValidatorIndex, whistleblower_index: ValidatorIndex = None\n) -&gt; None:\n    \"\"\"\n    Slash the validator with index ``slashed_index``.\n    \"\"\"\n    epoch = get_current_epoch(state)\n    initiate_validator_exit(state, slashed_index)\n    validator = state.validators[slashed_index]\n    validator.slashed = True\n    validator.withdrawable_epoch = max(\n        validator.withdrawable_epoch, Epoch(epoch + EPOCHS_PER_SLASHINGS_VECTOR)\n    )\n    state.slashings[epoch % EPOCHS_PER_SLASHINGS_VECTOR] += validator.effective_balance\n    decrease_balance(\n        state, slashed_index, validator.effective_balance // MIN_SLASHING_PENALTY_QUOTIENT_ALTAIR\n    )\n\n    # Apply proposer and whistleblower rewards\n    proposer_index = get_beacon_proposer_index(state)\n    if whistleblower_index is None:\n        whistleblower_index = proposer_index\n    whistleblower_reward = Gwei(validator.effective_balance // WHISTLEBLOWER_REWARD_QUOTIENT)\n    proposer_reward = Gwei(whistleblower_reward * PROPOSER_WEIGHT // WEIGHT_DENOMINATOR)\n    increase_balance(state, proposer_index, proposer_reward)\n    increase_balance(state, whistleblower_index, Gwei(whistleblower_reward - proposer_reward))\n</code></pre>"},{"location":"specs/altair/beacon-chain/#block-processing","title":"Block processing","text":"<pre><code>def process_block(state: BeaconState, block: BeaconBlock) -&gt; None:\n    process_block_header(state, block)\n    process_randao(state, block.body)\n    process_eth1_data(state, block.body)\n    # [Modified in Altair]\n    process_operations(state, block.body)\n    # [New in Altair]\n    process_sync_aggregate(state, block.body.sync_aggregate)\n</code></pre>"},{"location":"specs/altair/beacon-chain/#modified-process_attestation","title":"Modified <code>process_attestation</code>","text":"<p>Note: The function <code>process_attestation</code> is modified to do incentive accounting with epoch participation flags.</p> <pre><code>def process_attestation(state: BeaconState, attestation: Attestation) -&gt; None:\n    data = attestation.data\n    assert data.target.epoch in (get_previous_epoch(state), get_current_epoch(state))\n    assert data.target.epoch == compute_epoch_at_slot(data.slot)\n    assert data.slot + MIN_ATTESTATION_INCLUSION_DELAY &lt;= state.slot &lt;= data.slot + SLOTS_PER_EPOCH\n    assert data.index &lt; get_committee_count_per_slot(state, data.target.epoch)\n\n    committee = get_beacon_committee(state, data.slot, data.index)\n    assert len(attestation.aggregation_bits) == len(committee)\n\n    # Participation flag indices\n    participation_flag_indices = get_attestation_participation_flag_indices(\n        state, data, state.slot - data.slot\n    )\n\n    # Verify signature\n    assert is_valid_indexed_attestation(state, get_indexed_attestation(state, attestation))\n\n    # Update epoch participation flags\n    if data.target.epoch == get_current_epoch(state):\n        epoch_participation = state.current_epoch_participation\n    else:\n        epoch_participation = state.previous_epoch_participation\n\n    proposer_reward_numerator = 0\n    for index in get_attesting_indices(state, attestation):\n        for flag_index, weight in enumerate(PARTICIPATION_FLAG_WEIGHTS):\n            if flag_index in participation_flag_indices and not has_flag(\n                epoch_participation[index], flag_index\n            ):\n                epoch_participation[index] = add_flag(epoch_participation[index], flag_index)\n                proposer_reward_numerator += get_base_reward(state, index) * weight\n\n    # Reward proposer\n    proposer_reward_denominator = (\n        (WEIGHT_DENOMINATOR - PROPOSER_WEIGHT) * WEIGHT_DENOMINATOR // PROPOSER_WEIGHT\n    )\n    proposer_reward = Gwei(proposer_reward_numerator // proposer_reward_denominator)\n    increase_balance(state, get_beacon_proposer_index(state), proposer_reward)\n</code></pre>"},{"location":"specs/altair/beacon-chain/#modified-add_validator_to_registry","title":"Modified <code>add_validator_to_registry</code>","text":"<p>Note: The function <code>add_validator_to_registry</code> is modified to initialize <code>inactivity_scores</code>, <code>previous_epoch_participation</code>, and <code>current_epoch_participation</code>.</p> <pre><code>def add_validator_to_registry(\n    state: BeaconState, pubkey: BLSPubkey, withdrawal_credentials: Bytes32, amount: uint64\n) -&gt; None:\n    index = get_index_for_new_validator(state)\n    validator = get_validator_from_deposit(pubkey, withdrawal_credentials, amount)\n    set_or_append_list(state.validators, index, validator)\n    set_or_append_list(state.balances, index, amount)\n    # [New in Altair]\n    set_or_append_list(state.previous_epoch_participation, index, ParticipationFlags(0b0000_0000))\n    set_or_append_list(state.current_epoch_participation, index, ParticipationFlags(0b0000_0000))\n    set_or_append_list(state.inactivity_scores, index, uint64(0))\n</code></pre>"},{"location":"specs/altair/beacon-chain/#sync-aggregate-processing","title":"Sync aggregate processing","text":"<p>Note: The function <code>process_sync_aggregate</code> is new.</p> <pre><code>def process_sync_aggregate(state: BeaconState, sync_aggregate: SyncAggregate) -&gt; None:\n    # Verify sync committee aggregate signature signing over the previous slot block root\n    committee_pubkeys = state.current_sync_committee.pubkeys\n    participant_pubkeys = [\n        pubkey for pubkey, bit in zip(committee_pubkeys, sync_aggregate.sync_committee_bits) if bit\n    ]\n    previous_slot = max(state.slot, Slot(1)) - Slot(1)\n    domain = get_domain(state, DOMAIN_SYNC_COMMITTEE, compute_epoch_at_slot(previous_slot))\n    signing_root = compute_signing_root(get_block_root_at_slot(state, previous_slot), domain)\n    assert eth_fast_aggregate_verify(\n        participant_pubkeys, signing_root, sync_aggregate.sync_committee_signature\n    )\n\n    # Compute participant and proposer rewards\n    total_active_increments = get_total_active_balance(state) // EFFECTIVE_BALANCE_INCREMENT\n    total_base_rewards = Gwei(get_base_reward_per_increment(state) * total_active_increments)\n    max_participant_rewards = Gwei(\n        total_base_rewards * SYNC_REWARD_WEIGHT // WEIGHT_DENOMINATOR // SLOTS_PER_EPOCH\n    )\n    participant_reward = Gwei(max_participant_rewards // SYNC_COMMITTEE_SIZE)\n    proposer_reward = Gwei(\n        participant_reward * PROPOSER_WEIGHT // (WEIGHT_DENOMINATOR - PROPOSER_WEIGHT)\n    )\n\n    # Apply participant and proposer rewards\n    all_pubkeys = [v.pubkey for v in state.validators]\n    committee_indices = [\n        ValidatorIndex(all_pubkeys.index(pubkey)) for pubkey in state.current_sync_committee.pubkeys\n    ]\n    for participant_index, participation_bit in zip(\n        committee_indices, sync_aggregate.sync_committee_bits\n    ):\n        if participation_bit:\n            increase_balance(state, participant_index, participant_reward)\n            increase_balance(state, get_beacon_proposer_index(state), proposer_reward)\n        else:\n            decrease_balance(state, participant_index, participant_reward)\n</code></pre>"},{"location":"specs/altair/beacon-chain/#epoch-processing","title":"Epoch processing","text":"<pre><code>def process_epoch(state: BeaconState) -&gt; None:\n    # [Modified in Altair]\n    process_justification_and_finalization(state)\n    # [New in Altair]\n    process_inactivity_updates(state)\n    # [Modified in Altair]\n    process_rewards_and_penalties(state)\n    process_registry_updates(state)\n    # [Modified in Altair]\n    process_slashings(state)\n    process_eth1_data_reset(state)\n    process_effective_balance_updates(state)\n    process_slashings_reset(state)\n    process_randao_mixes_reset(state)\n    process_historical_roots_update(state)\n    # [New in Altair]\n    process_participation_flag_updates(state)\n    # [New in Altair]\n    process_sync_committee_updates(state)\n</code></pre>"},{"location":"specs/altair/beacon-chain/#justification-and-finalization","title":"Justification and finalization","text":"<p>Note: The function <code>process_justification_and_finalization</code> is modified to adapt to the new participation records.</p> <pre><code>def process_justification_and_finalization(state: BeaconState) -&gt; None:\n    # Initial FFG checkpoint values have a `0x00` stub for `root`.\n    # Skip FFG updates in the first two epochs to avoid corner cases that might result in modifying this stub.\n    if get_current_epoch(state) &lt;= GENESIS_EPOCH + 1:\n        return\n    previous_indices = get_unslashed_participating_indices(\n        state, TIMELY_TARGET_FLAG_INDEX, get_previous_epoch(state)\n    )\n    current_indices = get_unslashed_participating_indices(\n        state, TIMELY_TARGET_FLAG_INDEX, get_current_epoch(state)\n    )\n    total_active_balance = get_total_active_balance(state)\n    previous_target_balance = get_total_balance(state, previous_indices)\n    current_target_balance = get_total_balance(state, current_indices)\n    weigh_justification_and_finalization(\n        state, total_active_balance, previous_target_balance, current_target_balance\n    )\n</code></pre>"},{"location":"specs/altair/beacon-chain/#inactivity-scores","title":"Inactivity scores","text":"<p>Note: The function <code>process_inactivity_updates</code> is new.</p> <pre><code>def process_inactivity_updates(state: BeaconState) -&gt; None:\n    # Skip the genesis epoch as score updates are based on the previous epoch participation\n    if get_current_epoch(state) == GENESIS_EPOCH:\n        return\n\n    for index in get_eligible_validator_indices(state):\n        # Increase the inactivity score of inactive validators\n        if index in get_unslashed_participating_indices(\n            state, TIMELY_TARGET_FLAG_INDEX, get_previous_epoch(state)\n        ):\n            state.inactivity_scores[index] -= min(1, state.inactivity_scores[index])\n        else:\n            state.inactivity_scores[index] += INACTIVITY_SCORE_BIAS\n        # Decrease the inactivity score of all eligible validators during a leak-free epoch\n        if not is_in_inactivity_leak(state):\n            state.inactivity_scores[index] -= min(\n                INACTIVITY_SCORE_RECOVERY_RATE, state.inactivity_scores[index]\n            )\n</code></pre>"},{"location":"specs/altair/beacon-chain/#rewards-and-penalties_1","title":"Rewards and penalties","text":"<p>Note: The function <code>process_rewards_and_penalties</code> is modified to support the incentive accounting reforms.</p> <pre><code>def process_rewards_and_penalties(state: BeaconState) -&gt; None:\n    # No rewards are applied at the end of `GENESIS_EPOCH` because rewards are for work done in the previous epoch\n    if get_current_epoch(state) == GENESIS_EPOCH:\n        return\n\n    flag_deltas = [\n        get_flag_index_deltas(state, flag_index)\n        for flag_index in range(len(PARTICIPATION_FLAG_WEIGHTS))\n    ]\n    deltas = flag_deltas + [get_inactivity_penalty_deltas(state)]\n    for rewards, penalties in deltas:\n        for index in range(len(state.validators)):\n            increase_balance(state, ValidatorIndex(index), rewards[index])\n            decrease_balance(state, ValidatorIndex(index), penalties[index])\n</code></pre>"},{"location":"specs/altair/beacon-chain/#slashings","title":"Slashings","text":"<p>Note: The function <code>process_slashings</code> is modified to use <code>PROPORTIONAL_SLASHING_MULTIPLIER_ALTAIR</code>.</p> <pre><code>def process_slashings(state: BeaconState) -&gt; None:\n    epoch = get_current_epoch(state)\n    total_balance = get_total_active_balance(state)\n    adjusted_total_slashing_balance = min(\n        sum(state.slashings) * PROPORTIONAL_SLASHING_MULTIPLIER_ALTAIR, total_balance\n    )\n    for index, validator in enumerate(state.validators):\n        if (\n            validator.slashed\n            and epoch + EPOCHS_PER_SLASHINGS_VECTOR // 2 == validator.withdrawable_epoch\n        ):\n            increment = EFFECTIVE_BALANCE_INCREMENT  # Factored out from penalty numerator to avoid uint64 overflow\n            penalty_numerator = (\n                validator.effective_balance // increment * adjusted_total_slashing_balance\n            )\n            penalty = penalty_numerator // total_balance * increment\n            decrease_balance(state, ValidatorIndex(index), penalty)\n</code></pre>"},{"location":"specs/altair/beacon-chain/#participation-flags-updates","title":"Participation flags updates","text":"<p>Note: The function <code>process_participation_flag_updates</code> is new.</p> <pre><code>def process_participation_flag_updates(state: BeaconState) -&gt; None:\n    state.previous_epoch_participation = state.current_epoch_participation\n    state.current_epoch_participation = [\n        ParticipationFlags(0b0000_0000) for _ in range(len(state.validators))\n    ]\n</code></pre>"},{"location":"specs/altair/beacon-chain/#sync-committee-updates","title":"Sync committee updates","text":"<p>Note: The function <code>process_sync_committee_updates</code> is new.</p> <pre><code>def process_sync_committee_updates(state: BeaconState) -&gt; None:\n    next_epoch = get_current_epoch(state) + Epoch(1)\n    if next_epoch % EPOCHS_PER_SYNC_COMMITTEE_PERIOD == 0:\n        state.current_sync_committee = state.next_sync_committee\n        state.next_sync_committee = get_next_sync_committee(state)\n</code></pre>"},{"location":"specs/altair/bls/","title":"Altair -- BLS extensions","text":"<ul> <li>Introduction</li> <li>Constants</li> <li>Extensions</li> <li><code>eth_aggregate_pubkeys</code></li> <li><code>eth_fast_aggregate_verify</code></li> </ul>"},{"location":"specs/altair/bls/#introduction","title":"Introduction","text":"<p>A number of extensions are defined to handle BLS signatures in the Altair upgrade.</p> <p>Knowledge of the phase 0 specification is assumed, including type definitions.</p>"},{"location":"specs/altair/bls/#constants","title":"Constants","text":"Name Value <code>G2_POINT_AT_INFINITY</code> <code>BLSSignature(b'\\xc0' + b'\\x00' * 95)</code>"},{"location":"specs/altair/bls/#extensions","title":"Extensions","text":""},{"location":"specs/altair/bls/#eth_aggregate_pubkeys","title":"<code>eth_aggregate_pubkeys</code>","text":"<p>An additional function <code>AggregatePKs</code> is defined to extend the IETF BLS signature draft standard v4 spec referenced in the phase 0 document.</p> <pre><code>def eth_aggregate_pubkeys(pubkeys: Sequence[BLSPubkey]) -&gt; BLSPubkey:\n    \"\"\"\n    Return the aggregate public key for the public keys in ``pubkeys``.\n\n    Note: the ``+`` operation should be interpreted as elliptic curve point addition, which takes as input\n    elliptic curve points that must be decoded from the input ``BLSPubkey``s.\n    This implementation is for demonstrative purposes only and ignores encoding/decoding concerns.\n    Refer to the BLS signature draft standard for more information.\n    \"\"\"\n    assert len(pubkeys) &gt; 0\n    # Ensure that the given inputs are valid pubkeys\n    assert all(bls.KeyValidate(pubkey) for pubkey in pubkeys)\n\n    result = copy(pubkeys[0])\n    for pubkey in pubkeys[1:]:\n        result += pubkey\n    return result\n</code></pre>"},{"location":"specs/altair/bls/#eth_fast_aggregate_verify","title":"<code>eth_fast_aggregate_verify</code>","text":"<pre><code>def eth_fast_aggregate_verify(\n    pubkeys: Sequence[BLSPubkey], message: Bytes32, signature: BLSSignature\n) -&gt; bool:\n    \"\"\"\n    Wrapper to ``bls.FastAggregateVerify`` accepting the ``G2_POINT_AT_INFINITY`` signature when ``pubkeys`` is empty.\n    \"\"\"\n    if len(pubkeys) == 0 and signature == G2_POINT_AT_INFINITY:\n        return True\n    return bls.FastAggregateVerify(pubkeys, message, signature)\n</code></pre>"},{"location":"specs/altair/fork/","title":"Altair -- Fork Logic","text":"<ul> <li>Introduction</li> <li>Configuration</li> <li>Fork to Altair</li> <li>Fork trigger</li> <li>Upgrading the state</li> </ul>"},{"location":"specs/altair/fork/#introduction","title":"Introduction","text":"<p>This document describes the process of the first upgrade of the beacon chain: the Altair hard fork, introducing light client support and other improvements.</p>"},{"location":"specs/altair/fork/#configuration","title":"Configuration","text":"Name Value <code>ALTAIR_FORK_VERSION</code> <code>Version('0x01000000')</code> <code>ALTAIR_FORK_EPOCH</code> <code>Epoch(74240)</code> (Oct 27, 2021, 10:56:23am UTC)"},{"location":"specs/altair/fork/#fork-to-altair","title":"Fork to Altair","text":""},{"location":"specs/altair/fork/#fork-trigger","title":"Fork trigger","text":"<p>The fork is triggered at epoch <code>ALTAIR_FORK_EPOCH</code>.</p> <p>Note that for the pure Altair networks, we don't apply <code>upgrade_to_altair</code> since it starts with Altair version logic.</p>"},{"location":"specs/altair/fork/#upgrading-the-state","title":"Upgrading the state","text":"<p>If <code>state.slot % SLOTS_PER_EPOCH == 0</code> and <code>compute_epoch_at_slot(state.slot) == ALTAIR_FORK_EPOCH</code>, an irregular state change is made to upgrade to Altair.</p> <p>The upgrade occurs after the completion of the inner loop of <code>process_slots</code> that sets <code>state.slot</code> equal to <code>ALTAIR_FORK_EPOCH * SLOTS_PER_EPOCH</code>. Care must be taken when transitioning through the fork boundary as implementations will need a modified state transition function that deviates from the Phase 0 document. In particular, the outer <code>state_transition</code> function defined in the Phase 0 document will not expose the precise fork slot to execute the upgrade in the presence of skipped slots at the fork boundary. Instead the logic must be within <code>process_slots</code>.</p> <pre><code>def translate_participation(\n    state: BeaconState, pending_attestations: Sequence[phase0.PendingAttestation]\n) -&gt; None:\n    for attestation in pending_attestations:\n        data = attestation.data\n        inclusion_delay = attestation.inclusion_delay\n        # Translate attestation inclusion info to flag indices\n        participation_flag_indices = get_attestation_participation_flag_indices(\n            state, data, inclusion_delay\n        )\n\n        # Apply flags to all attesting validators\n        epoch_participation = state.previous_epoch_participation\n        for index in get_attesting_indices(state, attestation):\n            for flag_index in participation_flag_indices:\n                epoch_participation[index] = add_flag(epoch_participation[index], flag_index)\n\n\ndef upgrade_to_altair(pre: phase0.BeaconState) -&gt; BeaconState:\n    epoch = phase0.get_current_epoch(pre)\n    post = BeaconState(\n        genesis_time=pre.genesis_time,\n        genesis_validators_root=pre.genesis_validators_root,\n        slot=pre.slot,\n        fork=Fork(\n            previous_version=pre.fork.current_version,\n            current_version=ALTAIR_FORK_VERSION,\n            epoch=epoch,\n        ),\n        latest_block_header=pre.latest_block_header,\n        block_roots=pre.block_roots,\n        state_roots=pre.state_roots,\n        historical_roots=pre.historical_roots,\n        eth1_data=pre.eth1_data,\n        eth1_data_votes=pre.eth1_data_votes,\n        eth1_deposit_index=pre.eth1_deposit_index,\n        validators=pre.validators,\n        balances=pre.balances,\n        randao_mixes=pre.randao_mixes,\n        slashings=pre.slashings,\n        previous_epoch_participation=[\n            ParticipationFlags(0b0000_0000) for _ in range(len(pre.validators))\n        ],\n        current_epoch_participation=[\n            ParticipationFlags(0b0000_0000) for _ in range(len(pre.validators))\n        ],\n        justification_bits=pre.justification_bits,\n        previous_justified_checkpoint=pre.previous_justified_checkpoint,\n        current_justified_checkpoint=pre.current_justified_checkpoint,\n        finalized_checkpoint=pre.finalized_checkpoint,\n        inactivity_scores=[uint64(0) for _ in range(len(pre.validators))],\n    )\n    # Fill in previous epoch participation from the pre state's pending attestations\n    translate_participation(post, pre.previous_epoch_attestations)\n\n    # Fill in sync committees\n    # Note: A duplicate committee is assigned for the current and next committee at the fork boundary\n    post.current_sync_committee = get_next_sync_committee(post)\n    post.next_sync_committee = get_next_sync_committee(post)\n    return post\n</code></pre>"},{"location":"specs/altair/p2p-interface/","title":"Altair -- Networking","text":"<ul> <li>Introduction</li> <li>Modifications in Altair</li> <li>Modified <code>compute_fork_version</code></li> <li>MetaData</li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>beacon_block</code></li> <li><code>sync_committee_contribution_and_proof</code></li> </ul> </li> <li>Sync committee subnets<ul> <li><code>sync_committee_{subnet_id}</code></li> </ul> </li> <li>Sync committees and aggregation</li> <li>Transitioning the gossip</li> </ul> </li> <li>The Req/Resp domain<ul> <li>Req-Resp interaction</li> <li><code>ForkDigest</code>-context</li> <li>Messages</li> <li>BeaconBlocksByRange v2</li> <li>BeaconBlocksByRoot v2</li> <li>GetMetaData v2</li> <li>Transitioning from v1 to v2</li> </ul> </li> <li>The discovery domain: discv5<ul> <li>ENR structure</li> <li>Sync committee bitfield</li> </ul> </li> </ul>"},{"location":"specs/altair/p2p-interface/#introduction","title":"Introduction","text":"<p>This document contains the networking specification for Altair. This document should be viewed as additive to the document from Phase 0 and will be referred to as the \"Phase 0 document\" hereafter. Readers should understand the Phase 0 document and use it as a basis to understand the changes outlined in this document.</p> <p>Altair adds new messages, topics and data to the Req-Resp, Gossip and Discovery domain. Some Phase 0 features will be deprecated, but not removed immediately.</p>"},{"location":"specs/altair/p2p-interface/#modifications-in-altair","title":"Modifications in Altair","text":""},{"location":"specs/altair/p2p-interface/#modified-compute_fork_version","title":"Modified <code>compute_fork_version</code>","text":"<pre><code>def compute_fork_version(epoch: Epoch) -&gt; Version:\n    \"\"\"\n    Return the fork version at the given ``epoch``.\n    \"\"\"\n    if epoch &gt;= ALTAIR_FORK_EPOCH:\n        return ALTAIR_FORK_VERSION\n    return GENESIS_FORK_VERSION\n</code></pre>"},{"location":"specs/altair/p2p-interface/#metadata","title":"MetaData","text":"<p>The <code>MetaData</code> stored locally by clients is updated with an additional field to communicate the sync committee subnet subscriptions:</p> <pre><code>(\n  seq_number: uint64\n  attnets: Bitvector[ATTESTATION_SUBNET_COUNT]\n  syncnets: Bitvector[SYNC_COMMITTEE_SUBNET_COUNT]\n)\n</code></pre> <p>Where</p> <ul> <li><code>seq_number</code> and <code>attnets</code> have the same meaning defined in the Phase 0   document.</li> <li><code>syncnets</code> is a <code>Bitvector</code> representing the node's sync committee subnet   subscriptions. This field should mirror the data in the node's ENR as outlined   in the validator guide.</li> </ul>"},{"location":"specs/altair/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":"<p>Gossip meshes are added in Altair to support the consensus activities of the sync committees. Validators use an aggregation scheme to balance the processing and networking load across all of the relevant actors.</p>"},{"location":"specs/altair/p2p-interface/#topics-and-messages","title":"Topics and messages","text":"<p>Topics follow the same specification as in the Phase 0 document. New topics are added in Altair to support the sync committees and the beacon block topic is updated with the modified type.</p> <p>The specification around the creation, validation, and dissemination of messages has not changed from the Phase 0 document.</p> <p>The derivation of the <code>message-id</code> has changed starting with Altair to incorporate the message <code>topic</code> along with the message <code>data</code>. These are fields of the <code>Message</code> Protobuf, and interpreted as empty byte strings if missing. The <code>message-id</code> MUST be the following 20 byte value computed from the message:</p> <ul> <li>If <code>message.data</code> has a valid snappy decompression, set <code>message-id</code> to the   first 20 bytes of the <code>SHA256</code> hash of the concatenation of the following   data: <code>MESSAGE_DOMAIN_VALID_SNAPPY</code>, the length of the topic byte string   (encoded as little-endian <code>uint64</code>), the topic byte string, and the snappy   decompressed message data: i.e.   <code>SHA256(MESSAGE_DOMAIN_VALID_SNAPPY + uint_to_bytes(uint64(len(message.topic))) + message.topic + snappy_decompress(message.data))[:20]</code>.</li> <li>Otherwise, set <code>message-id</code> to the first 20 bytes of the <code>SHA256</code> hash of the   concatenation of the following data: <code>MESSAGE_DOMAIN_INVALID_SNAPPY</code>, the   length of the topic byte string (encoded as little-endian <code>uint64</code>), the topic   byte string, and the raw message data: i.e.   <code>SHA256(MESSAGE_DOMAIN_INVALID_SNAPPY + uint_to_bytes(uint64(len(message.topic))) + message.topic + message.data)[:20]</code>.</li> </ul> <p>Implementations may need to carefully handle the function that computes the <code>message-id</code>. In particular, messages on topics with the Phase 0 fork digest should use the <code>message-id</code> procedure specified in the Phase 0 document. Messages on topics with the Altair fork digest should use the <code>message-id</code> procedure defined here. If an implementation only supports a single <code>message-id</code> function, it can define a switch inline; for example, <code>if topic in phase0_topics: return phase0_msg_id_fn(message) else return altair_msg_id_fn(message)</code>.</p> <p>The new topics along with the type of the <code>data</code> field of a gossipsub message are given in this table:</p> Name Message Type <code>beacon_block</code> <code>SignedBeaconBlock</code> (modified) <code>sync_committee_contribution_and_proof</code> <code>SignedContributionAndProof</code> <code>sync_committee_{subnet_id}</code> <code>SyncCommitteeMessage</code> <p>Definitions of these new types can be found in the Altair validator guide.</p> <p>Note that the <code>ForkDigestValue</code> path segment of the topic separates the old and the new <code>beacon_block</code> topics.</p>"},{"location":"specs/altair/p2p-interface/#global-topics","title":"Global topics","text":"<p>Altair changes the type of the global beacon block topic and adds one global topic to propagate partially aggregated sync committee messages to all potential proposers of beacon blocks.</p>"},{"location":"specs/altair/p2p-interface/#beacon_block","title":"<code>beacon_block</code>","text":"<p>The existing specification for this topic does not change from the Phase 0 document, but the type of the payload does change to the (modified) <code>SignedBeaconBlock</code>. This type changes due to the inclusion of the inner <code>BeaconBlockBody</code> that is modified in Altair.</p> <p>See the state transition document for Altair for further details.</p>"},{"location":"specs/altair/p2p-interface/#sync_committee_contribution_and_proof","title":"<code>sync_committee_contribution_and_proof</code>","text":"<p>This topic is used to propagate partially aggregated sync committee messages to be included in future blocks.</p> <p>The following validations MUST pass before forwarding the <code>signed_contribution_and_proof</code> on the network; define <code>contribution_and_proof = signed_contribution_and_proof.message</code>, <code>contribution = contribution_and_proof.contribution</code>, and the following function <code>get_sync_subcommittee_pubkeys</code> for convenience:</p> <pre><code>def get_sync_subcommittee_pubkeys(\n    state: BeaconState, subcommittee_index: uint64\n) -&gt; Sequence[BLSPubkey]:\n    # Committees assigned to `slot` sign for `slot - 1`\n    # This creates the exceptional logic below when transitioning between sync committee periods\n    next_slot_epoch = compute_epoch_at_slot(Slot(state.slot + 1))\n    if compute_sync_committee_period(get_current_epoch(state)) == compute_sync_committee_period(\n        next_slot_epoch\n    ):\n        sync_committee = state.current_sync_committee\n    else:\n        sync_committee = state.next_sync_committee\n\n    # Return pubkeys for the subcommittee index\n    sync_subcommittee_size = SYNC_COMMITTEE_SIZE // SYNC_COMMITTEE_SUBNET_COUNT\n    i = subcommittee_index * sync_subcommittee_size\n    return sync_committee.pubkeys[i : i + sync_subcommittee_size]\n</code></pre> <ul> <li>[IGNORE] The contribution's slot is for the current slot (with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance), i.e.   <code>contribution.slot == current_slot</code>.</li> <li>[REJECT] The subcommittee index is in the allowed range, i.e.   <code>contribution.subcommittee_index &lt; SYNC_COMMITTEE_SUBNET_COUNT</code>.</li> <li>[REJECT] The contribution has participants -- that is,   <code>any(contribution.aggregation_bits)</code>.</li> <li>[REJECT] <code>contribution_and_proof.selection_proof</code> selects the validator as   an aggregator for the slot -- i.e.   <code>is_sync_committee_aggregator(contribution_and_proof.selection_proof)</code> returns   <code>True</code>.</li> <li>[REJECT] The aggregator's validator index is in the declared subcommittee of   the current sync committee -- i.e.   <code>state.validators[contribution_and_proof.aggregator_index].pubkey in get_sync_subcommittee_pubkeys(state, contribution.subcommittee_index)</code>.</li> <li>[IGNORE] A valid sync committee contribution with equal <code>slot</code>,   <code>beacon_block_root</code> and <code>subcommittee_index</code> whose <code>aggregation_bits</code> is   non-strict superset has not already been seen.</li> <li>[IGNORE] The sync committee contribution is the first valid contribution   received for the aggregator with index   <code>contribution_and_proof.aggregator_index</code> for the slot <code>contribution.slot</code> and   subcommittee index <code>contribution.subcommittee_index</code> (this requires   maintaining a cache of size <code>SYNC_COMMITTEE_SIZE</code> for this topic that can be   flushed after each slot).</li> <li>[REJECT] The <code>contribution_and_proof.selection_proof</code> is a valid signature   of the <code>SyncAggregatorSelectionData</code> derived from the <code>contribution</code> by the   validator with index <code>contribution_and_proof.aggregator_index</code>.</li> <li>[REJECT] The aggregator signature,   <code>signed_contribution_and_proof.signature</code>, is valid.</li> <li>[REJECT] The aggregate signature is valid for the message   <code>beacon_block_root</code> and aggregate pubkey derived from the participation info   in <code>aggregation_bits</code> for the subcommittee specified by the   <code>contribution.subcommittee_index</code>.</li> </ul>"},{"location":"specs/altair/p2p-interface/#sync-committee-subnets","title":"Sync committee subnets","text":"<p>Sync committee subnets are used to propagate unaggregated sync committee messages to subsections of the network.</p>"},{"location":"specs/altair/p2p-interface/#sync_committee_subnet_id","title":"<code>sync_committee_{subnet_id}</code>","text":"<p>The <code>sync_committee_{subnet_id}</code> topics are used to propagate unaggregated sync committee messages to the subnet <code>subnet_id</code> to be aggregated before being gossiped to the global <code>sync_committee_contribution_and_proof</code> topic.</p> <p>The following validations MUST pass before forwarding the <code>sync_committee_message</code> on the network:</p> <ul> <li>[IGNORE] The message's slot is for the current slot (with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance), i.e.   <code>sync_committee_message.slot == current_slot</code>.</li> <li>[REJECT] The <code>subnet_id</code> is valid for the given validator, i.e.   <code>subnet_id in compute_subnets_for_sync_committee(state, sync_committee_message.validator_index)</code>.   Note this validation implies the validator is part of the broader current sync   committee along with the correct subcommittee.</li> <li>[IGNORE] There has been no other valid sync committee message for the   declared <code>slot</code> for the validator referenced by   <code>sync_committee_message.validator_index</code> (this requires maintaining a cache of   size <code>SYNC_COMMITTEE_SIZE // SYNC_COMMITTEE_SUBNET_COUNT</code> for each subnet that   can be flushed after each slot). Note this validation is per topic so that   for a given <code>slot</code>, multiple messages could be forwarded with the same   <code>validator_index</code> as long as the <code>subnet_id</code>s are distinct.</li> <li>[REJECT] The <code>signature</code> is valid for the message <code>beacon_block_root</code> for   the validator referenced by <code>validator_index</code>.</li> </ul>"},{"location":"specs/altair/p2p-interface/#sync-committees-and-aggregation","title":"Sync committees and aggregation","text":"<p>The aggregation scheme closely follows the design of the attestation aggregation scheme. Sync committee messages are broadcast into \"subnets\" defined by a topic. The number of subnets is defined by <code>SYNC_COMMITTEE_SUBNET_COUNT</code> in the Altair validator guide. Sync committee members are divided into \"subcommittees\" which are then assigned to a subnet for the duration of tenure in the sync committee. Individual validators can be duplicated in the broader sync committee such that they are included multiple times in a given subcommittee or across multiple subcommittees.</p> <p>Unaggregated messages (along with metadata) are sent as <code>SyncCommitteeMessage</code>s on the <code>sync_committee_{subnet_id}</code> topics.</p> <p>Aggregated sync committee messages are packaged into (signed) <code>SyncCommitteeContribution</code> along with proofs and gossiped to the <code>sync_committee_contribution_and_proof</code> topic.</p>"},{"location":"specs/altair/p2p-interface/#transitioning-the-gossip","title":"Transitioning the gossip","text":"<p>With any fork, the fork version, and thus the <code>ForkDigestValue</code>, change. Message types are unique per topic, and so for a smooth transition a node must temporarily subscribe to both the old and new topics.</p> <p>The topics that are not removed in a fork are updated with a new <code>ForkDigestValue</code>. In advance of the fork, a node SHOULD subscribe to the post-fork variants of the topics.</p> <p>Subscriptions are expected to be well-received, all updated nodes should subscribe as well. Topic-meshes can be grafted quickly as the nodes are already connected and exchanging gossip control messages.</p> <p>Messages SHOULD NOT be re-broadcast from one fork to the other. A node's behavior before the fork and after the fork are as follows:</p> <p>Pre-fork:</p> <ul> <li>Peers who propagate messages on the post-fork topics MAY be scored negatively   proportionally to time till fork, to account for clock discrepancy.</li> <li>Messages can be IGNORED on the post-fork topics, with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> margin.</li> </ul> <p>Post-fork:</p> <ul> <li>Peers who propagate messages on the pre-fork topics MUST NOT be scored   negatively. Lagging IWANT may force them to.</li> <li>Messages on pre and post-fork variants of topics share application-level   caches. E.g. an attestation on the both the old and new topic is ignored like   any duplicate.</li> <li>Two epochs after the fork, pre-fork topics SHOULD be unsubscribed from. This   is well after the configured <code>seen_ttl</code>.</li> </ul>"},{"location":"specs/altair/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/altair/p2p-interface/#req-resp-interaction","title":"Req-Resp interaction","text":"<p>An additional <code>&lt;context-bytes&gt;</code> field is introduced to the <code>response_chunk</code> as defined in the Phase 0 document:</p> <pre><code>response_chunk  ::= &lt;result&gt; | &lt;context-bytes&gt; | &lt;encoding-dependent-header&gt; | &lt;encoded-payload&gt;\n</code></pre> <p>All Phase 0 methods are compatible: <code>&lt;context-bytes&gt;</code> is empty by default. On a non-zero <code>&lt;result&gt;</code> with <code>ErrorMessage</code> payload, the <code>&lt;context-bytes&gt;</code> is also empty.</p> <p>In Altair and later forks, <code>&lt;context-bytes&gt;</code> functions as a short meta-data, defined per req-resp method, and can parametrize the payload decoder.</p>"},{"location":"specs/altair/p2p-interface/#forkdigest-context","title":"<code>ForkDigest</code>-context","text":"<p>Starting with Altair, and in future forks, SSZ type definitions may change. For this common case, we define the <code>ForkDigest</code>-context:</p> <p>A fixed-width 4 byte <code>&lt;context-bytes&gt;</code>, set to the <code>ForkDigest</code> matching the chunk: <code>compute_fork_digest(genesis_validators_root, epoch)</code>.</p>"},{"location":"specs/altair/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/altair/p2p-interface/#beaconblocksbyrange-v2","title":"BeaconBlocksByRange v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_range/2/</code></p> <p>Request and Response remain unchanged. A <code>ForkDigest</code>-context is used to select the fork namespace of the Response type.</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(signed_beacon_block.message.slot)</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code>"},{"location":"specs/altair/p2p-interface/#beaconblocksbyroot-v2","title":"BeaconBlocksByRoot v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_root/2/</code></p> <p>Request and Response remain unchanged. A <code>ForkDigest</code>-context is used to select the fork namespace of the Response type.</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(signed_beacon_block.message.slot)</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code>"},{"location":"specs/altair/p2p-interface/#getmetadata-v2","title":"GetMetaData v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/metadata/2/</code></p> <p>No Request Content.</p> <p>Response Content:</p> <pre><code>(\n  MetaData\n)\n</code></pre> <p>Requests the MetaData of a peer, using the new <code>MetaData</code> definition given above that is extended from phase 0 in Altair. Other conditions for the <code>GetMetaData</code> protocol are unchanged from the phase 0 p2p networking document.</p>"},{"location":"specs/altair/p2p-interface/#transitioning-from-v1-to-v2","title":"Transitioning from v1 to v2","text":"<p>In advance of the fork, implementations can opt in to both run the v1 and v2 for a smooth transition. This is non-breaking, and is recommended as soon as the fork specification is stable.</p> <p>The v1 variants will be deprecated, and implementations should use v2 when available (as negotiated with peers via LibP2P multistream-select).</p> <p>The v1 method MAY be unregistered at the fork boundary. In the event of a request on v1 for an Altair specific payload, the responder MUST return the InvalidRequest response code.</p>"},{"location":"specs/altair/p2p-interface/#the-discovery-domain-discv5","title":"The discovery domain: discv5","text":""},{"location":"specs/altair/p2p-interface/#enr-structure","title":"ENR structure","text":""},{"location":"specs/altair/p2p-interface/#sync-committee-bitfield","title":"Sync committee bitfield","text":"<p>An additional bitfield is added to the ENR under the key <code>syncnets</code> to facilitate sync committee subnet discovery. The length of this bitfield is <code>SYNC_COMMITTEE_SUBNET_COUNT</code> where each bit corresponds to a distinct <code>subnet_id</code> for a specific sync committee subnet. The <code>i</code>th bit is set in this bitfield if the validator is currently subscribed to the <code>sync_committee_{i}</code> topic.</p> Key Value <code>syncnets</code> SSZ <code>Bitvector[SYNC_COMMITTEE_SUBNET_COUNT]</code> <p>See the validator document for further details on how the new bits are used.</p>"},{"location":"specs/altair/validator/","title":"Altair -- Honest Validator","text":"<p>This is an accompanying document to Altair -- The Beacon Chain, which describes the expected actions of a \"validator\" participating in the Ethereum proof-of-stake protocol.</p> <ul> <li>Introduction</li> <li>Prerequisites</li> <li>Constants</li> <li>Misc</li> <li>Configuration</li> <li>Time parameters</li> <li>Containers</li> <li><code>SyncCommitteeMessage</code></li> <li><code>SyncCommitteeContribution</code></li> <li><code>ContributionAndProof</code></li> <li><code>SignedContributionAndProof</code></li> <li><code>SyncAggregatorSelectionData</code></li> <li>Validator assignments</li> <li>Sync Committee</li> <li>Lookahead</li> <li>Beacon chain responsibilities</li> <li>Block proposal<ul> <li>Preparing a <code>BeaconBlock</code></li> <li>Constructing the <code>BeaconBlockBody</code></li> <li>Sync committee</li> <li>Packaging into a <code>SignedBeaconBlock</code></li> </ul> </li> <li>Attesting and attestation aggregation</li> <li>Sync committees<ul> <li>Sync committee messages</li> <li>Prepare sync committee message</li> <li>Broadcast sync committee message</li> <li>Sync committee contributions</li> <li>Aggregation selection</li> <li>Construct sync committee contribution<ul> <li>Slot</li> <li>Beacon block root</li> <li>Subcommittee index</li> <li>Aggregation bits</li> <li>Signature</li> </ul> </li> <li>Broadcast sync committee contribution</li> </ul> </li> <li>Sync committee subnet stability</li> </ul>"},{"location":"specs/altair/validator/#introduction","title":"Introduction","text":"<p>This document represents the expected behavior of an \"honest validator\" with respect to the Altair upgrade of the Ethereum proof-of-stake protocol. It builds on the previous document for the behavior of an \"honest validator\" from Phase 0 of the Ethereum proof-of-stake protocol. This previous document is referred to below as the \"Phase 0 document\".</p> <p>Altair introduces a new type of committee: the sync committee. Sync committees are responsible for signing each block of the canonical chain and there exists an efficient algorithm for light clients to sync the chain using the output of the sync committees. See the sync protocol for further details on the light client sync. Under this network upgrade, validators track their participation in this new committee type and produce the relevant signatures as required. Block proposers incorporate the (aggregated) sync committee signatures into each block they produce.</p>"},{"location":"specs/altair/validator/#prerequisites","title":"Prerequisites","text":"<p>All terminology, constants, functions, and protocol mechanics defined in the Altair -- The Beacon Chain doc are requisite for this document and used throughout. Please see this document before continuing and use as a reference throughout.</p>"},{"location":"specs/altair/validator/#constants","title":"Constants","text":""},{"location":"specs/altair/validator/#misc","title":"Misc","text":"Name Value Unit <code>TARGET_AGGREGATORS_PER_SYNC_SUBCOMMITTEE</code> <code>2**4</code> (= 16) validators <code>SYNC_COMMITTEE_SUBNET_COUNT</code> <code>4</code> The number of sync committee subnets used in the gossipsub aggregation protocol."},{"location":"specs/altair/validator/#configuration","title":"Configuration","text":""},{"location":"specs/altair/validator/#time-parameters","title":"Time parameters","text":"Name Value Unit Duration <code>SYNC_MESSAGE_DUE_BPS</code> <code>uint64(3333)</code> basis points ~33% of <code>SLOT_DURATION_MS</code> <code>CONTRIBUTION_DUE_BPS</code> <code>uint64(6667)</code> basis points ~67% of <code>SLOT_DURATION_MS</code>"},{"location":"specs/altair/validator/#containers","title":"Containers","text":""},{"location":"specs/altair/validator/#synccommitteemessage","title":"<code>SyncCommitteeMessage</code>","text":"<pre><code>class SyncCommitteeMessage(Container):\n    slot: Slot\n    beacon_block_root: Root\n    validator_index: ValidatorIndex\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/altair/validator/#synccommitteecontribution","title":"<code>SyncCommitteeContribution</code>","text":"<pre><code>class SyncCommitteeContribution(Container):\n    slot: Slot\n    beacon_block_root: Root\n    subcommittee_index: uint64\n    aggregation_bits: Bitvector[SYNC_COMMITTEE_SIZE // SYNC_COMMITTEE_SUBNET_COUNT]\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/altair/validator/#contributionandproof","title":"<code>ContributionAndProof</code>","text":"<pre><code>class ContributionAndProof(Container):\n    aggregator_index: ValidatorIndex\n    contribution: SyncCommitteeContribution\n    selection_proof: BLSSignature\n</code></pre>"},{"location":"specs/altair/validator/#signedcontributionandproof","title":"<code>SignedContributionAndProof</code>","text":"<pre><code>class SignedContributionAndProof(Container):\n    message: ContributionAndProof\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/altair/validator/#syncaggregatorselectiondata","title":"<code>SyncAggregatorSelectionData</code>","text":"<pre><code>class SyncAggregatorSelectionData(Container):\n    slot: Slot\n    subcommittee_index: uint64\n</code></pre>"},{"location":"specs/altair/validator/#validator-assignments","title":"Validator assignments","text":"<p>A validator determines beacon committee assignments and beacon block proposal duties as defined in the Phase 0 document.</p>"},{"location":"specs/altair/validator/#sync-committee","title":"Sync Committee","text":"<p>To determine sync committee assignments, a validator can run the following function: <code>is_assigned_to_sync_committee(state, epoch, validator_index)</code> where <code>epoch</code> is an epoch number within the current or next sync committee period. This function is a predicate indicating the presence or absence of the validator in the corresponding sync committee for the queried sync committee period.</p> <p>Note: Being assigned to a sync committee for a given <code>slot</code> means that the validator produces and broadcasts signatures for <code>slot - 1</code> for inclusion in <code>slot</code>. This means that when assigned to an <code>epoch</code> sync committee signatures must be produced and broadcast for slots on range <code>[compute_start_slot_at_epoch(epoch) - 1, compute_start_slot_at_epoch(epoch) + SLOTS_PER_EPOCH - 1)</code> rather than for the range <code>[compute_start_slot_at_epoch(epoch), compute_start_slot_at_epoch(epoch) + SLOTS_PER_EPOCH)</code>. To reduce complexity during the Altair fork, sync committees are not expected to produce signatures for <code>compute_start_slot_at_epoch(ALTAIR_FORK_EPOCH) - 1</code>.</p> <pre><code>def compute_sync_committee_period(epoch: Epoch) -&gt; uint64:\n    return epoch // EPOCHS_PER_SYNC_COMMITTEE_PERIOD\n</code></pre> <pre><code>def is_assigned_to_sync_committee(\n    state: BeaconState, epoch: Epoch, validator_index: ValidatorIndex\n) -&gt; bool:\n    sync_committee_period = compute_sync_committee_period(epoch)\n    current_epoch = get_current_epoch(state)\n    current_sync_committee_period = compute_sync_committee_period(current_epoch)\n    next_sync_committee_period = current_sync_committee_period + 1\n    assert sync_committee_period in (current_sync_committee_period, next_sync_committee_period)\n\n    pubkey = state.validators[validator_index].pubkey\n    if sync_committee_period == current_sync_committee_period:\n        return pubkey in state.current_sync_committee.pubkeys\n    else:  # sync_committee_period == next_sync_committee_period\n        return pubkey in state.next_sync_committee.pubkeys\n</code></pre>"},{"location":"specs/altair/validator/#lookahead","title":"Lookahead","text":"<p>The sync committee shufflings give validators 1 sync committee period of lookahead which amounts to <code>EPOCHS_PER_SYNC_COMMITTEE_PERIOD</code> epochs. At any given <code>epoch</code>, the <code>BeaconState</code> contains the current <code>SyncCommittee</code> and the next <code>SyncCommittee</code>. Once every <code>EPOCHS_PER_SYNC_COMMITTEE_PERIOD</code> epochs, the next <code>SyncCommittee</code> becomes the current <code>SyncCommittee</code> and the next committee is computed and stored.</p> <p>Note: The data required to compute a given committee is not cached in the <code>BeaconState</code> after committees are calculated at the period boundaries. For this reason, always get committee assignments via the fields of the <code>BeaconState</code> (<code>current_sync_committee</code> and <code>next_sync_committee</code>) or use the above reference code.</p> <p>A validator should plan for future sync committee assignments by noting which sync committee periods they are selected for participation. Specifically, a validator should:</p> <ul> <li>Upon (re)syncing the chain and upon sync committee period boundaries, check   for assignments in the current and next sync committee periods.</li> <li>If the validator is in the current sync committee period, then they perform   the responsibilities below for sync committee rewards.</li> <li>If the validator is in the next sync committee period, they should wait until   the next <code>EPOCHS_PER_SYNC_COMMITTEE_PERIOD</code> boundary and then perform the   responsibilities throughout that period.</li> </ul>"},{"location":"specs/altair/validator/#beacon-chain-responsibilities","title":"Beacon chain responsibilities","text":"<p>A validator maintains the responsibilities given in the Phase 0 document.</p> <p>Block proposals are modified to incorporate the sync committee signatures as detailed below.</p> <p>When assigned to a sync committee, validators have a new responsibility to sign and broadcast beacon block roots during each slot of the sync committee period. These signatures are aggregated and routed to the proposer over gossip for inclusion into a beacon block. Assignments to a particular sync committee are infrequent at normal validator counts; however, an action every slot is required when in the current active sync committee.</p>"},{"location":"specs/altair/validator/#block-proposal","title":"Block proposal","text":"<p>Refer to the phase 0 document for the majority of the block proposal responsibility. The validator should follow those instructions to prepare a <code>SignedBeaconBlock</code> for inclusion into the chain. All changes are additive to phase 0 and noted below.</p>"},{"location":"specs/altair/validator/#preparing-a-beaconblock","title":"Preparing a <code>BeaconBlock</code>","text":"<p>No change to Preparing for a <code>BeaconBlock</code>.</p>"},{"location":"specs/altair/validator/#constructing-the-beaconblockbody","title":"Constructing the <code>BeaconBlockBody</code>","text":"<p>Each section of Constructing the <code>BeaconBlockBody</code> should be followed. After constructing the <code>BeaconBlockBody</code> as per that section, the proposer has an additional task to include the sync committee signatures:</p>"},{"location":"specs/altair/validator/#sync-committee_1","title":"Sync committee","text":"<p>The proposer receives a number of <code>SyncCommitteeContribution</code>s (wrapped in <code>SignedContributionAndProof</code>s on the wire) from validators in the sync committee who are selected to partially aggregate signatures from independent subcommittees formed by breaking the full sync committee into <code>SYNC_COMMITTEE_SUBNET_COUNT</code> pieces (see below for details).</p> <p>The proposer collects the contributions that match their local view of the chain (i.e. <code>contribution.beacon_block_root == block.parent_root</code>) for further aggregation when preparing a block. Of these contributions, proposers should select the best contribution seen across all aggregators for each subnet/subcommittee. A contribution with more valid signatures is better than a contribution with fewer signatures.</p> <p>Recall <code>block.body.sync_aggregate.sync_committee_bits</code> is a <code>Bitvector</code> where the <code>i</code>th bit is <code>True</code> if the corresponding validator in the sync committee has produced a valid signature, and that <code>block.body.sync_aggregate.sync_committee_signature</code> is the aggregate BLS signature combining all of the valid signatures.</p> <p>Given a collection of the best seen <code>contributions</code> (with no repeating <code>subcommittee_index</code> values) and the <code>BeaconBlock</code> under construction, the proposer processes them as follows:</p> <pre><code>def process_sync_committee_contributions(\n    block: BeaconBlock, contributions: Set[SyncCommitteeContribution]\n) -&gt; None:\n    sync_aggregate = SyncAggregate()\n    signatures = []\n    sync_subcommittee_size = SYNC_COMMITTEE_SIZE // SYNC_COMMITTEE_SUBNET_COUNT\n\n    for contribution in contributions:\n        subcommittee_index = contribution.subcommittee_index\n        for index, participated in enumerate(contribution.aggregation_bits):\n            if participated:\n                participant_index = sync_subcommittee_size * subcommittee_index + index\n                sync_aggregate.sync_committee_bits[participant_index] = True\n        signatures.append(contribution.signature)\n\n    sync_aggregate.sync_committee_signature = bls.Aggregate(signatures)\n\n    block.body.sync_aggregate = sync_aggregate\n</code></pre> <p>Note: The resulting block must pass the validations for the <code>SyncAggregate</code> defined in <code>process_sync_aggregate</code> defined in the state transition document. In particular, this means <code>SyncCommitteeContribution</code>s received from gossip must have a <code>beacon_block_root</code> that matches the proposer's local view of the chain.</p>"},{"location":"specs/altair/validator/#packaging-into-a-signedbeaconblock","title":"Packaging into a <code>SignedBeaconBlock</code>","text":"<p>No change to Packaging into a <code>SignedBeaconBlock</code>.</p>"},{"location":"specs/altair/validator/#attesting-and-attestation-aggregation","title":"Attesting and attestation aggregation","text":"<p>Refer to the phase 0 document for the attesting and attestation aggregation responsibilities. There is no change compared to the phase 0 document.</p>"},{"location":"specs/altair/validator/#sync-committees","title":"Sync committees","text":"<p>Sync committee members employ an aggregation scheme to reduce load on the global proposer channel that is monitored by all potential proposers to be able to include the full output of the sync committee every slot. Sync committee members produce individual signatures on subnets (similar to the attestation subnets) via <code>SyncCommitteeMessage</code>s which are then collected by aggregators sampled from the sync subcommittees to produce a <code>SyncCommitteeContribution</code> which is gossiped to proposers. This process occurs each slot.</p>"},{"location":"specs/altair/validator/#sync-committee-messages","title":"Sync committee messages","text":""},{"location":"specs/altair/validator/#prepare-sync-committee-message","title":"Prepare sync committee message","text":"<p>If a validator is in the current sync committee (i.e. <code>is_assigned_to_sync_committee()</code> above returns <code>True</code>), then for every <code>slot</code> in the current sync committee period, the validator should prepare a <code>SyncCommitteeMessage</code> for the previous slot (<code>slot - 1</code>) according to the logic in <code>get_sync_committee_message</code> as soon as they have determined the head block of <code>slot - 1</code>. This means that when assigned to <code>slot</code> a <code>SyncCommitteeMessage</code> is prepared and broadcast in <code>slot-1</code> instead of <code>slot</code>.</p> <p>This logic is triggered upon the same conditions as when producing an attestation. Meaning, a sync committee member should produce and broadcast a <code>SyncCommitteeMessage</code> either when (a) the validator has received a valid block from the expected block proposer for the current <code>slot</code> or (b) <code>get_slot_component_duration_ms(SYNC_MESSAGE_DUE_BPS)</code> milliseconds has transpired since the start of the slot -- whichever comes first.</p> <p><code>get_sync_committee_message(state, block_root, validator_index, privkey)</code> assumes the parameter <code>state</code> is the head state corresponding to processing the block up to the current slot as determined by the fork choice (including any empty slots up to the current slot processed with <code>process_slots</code> on top of the latest block), <code>block_root</code> is the root of the head block, <code>validator_index</code> is the index of the validator in the registry <code>state.validators</code> controlled by <code>privkey</code>, and <code>privkey</code> is the BLS private key for the validator.</p> <pre><code>def get_sync_committee_message(\n    state: BeaconState, block_root: Root, validator_index: ValidatorIndex, privkey: int\n) -&gt; SyncCommitteeMessage:\n    epoch = get_current_epoch(state)\n    domain = get_domain(state, DOMAIN_SYNC_COMMITTEE, epoch)\n    signing_root = compute_signing_root(block_root, domain)\n    signature = bls.Sign(privkey, signing_root)\n\n    return SyncCommitteeMessage(\n        slot=state.slot,\n        beacon_block_root=block_root,\n        validator_index=validator_index,\n        signature=signature,\n    )\n</code></pre>"},{"location":"specs/altair/validator/#broadcast-sync-committee-message","title":"Broadcast sync committee message","text":"<p>The validator broadcasts the assembled signature to the assigned subnet, the <code>sync_committee_{subnet_id}</code> pubsub topic.</p> <p>The <code>subnet_id</code> is derived from the position in the sync committee such that the sync committee is divided into \"subcommittees\". <code>subnet_id</code> can be computed via <code>compute_subnets_for_sync_committee(state, validator_index)</code> where <code>state</code> is a <code>BeaconState</code> during the matching sync committee period.</p> <p>Note: This function returns multiple deduplicated subnets if a given validator index is included multiple times in a given sync committee across multiple subcommittees.</p> <pre><code>def compute_subnets_for_sync_committee(\n    state: BeaconState, validator_index: ValidatorIndex\n) -&gt; Set[SubnetID]:\n    next_slot_epoch = compute_epoch_at_slot(Slot(state.slot + 1))\n    if compute_sync_committee_period(get_current_epoch(state)) == compute_sync_committee_period(\n        next_slot_epoch\n    ):\n        sync_committee = state.current_sync_committee\n    else:\n        sync_committee = state.next_sync_committee\n\n    target_pubkey = state.validators[validator_index].pubkey\n    sync_committee_indices = [\n        index for index, pubkey in enumerate(sync_committee.pubkeys) if pubkey == target_pubkey\n    ]\n    return set(\n        [\n            SubnetID(index // (SYNC_COMMITTEE_SIZE // SYNC_COMMITTEE_SUBNET_COUNT))\n            for index in sync_committee_indices\n        ]\n    )\n</code></pre> <p>Note: Subnet assignment does not change during the duration of a validator's assignment to a given sync committee.</p> <p>Note: If a validator has multiple <code>subnet_id</code> results from <code>compute_subnets_for_sync_committee</code>, the validator should broadcast a copy of the <code>sync_committee_message</code> on each of the distinct subnets.</p>"},{"location":"specs/altair/validator/#sync-committee-contributions","title":"Sync committee contributions","text":"<p>Each slot, some sync committee members in each subcommittee are selected to aggregate the <code>SyncCommitteeMessage</code>s into a <code>SyncCommitteeContribution</code> which is broadcast on a global channel for inclusion into the next block.</p>"},{"location":"specs/altair/validator/#aggregation-selection","title":"Aggregation selection","text":"<p>A validator is selected to aggregate based on the value returned by <code>is_sync_committee_aggregator()</code> where <code>signature</code> is the BLS signature returned by <code>get_sync_committee_selection_proof()</code>. The signature function takes a <code>BeaconState</code> with the relevant sync committees for the queried <code>slot</code> (i.e. <code>state.slot</code> is within the span covered by the current or next sync committee period), the <code>subcommittee_index</code> equal to the <code>subnet_id</code>, and the <code>privkey</code> is the BLS private key associated with the validator.</p> <pre><code>def get_sync_committee_selection_proof(\n    state: BeaconState, slot: Slot, subcommittee_index: uint64, privkey: int\n) -&gt; BLSSignature:\n    domain = get_domain(state, DOMAIN_SYNC_COMMITTEE_SELECTION_PROOF, compute_epoch_at_slot(slot))\n    signing_data = SyncAggregatorSelectionData(\n        slot=slot,\n        subcommittee_index=subcommittee_index,\n    )\n    signing_root = compute_signing_root(signing_data, domain)\n    return bls.Sign(privkey, signing_root)\n</code></pre> <pre><code>def is_sync_committee_aggregator(signature: BLSSignature) -&gt; bool:\n    modulo = max(\n        1,\n        SYNC_COMMITTEE_SIZE\n        // SYNC_COMMITTEE_SUBNET_COUNT\n        // TARGET_AGGREGATORS_PER_SYNC_SUBCOMMITTEE,\n    )\n    return bytes_to_uint64(hash(signature)[0:8]) % modulo == 0\n</code></pre> <p>Note: The set of aggregators generally changes every slot; however, the assignments can be computed ahead of time as soon as the committee is known.</p>"},{"location":"specs/altair/validator/#construct-sync-committee-contribution","title":"Construct sync committee contribution","text":"<p>If a validator is selected to aggregate the <code>SyncCommitteeMessage</code>s produced on a subnet during a given <code>slot</code>, they construct an aggregated <code>SyncCommitteeContribution</code>.</p> <p>Collect all of the (valid) <code>sync_committee_messages: Set[SyncCommitteeMessage]</code> from the <code>sync_committee_{subnet_id}</code> gossip during the selected <code>slot</code> with an equivalent <code>beacon_block_root</code> to that of the aggregator. If <code>len(sync_committee_messages) &gt; 0</code>, the aggregator creates a <code>contribution: SyncCommitteeContribution</code> with the following fields:</p>"},{"location":"specs/altair/validator/#slot","title":"Slot","text":"<p>Set <code>contribution.slot = state.slot</code> where <code>state</code> is the <code>BeaconState</code> for the slot in question.</p>"},{"location":"specs/altair/validator/#beacon-block-root","title":"Beacon block root","text":"<p>Set <code>contribution.beacon_block_root = beacon_block_root</code> from the <code>beacon_block_root</code> found in the <code>sync_committee_messages</code>.</p>"},{"location":"specs/altair/validator/#subcommittee-index","title":"Subcommittee index","text":"<p>Set <code>contribution.subcommittee_index</code> to the index for the subcommittee index corresponding to the subcommittee assigned to this subnet. This index matches the <code>subnet_id</code> used to derive the topic name.</p>"},{"location":"specs/altair/validator/#aggregation-bits","title":"Aggregation bits","text":"<p>Let <code>contribution.aggregation_bits</code> be a <code>Bitvector[SYNC_COMMITTEE_SIZE // SYNC_COMMITTEE_SUBNET_COUNT]</code>, where the <code>index</code>th bit is set in the <code>Bitvector</code> for each corresponding validator included in this aggregate from the corresponding subcommittee. An aggregator finds the index in the sync committee (as determined by a reverse pubkey lookup on <code>state.current_sync_committee.pubkeys</code>) for a given validator referenced by <code>sync_committee_message.validator_index</code> and maps the sync committee index to an index in the subcommittee (along with the prior <code>subcommittee_index</code>). This index within the subcommittee is set in <code>contribution.aggregation_bits</code>.</p> <p>For example, if a validator with index <code>2044</code> is pseudo-randomly sampled to sync committee index <code>135</code>. This sync committee index maps to <code>subcommittee_index</code> <code>1</code> with position <code>7</code> in the <code>Bitvector</code> for the contribution.</p> <p>Note: A validator could be included multiple times in a given subcommittee such that multiple bits are set for a single <code>SyncCommitteeMessage</code>.</p>"},{"location":"specs/altair/validator/#signature","title":"Signature","text":"<p>Set <code>contribution.signature = aggregate_signature</code> where <code>aggregate_signature</code> is obtained by assembling the appropriate collection of <code>BLSSignature</code>s from the set of <code>sync_committee_messages</code> and using the <code>bls.Aggregate()</code> function to produce an aggregate <code>BLSSignature</code>.</p> <p>The collection of input signatures should include one signature per validator who had a bit set in the <code>aggregation_bits</code> bitfield, with repeated signatures if one validator maps to multiple indices within the subcommittee.</p>"},{"location":"specs/altair/validator/#broadcast-sync-committee-contribution","title":"Broadcast sync committee contribution","text":"<p>If the validator is selected to aggregate (<code>is_sync_committee_aggregator()</code>), then they broadcast their best aggregate as a <code>SignedContributionAndProof</code> to the global aggregate channel (<code>sync_committee_contribution_and_proof</code> topic) <code>get_slot_component_duration_ms(CONTRIBUTION_DUE_BPS)</code> milliseconds into the slot.</p> <p>Selection proofs are provided in <code>ContributionAndProof</code> to prove to the gossip channel that the validator has been selected as an aggregator.</p> <p><code>ContributionAndProof</code> messages are signed by the aggregator and broadcast inside of <code>SignedContributionAndProof</code> objects to prevent a class of DoS attacks and message forgeries.</p> <p>First, <code>contribution_and_proof = get_contribution_and_proof(state, validator_index, contribution, privkey)</code> is constructed.</p> <pre><code>def get_contribution_and_proof(\n    state: BeaconState,\n    aggregator_index: ValidatorIndex,\n    contribution: SyncCommitteeContribution,\n    privkey: int,\n) -&gt; ContributionAndProof:\n    selection_proof = get_sync_committee_selection_proof(\n        state,\n        contribution.slot,\n        contribution.subcommittee_index,\n        privkey,\n    )\n    return ContributionAndProof(\n        aggregator_index=aggregator_index,\n        contribution=contribution,\n        selection_proof=selection_proof,\n    )\n</code></pre> <p>Then <code>signed_contribution_and_proof = SignedContributionAndProof(message=contribution_and_proof, signature=signature)</code> is constructed and broadcast. Where <code>signature</code> is obtained from:</p> <pre><code>def get_contribution_and_proof_signature(\n    state: BeaconState, contribution_and_proof: ContributionAndProof, privkey: int\n) -&gt; BLSSignature:\n    contribution = contribution_and_proof.contribution\n    domain = get_domain(\n        state, DOMAIN_CONTRIBUTION_AND_PROOF, compute_epoch_at_slot(contribution.slot)\n    )\n    signing_root = compute_signing_root(contribution_and_proof, domain)\n    return bls.Sign(privkey, signing_root)\n</code></pre>"},{"location":"specs/altair/validator/#sync-committee-subnet-stability","title":"Sync committee subnet stability","text":"<p>The sync committee subnets need special care to ensure stability given the relatively low number of validators involved in the sync committee at any particular time. To provide this stability, a validator must do the following:</p> <ul> <li>Maintain advertisement of the subnet the validator in the sync committee is   assigned to in their node's ENR as soon as they have joined the subnet. Subnet   assignments are known <code>EPOCHS_PER_SYNC_COMMITTEE_PERIOD</code> epochs in advance and   can be computed with <code>compute_subnets_for_sync_committee</code> defined above. ENR   advertisement is indicated by setting the appropriate bit(s) of the bitfield   found under the <code>syncnets</code> key in the ENR corresponding to the derived   <code>subnet_id</code>(s). Any bits modified for the sync committee responsibilities are   unset in the ENR once the node no longer has any validators in the   subcommittee.</li> </ul> <p>Note: The first sync committee from phase 0 to the Altair fork will not be   known until the fork happens, which implies subnet assignments are not known   until then. Early sync committee members should listen for topic subscriptions   from peers and employ discovery via the ENR advertisements near the fork   boundary to form initial subnets. Some early sync committee rewards may be   missed while the initial subnets form.</p> <ul> <li>To join a sync committee subnet, select a random number of epochs before the   end of the current sync committee period between 1 and   <code>SYNC_COMMITTEE_SUBNET_COUNT</code>, inclusive. Validators should join their member   subnet at the beginning of the epoch they have randomly selected. For example,   if the next sync committee period starts at epoch <code>853,248</code> and the validator   randomly selects an offset of <code>3</code>, they should join the subnet at the   beginning of epoch <code>853,245</code>. Validators should leverage the lookahead period   on sync committee assignments so that they can join the appropriate subnets   ahead of their assigned sync committee period.</li> </ul>"},{"location":"specs/altair/light-client/full-node/","title":"Altair Light Client -- Full Node","text":"<ul> <li>Introduction</li> <li>Helper functions</li> <li><code>compute_merkle_proof</code></li> <li><code>block_to_light_client_header</code></li> <li>Deriving light client data</li> <li><code>create_light_client_bootstrap</code></li> <li><code>create_light_client_update</code></li> <li><code>create_light_client_finality_update</code></li> <li><code>create_light_client_optimistic_update</code></li> </ul>"},{"location":"specs/altair/light-client/full-node/#introduction","title":"Introduction","text":"<p>This document provides helper functions to enable full nodes to serve light client data. Full nodes SHOULD implement the described functionality to enable light clients to sync with the network.</p>"},{"location":"specs/altair/light-client/full-node/#helper-functions","title":"Helper functions","text":""},{"location":"specs/altair/light-client/full-node/#compute_merkle_proof","title":"<code>compute_merkle_proof</code>","text":"<p>This function return the Merkle proof of the given SSZ object <code>object</code> at generalized index <code>index</code>.</p> <pre><code>def compute_merkle_proof(object: SSZObject, index: GeneralizedIndex) -&gt; Sequence[Bytes32]: ...\n</code></pre>"},{"location":"specs/altair/light-client/full-node/#block_to_light_client_header","title":"<code>block_to_light_client_header</code>","text":"<pre><code>def block_to_light_client_header(block: SignedBeaconBlock) -&gt; LightClientHeader:\n    return LightClientHeader(\n        beacon=BeaconBlockHeader(\n            slot=block.message.slot,\n            proposer_index=block.message.proposer_index,\n            parent_root=block.message.parent_root,\n            state_root=block.message.state_root,\n            body_root=hash_tree_root(block.message.body),\n        ),\n    )\n</code></pre>"},{"location":"specs/altair/light-client/full-node/#deriving-light-client-data","title":"Deriving light client data","text":"<p>Full nodes are expected to derive light client data from historic blocks and states and provide it to other clients.</p>"},{"location":"specs/altair/light-client/full-node/#create_light_client_bootstrap","title":"<code>create_light_client_bootstrap</code>","text":"<p>To form a <code>LightClientBootstrap</code>, the following objects are needed:</p> <ul> <li><code>state</code>: the post state of any post-Altair block</li> <li><code>block</code>: the corresponding block</li> </ul> <pre><code>def create_light_client_bootstrap(\n    state: BeaconState, block: SignedBeaconBlock\n) -&gt; LightClientBootstrap:\n    assert compute_epoch_at_slot(state.slot) &gt;= ALTAIR_FORK_EPOCH\n\n    assert state.slot == state.latest_block_header.slot\n    header = state.latest_block_header.copy()\n    header.state_root = hash_tree_root(state)\n    assert hash_tree_root(header) == hash_tree_root(block.message)\n\n    return LightClientBootstrap(\n        header=block_to_light_client_header(block),\n        current_sync_committee=state.current_sync_committee,\n        current_sync_committee_branch=CurrentSyncCommitteeBranch(\n            compute_merkle_proof(state, current_sync_committee_gindex_at_slot(state.slot))\n        ),\n    )\n</code></pre> <p>Full nodes SHOULD provide <code>LightClientBootstrap</code> for all finalized epoch boundary blocks in the epoch range <code>[max(ALTAIR_FORK_EPOCH, current_epoch - MIN_EPOCHS_FOR_BLOCK_REQUESTS), current_epoch]</code> where <code>current_epoch</code> is defined by the current wall-clock time. Full nodes MAY also provide <code>LightClientBootstrap</code> for other blocks.</p> <p>Blocks are considered to be epoch boundary blocks if their block root can occur as part of a valid <code>Checkpoint</code>, i.e., if their slot is the initial slot of an epoch, or if all following slots through the initial slot of the next epoch are empty (no block proposed / orphaned).</p> <p><code>LightClientBootstrap</code> is computed from the block's immediate post state (without applying empty slots).</p>"},{"location":"specs/altair/light-client/full-node/#create_light_client_update","title":"<code>create_light_client_update</code>","text":"<p>To form a <code>LightClientUpdate</code>, the following historical states and blocks are needed:</p> <ul> <li><code>state</code>: the post state of any block with a post-Altair parent block</li> <li><code>block</code>: the corresponding block</li> <li><code>attested_state</code>: the post state of <code>attested_block</code></li> <li><code>attested_block</code>: the block referred to by <code>block.parent_root</code></li> <li><code>finalized_block</code>: the block referred to by   <code>attested_state.finalized_checkpoint.root</code>, if locally available (may be   unavailable, e.g., when using checkpoint sync, or if it was pruned locally)</li> </ul> <pre><code>def create_light_client_update(\n    state: BeaconState,\n    block: SignedBeaconBlock,\n    attested_state: BeaconState,\n    attested_block: SignedBeaconBlock,\n    finalized_block: Optional[SignedBeaconBlock],\n) -&gt; LightClientUpdate:\n    assert compute_epoch_at_slot(attested_state.slot) &gt;= ALTAIR_FORK_EPOCH\n    assert (\n        sum(block.message.body.sync_aggregate.sync_committee_bits)\n        &gt;= MIN_SYNC_COMMITTEE_PARTICIPANTS\n    )\n\n    assert state.slot == state.latest_block_header.slot\n    header = state.latest_block_header.copy()\n    header.state_root = hash_tree_root(state)\n    assert hash_tree_root(header) == hash_tree_root(block.message)\n    update_signature_period = compute_sync_committee_period_at_slot(block.message.slot)\n\n    assert attested_state.slot == attested_state.latest_block_header.slot\n    attested_header = attested_state.latest_block_header.copy()\n    attested_header.state_root = hash_tree_root(attested_state)\n    assert (\n        hash_tree_root(attested_header)\n        == hash_tree_root(attested_block.message)\n        == block.message.parent_root\n    )\n    update_attested_period = compute_sync_committee_period_at_slot(attested_block.message.slot)\n\n    update = LightClientUpdate()\n\n    update.attested_header = block_to_light_client_header(attested_block)\n\n    # `next_sync_committee` is only useful if the message is signed by the current sync committee\n    if update_attested_period == update_signature_period:\n        update.next_sync_committee = attested_state.next_sync_committee\n        update.next_sync_committee_branch = NextSyncCommitteeBranch(\n            compute_merkle_proof(\n                attested_state, next_sync_committee_gindex_at_slot(attested_state.slot)\n            )\n        )\n\n    # Indicate finality whenever possible\n    if finalized_block is not None:\n        if finalized_block.message.slot != GENESIS_SLOT:\n            update.finalized_header = block_to_light_client_header(finalized_block)\n            assert (\n                hash_tree_root(update.finalized_header.beacon)\n                == attested_state.finalized_checkpoint.root\n            )\n        else:\n            assert attested_state.finalized_checkpoint.root == Bytes32()\n        update.finality_branch = FinalityBranch(\n            compute_merkle_proof(attested_state, finalized_root_gindex_at_slot(attested_state.slot))\n        )\n\n    update.sync_aggregate = block.message.body.sync_aggregate\n    update.signature_slot = block.message.slot\n\n    return update\n</code></pre> <p>Full nodes SHOULD provide the best derivable <code>LightClientUpdate</code> (according to <code>is_better_update</code>) for each sync committee period covering any epochs in range <code>[max(ALTAIR_FORK_EPOCH, current_epoch - MIN_EPOCHS_FOR_BLOCK_REQUESTS), current_epoch]</code> where <code>current_epoch</code> is defined by the current wall-clock time. Full nodes MAY also provide <code>LightClientUpdate</code> for other sync committee periods.</p> <ul> <li><code>LightClientUpdate</code> are assigned to sync committee periods based on their   <code>attested_header.beacon.slot</code></li> <li><code>LightClientUpdate</code> are only considered if   <code>compute_sync_committee_period_at_slot(update.attested_header.beacon.slot) == compute_sync_committee_period_at_slot(update.signature_slot)</code></li> <li>Only <code>LightClientUpdate</code> with <code>sync_aggregate</code> from blocks on the canonical   chain as selected by fork choice are considered, regardless of ranking by   <code>is_better_update</code>. <code>LightClientUpdate</code> referring to orphaned blocks SHOULD   NOT be provided.</li> </ul>"},{"location":"specs/altair/light-client/full-node/#create_light_client_finality_update","title":"<code>create_light_client_finality_update</code>","text":"<pre><code>def create_light_client_finality_update(update: LightClientUpdate) -&gt; LightClientFinalityUpdate:\n    return LightClientFinalityUpdate(\n        attested_header=update.attested_header,\n        finalized_header=update.finalized_header,\n        finality_branch=update.finality_branch,\n        sync_aggregate=update.sync_aggregate,\n        signature_slot=update.signature_slot,\n    )\n</code></pre> <p>Full nodes SHOULD provide the <code>LightClientFinalityUpdate</code> with the highest <code>attested_header.beacon.slot</code> (if multiple, highest <code>signature_slot</code>) as selected by fork choice, and SHOULD support a push mechanism to deliver new <code>LightClientFinalityUpdate</code> whenever <code>finalized_header</code> changes. If that <code>LightClientFinalityUpdate</code> does not have supermajority (&gt; 2/3) sync committee participation, a second <code>LightClientFinalityUpdate</code> SHOULD be delivered for the same <code>finalized_header</code> once supermajority participation is obtained.</p>"},{"location":"specs/altair/light-client/full-node/#create_light_client_optimistic_update","title":"<code>create_light_client_optimistic_update</code>","text":"<pre><code>def create_light_client_optimistic_update(update: LightClientUpdate) -&gt; LightClientOptimisticUpdate:\n    return LightClientOptimisticUpdate(\n        attested_header=update.attested_header,\n        sync_aggregate=update.sync_aggregate,\n        signature_slot=update.signature_slot,\n    )\n</code></pre> <p>Full nodes SHOULD provide the <code>LightClientOptimisticUpdate</code> with the highest <code>attested_header.beacon.slot</code> (if multiple, highest <code>signature_slot</code>) as selected by fork choice, and SHOULD support a push mechanism to deliver new <code>LightClientOptimisticUpdate</code> whenever <code>attested_header</code> changes.</p>"},{"location":"specs/altair/light-client/light-client/","title":"Altair Light Client -- Light Client","text":"<ul> <li>Introduction</li> <li>Light client sync process</li> </ul>"},{"location":"specs/altair/light-client/light-client/#introduction","title":"Introduction","text":"<p>This document explains how light clients MAY obtain light client data to sync with the network.</p>"},{"location":"specs/altair/light-client/light-client/#light-client-sync-process","title":"Light client sync process","text":"<ol> <li>The light client MUST be configured out-of-band with a spec/preset (including    fork schedule), with <code>genesis_state</code> (including <code>genesis_time</code> and    <code>genesis_validators_root</code>), and with a trusted block root. The trusted block    SHOULD be within the weak subjectivity period, and its root SHOULD be from a    finalized <code>Checkpoint</code>.</li> <li>The local clock is initialized based on the configured <code>genesis_time</code>, and    the current fork digest is determined to browse for and connect to relevant    light client data providers.</li> <li>The light client fetches a    <code>LightClientBootstrap</code> object for    the configured trusted block root. The <code>bootstrap</code> object is passed to    <code>initialize_light_client_store</code>    to obtain a local <code>LightClientStore</code>.</li> <li>The light client tracks the sync committee periods <code>finalized_period</code> from    <code>store.finalized_header.beacon.slot</code>, <code>optimistic_period</code> from    <code>store.optimistic_header.beacon.slot</code>, and <code>current_period</code> from    <code>current_slot</code> based on the local clock.</li> <li>When <code>finalized_period == optimistic_period</code> and       <code>is_next_sync_committee_known</code>       indicates <code>False</code>, the light client fetches a       <code>LightClientUpdate</code> for       <code>finalized_period</code>. If <code>finalized_period == current_period</code>, this fetch       SHOULD be scheduled at a random time before <code>current_period</code> advances.</li> <li>When <code>finalized_period + 1 &lt; current_period</code>, the light client fetches a       <code>LightClientUpdate</code> for each sync committee period in range       <code>[finalized_period + 1, current_period)</code> (current period excluded)</li> <li>When <code>finalized_period + 1 &gt;= current_period</code>, the light client keeps       observing       <code>LightClientFinalityUpdate</code>       and       <code>LightClientOptimisticUpdate</code>.       Received objects are passed to       <code>process_light_client_finality_update</code>       and       <code>process_light_client_optimistic_update</code>.       This ensures that <code>finalized_header</code> and <code>optimistic_header</code> reflect the       latest blocks.</li> <li><code>process_light_client_store_force_update</code>    MAY be called based on use case dependent heuristics if light client sync    appears stuck. If available, falling back to an alternative syncing mechanism    to cover the affected sync committee period is preferred.</li> </ol>"},{"location":"specs/altair/light-client/p2p-interface/","title":"Altair Light Client -- Networking","text":"<ul> <li>Networking</li> <li>Configuration</li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>light_client_finality_update</code></li> <li><code>light_client_optimistic_update</code></li> </ul> </li> </ul> </li> <li>The Req/Resp domain<ul> <li>Messages</li> <li>GetLightClientBootstrap</li> <li>LightClientUpdatesByRange</li> <li>GetLightClientFinalityUpdate</li> <li>GetLightClientOptimisticUpdate</li> </ul> </li> <li>Light clients</li> <li>Validator assignments</li> <li>Beacon chain responsibilities</li> <li>Sync committee</li> </ul>"},{"location":"specs/altair/light-client/p2p-interface/#networking","title":"Networking","text":"<p>This section extends the networking specification for Altair with additional messages, topics and data to the Req-Resp and Gossip domains.</p>"},{"location":"specs/altair/light-client/p2p-interface/#configuration","title":"Configuration","text":"Name Value Description <code>MAX_REQUEST_LIGHT_CLIENT_UPDATES</code> <code>2**7</code> (= 128) Maximum number of <code>LightClientUpdate</code> instances in a single request"},{"location":"specs/altair/light-client/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":"<p>Gossip meshes are added to allow light clients to stay in sync with the network.</p>"},{"location":"specs/altair/light-client/p2p-interface/#topics-and-messages","title":"Topics and messages","text":"<p>New global topics are added to provide light clients with the latest updates.</p> name Message Type <code>light_client_finality_update</code> <code>LightClientFinalityUpdate</code> <code>light_client_optimistic_update</code> <code>LightClientOptimisticUpdate</code>"},{"location":"specs/altair/light-client/p2p-interface/#global-topics","title":"Global topics","text":""},{"location":"specs/altair/light-client/p2p-interface/#light_client_finality_update","title":"<code>light_client_finality_update</code>","text":"<p>This topic is used to propagate the latest <code>LightClientFinalityUpdate</code> to light clients, allowing them to keep track of the latest <code>finalized_header</code>.</p> <p>The following validations MUST pass before forwarding the <code>finality_update</code> on the network.</p> <ul> <li>[IGNORE] The <code>finalized_header.beacon.slot</code> is greater than that of all   previously forwarded <code>finality_update</code>s, or it matches the highest previously   forwarded slot and also has a <code>sync_aggregate</code> indicating supermajority (&gt;   2/3) sync committee participation while the previously forwarded   <code>finality_update</code> for that slot did not indicate supermajority</li> <li>[IGNORE] The <code>finality_update</code> is received after the block at   <code>signature_slot</code> was given enough time to propagate through the network --   i.e. validatate that <code>get_slot_component_duration_ms(SYNC_MESSAGE_DUE_BPS)</code>   milliseconds (with a <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) has   transpired since the start of <code>signature_slot</code>.</li> </ul> <p>For full nodes, the following validations MUST additionally pass before forwarding the <code>finality_update</code> on the network.</p> <ul> <li>[IGNORE] The received <code>finality_update</code> matches the locally computed one   exactly (as defined in   <code>create_light_client_finality_update</code>)</li> </ul> <p>For light clients, the following validations MUST additionally pass before forwarding the <code>finality_update</code> on the network.</p> <ul> <li>[REJECT] The <code>finality_update</code> is valid -- i.e. validate that   <code>process_light_client_finality_update</code> does not indicate errors</li> <li>[IGNORE] The <code>finality_update</code> advances the <code>finalized_header</code> of the local   <code>LightClientStore</code> -- i.e. validate that processing <code>finality_update</code>   increases <code>store.finalized_header.beacon.slot</code></li> </ul> <p>Light clients SHOULD call <code>process_light_client_finality_update</code> even if the message is ignored.</p> <p>The <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(finality_update.attested_header.beacon.slot)</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Message SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> and later <code>altair.LightClientFinalityUpdate</code>"},{"location":"specs/altair/light-client/p2p-interface/#light_client_optimistic_update","title":"<code>light_client_optimistic_update</code>","text":"<p>This topic is used to propagate the latest <code>LightClientOptimisticUpdate</code> to light clients, allowing them to keep track of the latest <code>optimistic_header</code>.</p> <p>The following validations MUST pass before forwarding the <code>optimistic_update</code> on the network.</p> <ul> <li>[IGNORE] The <code>attested_header.beacon.slot</code> is greater than that of all   previously forwarded <code>optimistic_update</code>s</li> <li>[IGNORE] The <code>optimistic_update</code> is received after the block at   <code>signature_slot</code> was given enough time to propagate through the network --   i.e. validatate that <code>get_slot_component_duration_ms(SYNC_MESSAGE_DUE_BPS)</code>   milliseconds (with a <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) has   transpired since the start of <code>optimistic_update.signature_slot</code>.</li> </ul> <p>For full nodes, the following validations MUST additionally pass before forwarding the <code>optimistic_update</code> on the network.</p> <ul> <li>[IGNORE] The received <code>optimistic_update</code> matches the locally computed one   exactly (as defined in   <code>create_light_client_optimistic_update</code>)</li> </ul> <p>For light clients, the following validations MUST additionally pass before forwarding the <code>optimistic_update</code> on the network.</p> <ul> <li>[REJECT] The <code>optimistic_update</code> is valid -- i.e. validate that   <code>process_light_client_optimistic_update</code> does not indicate errors</li> <li>[IGNORE] The <code>optimistic_update</code> either matches corresponding fields of the   most recently forwarded <code>LightClientFinalityUpdate</code> (if any), or it advances   the <code>optimistic_header</code> of the local <code>LightClientStore</code> -- i.e. validate that   processing <code>optimistic_update</code> increases <code>store.optimistic_header.beacon.slot</code></li> </ul> <p>Light clients SHOULD call <code>process_light_client_optimistic_update</code> even if the message is ignored.</p> <p>The <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(optimistic_update.attested_header.beacon.slot)</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Message SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> and later <code>altair.LightClientOptimisticUpdate</code>"},{"location":"specs/altair/light-client/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/altair/light-client/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/altair/light-client/p2p-interface/#getlightclientbootstrap","title":"GetLightClientBootstrap","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/light_client_bootstrap/1/</code></p> <p>Request Content:</p> <pre><code>(\n  Root\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  LightClientBootstrap\n)\n</code></pre> <p>Requests the <code>LightClientBootstrap</code> structure corresponding to a given post-Altair beacon block root.</p> <p>The request MUST be encoded as an SSZ-field.</p> <p>Peers SHOULD provide results as defined in <code>create_light_client_bootstrap</code>. To fulfill a request, the requested block and its post state need to be known.</p> <p>When a <code>LightClientBootstrap</code> instance cannot be produced for a given block root, peers SHOULD respond with error code <code>3: ResourceUnavailable</code>.</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(bootstrap.header.beacon.slot)</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> and later <code>altair.LightClientBootstrap</code>"},{"location":"specs/altair/light-client/p2p-interface/#lightclientupdatesbyrange","title":"LightClientUpdatesByRange","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/light_client_updates_by_range/1/</code></p> <p>Request Content:</p> <pre><code>(\n  start_period: uint64\n  count: uint64\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[LightClientUpdate, MAX_REQUEST_LIGHT_CLIENT_UPDATES]\n)\n</code></pre> <p>Requests the <code>LightClientUpdate</code> instances in the sync committee period range <code>[start_period, start_period + count)</code>, leading up to the current head sync committee period as selected by fork choice.</p> <p>The request MUST be encoded as an SSZ-container.</p> <p>The response MUST consist of zero or more <code>response_chunk</code>. Each successful <code>response_chunk</code> MUST contain a single <code>LightClientUpdate</code> payload.</p> <p>Peers SHOULD provide results as defined in <code>create_light_client_update</code>. They MUST respond with at least the earliest known result within the requested range, and MUST send results in consecutive order (by period). The response MUST NOT contain more than <code>min(MAX_REQUEST_LIGHT_CLIENT_UPDATES, count)</code> results.</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(update.attested_header.beacon.slot)</code>. Note that the context epoch may differ from the one used to verify the <code>update.sync_aggregate</code>, which is based on <code>update.signature_slot</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Response chunk SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> and later <code>altair.LightClientUpdate</code>"},{"location":"specs/altair/light-client/p2p-interface/#getlightclientfinalityupdate","title":"GetLightClientFinalityUpdate","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/light_client_finality_update/1/</code></p> <p>No Request Content.</p> <p>Response Content:</p> <pre><code>(\n  LightClientFinalityUpdate\n)\n</code></pre> <p>Requests the latest <code>LightClientFinalityUpdate</code> known by a peer.</p> <p>Peers SHOULD provide results as defined in <code>create_light_client_finality_update</code>.</p> <p>When no <code>LightClientFinalityUpdate</code> is available, peers SHOULD respond with error code <code>3: ResourceUnavailable</code>.</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(finality_update.attested_header.beacon.slot)</code>. Note that the context epoch may differ from the one used to verify the <code>finality_update.sync_aggregate</code>, which is based on <code>finality_update.signature_slot</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> and later <code>altair.LightClientFinalityUpdate</code>"},{"location":"specs/altair/light-client/p2p-interface/#getlightclientoptimisticupdate","title":"GetLightClientOptimisticUpdate","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/light_client_optimistic_update/1/</code></p> <p>No Request Content.</p> <p>Response Content:</p> <pre><code>(\n  LightClientOptimisticUpdate\n)\n</code></pre> <p>Requests the latest <code>LightClientOptimisticUpdate</code> known by a peer.</p> <p>Peers SHOULD provide results as defined in <code>create_light_client_optimistic_update</code>.</p> <p>When no <code>LightClientOptimisticUpdate</code> is available, peers SHOULD respond with error code <code>3: ResourceUnavailable</code>.</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(optimistic_update.attested_header.beacon.slot)</code>. Note that the context epoch may differ from the one used to verify the <code>optimistic_update.sync_aggregate</code>, which is based on <code>optimistic_update.signature_slot</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> and later <code>altair.LightClientOptimisticUpdate</code>"},{"location":"specs/altair/light-client/p2p-interface/#light-clients","title":"Light clients","text":"<p>Light clients using libp2p to stay in sync with the network SHOULD subscribe to the <code>light_client_finality_update</code> and <code>light_client_optimistic_update</code> pubsub topics and validate all received messages while the light client sync process supports processing <code>LightClientFinalityUpdate</code> and <code>LightClientOptimisticUpdate</code> structures.</p> <p>Light clients MAY also collect historic light client data and make it available to other peers. If they do, they SHOULD advertise supported message endpoints in the Req/Resp domain, and MAY also update the contents of their <code>Status</code> message to reflect the locally available light client data.</p> <p>If only limited light client data is locally available, the light client SHOULD use data based on <code>genesis_block</code> and <code>GENESIS_SLOT</code> in its <code>Status</code> message. Hybrid peers that also implement full node functionality MUST only incorporate data based on their full node sync progress into their <code>Status</code> message.</p>"},{"location":"specs/altair/light-client/p2p-interface/#validator-assignments","title":"Validator assignments","text":"<p>This section extends the honest validator specification with additional responsibilities to enable light clients to sync with the network.</p>"},{"location":"specs/altair/light-client/p2p-interface/#beacon-chain-responsibilities","title":"Beacon chain responsibilities","text":"<p>All full nodes SHOULD subscribe to and provide stability on the <code>light_client_finality_update</code> and <code>light_client_optimistic_update</code> pubsub topics by validating all received messages.</p>"},{"location":"specs/altair/light-client/p2p-interface/#sync-committee","title":"Sync committee","text":"<p>Whenever fork choice selects a new head block with a sync aggregate participation <code>&gt;= MIN_SYNC_COMMITTEE_PARTICIPANTS</code> and a post-Altair parent block, full nodes with at least one validator assigned to the current sync committee at the block's <code>slot</code> SHOULD broadcast derived light client data as follows:</p> <ul> <li>If <code>finalized_header.beacon.slot</code> increased, a <code>LightClientFinalityUpdate</code>   SHOULD be broadcasted to the pubsub topic <code>light_client_finality_update</code> if no   matching message has not yet been forwarded as part of gossip validation.</li> <li>If <code>attested_header.beacon.slot</code> increased, a <code>LightClientOptimisticUpdate</code>   SHOULD be broadcasted to the pubsub topic <code>light_client_optimistic_update</code> if   no matching message has not yet been forwarded as part of gossip validation.</li> </ul> <p>These messages SHOULD be broadcasted <code>get_slot_component_duration_ms(SYNC_MESSAGE_DUE_BPS)</code> milliseconds after the start of the slot. To ensure that the corresponding block was given enough time to propagate through the network, they SHOULD NOT be sent earlier. Note that this is different from how other messages are handled, e.g., attestations, which may be sent early.</p>"},{"location":"specs/altair/light-client/sync-protocol/","title":"Altair Light Client -- Sync Protocol","text":"<ul> <li>Introduction</li> <li>Custom types</li> <li>Constants</li> <li>Preset</li> <li>Misc</li> <li>Containers</li> <li><code>LightClientHeader</code></li> <li><code>LightClientBootstrap</code></li> <li><code>LightClientUpdate</code></li> <li><code>LightClientFinalityUpdate</code></li> <li><code>LightClientOptimisticUpdate</code></li> <li><code>LightClientStore</code></li> <li>Helper functions</li> <li><code>finalized_root_gindex_at_slot</code></li> <li><code>current_sync_committee_gindex_at_slot</code></li> <li><code>next_sync_committee_gindex_at_slot</code></li> <li><code>is_valid_light_client_header</code></li> <li><code>is_sync_committee_update</code></li> <li><code>is_finality_update</code></li> <li><code>is_better_update</code></li> <li><code>is_next_sync_committee_known</code></li> <li><code>get_safety_threshold</code></li> <li><code>get_subtree_index</code></li> <li><code>is_valid_normalized_merkle_branch</code></li> <li><code>compute_sync_committee_period_at_slot</code></li> <li>Light client initialization</li> <li><code>initialize_light_client_store</code></li> <li>Light client state updates</li> <li><code>validate_light_client_update</code></li> <li><code>apply_light_client_update</code></li> <li><code>process_light_client_store_force_update</code></li> <li><code>process_light_client_update</code></li> <li><code>process_light_client_finality_update</code></li> <li><code>process_light_client_optimistic_update</code></li> </ul>"},{"location":"specs/altair/light-client/sync-protocol/#introduction","title":"Introduction","text":"<p>The beacon chain is designed to be light client friendly for constrained environments to access Ethereum with reasonable safety and liveness. Such environments include resource-constrained devices (e.g. phones for trust-minimized wallets) and metered VMs (e.g. blockchain VMs for cross-chain bridges).</p> <p>This document suggests a minimal light client design for the beacon chain that uses sync committees introduced in this beacon chain extension.</p> <p>Additional documents describe how the light client sync protocol can be used:</p> <ul> <li>Full node</li> <li>Light client</li> <li>Networking</li> </ul>"},{"location":"specs/altair/light-client/sync-protocol/#custom-types","title":"Custom types","text":"Name SSZ equivalent Description <code>FinalityBranch</code> <code>Vector[Bytes32, floorlog2(FINALIZED_ROOT_GINDEX)]</code> Merkle branch of <code>finalized_checkpoint.root</code> within <code>BeaconState</code> <code>CurrentSyncCommitteeBranch</code> <code>Vector[Bytes32, floorlog2(CURRENT_SYNC_COMMITTEE_GINDEX)]</code> Merkle branch of <code>current_sync_committee</code> within <code>BeaconState</code> <code>NextSyncCommitteeBranch</code> <code>Vector[Bytes32, floorlog2(NEXT_SYNC_COMMITTEE_GINDEX)]</code> Merkle branch of <code>next_sync_committee</code> within <code>BeaconState</code>"},{"location":"specs/altair/light-client/sync-protocol/#constants","title":"Constants","text":"Name Value <code>FINALIZED_ROOT_GINDEX</code> <code>get_generalized_index(BeaconState, 'finalized_checkpoint', 'root')</code> (= 105) <code>CURRENT_SYNC_COMMITTEE_GINDEX</code> <code>get_generalized_index(BeaconState, 'current_sync_committee')</code> (= 54) <code>NEXT_SYNC_COMMITTEE_GINDEX</code> <code>get_generalized_index(BeaconState, 'next_sync_committee')</code> (= 55)"},{"location":"specs/altair/light-client/sync-protocol/#preset","title":"Preset","text":""},{"location":"specs/altair/light-client/sync-protocol/#misc","title":"Misc","text":"Name Value Unit Duration <code>MIN_SYNC_COMMITTEE_PARTICIPANTS</code> <code>1</code> validators <code>UPDATE_TIMEOUT</code> <code>SLOTS_PER_EPOCH * EPOCHS_PER_SYNC_COMMITTEE_PERIOD</code> slots ~27.3 hours"},{"location":"specs/altair/light-client/sync-protocol/#containers","title":"Containers","text":""},{"location":"specs/altair/light-client/sync-protocol/#lightclientheader","title":"<code>LightClientHeader</code>","text":"<pre><code>class LightClientHeader(Container):\n    beacon: BeaconBlockHeader\n</code></pre> <p>Future upgrades may introduce additional fields to this structure, and validate them by extending <code>is_valid_light_client_header</code>.</p>"},{"location":"specs/altair/light-client/sync-protocol/#lightclientbootstrap","title":"<code>LightClientBootstrap</code>","text":"<pre><code>class LightClientBootstrap(Container):\n    # Header matching the requested beacon block root\n    header: LightClientHeader\n    # Current sync committee corresponding to `header.beacon.state_root`\n    current_sync_committee: SyncCommittee\n    current_sync_committee_branch: CurrentSyncCommitteeBranch\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#lightclientupdate","title":"<code>LightClientUpdate</code>","text":"<pre><code>class LightClientUpdate(Container):\n    # Header attested to by the sync committee\n    attested_header: LightClientHeader\n    # Next sync committee corresponding to `attested_header.beacon.state_root`\n    next_sync_committee: SyncCommittee\n    next_sync_committee_branch: NextSyncCommitteeBranch\n    # Finalized header corresponding to `attested_header.beacon.state_root`\n    finalized_header: LightClientHeader\n    finality_branch: FinalityBranch\n    # Sync committee aggregate signature\n    sync_aggregate: SyncAggregate\n    # Slot at which the aggregate signature was created (untrusted)\n    signature_slot: Slot\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#lightclientfinalityupdate","title":"<code>LightClientFinalityUpdate</code>","text":"<pre><code>class LightClientFinalityUpdate(Container):\n    # Header attested to by the sync committee\n    attested_header: LightClientHeader\n    # Finalized header corresponding to `attested_header.beacon.state_root`\n    finalized_header: LightClientHeader\n    finality_branch: FinalityBranch\n    # Sync committee aggregate signature\n    sync_aggregate: SyncAggregate\n    # Slot at which the aggregate signature was created (untrusted)\n    signature_slot: Slot\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#lightclientoptimisticupdate","title":"<code>LightClientOptimisticUpdate</code>","text":"<pre><code>class LightClientOptimisticUpdate(Container):\n    # Header attested to by the sync committee\n    attested_header: LightClientHeader\n    # Sync committee aggregate signature\n    sync_aggregate: SyncAggregate\n    # Slot at which the aggregate signature was created (untrusted)\n    signature_slot: Slot\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#lightclientstore","title":"<code>LightClientStore</code>","text":"<pre><code>@dataclass\nclass LightClientStore(object):\n    # Header that is finalized\n    finalized_header: LightClientHeader\n    # Sync committees corresponding to the finalized header\n    current_sync_committee: SyncCommittee\n    next_sync_committee: SyncCommittee\n    # Best available header to switch finalized head to if we see nothing else\n    best_valid_update: Optional[LightClientUpdate]\n    # Most recent available reasonably-safe header\n    optimistic_header: LightClientHeader\n    # Max number of active participants in a sync committee (used to calculate safety threshold)\n    previous_max_active_participants: uint64\n    current_max_active_participants: uint64\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#helper-functions","title":"Helper functions","text":""},{"location":"specs/altair/light-client/sync-protocol/#finalized_root_gindex_at_slot","title":"<code>finalized_root_gindex_at_slot</code>","text":"<pre><code>def finalized_root_gindex_at_slot(_slot: Slot) -&gt; GeneralizedIndex:\n    return FINALIZED_ROOT_GINDEX\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#current_sync_committee_gindex_at_slot","title":"<code>current_sync_committee_gindex_at_slot</code>","text":"<pre><code>def current_sync_committee_gindex_at_slot(_slot: Slot) -&gt; GeneralizedIndex:\n    return CURRENT_SYNC_COMMITTEE_GINDEX\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#next_sync_committee_gindex_at_slot","title":"<code>next_sync_committee_gindex_at_slot</code>","text":"<pre><code>def next_sync_committee_gindex_at_slot(_slot: Slot) -&gt; GeneralizedIndex:\n    return NEXT_SYNC_COMMITTEE_GINDEX\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#is_valid_light_client_header","title":"<code>is_valid_light_client_header</code>","text":"<pre><code>def is_valid_light_client_header(_header: LightClientHeader) -&gt; bool:\n    return True\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#is_sync_committee_update","title":"<code>is_sync_committee_update</code>","text":"<pre><code>def is_sync_committee_update(update: LightClientUpdate) -&gt; bool:\n    return update.next_sync_committee_branch != NextSyncCommitteeBranch()\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#is_finality_update","title":"<code>is_finality_update</code>","text":"<pre><code>def is_finality_update(update: LightClientUpdate) -&gt; bool:\n    return update.finality_branch != FinalityBranch()\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#is_better_update","title":"<code>is_better_update</code>","text":"<pre><code>def is_better_update(new_update: LightClientUpdate, old_update: LightClientUpdate) -&gt; bool:\n    # Compare supermajority (&gt; 2/3) sync committee participation\n    max_active_participants = len(new_update.sync_aggregate.sync_committee_bits)\n    new_num_active_participants = sum(new_update.sync_aggregate.sync_committee_bits)\n    old_num_active_participants = sum(old_update.sync_aggregate.sync_committee_bits)\n    new_has_supermajority = new_num_active_participants * 3 &gt;= max_active_participants * 2\n    old_has_supermajority = old_num_active_participants * 3 &gt;= max_active_participants * 2\n    if new_has_supermajority != old_has_supermajority:\n        return new_has_supermajority\n    if not new_has_supermajority and new_num_active_participants != old_num_active_participants:\n        return new_num_active_participants &gt; old_num_active_participants\n\n    # Compare presence of relevant sync committee\n    new_has_relevant_sync_committee = is_sync_committee_update(new_update) and (\n        compute_sync_committee_period_at_slot(new_update.attested_header.beacon.slot)\n        == compute_sync_committee_period_at_slot(new_update.signature_slot)\n    )\n    old_has_relevant_sync_committee = is_sync_committee_update(old_update) and (\n        compute_sync_committee_period_at_slot(old_update.attested_header.beacon.slot)\n        == compute_sync_committee_period_at_slot(old_update.signature_slot)\n    )\n    if new_has_relevant_sync_committee != old_has_relevant_sync_committee:\n        return new_has_relevant_sync_committee\n\n    # Compare indication of any finality\n    new_has_finality = is_finality_update(new_update)\n    old_has_finality = is_finality_update(old_update)\n    if new_has_finality != old_has_finality:\n        return new_has_finality\n\n    # Compare sync committee finality\n    if new_has_finality:\n        new_has_sync_committee_finality = compute_sync_committee_period_at_slot(\n            new_update.finalized_header.beacon.slot\n        ) == compute_sync_committee_period_at_slot(new_update.attested_header.beacon.slot)\n        old_has_sync_committee_finality = compute_sync_committee_period_at_slot(\n            old_update.finalized_header.beacon.slot\n        ) == compute_sync_committee_period_at_slot(old_update.attested_header.beacon.slot)\n        if new_has_sync_committee_finality != old_has_sync_committee_finality:\n            return new_has_sync_committee_finality\n\n    # Tiebreaker 1: Sync committee participation beyond supermajority\n    if new_num_active_participants != old_num_active_participants:\n        return new_num_active_participants &gt; old_num_active_participants\n\n    # Tiebreaker 2: Prefer older data (fewer changes to best)\n    if new_update.attested_header.beacon.slot != old_update.attested_header.beacon.slot:\n        return new_update.attested_header.beacon.slot &lt; old_update.attested_header.beacon.slot\n\n    # Tiebreaker 3: Prefer updates with earlier signature slots\n    return new_update.signature_slot &lt; old_update.signature_slot\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#is_next_sync_committee_known","title":"<code>is_next_sync_committee_known</code>","text":"<pre><code>def is_next_sync_committee_known(store: LightClientStore) -&gt; bool:\n    return store.next_sync_committee != SyncCommittee()\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#get_safety_threshold","title":"<code>get_safety_threshold</code>","text":"<pre><code>def get_safety_threshold(store: LightClientStore) -&gt; uint64:\n    return (\n        max(\n            store.previous_max_active_participants,\n            store.current_max_active_participants,\n        )\n        // 2\n    )\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#get_subtree_index","title":"<code>get_subtree_index</code>","text":"<pre><code>def get_subtree_index(generalized_index: GeneralizedIndex) -&gt; uint64:\n    return uint64(generalized_index % 2 ** (floorlog2(generalized_index)))\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#is_valid_normalized_merkle_branch","title":"<code>is_valid_normalized_merkle_branch</code>","text":"<pre><code>def is_valid_normalized_merkle_branch(\n    leaf: Bytes32, branch: Sequence[Bytes32], gindex: GeneralizedIndex, root: Root\n) -&gt; bool:\n    depth = floorlog2(gindex)\n    index = get_subtree_index(gindex)\n    num_extra = len(branch) - depth\n    for i in range(num_extra):\n        if branch[i] != Bytes32():\n            return False\n    return is_valid_merkle_branch(leaf, branch[num_extra:], depth, index, root)\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#compute_sync_committee_period_at_slot","title":"<code>compute_sync_committee_period_at_slot</code>","text":"<pre><code>def compute_sync_committee_period_at_slot(slot: Slot) -&gt; uint64:\n    return compute_sync_committee_period(compute_epoch_at_slot(slot))\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#light-client-initialization","title":"Light client initialization","text":"<p>A light client maintains its state in a <code>store</code> object of type <code>LightClientStore</code>. <code>initialize_light_client_store</code> initializes a new <code>store</code> with a received <code>LightClientBootstrap</code> derived from a given <code>trusted_block_root</code>.</p>"},{"location":"specs/altair/light-client/sync-protocol/#initialize_light_client_store","title":"<code>initialize_light_client_store</code>","text":"<pre><code>def initialize_light_client_store(\n    trusted_block_root: Root, bootstrap: LightClientBootstrap\n) -&gt; LightClientStore:\n    assert is_valid_light_client_header(bootstrap.header)\n    assert hash_tree_root(bootstrap.header.beacon) == trusted_block_root\n\n    assert is_valid_normalized_merkle_branch(\n        leaf=hash_tree_root(bootstrap.current_sync_committee),\n        branch=bootstrap.current_sync_committee_branch,\n        gindex=current_sync_committee_gindex_at_slot(bootstrap.header.beacon.slot),\n        root=bootstrap.header.beacon.state_root,\n    )\n\n    return LightClientStore(\n        finalized_header=bootstrap.header,\n        current_sync_committee=bootstrap.current_sync_committee,\n        next_sync_committee=SyncCommittee(),\n        best_valid_update=None,\n        optimistic_header=bootstrap.header,\n        previous_max_active_participants=0,\n        current_max_active_participants=0,\n    )\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#light-client-state-updates","title":"Light client state updates","text":"<ul> <li>A light client receives objects of type <code>LightClientUpdate</code>,   <code>LightClientFinalityUpdate</code> and <code>LightClientOptimisticUpdate</code>:</li> <li><code>update: LightClientUpdate</code>: Every <code>update</code> triggers     <code>process_light_client_update(store, update, current_slot, genesis_validators_root)</code>     where <code>current_slot</code> is the current slot based on a local clock.</li> <li><code>finality_update: LightClientFinalityUpdate</code>: Every <code>finality_update</code>     triggers     <code>process_light_client_finality_update(store, finality_update, current_slot, genesis_validators_root)</code>.</li> <li><code>optimistic_update: LightClientOptimisticUpdate</code>: Every     <code>optimistic_update</code> triggers     <code>process_light_client_optimistic_update(store, optimistic_update, current_slot, genesis_validators_root)</code>.</li> <li><code>process_light_client_store_force_update</code> MAY be called based on use case   dependent heuristics if light client sync appears stuck.</li> </ul>"},{"location":"specs/altair/light-client/sync-protocol/#validate_light_client_update","title":"<code>validate_light_client_update</code>","text":"<pre><code>def validate_light_client_update(\n    store: LightClientStore,\n    update: LightClientUpdate,\n    current_slot: Slot,\n    genesis_validators_root: Root,\n) -&gt; None:\n    # Verify sync committee has sufficient participants\n    sync_aggregate = update.sync_aggregate\n    assert sum(sync_aggregate.sync_committee_bits) &gt;= MIN_SYNC_COMMITTEE_PARTICIPANTS\n\n    # Verify update does not skip a sync committee period\n    assert is_valid_light_client_header(update.attested_header)\n    update_attested_slot = update.attested_header.beacon.slot\n    update_finalized_slot = update.finalized_header.beacon.slot\n    assert current_slot &gt;= update.signature_slot &gt; update_attested_slot &gt;= update_finalized_slot\n    store_period = compute_sync_committee_period_at_slot(store.finalized_header.beacon.slot)\n    update_signature_period = compute_sync_committee_period_at_slot(update.signature_slot)\n    if is_next_sync_committee_known(store):\n        assert update_signature_period in (store_period, store_period + 1)\n    else:\n        assert update_signature_period == store_period\n\n    # Verify update is relevant\n    update_attested_period = compute_sync_committee_period_at_slot(update_attested_slot)\n    update_has_next_sync_committee = not is_next_sync_committee_known(store) and (\n        is_sync_committee_update(update) and update_attested_period == store_period\n    )\n    assert (\n        update_attested_slot &gt; store.finalized_header.beacon.slot or update_has_next_sync_committee\n    )\n\n    # Verify that the `finality_branch`, if present, confirms `finalized_header`\n    # to match the finalized checkpoint root saved in the state of `attested_header`.\n    # Note that the genesis finalized checkpoint root is represented as a zero hash.\n    if not is_finality_update(update):\n        assert update.finalized_header == LightClientHeader()\n    else:\n        if update_finalized_slot == GENESIS_SLOT:\n            assert update.finalized_header == LightClientHeader()\n            finalized_root = Bytes32()\n        else:\n            assert is_valid_light_client_header(update.finalized_header)\n            finalized_root = hash_tree_root(update.finalized_header.beacon)\n        assert is_valid_normalized_merkle_branch(\n            leaf=finalized_root,\n            branch=update.finality_branch,\n            gindex=finalized_root_gindex_at_slot(update.attested_header.beacon.slot),\n            root=update.attested_header.beacon.state_root,\n        )\n\n    # Verify that the `next_sync_committee`, if present, actually is the next sync committee saved in the\n    # state of the `attested_header`\n    if not is_sync_committee_update(update):\n        assert update.next_sync_committee == SyncCommittee()\n    else:\n        if update_attested_period == store_period and is_next_sync_committee_known(store):\n            assert update.next_sync_committee == store.next_sync_committee\n        assert is_valid_normalized_merkle_branch(\n            leaf=hash_tree_root(update.next_sync_committee),\n            branch=update.next_sync_committee_branch,\n            gindex=next_sync_committee_gindex_at_slot(update.attested_header.beacon.slot),\n            root=update.attested_header.beacon.state_root,\n        )\n\n    # Verify sync committee aggregate signature\n    if update_signature_period == store_period:\n        sync_committee = store.current_sync_committee\n    else:\n        sync_committee = store.next_sync_committee\n    participant_pubkeys = [\n        pubkey\n        for (bit, pubkey) in zip(sync_aggregate.sync_committee_bits, sync_committee.pubkeys)\n        if bit\n    ]\n    fork_version_slot = max(update.signature_slot, Slot(1)) - Slot(1)\n    fork_version = compute_fork_version(compute_epoch_at_slot(fork_version_slot))\n    domain = compute_domain(DOMAIN_SYNC_COMMITTEE, fork_version, genesis_validators_root)\n    signing_root = compute_signing_root(update.attested_header.beacon, domain)\n    assert bls.FastAggregateVerify(\n        participant_pubkeys, signing_root, sync_aggregate.sync_committee_signature\n    )\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#apply_light_client_update","title":"<code>apply_light_client_update</code>","text":"<pre><code>def apply_light_client_update(store: LightClientStore, update: LightClientUpdate) -&gt; None:\n    store_period = compute_sync_committee_period_at_slot(store.finalized_header.beacon.slot)\n    update_finalized_period = compute_sync_committee_period_at_slot(\n        update.finalized_header.beacon.slot\n    )\n    if not is_next_sync_committee_known(store):\n        assert update_finalized_period == store_period\n        store.next_sync_committee = update.next_sync_committee\n    elif update_finalized_period == store_period + 1:\n        store.current_sync_committee = store.next_sync_committee\n        store.next_sync_committee = update.next_sync_committee\n        store.previous_max_active_participants = store.current_max_active_participants\n        store.current_max_active_participants = 0\n    if update.finalized_header.beacon.slot &gt; store.finalized_header.beacon.slot:\n        store.finalized_header = update.finalized_header\n        if store.finalized_header.beacon.slot &gt; store.optimistic_header.beacon.slot:\n            store.optimistic_header = store.finalized_header\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#process_light_client_store_force_update","title":"<code>process_light_client_store_force_update</code>","text":"<pre><code>def process_light_client_store_force_update(store: LightClientStore, current_slot: Slot) -&gt; None:\n    if (\n        current_slot &gt; store.finalized_header.beacon.slot + UPDATE_TIMEOUT\n        and store.best_valid_update is not None\n    ):\n        # Forced best update when the update timeout has elapsed.\n        # Because the apply logic waits for `finalized_header.beacon.slot` to indicate sync committee finality,\n        # the `attested_header` may be treated as `finalized_header` in extended periods of non-finality\n        # to guarantee progression into later sync committee periods according to `is_better_update`.\n        if (\n            store.best_valid_update.finalized_header.beacon.slot\n            &lt;= store.finalized_header.beacon.slot\n        ):\n            store.best_valid_update.finalized_header = store.best_valid_update.attested_header\n        apply_light_client_update(store, store.best_valid_update)\n        store.best_valid_update = None\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#process_light_client_update","title":"<code>process_light_client_update</code>","text":"<pre><code>def process_light_client_update(\n    store: LightClientStore,\n    update: LightClientUpdate,\n    current_slot: Slot,\n    genesis_validators_root: Root,\n) -&gt; None:\n    validate_light_client_update(store, update, current_slot, genesis_validators_root)\n\n    sync_committee_bits = update.sync_aggregate.sync_committee_bits\n\n    # Update the best update in case we have to force-update to it if the timeout elapses\n    if store.best_valid_update is None or is_better_update(update, store.best_valid_update):\n        store.best_valid_update = update\n\n    # Track the maximum number of active participants in the committee signatures\n    store.current_max_active_participants = max(\n        store.current_max_active_participants,\n        sum(sync_committee_bits),\n    )\n\n    # Update the optimistic header\n    if (\n        sum(sync_committee_bits) &gt; get_safety_threshold(store)\n        and update.attested_header.beacon.slot &gt; store.optimistic_header.beacon.slot\n    ):\n        store.optimistic_header = update.attested_header\n\n    # Update finalized header\n    update_has_finalized_next_sync_committee = (\n        not is_next_sync_committee_known(store)\n        and is_sync_committee_update(update)\n        and is_finality_update(update)\n        and (\n            compute_sync_committee_period_at_slot(update.finalized_header.beacon.slot)\n            == compute_sync_committee_period_at_slot(update.attested_header.beacon.slot)\n        )\n    )\n    if sum(sync_committee_bits) * 3 &gt;= len(sync_committee_bits) * 2 and (\n        update.finalized_header.beacon.slot &gt; store.finalized_header.beacon.slot\n        or update_has_finalized_next_sync_committee\n    ):\n        # Normal update through 2/3 threshold\n        apply_light_client_update(store, update)\n        store.best_valid_update = None\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#process_light_client_finality_update","title":"<code>process_light_client_finality_update</code>","text":"<pre><code>def process_light_client_finality_update(\n    store: LightClientStore,\n    finality_update: LightClientFinalityUpdate,\n    current_slot: Slot,\n    genesis_validators_root: Root,\n) -&gt; None:\n    update = LightClientUpdate(\n        attested_header=finality_update.attested_header,\n        next_sync_committee=SyncCommittee(),\n        next_sync_committee_branch=NextSyncCommitteeBranch(),\n        finalized_header=finality_update.finalized_header,\n        finality_branch=finality_update.finality_branch,\n        sync_aggregate=finality_update.sync_aggregate,\n        signature_slot=finality_update.signature_slot,\n    )\n    process_light_client_update(store, update, current_slot, genesis_validators_root)\n</code></pre>"},{"location":"specs/altair/light-client/sync-protocol/#process_light_client_optimistic_update","title":"<code>process_light_client_optimistic_update</code>","text":"<pre><code>def process_light_client_optimistic_update(\n    store: LightClientStore,\n    optimistic_update: LightClientOptimisticUpdate,\n    current_slot: Slot,\n    genesis_validators_root: Root,\n) -&gt; None:\n    update = LightClientUpdate(\n        attested_header=optimistic_update.attested_header,\n        next_sync_committee=SyncCommittee(),\n        next_sync_committee_branch=NextSyncCommitteeBranch(),\n        finalized_header=LightClientHeader(),\n        finality_branch=FinalityBranch(),\n        sync_aggregate=optimistic_update.sync_aggregate,\n        signature_slot=optimistic_update.signature_slot,\n    )\n    process_light_client_update(store, update, current_slot, genesis_validators_root)\n</code></pre>"},{"location":"specs/bellatrix/","title":"Index","text":""},{"location":"specs/bellatrix/#core","title":"Core","text":"<ul> <li>Beacon Chain</li> <li>Fork Choice</li> <li>Fork</li> <li>P2P Interface</li> <li>Validator</li> </ul>"},{"location":"specs/bellatrix/beacon-chain/","title":"Bellatrix -- The Beacon Chain","text":"<ul> <li>Introduction</li> <li>Custom types</li> <li>Preset</li> <li>Rewards and penalties</li> <li>Execution</li> <li>Configuration</li> <li>Transition settings</li> <li>Containers</li> <li>Modified containers<ul> <li><code>BeaconBlockBody</code></li> <li><code>BeaconState</code></li> </ul> </li> <li>New containers<ul> <li><code>ExecutionPayload</code></li> <li><code>ExecutionPayloadHeader</code></li> </ul> </li> <li>Helper functions</li> <li>Predicates<ul> <li><code>is_merge_transition_complete</code></li> <li><code>is_merge_transition_block</code></li> <li><code>is_execution_enabled</code></li> </ul> </li> <li>Beacon state accessors<ul> <li>Modified <code>get_inactivity_penalty_deltas</code></li> </ul> </li> <li>Beacon state mutators<ul> <li>Modified <code>slash_validator</code></li> </ul> </li> <li>Beacon chain state transition function</li> <li>Execution engine<ul> <li>Request data</li> <li><code>NewPayloadRequest</code></li> <li>Engine APIs</li> <li><code>notify_new_payload</code></li> <li><code>is_valid_block_hash</code></li> <li><code>verify_and_notify_new_payload</code></li> </ul> </li> <li>Block processing<ul> <li>Execution payload</li> <li><code>process_execution_payload</code></li> </ul> </li> <li>Epoch processing<ul> <li>Slashings</li> </ul> </li> </ul>"},{"location":"specs/bellatrix/beacon-chain/#introduction","title":"Introduction","text":"<p>This upgrade adds transaction execution to the beacon chain as part of Bellatrix upgrade.</p> <p>Additionally, this upgrade introduces the following minor changes:</p> <ul> <li>Penalty parameter updates to their planned maximally punitive values</li> </ul>"},{"location":"specs/bellatrix/beacon-chain/#custom-types","title":"Custom types","text":"<p>Note: The <code>Transaction</code> type is a stub which is not final.</p> Name SSZ equivalent Description <code>Transaction</code> <code>ByteList[MAX_BYTES_PER_TRANSACTION]</code> either a typed transaction envelope or a legacy transaction <code>ExecutionAddress</code> <code>Bytes20</code> Address of account on the execution layer"},{"location":"specs/bellatrix/beacon-chain/#preset","title":"Preset","text":""},{"location":"specs/bellatrix/beacon-chain/#rewards-and-penalties","title":"Rewards and penalties","text":"<p>Bellatrix updates a few configuration values to move penalty parameters to their final, maximum security values.</p> <p>Note: The spec does not override previous configuration values but instead creates new values and replaces usage throughout.</p> Name Value <code>INACTIVITY_PENALTY_QUOTIENT_BELLATRIX</code> <code>uint64(2**24)</code> (= 16,777,216) <code>MIN_SLASHING_PENALTY_QUOTIENT_BELLATRIX</code> <code>uint64(2**5)</code> (= 32) <code>PROPORTIONAL_SLASHING_MULTIPLIER_BELLATRIX</code> <code>uint64(3)</code>"},{"location":"specs/bellatrix/beacon-chain/#execution","title":"Execution","text":"Name Value <code>MAX_BYTES_PER_TRANSACTION</code> <code>uint64(2**30)</code> (= 1,073,741,824) <code>MAX_TRANSACTIONS_PER_PAYLOAD</code> <code>uint64(2**20)</code> (= 1,048,576) <code>BYTES_PER_LOGS_BLOOM</code> <code>uint64(2**8)</code> (= 256) <code>MAX_EXTRA_DATA_BYTES</code> <code>2**5</code> (= 32)"},{"location":"specs/bellatrix/beacon-chain/#configuration","title":"Configuration","text":""},{"location":"specs/bellatrix/beacon-chain/#transition-settings","title":"Transition settings","text":"Name Value <code>TERMINAL_TOTAL_DIFFICULTY</code> <code>58750000000000000000000</code> (Estimated: Sept 15, 2022) <code>TERMINAL_BLOCK_HASH</code> <code>Hash32()</code> <code>TERMINAL_BLOCK_HASH_ACTIVATION_EPOCH</code> <code>FAR_FUTURE_EPOCH</code>"},{"location":"specs/bellatrix/beacon-chain/#containers","title":"Containers","text":""},{"location":"specs/bellatrix/beacon-chain/#modified-containers","title":"Modified containers","text":""},{"location":"specs/bellatrix/beacon-chain/#beaconblockbody","title":"<code>BeaconBlockBody</code>","text":"<pre><code>class BeaconBlockBody(Container):\n    randao_reveal: BLSSignature\n    eth1_data: Eth1Data\n    graffiti: Bytes32\n    proposer_slashings: List[ProposerSlashing, MAX_PROPOSER_SLASHINGS]\n    attester_slashings: List[AttesterSlashing, MAX_ATTESTER_SLASHINGS]\n    attestations: List[Attestation, MAX_ATTESTATIONS]\n    deposits: List[Deposit, MAX_DEPOSITS]\n    voluntary_exits: List[SignedVoluntaryExit, MAX_VOLUNTARY_EXITS]\n    sync_aggregate: SyncAggregate\n    # [New in Bellatrix]\n    execution_payload: ExecutionPayload\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#beaconstate","title":"<code>BeaconState</code>","text":"<pre><code>class BeaconState(Container):\n    genesis_time: uint64\n    genesis_validators_root: Root\n    slot: Slot\n    fork: Fork\n    latest_block_header: BeaconBlockHeader\n    block_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    state_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    historical_roots: List[Root, HISTORICAL_ROOTS_LIMIT]\n    eth1_data: Eth1Data\n    eth1_data_votes: List[Eth1Data, EPOCHS_PER_ETH1_VOTING_PERIOD * SLOTS_PER_EPOCH]\n    eth1_deposit_index: uint64\n    validators: List[Validator, VALIDATOR_REGISTRY_LIMIT]\n    balances: List[Gwei, VALIDATOR_REGISTRY_LIMIT]\n    randao_mixes: Vector[Bytes32, EPOCHS_PER_HISTORICAL_VECTOR]\n    slashings: Vector[Gwei, EPOCHS_PER_SLASHINGS_VECTOR]\n    previous_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    current_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    justification_bits: Bitvector[JUSTIFICATION_BITS_LENGTH]\n    previous_justified_checkpoint: Checkpoint\n    current_justified_checkpoint: Checkpoint\n    finalized_checkpoint: Checkpoint\n    inactivity_scores: List[uint64, VALIDATOR_REGISTRY_LIMIT]\n    current_sync_committee: SyncCommittee\n    next_sync_committee: SyncCommittee\n    # [New in Bellatrix]\n    latest_execution_payload_header: ExecutionPayloadHeader\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#new-containers","title":"New containers","text":""},{"location":"specs/bellatrix/beacon-chain/#executionpayload","title":"<code>ExecutionPayload</code>","text":"<p>Note: <code>fee_recipient</code>, <code>prev_randao</code>, and <code>block_number</code> correspond to <code>beneficiary</code>, <code>difficulty</code>, and <code>number</code> in the yellow paper, respectively.</p> <pre><code>class ExecutionPayload(Container):\n    parent_hash: Hash32\n    fee_recipient: ExecutionAddress\n    state_root: Bytes32\n    receipts_root: Bytes32\n    logs_bloom: ByteVector[BYTES_PER_LOGS_BLOOM]\n    prev_randao: Bytes32\n    block_number: uint64\n    gas_limit: uint64\n    gas_used: uint64\n    timestamp: uint64\n    extra_data: ByteList[MAX_EXTRA_DATA_BYTES]\n    base_fee_per_gas: uint256\n    block_hash: Hash32\n    transactions: List[Transaction, MAX_TRANSACTIONS_PER_PAYLOAD]\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#executionpayloadheader","title":"<code>ExecutionPayloadHeader</code>","text":"<p>Note: <code>block_hash</code> is the hash of the execution block.</p> <pre><code>class ExecutionPayloadHeader(Container):\n    parent_hash: Hash32\n    fee_recipient: ExecutionAddress\n    state_root: Bytes32\n    receipts_root: Bytes32\n    logs_bloom: ByteVector[BYTES_PER_LOGS_BLOOM]\n    prev_randao: Bytes32\n    block_number: uint64\n    gas_limit: uint64\n    gas_used: uint64\n    timestamp: uint64\n    extra_data: ByteList[MAX_EXTRA_DATA_BYTES]\n    base_fee_per_gas: uint256\n    block_hash: Hash32\n    transactions_root: Root\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#helper-functions","title":"Helper functions","text":""},{"location":"specs/bellatrix/beacon-chain/#predicates","title":"Predicates","text":""},{"location":"specs/bellatrix/beacon-chain/#is_merge_transition_complete","title":"<code>is_merge_transition_complete</code>","text":"<pre><code>def is_merge_transition_complete(state: BeaconState) -&gt; bool:\n    return state.latest_execution_payload_header != ExecutionPayloadHeader()\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#is_merge_transition_block","title":"<code>is_merge_transition_block</code>","text":"<pre><code>def is_merge_transition_block(state: BeaconState, body: BeaconBlockBody) -&gt; bool:\n    return not is_merge_transition_complete(state) and body.execution_payload != ExecutionPayload()\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#is_execution_enabled","title":"<code>is_execution_enabled</code>","text":"<pre><code>def is_execution_enabled(state: BeaconState, body: BeaconBlockBody) -&gt; bool:\n    return is_merge_transition_block(state, body) or is_merge_transition_complete(state)\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#beacon-state-accessors","title":"Beacon state accessors","text":""},{"location":"specs/bellatrix/beacon-chain/#modified-get_inactivity_penalty_deltas","title":"Modified <code>get_inactivity_penalty_deltas</code>","text":"<p>Note: The function <code>get_inactivity_penalty_deltas</code> is modified to use <code>INACTIVITY_PENALTY_QUOTIENT_BELLATRIX</code>.</p> <pre><code>def get_inactivity_penalty_deltas(state: BeaconState) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:\n    \"\"\"\n    Return the inactivity penalty deltas by considering timely target participation flags and inactivity scores.\n    \"\"\"\n    rewards = [Gwei(0) for _ in range(len(state.validators))]\n    penalties = [Gwei(0) for _ in range(len(state.validators))]\n    previous_epoch = get_previous_epoch(state)\n    matching_target_indices = get_unslashed_participating_indices(\n        state, TIMELY_TARGET_FLAG_INDEX, previous_epoch\n    )\n    for index in get_eligible_validator_indices(state):\n        if index not in matching_target_indices:\n            penalty_numerator = (\n                state.validators[index].effective_balance * state.inactivity_scores[index]\n            )\n            # [Modified in Bellatrix]\n            penalty_denominator = INACTIVITY_SCORE_BIAS * INACTIVITY_PENALTY_QUOTIENT_BELLATRIX\n            penalties[index] += Gwei(penalty_numerator // penalty_denominator)\n    return rewards, penalties\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#beacon-state-mutators","title":"Beacon state mutators","text":""},{"location":"specs/bellatrix/beacon-chain/#modified-slash_validator","title":"Modified <code>slash_validator</code>","text":"<p>Note: The function <code>slash_validator</code> is modified to use <code>MIN_SLASHING_PENALTY_QUOTIENT_BELLATRIX</code>.</p> <pre><code>def slash_validator(\n    state: BeaconState, slashed_index: ValidatorIndex, whistleblower_index: ValidatorIndex = None\n) -&gt; None:\n    \"\"\"\n    Slash the validator with index ``slashed_index``.\n    \"\"\"\n    epoch = get_current_epoch(state)\n    initiate_validator_exit(state, slashed_index)\n    validator = state.validators[slashed_index]\n    validator.slashed = True\n    validator.withdrawable_epoch = max(\n        validator.withdrawable_epoch, Epoch(epoch + EPOCHS_PER_SLASHINGS_VECTOR)\n    )\n    state.slashings[epoch % EPOCHS_PER_SLASHINGS_VECTOR] += validator.effective_balance\n    # [Modified in Bellatrix]\n    slashing_penalty = validator.effective_balance // MIN_SLASHING_PENALTY_QUOTIENT_BELLATRIX\n    decrease_balance(state, slashed_index, slashing_penalty)\n\n    # Apply proposer and whistleblower rewards\n    proposer_index = get_beacon_proposer_index(state)\n    if whistleblower_index is None:\n        whistleblower_index = proposer_index\n    whistleblower_reward = Gwei(validator.effective_balance // WHISTLEBLOWER_REWARD_QUOTIENT)\n    proposer_reward = Gwei(whistleblower_reward * PROPOSER_WEIGHT // WEIGHT_DENOMINATOR)\n    increase_balance(state, proposer_index, proposer_reward)\n    increase_balance(state, whistleblower_index, Gwei(whistleblower_reward - proposer_reward))\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#beacon-chain-state-transition-function","title":"Beacon chain state transition function","text":""},{"location":"specs/bellatrix/beacon-chain/#execution-engine","title":"Execution engine","text":""},{"location":"specs/bellatrix/beacon-chain/#request-data","title":"Request data","text":""},{"location":"specs/bellatrix/beacon-chain/#newpayloadrequest","title":"<code>NewPayloadRequest</code>","text":"<pre><code>@dataclass\nclass NewPayloadRequest(object):\n    execution_payload: ExecutionPayload\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#engine-apis","title":"Engine APIs","text":"<p>The implementation-dependent <code>ExecutionEngine</code> protocol encapsulates the execution sub-system logic via:</p> <ul> <li>a state object <code>self.execution_state</code> of type <code>ExecutionState</code></li> <li>a notification function <code>self.notify_new_payload</code> which may apply changes to   the <code>self.execution_state</code></li> </ul> <p>The body of these functions are implementation dependent. The Engine API may be used to implement this and similarly defined functions via an external execution engine.</p>"},{"location":"specs/bellatrix/beacon-chain/#notify_new_payload","title":"<code>notify_new_payload</code>","text":"<p><code>notify_new_payload</code> is a function accessed through the <code>EXECUTION_ENGINE</code> module which instantiates the <code>ExecutionEngine</code> protocol.</p> <pre><code>def notify_new_payload(self: ExecutionEngine, execution_payload: ExecutionPayload) -&gt; bool:\n    \"\"\"\n    Return ``True`` if and only if ``execution_payload`` is valid with respect to ``self.execution_state``.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#is_valid_block_hash","title":"<code>is_valid_block_hash</code>","text":"<pre><code>def is_valid_block_hash(self: ExecutionEngine, execution_payload: ExecutionPayload) -&gt; bool:\n    \"\"\"\n    Return ``True`` if and only if ``execution_payload.block_hash`` is computed correctly.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#verify_and_notify_new_payload","title":"<code>verify_and_notify_new_payload</code>","text":"<pre><code>def verify_and_notify_new_payload(\n    self: ExecutionEngine, new_payload_request: NewPayloadRequest\n) -&gt; bool:\n    \"\"\"\n    Return ``True`` if and only if ``new_payload_request`` is valid with respect to ``self.execution_state``.\n    \"\"\"\n    execution_payload = new_payload_request.execution_payload\n\n    if b\"\" in execution_payload.transactions:\n        return False\n\n    if not self.is_valid_block_hash(execution_payload):\n        return False\n\n    if not self.notify_new_payload(execution_payload):\n        return False\n\n    return True\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#block-processing","title":"Block processing","text":"<p>Note: The call to the <code>process_execution_payload</code> must happen before the call to the <code>process_randao</code> as the former depends on the <code>randao_mix</code> computed with the reveal of the previous block.</p> <pre><code>def process_block(state: BeaconState, block: BeaconBlock) -&gt; None:\n    process_block_header(state, block)\n    if is_execution_enabled(state, block.body):\n        # [New in Bellatrix]\n        process_execution_payload(state, block.body, EXECUTION_ENGINE)\n    process_randao(state, block.body)\n    process_eth1_data(state, block.body)\n    process_operations(state, block.body)\n    process_sync_aggregate(state, block.body.sync_aggregate)\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#execution-payload","title":"Execution payload","text":""},{"location":"specs/bellatrix/beacon-chain/#process_execution_payload","title":"<code>process_execution_payload</code>","text":"<pre><code>def process_execution_payload(\n    state: BeaconState, body: BeaconBlockBody, execution_engine: ExecutionEngine\n) -&gt; None:\n    payload = body.execution_payload\n\n    # Verify consistency of the parent hash with respect to the previous execution payload header\n    if is_merge_transition_complete(state):\n        assert payload.parent_hash == state.latest_execution_payload_header.block_hash\n    # Verify prev_randao\n    assert payload.prev_randao == get_randao_mix(state, get_current_epoch(state))\n    # Verify timestamp\n    assert payload.timestamp == compute_time_at_slot(state, state.slot)\n    # Verify the execution payload is valid\n    assert execution_engine.verify_and_notify_new_payload(\n        NewPayloadRequest(execution_payload=payload)\n    )\n    # Cache execution payload header\n    state.latest_execution_payload_header = ExecutionPayloadHeader(\n        parent_hash=payload.parent_hash,\n        fee_recipient=payload.fee_recipient,\n        state_root=payload.state_root,\n        receipts_root=payload.receipts_root,\n        logs_bloom=payload.logs_bloom,\n        prev_randao=payload.prev_randao,\n        block_number=payload.block_number,\n        gas_limit=payload.gas_limit,\n        gas_used=payload.gas_used,\n        timestamp=payload.timestamp,\n        extra_data=payload.extra_data,\n        base_fee_per_gas=payload.base_fee_per_gas,\n        block_hash=payload.block_hash,\n        transactions_root=hash_tree_root(payload.transactions),\n    )\n</code></pre>"},{"location":"specs/bellatrix/beacon-chain/#epoch-processing","title":"Epoch processing","text":""},{"location":"specs/bellatrix/beacon-chain/#slashings","title":"Slashings","text":"<p>Note: The function <code>process_slashings</code> is modified to use <code>PROPORTIONAL_SLASHING_MULTIPLIER_BELLATRIX</code>.</p> <pre><code>def process_slashings(state: BeaconState) -&gt; None:\n    epoch = get_current_epoch(state)\n    total_balance = get_total_active_balance(state)\n    adjusted_total_slashing_balance = min(\n        sum(state.slashings)\n        # [Modified in Bellatrix]\n        * PROPORTIONAL_SLASHING_MULTIPLIER_BELLATRIX,\n        total_balance,\n    )\n    for index, validator in enumerate(state.validators):\n        if (\n            validator.slashed\n            and epoch + EPOCHS_PER_SLASHINGS_VECTOR // 2 == validator.withdrawable_epoch\n        ):\n            increment = EFFECTIVE_BALANCE_INCREMENT  # Factored out from penalty numerator to avoid uint64 overflow\n            penalty_numerator = (\n                validator.effective_balance // increment * adjusted_total_slashing_balance\n            )\n            penalty = penalty_numerator // total_balance * increment\n            decrease_balance(state, ValidatorIndex(index), penalty)\n</code></pre>"},{"location":"specs/bellatrix/fork-choice/","title":"Bellatrix -- Fork Choice","text":"<ul> <li>Introduction</li> <li>Custom types</li> <li>Protocols</li> <li><code>ExecutionEngine</code><ul> <li><code>notify_forkchoice_updated</code></li> <li><code>safe_block_hash</code></li> <li><code>should_override_forkchoice_update</code></li> </ul> </li> <li>Helpers</li> <li><code>PayloadAttributes</code></li> <li><code>PowBlock</code></li> <li><code>get_pow_block</code></li> <li><code>is_valid_terminal_pow_block</code></li> <li><code>validate_merge_block</code></li> <li>Updated fork-choice handlers</li> <li><code>on_block</code></li> </ul>"},{"location":"specs/bellatrix/fork-choice/#introduction","title":"Introduction","text":"<p>This is the modification of the fork choice according to the executable beacon chain proposal.</p> <p>Note: It introduces the process of transition from the last PoW block to the first PoS block.</p>"},{"location":"specs/bellatrix/fork-choice/#custom-types","title":"Custom types","text":"Name SSZ equivalent Description <code>PayloadId</code> <code>Bytes8</code> Identifier of a payload building process"},{"location":"specs/bellatrix/fork-choice/#protocols","title":"Protocols","text":""},{"location":"specs/bellatrix/fork-choice/#executionengine","title":"<code>ExecutionEngine</code>","text":"<p>Note: The <code>notify_forkchoice_updated</code> function is added to the <code>ExecutionEngine</code> protocol to signal the fork choice updates.</p> <p>The body of this function is implementation dependent. The Engine API may be used to implement it with an external execution engine.</p>"},{"location":"specs/bellatrix/fork-choice/#notify_forkchoice_updated","title":"<code>notify_forkchoice_updated</code>","text":"<p>This function performs three actions atomically:</p> <ul> <li>Re-organizes the execution payload chain and corresponding state to make   <code>head_block_hash</code> the head.</li> <li>Updates safe block hash with the value provided by <code>safe_block_hash</code>   parameter.</li> <li>Applies finality to the execution state: it irreversibly persists the chain of   all execution payloads and corresponding state, up to and including   <code>finalized_block_hash</code>.</li> </ul> <p>Additionally, if <code>payload_attributes</code> is provided, this function sets in motion a payload build process on top of <code>head_block_hash</code> and returns an identifier of initiated process.</p> <pre><code>def notify_forkchoice_updated(\n    self: ExecutionEngine,\n    head_block_hash: Hash32,\n    safe_block_hash: Hash32,\n    finalized_block_hash: Hash32,\n    payload_attributes: Optional[PayloadAttributes],\n) -&gt; Optional[PayloadId]: ...\n</code></pre> <p>Note: The <code>(head_block_hash, finalized_block_hash)</code> values of the <code>notify_forkchoice_updated</code> function call maps on the <code>POS_FORKCHOICE_UPDATED</code> event defined in the EIP-3675. As per EIP-3675, before a post-transition block is finalized, <code>notify_forkchoice_updated</code> MUST be called with <code>finalized_block_hash = Hash32()</code>.</p> <p>Note: Client software MUST NOT call this function until the transition conditions are met on the PoW network, i.e. there exists a block for which <code>is_valid_terminal_pow_block</code> function returns <code>True</code>.</p> <p>Note: Client software MUST call this function to initiate the payload build process to produce the merge transition block; the <code>head_block_hash</code> parameter MUST be set to the hash of a terminal PoW block in this case.</p>"},{"location":"specs/bellatrix/fork-choice/#safe_block_hash","title":"<code>safe_block_hash</code>","text":"<p>The <code>safe_block_hash</code> parameter MUST be set to return value of <code>get_safe_execution_block_hash(store: Store)</code> function.</p>"},{"location":"specs/bellatrix/fork-choice/#should_override_forkchoice_update","title":"<code>should_override_forkchoice_update</code>","text":"<p>If proposer boost re-orgs are implemented and enabled (see <code>get_proposer_head</code>) then additional care must be taken to ensure that the proposer is able to build an execution payload.</p> <p>If a beacon node knows it will propose the next block then it SHOULD NOT call <code>notify_forkchoice_updated</code> if it detects the current head to be weak and potentially capable of being re-orged. Complete information for evaluating <code>get_proposer_head</code> will not be available immediately after the receipt of a new block, so an approximation of those conditions should be used when deciding whether to send or suppress a fork choice notification. The exact conditions used may be implementation-specific, a suggested implementation is below.</p> <p>Let <code>validator_is_connected(validator_index: ValidatorIndex) -&gt; bool</code> be a function that indicates whether the validator with <code>validator_index</code> is connected to the node (e.g. has sent an unexpired proposer preparation message).</p> <pre><code>def should_override_forkchoice_update(store: Store, head_root: Root) -&gt; bool:\n    head_block = store.blocks[head_root]\n    parent_root = head_block.parent_root\n    parent_block = store.blocks[parent_root]\n    current_slot = get_current_slot(store)\n    proposal_slot = head_block.slot + Slot(1)\n\n    # Only re-org the head_block block if it arrived later than the attestation deadline.\n    head_late = is_head_late(store, head_root)\n\n    # Shuffling stable.\n    shuffling_stable = is_shuffling_stable(proposal_slot)\n\n    # FFG information of the new head_block will be competitive with the current head.\n    ffg_competitive = is_ffg_competitive(store, head_root, parent_root)\n\n    # Do not re-org if the chain is not finalizing with acceptable frequency.\n    finalization_ok = is_finalization_ok(store, proposal_slot)\n\n    # Only suppress the fork choice update if we are confident that we will propose the next block.\n    parent_state_advanced = store.block_states[parent_root].copy()\n    process_slots(parent_state_advanced, proposal_slot)\n    proposer_index = get_beacon_proposer_index(parent_state_advanced)\n    proposing_reorg_slot = validator_is_connected(proposer_index)\n\n    # Single slot re-org.\n    parent_slot_ok = parent_block.slot + 1 == head_block.slot\n    proposing_on_time = is_proposing_on_time(store)\n\n    # Note that this condition is different from `get_proposer_head`\n    current_time_ok = head_block.slot == current_slot or (\n        proposal_slot == current_slot and proposing_on_time\n    )\n    single_slot_reorg = parent_slot_ok and current_time_ok\n\n    # Check the head weight only if the attestations from the head slot have already been applied.\n    # Implementations may want to do this in different ways, e.g. by advancing\n    # `store.time` early, or by counting queued attestations during the head block's slot.\n    if current_slot &gt; head_block.slot:\n        head_weak = is_head_weak(store, head_root)\n        parent_strong = is_parent_strong(store, parent_root)\n    else:\n        head_weak = True\n        parent_strong = True\n\n    return all(\n        [\n            head_late,\n            shuffling_stable,\n            ffg_competitive,\n            finalization_ok,\n            proposing_reorg_slot,\n            single_slot_reorg,\n            head_weak,\n            parent_strong,\n        ]\n    )\n</code></pre> <p>Note: The ordering of conditions is a suggestion only. Implementations are free to optimize by re-ordering the conditions from least to most expensive and by returning early if any of the early conditions are <code>False</code>.</p> <p>In case <code>should_override_forkchoice_update</code> returns <code>True</code>, a node SHOULD instead call <code>notify_forkchoice_updated</code> with parameters appropriate for building upon the parent block. Care must be taken to compute the correct <code>payload_attributes</code>, as they may change depending on the slot of the block to be proposed (due to withdrawals).</p> <p>If <code>should_override_forkchoice_update</code> returns <code>True</code> but <code>get_proposer_head</code> later chooses the canonical head rather than its parent, then this is a misprediction that will cause the node to construct a payload with less notice. The result of <code>get_proposer_head</code> MUST be preferred over the result of <code>should_override_forkchoice_update</code> (when proposer reorgs are enabled).</p>"},{"location":"specs/bellatrix/fork-choice/#helpers","title":"Helpers","text":""},{"location":"specs/bellatrix/fork-choice/#payloadattributes","title":"<code>PayloadAttributes</code>","text":"<p>Used to signal to initiate the payload build process via <code>notify_forkchoice_updated</code>.</p> <pre><code>@dataclass\nclass PayloadAttributes(object):\n    timestamp: uint64\n    prev_randao: Bytes32\n    suggested_fee_recipient: ExecutionAddress\n</code></pre>"},{"location":"specs/bellatrix/fork-choice/#powblock","title":"<code>PowBlock</code>","text":"<pre><code>class PowBlock(Container):\n    block_hash: Hash32\n    parent_hash: Hash32\n    total_difficulty: uint256\n</code></pre>"},{"location":"specs/bellatrix/fork-choice/#get_pow_block","title":"<code>get_pow_block</code>","text":"<p>Let <code>get_pow_block(block_hash: Hash32) -&gt; Optional[PowBlock]</code> be the function that given the hash of the PoW block returns its data. It may result in <code>None</code> if the requested block is not yet available.</p> <p>Note: The <code>eth_getBlockByHash</code> JSON-RPC method may be used to pull this information from an execution client.</p>"},{"location":"specs/bellatrix/fork-choice/#is_valid_terminal_pow_block","title":"<code>is_valid_terminal_pow_block</code>","text":"<p>Used by fork-choice handler, <code>on_block</code>.</p> <pre><code>def is_valid_terminal_pow_block(block: PowBlock, parent: PowBlock) -&gt; bool:\n    is_total_difficulty_reached = block.total_difficulty &gt;= TERMINAL_TOTAL_DIFFICULTY\n    is_parent_total_difficulty_valid = parent.total_difficulty &lt; TERMINAL_TOTAL_DIFFICULTY\n    return is_total_difficulty_reached and is_parent_total_difficulty_valid\n</code></pre>"},{"location":"specs/bellatrix/fork-choice/#validate_merge_block","title":"<code>validate_merge_block</code>","text":"<pre><code>def validate_merge_block(block: BeaconBlock) -&gt; None:\n    \"\"\"\n    Check the parent PoW block of execution payload is a valid terminal PoW block.\n\n    Note: Unavailable PoW block(s) may later become available,\n    and a client software MAY delay a call to ``validate_merge_block``\n    until the PoW block(s) become available.\n    \"\"\"\n    if TERMINAL_BLOCK_HASH != Hash32():\n        # If `TERMINAL_BLOCK_HASH` is used as an override, the activation epoch must be reached.\n        assert compute_epoch_at_slot(block.slot) &gt;= TERMINAL_BLOCK_HASH_ACTIVATION_EPOCH\n        assert block.body.execution_payload.parent_hash == TERMINAL_BLOCK_HASH\n        return\n\n    pow_block = get_pow_block(block.body.execution_payload.parent_hash)\n    # Check if `pow_block` is available\n    assert pow_block is not None\n    pow_parent = get_pow_block(pow_block.parent_hash)\n    # Check if `pow_parent` is available\n    assert pow_parent is not None\n    # Check if `pow_block` is a valid terminal PoW block\n    assert is_valid_terminal_pow_block(pow_block, pow_parent)\n</code></pre>"},{"location":"specs/bellatrix/fork-choice/#updated-fork-choice-handlers","title":"Updated fork-choice handlers","text":""},{"location":"specs/bellatrix/fork-choice/#on_block","title":"<code>on_block</code>","text":"<p>Note: The only modification is the addition of the verification of transition block conditions.</p> <pre><code>def on_block(store: Store, signed_block: SignedBeaconBlock) -&gt; None:\n    \"\"\"\n    Run ``on_block`` upon receiving a new block.\n\n    A block that is asserted as invalid due to unavailable PoW block may be valid at a later time,\n    consider scheduling it for later processing in such case.\n    \"\"\"\n    block = signed_block.message\n    # Parent block must be known\n    assert block.parent_root in store.block_states\n    # Make a copy of the state to avoid mutability issues\n    pre_state = copy(store.block_states[block.parent_root])\n    # Blocks cannot be in the future. If they are, their consideration must be delayed until they are in the past.\n    assert get_current_slot(store) &gt;= block.slot\n\n    # Check that block is later than the finalized epoch slot (optimization to reduce calls to get_ancestor)\n    finalized_slot = compute_start_slot_at_epoch(store.finalized_checkpoint.epoch)\n    assert block.slot &gt; finalized_slot\n    # Check block is a descendant of the finalized block at the checkpoint finalized slot\n    finalized_checkpoint_block = get_checkpoint_block(\n        store,\n        block.parent_root,\n        store.finalized_checkpoint.epoch,\n    )\n    assert store.finalized_checkpoint.root == finalized_checkpoint_block\n\n    # Check the block is valid and compute the post-state\n    state = pre_state.copy()\n    block_root = hash_tree_root(block)\n    state_transition(state, signed_block, True)\n\n    # [New in Bellatrix]\n    if is_merge_transition_block(pre_state, block.body):\n        validate_merge_block(block)\n\n    # Add new block to the store\n    store.blocks[block_root] = block\n    # Add new state for this block to the store\n    store.block_states[block_root] = state\n\n    # Add block timeliness to the store\n    seconds_since_genesis = store.time - store.genesis_time\n    time_into_slot_ms = seconds_to_milliseconds(seconds_since_genesis) % SLOT_DURATION_MS\n    attestation_threshold_ms = get_slot_component_duration_ms(ATTESTATION_DUE_BPS)\n    is_before_attesting_interval = time_into_slot_ms &lt; attestation_threshold_ms\n    is_timely = get_current_slot(store) == block.slot and is_before_attesting_interval\n    store.block_timeliness[hash_tree_root(block)] = is_timely\n\n    # Add proposer score boost if the block is timely and not conflicting with an existing block\n    is_first_block = store.proposer_boost_root == Root()\n    if is_timely and is_first_block:\n        store.proposer_boost_root = hash_tree_root(block)\n\n    # Update checkpoints in store if necessary\n    update_checkpoints(store, state.current_justified_checkpoint, state.finalized_checkpoint)\n\n    # Eagerly compute unrealized justification and finality.\n    compute_pulled_up_tip(store, block_root)\n</code></pre>"},{"location":"specs/bellatrix/fork/","title":"Bellatrix -- Fork Logic","text":"<ul> <li>Introduction</li> <li>Configuration</li> <li>Fork to Bellatrix</li> <li>Fork trigger</li> <li>Upgrading the state</li> </ul>"},{"location":"specs/bellatrix/fork/#introduction","title":"Introduction","text":"<p>This document describes the process of Bellatrix upgrade.</p>"},{"location":"specs/bellatrix/fork/#configuration","title":"Configuration","text":"Name Value <code>BELLATRIX_FORK_VERSION</code> <code>Version('0x02000000')</code> <code>BELLATRIX_FORK_EPOCH</code> <code>Epoch(144896)</code> (Sept 6, 2022, 11:34:47am UTC)"},{"location":"specs/bellatrix/fork/#fork-to-bellatrix","title":"Fork to Bellatrix","text":""},{"location":"specs/bellatrix/fork/#fork-trigger","title":"Fork trigger","text":"<p>TBD. Social consensus, along with state conditions such as epoch boundary, finality, deposits, active validator count, etc. may be part of the decision process to trigger the fork. For now we assume the condition will be triggered at epoch <code>BELLATRIX_FORK_EPOCH</code>.</p> <p>Note that for the pure Bellatrix networks, we don't apply <code>upgrade_to_bellatrix</code> since it starts with Bellatrix version logic.</p>"},{"location":"specs/bellatrix/fork/#upgrading-the-state","title":"Upgrading the state","text":"<p>As with the Phase0-to-Altair upgrade, the <code>state_transition</code> is modified to upgrade the <code>BeaconState</code>. The <code>BeaconState</code> upgrade runs as part of <code>process_slots</code>, slots with missing block proposals do not affect the upgrade time.</p> <p>If <code>state.slot % SLOTS_PER_EPOCH == 0</code> and <code>compute_epoch_at_slot(state.slot) == BELLATRIX_FORK_EPOCH</code>, an irregular state change is made to upgrade to Bellatrix. The upgrade occurs after the completion of the inner loop of <code>process_slots</code> that sets <code>state.slot</code> equal to <code>BELLATRIX_FORK_EPOCH * SLOTS_PER_EPOCH</code>.</p> <p>When multiple upgrades are scheduled for the same epoch (common for test-networks), all the upgrades run in sequence before resuming the regular state transition.</p> <pre><code>def upgrade_to_bellatrix(pre: altair.BeaconState) -&gt; BeaconState:\n    epoch = altair.get_current_epoch(pre)\n    post = BeaconState(\n        genesis_time=pre.genesis_time,\n        genesis_validators_root=pre.genesis_validators_root,\n        slot=pre.slot,\n        fork=Fork(\n            previous_version=pre.fork.current_version,\n            # [New in Bellatrix]\n            current_version=BELLATRIX_FORK_VERSION,\n            epoch=epoch,\n        ),\n        latest_block_header=pre.latest_block_header,\n        block_roots=pre.block_roots,\n        state_roots=pre.state_roots,\n        historical_roots=pre.historical_roots,\n        eth1_data=pre.eth1_data,\n        eth1_data_votes=pre.eth1_data_votes,\n        eth1_deposit_index=pre.eth1_deposit_index,\n        validators=pre.validators,\n        balances=pre.balances,\n        randao_mixes=pre.randao_mixes,\n        slashings=pre.slashings,\n        previous_epoch_participation=pre.previous_epoch_participation,\n        current_epoch_participation=pre.current_epoch_participation,\n        justification_bits=pre.justification_bits,\n        previous_justified_checkpoint=pre.previous_justified_checkpoint,\n        current_justified_checkpoint=pre.current_justified_checkpoint,\n        finalized_checkpoint=pre.finalized_checkpoint,\n        inactivity_scores=pre.inactivity_scores,\n        current_sync_committee=pre.current_sync_committee,\n        next_sync_committee=pre.next_sync_committee,\n        # [New in Bellatrix]\n        latest_execution_payload_header=ExecutionPayloadHeader(),\n    )\n\n    return post\n</code></pre>"},{"location":"specs/bellatrix/p2p-interface/","title":"Bellatrix -- Networking","text":"<ul> <li>Introduction</li> <li>Modifications in Bellatrix</li> <li>Helper functions<ul> <li>Modified <code>compute_fork_version</code></li> </ul> </li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>beacon_block</code></li> </ul> </li> <li>Transitioning the gossip</li> </ul> </li> <li>The Req/Resp domain<ul> <li>Messages</li> <li>BeaconBlocksByRange v2</li> <li>BeaconBlocksByRoot v2</li> </ul> </li> <li>Gossipsub<ul> <li>Why was the max gossip message size increased at Bellatrix?</li> </ul> </li> <li>Req/Resp<ul> <li>Why was the max chunk response size increased at Bellatrix?</li> <li>Why allow invalid payloads on the P2P network?</li> </ul> </li> </ul>"},{"location":"specs/bellatrix/p2p-interface/#introduction","title":"Introduction","text":"<p>This document contains the networking specification for Bellatrix.</p> <p>The specification of these changes continues in the same format as the network specifications of previous upgrades, and assumes them as pre-requisite. This document should be viewed as additive to the documents from Phase 0 and from Altair and will be referred to as the \"Phase 0 document\" and \"Altair document\" respectively, hereafter. Readers should understand the Phase 0 and Altair documents and use them as a basis to understand the changes outlined in this document.</p>"},{"location":"specs/bellatrix/p2p-interface/#modifications-in-bellatrix","title":"Modifications in Bellatrix","text":""},{"location":"specs/bellatrix/p2p-interface/#helper-functions","title":"Helper functions","text":""},{"location":"specs/bellatrix/p2p-interface/#modified-compute_fork_version","title":"Modified <code>compute_fork_version</code>","text":"<pre><code>def compute_fork_version(epoch: Epoch) -&gt; Version:\n    \"\"\"\n    Return the fork version at the given ``epoch``.\n    \"\"\"\n    if epoch &gt;= BELLATRIX_FORK_EPOCH:\n        return BELLATRIX_FORK_VERSION\n    if epoch &gt;= ALTAIR_FORK_EPOCH:\n        return ALTAIR_FORK_VERSION\n    return GENESIS_FORK_VERSION\n</code></pre>"},{"location":"specs/bellatrix/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":"<p>Some gossip meshes are upgraded in Bellatrix to support upgraded types.</p>"},{"location":"specs/bellatrix/p2p-interface/#topics-and-messages","title":"Topics and messages","text":"<p>Topics follow the same specification as in prior upgrades. All topics remain stable except the beacon block topic which is updated with the modified type.</p> <p>The specification around the creation, validation, and dissemination of messages has not changed from the Phase 0 and Altair documents unless explicitly noted here.</p> <p>The derivation of the <code>message-id</code> remains stable.</p> <p>The new topics along with the type of the <code>data</code> field of a gossipsub message are given in this table:</p> Name Message Type <code>beacon_block</code> <code>SignedBeaconBlock</code> (modified) <p>Note that the <code>ForkDigestValue</code> path segment of the topic separates the old and the new <code>beacon_block</code> topics.</p>"},{"location":"specs/bellatrix/p2p-interface/#global-topics","title":"Global topics","text":"<p>Bellatrix changes the type of the global beacon block topic.</p>"},{"location":"specs/bellatrix/p2p-interface/#beacon_block","title":"<code>beacon_block</code>","text":"<p>The type of the payload of this topic changes to the (modified) <code>SignedBeaconBlock</code> found in Bellatrix. Specifically, this type changes with the addition of <code>execution_payload</code> to the inner <code>BeaconBlockBody</code>. See Bellatrix state transition document for further details.</p> <p>Blocks with execution enabled will be permitted to propagate regardless of the validity of the execution payload. This prevents network segregation between optimistic and non-optimistic nodes.</p> <p>In addition to the gossip validations for this topic from prior specifications, the following validations MUST pass before forwarding the <code>signed_beacon_block</code> on the network. Alias <code>block = signed_beacon_block.message</code>, <code>execution_payload = block.body.execution_payload</code>.</p> <p>If the execution is enabled for the block -- i.e. <code>is_execution_enabled(state, block.body)</code> then validate the following:</p> <ul> <li>[REJECT] The block's execution payload timestamp is correct with respect to   the slot -- i.e.   <code>execution_payload.timestamp == compute_time_at_slot(state, block.slot)</code>.</li> <li>If <code>execution_payload</code> verification of block's parent by an execution node is   not complete:</li> <li>[REJECT] The block's parent (defined by <code>block.parent_root</code>) passes all     validation (excluding execution node verification of the     <code>block.body.execution_payload</code>).</li> <li>Otherwise:</li> <li>[IGNORE] The block's parent (defined by <code>block.parent_root</code>) passes all     validation (including execution node verification of the     <code>block.body.execution_payload</code>).</li> </ul> <p>The following gossip validation from prior specifications MUST NOT be applied if the execution is enabled for the block -- i.e. <code>is_execution_enabled(state, block.body)</code>:</p> <ul> <li>[REJECT] The block's parent (defined by <code>block.parent_root</code>) passes   validation.</li> </ul>"},{"location":"specs/bellatrix/p2p-interface/#transitioning-the-gossip","title":"Transitioning the gossip","text":"<p>See gossip transition details found in the Altair document for details on how to handle transitioning gossip topics.</p>"},{"location":"specs/bellatrix/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":"<p>Non-faulty, optimistic nodes may send blocks which result in an INVALID response from an execution engine. To prevent network segregation between optimistic and non-optimistic nodes, transmission of an INVALID execution payload via the Req/Resp domain SHOULD NOT cause a node to be down-scored or disconnected. Transmission of a block which is invalid due to any consensus layer rules (i.e., not execution layer rules) MAY result in down-scoring or disconnection.</p>"},{"location":"specs/bellatrix/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/bellatrix/p2p-interface/#beaconblocksbyrange-v2","title":"BeaconBlocksByRange v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_range/2/</code></p> <p>Request and Response remain unchanged. Bellatrix fork-digest is introduced to the <code>context</code> enum to specify Bellatrix block type.</p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code> <code>BELLATRIX_FORK_VERSION</code> <code>bellatrix.SignedBeaconBlock</code>"},{"location":"specs/bellatrix/p2p-interface/#beaconblocksbyroot-v2","title":"BeaconBlocksByRoot v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_root/2/</code></p> <p>Request and Response remain unchanged. Bellatrix fork-digest is introduced to the <code>context</code> enum to specify Bellatrix block type.</p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code> <code>BELLATRIX_FORK_VERSION</code> <code>bellatrix.SignedBeaconBlock</code>"},{"location":"specs/bellatrix/p2p-interface/#design-decision-rationale","title":"Design decision rationale","text":""},{"location":"specs/bellatrix/p2p-interface/#gossipsub","title":"Gossipsub","text":""},{"location":"specs/bellatrix/p2p-interface/#why-was-the-max-gossip-message-size-increased-at-bellatrix","title":"Why was the max gossip message size increased at Bellatrix?","text":"<p>With the addition of <code>ExecutionPayload</code> to <code>BeaconBlock</code>s, there is a dynamic field -- <code>transactions</code> -- which can validly exceed the <code>MAX_PAYLOAD_SIZE</code> limit (1 MiB) put in place at Phase 0, so MAX_PAYLOAD_SIZE has increased to 10 MiB on the network. At the <code>GAS_LIMIT</code> (~30M) currently seen on mainnet in 2021, a single transaction filled entirely with data at a cost of 16 gas per byte can create a valid <code>ExecutionPayload</code> of ~2 MiB. Thus we need a size limit to at least account for current mainnet conditions.</p> <p>Note, that due to additional size induced by the <code>BeaconBlock</code> contents (e.g. proposer signature, operations lists, etc) this does reduce the theoretical max valid <code>ExecutionPayload</code> (and <code>transactions</code> list) size as slightly lower than 10 MiB. Considering that <code>BeaconBlock</code> max size is on the order of 128 KiB in the worst case and the current gas limit (~30M) bounds max blocksize to less than 2 MiB today, this marginal difference in theoretical bounds will have zero impact on network functionality and security.</p>"},{"location":"specs/bellatrix/p2p-interface/#reqresp","title":"Req/Resp","text":""},{"location":"specs/bellatrix/p2p-interface/#why-was-the-max-chunk-response-size-increased-at-bellatrix","title":"Why was the max chunk response size increased at Bellatrix?","text":"<p>Similar to the discussion about the maximum gossip size increase, the <code>ExecutionPayload</code> type can cause <code>BeaconBlock</code>s to exceed the 1 MiB bounds put in place during Phase 0.</p> <p>As with the gossip limit, 10 MiB is selected because this is firmly above any valid block sizes in the range of gas limits expected in the medium term.</p> <p>As with both gossip and req/rsp maximum values, type-specific limits should always by simultaneously respected.</p>"},{"location":"specs/bellatrix/p2p-interface/#why-allow-invalid-payloads-on-the-p2p-network","title":"Why allow invalid payloads on the P2P network?","text":"<p>The specification allows blocks with invalid execution payloads to propagate across gossip and via RPC calls. The reasoning for this is as follows:</p> <ol> <li>Optimistic nodes must listen to block gossip to obtain a view of the head of    the chain.</li> <li>Therefore, optimistic nodes must propagate gossip blocks. Otherwise, they'd    be censoring.</li> <li>If optimistic nodes will propagate blocks via gossip, then they must respond    to requests for the parent via RPC.</li> <li>Therefore, optimistic nodes must send optimistic blocks via RPC.</li> </ol> <p>So, to prevent network segregation from optimistic nodes inadvertently sending invalid execution payloads, nodes should never downscore/disconnect nodes due to such invalid payloads. This does open the network to some DoS attacks from invalid execution payloads, but the scope of actors is limited to validators who can put those payloads in valid (and slashable) beacon blocks. Therefore, it is argued that the DoS risk introduced in tolerable.</p> <p>More complicated schemes are possible that could restrict invalid payloads from RPC. However, it's not clear that complexity is warranted.</p>"},{"location":"specs/bellatrix/validator/","title":"Bellatrix -- Honest Validator","text":"<ul> <li>Introduction</li> <li>Prerequisites</li> <li>Helpers</li> <li><code>GetPayloadResponse</code></li> <li><code>get_pow_block_at_terminal_total_difficulty</code></li> <li><code>get_terminal_pow_block</code></li> <li>Protocols</li> <li><code>ExecutionEngine</code><ul> <li><code>get_payload</code></li> </ul> </li> <li>Beacon chain responsibilities</li> <li>Block proposal<ul> <li>Constructing the <code>BeaconBlockBody</code></li> <li>ExecutionPayload</li> </ul> </li> </ul>"},{"location":"specs/bellatrix/validator/#introduction","title":"Introduction","text":"<p>This document represents the changes to be made in the code of an \"honest validator\" to implement executable beacon chain proposal.</p>"},{"location":"specs/bellatrix/validator/#prerequisites","title":"Prerequisites","text":"<p>This document is an extension of the Altair -- Honest Validator guide. All behaviors and definitions defined in this document, and documents it extends, carry over unless explicitly noted or overridden.</p> <p>All terminology, constants, functions, and protocol mechanics defined in the updated Beacon Chain doc of Bellatrix are requisite for this document and used throughout. Please see related Beacon Chain doc before continuing and use them as a reference throughout.</p>"},{"location":"specs/bellatrix/validator/#helpers","title":"Helpers","text":""},{"location":"specs/bellatrix/validator/#getpayloadresponse","title":"<code>GetPayloadResponse</code>","text":"<pre><code>@dataclass\nclass GetPayloadResponse(object):\n    execution_payload: ExecutionPayload\n</code></pre>"},{"location":"specs/bellatrix/validator/#get_pow_block_at_terminal_total_difficulty","title":"<code>get_pow_block_at_terminal_total_difficulty</code>","text":"<pre><code>def get_pow_block_at_terminal_total_difficulty(\n    pow_chain: Dict[Hash32, PowBlock],\n) -&gt; Optional[PowBlock]:\n    # `pow_chain` abstractly represents all blocks in the PoW chain\n    for block in pow_chain.values():\n        block_reached_ttd = block.total_difficulty &gt;= TERMINAL_TOTAL_DIFFICULTY\n        if block_reached_ttd:\n            # If genesis block, no parent exists so reaching TTD alone qualifies as valid terminal block\n            if block.parent_hash == Hash32():\n                return block\n            parent = pow_chain[block.parent_hash]\n            parent_reached_ttd = parent.total_difficulty &gt;= TERMINAL_TOTAL_DIFFICULTY\n            if not parent_reached_ttd:\n                return block\n\n    return None\n</code></pre>"},{"location":"specs/bellatrix/validator/#get_terminal_pow_block","title":"<code>get_terminal_pow_block</code>","text":"<pre><code>def get_terminal_pow_block(pow_chain: Dict[Hash32, PowBlock]) -&gt; Optional[PowBlock]:\n    if TERMINAL_BLOCK_HASH != Hash32():\n        # Terminal block hash override takes precedence over terminal total difficulty\n        if TERMINAL_BLOCK_HASH in pow_chain:\n            return pow_chain[TERMINAL_BLOCK_HASH]\n        else:\n            return None\n\n    return get_pow_block_at_terminal_total_difficulty(pow_chain)\n</code></pre> <p>Note: This function does not use simple serialize <code>hash_tree_root</code> as to avoid requiring simple serialize hashing capabilities in the Execution Layer.</p>"},{"location":"specs/bellatrix/validator/#protocols","title":"Protocols","text":""},{"location":"specs/bellatrix/validator/#executionengine","title":"<code>ExecutionEngine</code>","text":"<p>Note: <code>get_payload</code> function is added to the <code>ExecutionEngine</code> protocol for use as a validator.</p> <p>The body of this function is implementation dependent. The Engine API may be used to implement it with an external execution engine.</p>"},{"location":"specs/bellatrix/validator/#get_payload","title":"<code>get_payload</code>","text":"<p>Given the <code>payload_id</code>, <code>get_payload</code> returns <code>GetPayloadResponse</code> with the most recent version of the execution payload that has been built since the corresponding call to <code>notify_forkchoice_updated</code> method.</p> <pre><code>def get_payload(self: ExecutionEngine, payload_id: PayloadId) -&gt; GetPayloadResponse:\n    \"\"\"\n    Return ``GetPayloadResponse`` object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"specs/bellatrix/validator/#beacon-chain-responsibilities","title":"Beacon chain responsibilities","text":"<p>All validator responsibilities remain unchanged other than those noted below. Namely, the transition block handling and the addition of <code>ExecutionPayload</code>.</p> <p>Note: A validator must not propose on or attest to a block that isn't deemed valid, i.e. hasn't yet passed the beacon chain state transition and execution validations. In future upgrades, an \"execution Proof-of-Custody\" will be integrated to prevent outsourcing of execution payload validations.</p>"},{"location":"specs/bellatrix/validator/#block-proposal","title":"Block proposal","text":""},{"location":"specs/bellatrix/validator/#constructing-the-beaconblockbody","title":"Constructing the <code>BeaconBlockBody</code>","text":""},{"location":"specs/bellatrix/validator/#executionpayload","title":"ExecutionPayload","text":"<p>To obtain an execution payload, a block proposer building a block on top of a <code>state</code> must take the following actions:</p> <ol> <li>Set    <code>payload_id = prepare_execution_payload(state, pow_chain, safe_block_hash, finalized_block_hash, suggested_fee_recipient, execution_engine)</code>,    where:    - <code>state</code> is the state object after applying <code>process_slots(state, slot)</code>      transition to the resulting state of the parent block processing    - <code>pow_chain</code> is a <code>Dict[Hash32, PowBlock]</code> dictionary that abstractly      represents all blocks in the PoW chain with block hash as the dictionary      key    - <code>safe_block_hash</code> is the return value of the      <code>get_safe_execution_block_hash(store: Store)</code> function call    - <code>finalized_block_hash</code> is the block hash of the latest finalized execution      payload (<code>Hash32()</code> if none yet finalized)    - <code>suggested_fee_recipient</code> is the value suggested to be used for the      <code>fee_recipient</code> field of the execution payload</li> </ol> <pre><code>def prepare_execution_payload(\n    state: BeaconState,\n    safe_block_hash: Hash32,\n    finalized_block_hash: Hash32,\n    suggested_fee_recipient: ExecutionAddress,\n    execution_engine: ExecutionEngine,\n    pow_chain: Optional[Dict[Hash32, PowBlock]] = None,\n) -&gt; Optional[PayloadId]:\n    if not is_merge_transition_complete(state):\n        assert pow_chain is not None\n        is_terminal_block_hash_set = TERMINAL_BLOCK_HASH != Hash32()\n        is_activation_epoch_reached = (\n            get_current_epoch(state) &gt;= TERMINAL_BLOCK_HASH_ACTIVATION_EPOCH\n        )\n        if is_terminal_block_hash_set and not is_activation_epoch_reached:\n            # Terminal block hash is set but activation epoch is not yet reached, no prepare payload call is needed\n            return None\n\n        terminal_pow_block = get_terminal_pow_block(pow_chain)\n        if terminal_pow_block is None:\n            # Pre-merge, no prepare payload call is needed\n            return None\n        # Signify merge via producing on top of the terminal PoW block\n        parent_hash = terminal_pow_block.block_hash\n    else:\n        # Post-merge, normal payload\n        parent_hash = state.latest_execution_payload_header.block_hash\n\n    # Set the forkchoice head and initiate the payload build process\n    payload_attributes = PayloadAttributes(\n        timestamp=compute_time_at_slot(state, state.slot),\n        prev_randao=get_randao_mix(state, get_current_epoch(state)),\n        suggested_fee_recipient=suggested_fee_recipient,\n    )\n    return execution_engine.notify_forkchoice_updated(\n        head_block_hash=parent_hash,\n        safe_block_hash=safe_block_hash,\n        finalized_block_hash=finalized_block_hash,\n        payload_attributes=payload_attributes,\n    )\n</code></pre> <ol> <li>Set    <code>block.body.execution_payload = get_execution_payload(payload_id, execution_engine)</code>,    where:</li> </ol> <pre><code>def get_execution_payload(\n    payload_id: Optional[PayloadId], execution_engine: ExecutionEngine\n) -&gt; ExecutionPayload:\n    if payload_id is None:\n        # Pre-merge, empty payload\n        return ExecutionPayload()\n    else:\n        return execution_engine.get_payload(payload_id).execution_payload\n</code></pre> <p>Note: It is recommended for a validator to call <code>prepare_execution_payload</code> as soon as input parameters become known, and make subsequent calls to this function when any of these parameters gets updated.</p>"},{"location":"specs/capella/","title":"Index","text":""},{"location":"specs/capella/#core","title":"Core","text":"<ul> <li>Beacon Chain</li> <li>Fork Choice</li> <li>Fork</li> <li>P2P Interface</li> <li>Validator</li> </ul>"},{"location":"specs/capella/#light-client","title":"Light Client","text":"<ul> <li>Fork</li> <li>Full Node</li> <li>P2P Interface</li> <li>Sync Protocol</li> </ul>"},{"location":"specs/capella/beacon-chain/","title":"Capella -- The Beacon Chain","text":"<ul> <li>Introduction</li> <li>Custom types</li> <li>Domain types</li> <li>Preset</li> <li>Max operations per block</li> <li>Execution</li> <li>Withdrawals processing</li> <li>Containers</li> <li>New containers<ul> <li><code>Withdrawal</code></li> <li><code>BLSToExecutionChange</code></li> <li><code>SignedBLSToExecutionChange</code></li> <li><code>HistoricalSummary</code></li> </ul> </li> <li>Modified containers<ul> <li><code>ExecutionPayload</code></li> <li><code>ExecutionPayloadHeader</code></li> <li><code>BeaconBlockBody</code></li> <li><code>BeaconState</code></li> </ul> </li> <li>Helpers</li> <li>Predicates<ul> <li><code>has_eth1_withdrawal_credential</code></li> <li><code>is_fully_withdrawable_validator</code></li> <li><code>is_partially_withdrawable_validator</code></li> </ul> </li> <li>Beacon chain state transition function</li> <li>Epoch processing<ul> <li>Historical summaries updates</li> </ul> </li> <li>Block processing<ul> <li>New <code>get_expected_withdrawals</code></li> <li>New <code>process_withdrawals</code></li> <li>Modified <code>process_execution_payload</code></li> <li>Modified <code>process_operations</code></li> <li>New <code>process_bls_to_execution_change</code></li> </ul> </li> </ul>"},{"location":"specs/capella/beacon-chain/#introduction","title":"Introduction","text":"<p>Capella is a consensus-layer upgrade containing a number of features related to validator withdrawals. Including:</p> <ul> <li>Automatic withdrawals of <code>withdrawable</code> validators.</li> <li>Partial withdrawals sweep for validators with 0x01 withdrawal credentials and   balances in excess of <code>MAX_EFFECTIVE_BALANCE</code>.</li> <li>Operation to change from <code>BLS_WITHDRAWAL_PREFIX</code> to   <code>ETH1_ADDRESS_WITHDRAWAL_PREFIX</code> versioned withdrawal credentials to enable   withdrawals for a validator.</li> </ul> <p>Another new feature is the new independent state and block historical accumulators that replace the original singular historical roots. With these accumulators, it becomes possible to validate the entire block history that led up to that particular state without any additional information beyond the state and the blocks.</p>"},{"location":"specs/capella/beacon-chain/#custom-types","title":"Custom types","text":"<p>We define the following Python custom types for type hinting and readability:</p> Name SSZ equivalent Description <code>WithdrawalIndex</code> <code>uint64</code> an index of a <code>Withdrawal</code>"},{"location":"specs/capella/beacon-chain/#domain-types","title":"Domain types","text":"Name Value <code>DOMAIN_BLS_TO_EXECUTION_CHANGE</code> <code>DomainType('0x0A000000')</code>"},{"location":"specs/capella/beacon-chain/#preset","title":"Preset","text":""},{"location":"specs/capella/beacon-chain/#max-operations-per-block","title":"Max operations per block","text":"Name Value <code>MAX_BLS_TO_EXECUTION_CHANGES</code> <code>2**4</code> (= 16)"},{"location":"specs/capella/beacon-chain/#execution","title":"Execution","text":"Name Value Description <code>MAX_WITHDRAWALS_PER_PAYLOAD</code> <code>uint64(2**4)</code> (= 16) Maximum amount of withdrawals allowed in each payload"},{"location":"specs/capella/beacon-chain/#withdrawals-processing","title":"Withdrawals processing","text":"Name Value <code>MAX_VALIDATORS_PER_WITHDRAWALS_SWEEP</code> <code>2**14</code> (= 16,384)"},{"location":"specs/capella/beacon-chain/#containers","title":"Containers","text":""},{"location":"specs/capella/beacon-chain/#new-containers","title":"New containers","text":""},{"location":"specs/capella/beacon-chain/#withdrawal","title":"<code>Withdrawal</code>","text":"<pre><code>class Withdrawal(Container):\n    index: WithdrawalIndex\n    validator_index: ValidatorIndex\n    address: ExecutionAddress\n    amount: Gwei\n</code></pre>"},{"location":"specs/capella/beacon-chain/#blstoexecutionchange","title":"<code>BLSToExecutionChange</code>","text":"<pre><code>class BLSToExecutionChange(Container):\n    validator_index: ValidatorIndex\n    from_bls_pubkey: BLSPubkey\n    to_execution_address: ExecutionAddress\n</code></pre>"},{"location":"specs/capella/beacon-chain/#signedblstoexecutionchange","title":"<code>SignedBLSToExecutionChange</code>","text":"<pre><code>class SignedBLSToExecutionChange(Container):\n    message: BLSToExecutionChange\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/capella/beacon-chain/#historicalsummary","title":"<code>HistoricalSummary</code>","text":"<p>Note: <code>HistoricalSummary</code> matches the components of the phase0 <code>HistoricalBatch</code> making the two *hash_tree_root-compatible.</p> <pre><code>class HistoricalSummary(Container):\n    block_summary_root: Root\n    state_summary_root: Root\n</code></pre>"},{"location":"specs/capella/beacon-chain/#modified-containers","title":"Modified containers","text":""},{"location":"specs/capella/beacon-chain/#executionpayload","title":"<code>ExecutionPayload</code>","text":"<pre><code>class ExecutionPayload(Container):\n    parent_hash: Hash32\n    fee_recipient: ExecutionAddress\n    state_root: Bytes32\n    receipts_root: Bytes32\n    logs_bloom: ByteVector[BYTES_PER_LOGS_BLOOM]\n    prev_randao: Bytes32\n    block_number: uint64\n    gas_limit: uint64\n    gas_used: uint64\n    timestamp: uint64\n    extra_data: ByteList[MAX_EXTRA_DATA_BYTES]\n    base_fee_per_gas: uint256\n    block_hash: Hash32\n    transactions: List[Transaction, MAX_TRANSACTIONS_PER_PAYLOAD]\n    # [New in Capella]\n    withdrawals: List[Withdrawal, MAX_WITHDRAWALS_PER_PAYLOAD]\n</code></pre>"},{"location":"specs/capella/beacon-chain/#executionpayloadheader","title":"<code>ExecutionPayloadHeader</code>","text":"<pre><code>class ExecutionPayloadHeader(Container):\n    parent_hash: Hash32\n    fee_recipient: ExecutionAddress\n    state_root: Bytes32\n    receipts_root: Bytes32\n    logs_bloom: ByteVector[BYTES_PER_LOGS_BLOOM]\n    prev_randao: Bytes32\n    block_number: uint64\n    gas_limit: uint64\n    gas_used: uint64\n    timestamp: uint64\n    extra_data: ByteList[MAX_EXTRA_DATA_BYTES]\n    base_fee_per_gas: uint256\n    block_hash: Hash32\n    transactions_root: Root\n    # [New in Capella]\n    withdrawals_root: Root\n</code></pre>"},{"location":"specs/capella/beacon-chain/#beaconblockbody","title":"<code>BeaconBlockBody</code>","text":"<pre><code>class BeaconBlockBody(Container):\n    randao_reveal: BLSSignature\n    eth1_data: Eth1Data\n    graffiti: Bytes32\n    proposer_slashings: List[ProposerSlashing, MAX_PROPOSER_SLASHINGS]\n    attester_slashings: List[AttesterSlashing, MAX_ATTESTER_SLASHINGS]\n    attestations: List[Attestation, MAX_ATTESTATIONS]\n    deposits: List[Deposit, MAX_DEPOSITS]\n    voluntary_exits: List[SignedVoluntaryExit, MAX_VOLUNTARY_EXITS]\n    sync_aggregate: SyncAggregate\n    execution_payload: ExecutionPayload\n    # [New in Capella]\n    bls_to_execution_changes: List[SignedBLSToExecutionChange, MAX_BLS_TO_EXECUTION_CHANGES]\n</code></pre>"},{"location":"specs/capella/beacon-chain/#beaconstate","title":"<code>BeaconState</code>","text":"<p>Note: <code>historical_roots</code> is frozen in Capella and is replaced by <code>historical_summaries</code>.</p> <pre><code>class BeaconState(Container):\n    genesis_time: uint64\n    genesis_validators_root: Root\n    slot: Slot\n    fork: Fork\n    latest_block_header: BeaconBlockHeader\n    block_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    state_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    historical_roots: List[Root, HISTORICAL_ROOTS_LIMIT]\n    eth1_data: Eth1Data\n    eth1_data_votes: List[Eth1Data, EPOCHS_PER_ETH1_VOTING_PERIOD * SLOTS_PER_EPOCH]\n    eth1_deposit_index: uint64\n    validators: List[Validator, VALIDATOR_REGISTRY_LIMIT]\n    balances: List[Gwei, VALIDATOR_REGISTRY_LIMIT]\n    randao_mixes: Vector[Bytes32, EPOCHS_PER_HISTORICAL_VECTOR]\n    slashings: Vector[Gwei, EPOCHS_PER_SLASHINGS_VECTOR]\n    previous_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    current_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    justification_bits: Bitvector[JUSTIFICATION_BITS_LENGTH]\n    previous_justified_checkpoint: Checkpoint\n    current_justified_checkpoint: Checkpoint\n    finalized_checkpoint: Checkpoint\n    inactivity_scores: List[uint64, VALIDATOR_REGISTRY_LIMIT]\n    current_sync_committee: SyncCommittee\n    next_sync_committee: SyncCommittee\n    # [Modified in Capella]\n    latest_execution_payload_header: ExecutionPayloadHeader\n    # [New in Capella]\n    next_withdrawal_index: WithdrawalIndex\n    # [New in Capella]\n    next_withdrawal_validator_index: ValidatorIndex\n    # [New in Capella]\n    historical_summaries: List[HistoricalSummary, HISTORICAL_ROOTS_LIMIT]\n</code></pre>"},{"location":"specs/capella/beacon-chain/#helpers","title":"Helpers","text":""},{"location":"specs/capella/beacon-chain/#predicates","title":"Predicates","text":""},{"location":"specs/capella/beacon-chain/#has_eth1_withdrawal_credential","title":"<code>has_eth1_withdrawal_credential</code>","text":"<pre><code>def has_eth1_withdrawal_credential(validator: Validator) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` has an 0x01 prefixed \"eth1\" withdrawal credential.\n    \"\"\"\n    return validator.withdrawal_credentials[:1] == ETH1_ADDRESS_WITHDRAWAL_PREFIX\n</code></pre>"},{"location":"specs/capella/beacon-chain/#is_fully_withdrawable_validator","title":"<code>is_fully_withdrawable_validator</code>","text":"<pre><code>def is_fully_withdrawable_validator(validator: Validator, balance: Gwei, epoch: Epoch) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` is fully withdrawable.\n    \"\"\"\n    return (\n        has_eth1_withdrawal_credential(validator)\n        and validator.withdrawable_epoch &lt;= epoch\n        and balance &gt; 0\n    )\n</code></pre>"},{"location":"specs/capella/beacon-chain/#is_partially_withdrawable_validator","title":"<code>is_partially_withdrawable_validator</code>","text":"<pre><code>def is_partially_withdrawable_validator(validator: Validator, balance: Gwei) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` is partially withdrawable.\n    \"\"\"\n    has_max_effective_balance = validator.effective_balance == MAX_EFFECTIVE_BALANCE\n    has_excess_balance = balance &gt; MAX_EFFECTIVE_BALANCE\n    return (\n        has_eth1_withdrawal_credential(validator)\n        and has_max_effective_balance\n        and has_excess_balance\n    )\n</code></pre>"},{"location":"specs/capella/beacon-chain/#beacon-chain-state-transition-function","title":"Beacon chain state transition function","text":""},{"location":"specs/capella/beacon-chain/#epoch-processing","title":"Epoch processing","text":"<p>Note: The function <code>process_historical_summaries_update</code> replaces <code>process_historical_roots_update</code> in Capella.</p> <pre><code>def process_epoch(state: BeaconState) -&gt; None:\n    process_justification_and_finalization(state)\n    process_inactivity_updates(state)\n    process_rewards_and_penalties(state)\n    process_registry_updates(state)\n    process_slashings(state)\n    process_eth1_data_reset(state)\n    process_effective_balance_updates(state)\n    process_slashings_reset(state)\n    process_randao_mixes_reset(state)\n    # [Modified in Capella]\n    process_historical_summaries_update(state)\n    process_participation_flag_updates(state)\n    process_sync_committee_updates(state)\n</code></pre>"},{"location":"specs/capella/beacon-chain/#historical-summaries-updates","title":"Historical summaries updates","text":"<pre><code>def process_historical_summaries_update(state: BeaconState) -&gt; None:\n    # Set historical block root accumulator.\n    next_epoch = Epoch(get_current_epoch(state) + 1)\n    if next_epoch % (SLOTS_PER_HISTORICAL_ROOT // SLOTS_PER_EPOCH) == 0:\n        historical_summary = HistoricalSummary(\n            block_summary_root=hash_tree_root(state.block_roots),\n            state_summary_root=hash_tree_root(state.state_roots),\n        )\n        state.historical_summaries.append(historical_summary)\n</code></pre>"},{"location":"specs/capella/beacon-chain/#block-processing","title":"Block processing","text":"<pre><code>def process_block(state: BeaconState, block: BeaconBlock) -&gt; None:\n    process_block_header(state, block)\n    # [Modified in Capella]\n    # Removed `is_execution_enabled` call\n    # [New in Capella]\n    process_withdrawals(state, block.body.execution_payload)\n    # [Modified in Capella]\n    process_execution_payload(state, block.body, EXECUTION_ENGINE)\n    process_randao(state, block.body)\n    process_eth1_data(state, block.body)\n    # [Modified in Capella]\n    process_operations(state, block.body)\n    process_sync_aggregate(state, block.body.sync_aggregate)\n</code></pre>"},{"location":"specs/capella/beacon-chain/#new-get_expected_withdrawals","title":"New <code>get_expected_withdrawals</code>","text":"<pre><code>def get_expected_withdrawals(state: BeaconState) -&gt; Sequence[Withdrawal]:\n    epoch = get_current_epoch(state)\n    withdrawal_index = state.next_withdrawal_index\n    validator_index = state.next_withdrawal_validator_index\n    withdrawals: List[Withdrawal] = []\n    bound = min(len(state.validators), MAX_VALIDATORS_PER_WITHDRAWALS_SWEEP)\n    for _ in range(bound):\n        validator = state.validators[validator_index]\n        balance = state.balances[validator_index]\n        if is_fully_withdrawable_validator(validator, balance, epoch):\n            withdrawals.append(\n                Withdrawal(\n                    index=withdrawal_index,\n                    validator_index=validator_index,\n                    address=ExecutionAddress(validator.withdrawal_credentials[12:]),\n                    amount=balance,\n                )\n            )\n            withdrawal_index += WithdrawalIndex(1)\n        elif is_partially_withdrawable_validator(validator, balance):\n            withdrawals.append(\n                Withdrawal(\n                    index=withdrawal_index,\n                    validator_index=validator_index,\n                    address=ExecutionAddress(validator.withdrawal_credentials[12:]),\n                    amount=balance - MAX_EFFECTIVE_BALANCE,\n                )\n            )\n            withdrawal_index += WithdrawalIndex(1)\n        if len(withdrawals) == MAX_WITHDRAWALS_PER_PAYLOAD:\n            break\n        validator_index = ValidatorIndex((validator_index + 1) % len(state.validators))\n    return withdrawals\n</code></pre>"},{"location":"specs/capella/beacon-chain/#new-process_withdrawals","title":"New <code>process_withdrawals</code>","text":"<pre><code>def process_withdrawals(state: BeaconState, payload: ExecutionPayload) -&gt; None:\n    expected_withdrawals = get_expected_withdrawals(state)\n    assert payload.withdrawals == expected_withdrawals\n\n    for withdrawal in expected_withdrawals:\n        decrease_balance(state, withdrawal.validator_index, withdrawal.amount)\n\n    # Update the next withdrawal index if this block contained withdrawals\n    if len(expected_withdrawals) != 0:\n        latest_withdrawal = expected_withdrawals[-1]\n        state.next_withdrawal_index = WithdrawalIndex(latest_withdrawal.index + 1)\n\n    # Update the next validator index to start the next withdrawal sweep\n    if len(expected_withdrawals) == MAX_WITHDRAWALS_PER_PAYLOAD:\n        # Next sweep starts after the latest withdrawal's validator index\n        next_validator_index = ValidatorIndex(\n            (expected_withdrawals[-1].validator_index + 1) % len(state.validators)\n        )\n        state.next_withdrawal_validator_index = next_validator_index\n    else:\n        # Advance sweep by the max length of the sweep if there was not a full set of withdrawals\n        next_index = state.next_withdrawal_validator_index + MAX_VALIDATORS_PER_WITHDRAWALS_SWEEP\n        next_validator_index = ValidatorIndex(next_index % len(state.validators))\n        state.next_withdrawal_validator_index = next_validator_index\n</code></pre>"},{"location":"specs/capella/beacon-chain/#modified-process_execution_payload","title":"Modified <code>process_execution_payload</code>","text":"<p>Note: The function <code>process_execution_payload</code> is modified to use the new <code>ExecutionPayloadHeader</code> type and removed the <code>is_merge_transition_complete</code> check.</p> <pre><code>def process_execution_payload(\n    state: BeaconState, body: BeaconBlockBody, execution_engine: ExecutionEngine\n) -&gt; None:\n    payload = body.execution_payload\n    # [Modified in Capella]\n    # Removed `is_merge_transition_complete` check\n    # Verify consistency of the parent hash with respect to the previous execution payload header\n    assert payload.parent_hash == state.latest_execution_payload_header.block_hash\n    # Verify prev_randao\n    assert payload.prev_randao == get_randao_mix(state, get_current_epoch(state))\n    # Verify timestamp\n    assert payload.timestamp == compute_time_at_slot(state, state.slot)\n    # Verify the execution payload is valid\n    assert execution_engine.verify_and_notify_new_payload(\n        NewPayloadRequest(execution_payload=payload)\n    )\n    # Cache execution payload header\n    state.latest_execution_payload_header = ExecutionPayloadHeader(\n        parent_hash=payload.parent_hash,\n        fee_recipient=payload.fee_recipient,\n        state_root=payload.state_root,\n        receipts_root=payload.receipts_root,\n        logs_bloom=payload.logs_bloom,\n        prev_randao=payload.prev_randao,\n        block_number=payload.block_number,\n        gas_limit=payload.gas_limit,\n        gas_used=payload.gas_used,\n        timestamp=payload.timestamp,\n        extra_data=payload.extra_data,\n        base_fee_per_gas=payload.base_fee_per_gas,\n        block_hash=payload.block_hash,\n        transactions_root=hash_tree_root(payload.transactions),\n        # [New in Capella]\n        withdrawals_root=hash_tree_root(payload.withdrawals),\n    )\n</code></pre>"},{"location":"specs/capella/beacon-chain/#modified-process_operations","title":"Modified <code>process_operations</code>","text":"<p>Note: The function <code>process_operations</code> is modified to process <code>BLSToExecutionChange</code> operations included in the block.</p> <pre><code>def process_operations(state: BeaconState, body: BeaconBlockBody) -&gt; None:\n    # Verify that outstanding deposits are processed up to the maximum number of deposits\n    assert len(body.deposits) == min(\n        MAX_DEPOSITS, state.eth1_data.deposit_count - state.eth1_deposit_index\n    )\n\n    def for_ops(operations: Sequence[Any], fn: Callable[[BeaconState, Any], None]) -&gt; None:\n        for operation in operations:\n            fn(state, operation)\n\n    for_ops(body.proposer_slashings, process_proposer_slashing)\n    for_ops(body.attester_slashings, process_attester_slashing)\n    for_ops(body.attestations, process_attestation)\n    for_ops(body.deposits, process_deposit)\n    for_ops(body.voluntary_exits, process_voluntary_exit)\n    # [New in Capella]\n    for_ops(body.bls_to_execution_changes, process_bls_to_execution_change)\n</code></pre>"},{"location":"specs/capella/beacon-chain/#new-process_bls_to_execution_change","title":"New <code>process_bls_to_execution_change</code>","text":"<pre><code>def process_bls_to_execution_change(\n    state: BeaconState, signed_address_change: SignedBLSToExecutionChange\n) -&gt; None:\n    address_change = signed_address_change.message\n\n    assert address_change.validator_index &lt; len(state.validators)\n\n    validator = state.validators[address_change.validator_index]\n\n    assert validator.withdrawal_credentials[:1] == BLS_WITHDRAWAL_PREFIX\n    assert validator.withdrawal_credentials[1:] == hash(address_change.from_bls_pubkey)[1:]\n\n    # Fork-agnostic domain since address changes are valid across forks\n    domain = compute_domain(\n        DOMAIN_BLS_TO_EXECUTION_CHANGE, genesis_validators_root=state.genesis_validators_root\n    )\n    signing_root = compute_signing_root(address_change, domain)\n    assert bls.Verify(address_change.from_bls_pubkey, signing_root, signed_address_change.signature)\n\n    validator.withdrawal_credentials = (\n        ETH1_ADDRESS_WITHDRAWAL_PREFIX + b\"\\x00\" * 11 + address_change.to_execution_address\n    )\n</code></pre>"},{"location":"specs/capella/fork-choice/","title":"Capella -- Fork Choice","text":"<ul> <li>Introduction</li> <li>Protocols</li> <li><code>ExecutionEngine</code><ul> <li><code>notify_forkchoice_updated</code></li> </ul> </li> <li>Helpers</li> <li>Modified <code>PayloadAttributes</code></li> <li>Updated fork-choice handlers</li> <li><code>on_block</code></li> </ul>"},{"location":"specs/capella/fork-choice/#introduction","title":"Introduction","text":"<p>This is the modification of the fork choice according to the Capella upgrade.</p> <p>Unless stated explicitly, all prior functionality from Bellatrix is inherited.</p>"},{"location":"specs/capella/fork-choice/#protocols","title":"Protocols","text":""},{"location":"specs/capella/fork-choice/#executionengine","title":"<code>ExecutionEngine</code>","text":"<p>Note: The <code>notify_forkchoice_updated</code> function is modified in the <code>ExecutionEngine</code> protocol at the Capella upgrade.</p>"},{"location":"specs/capella/fork-choice/#notify_forkchoice_updated","title":"<code>notify_forkchoice_updated</code>","text":"<p>The only change made is to the <code>PayloadAttributes</code> container through the addition of <code>withdrawals</code>. Otherwise, <code>notify_forkchoice_updated</code> inherits all prior functionality.</p> <pre><code>def notify_forkchoice_updated(\n    self: ExecutionEngine,\n    head_block_hash: Hash32,\n    safe_block_hash: Hash32,\n    finalized_block_hash: Hash32,\n    payload_attributes: Optional[PayloadAttributes],\n) -&gt; Optional[PayloadId]: ...\n</code></pre>"},{"location":"specs/capella/fork-choice/#helpers","title":"Helpers","text":""},{"location":"specs/capella/fork-choice/#modified-payloadattributes","title":"Modified <code>PayloadAttributes</code>","text":"<p><code>PayloadAttributes</code> is extended with the <code>withdrawals</code> field.</p> <pre><code>@dataclass\nclass PayloadAttributes(object):\n    timestamp: uint64\n    prev_randao: Bytes32\n    suggested_fee_recipient: ExecutionAddress\n    # [New in Capella]\n    withdrawals: Sequence[Withdrawal]\n</code></pre>"},{"location":"specs/capella/fork-choice/#updated-fork-choice-handlers","title":"Updated fork-choice handlers","text":""},{"location":"specs/capella/fork-choice/#on_block","title":"<code>on_block</code>","text":"<p>Note: The only modification is the deletion of the verification of merge transition block conditions.</p> <pre><code>def on_block(store: Store, signed_block: SignedBeaconBlock) -&gt; None:\n    \"\"\"\n    Run ``on_block`` upon receiving a new block.\n    \"\"\"\n    block = signed_block.message\n    # Parent block must be known\n    assert block.parent_root in store.block_states\n    # Blocks cannot be in the future. If they are, their consideration must be delayed until they are in the past.\n    assert get_current_slot(store) &gt;= block.slot\n\n    # Check that block is later than the finalized epoch slot (optimization to reduce calls to get_ancestor)\n    finalized_slot = compute_start_slot_at_epoch(store.finalized_checkpoint.epoch)\n    assert block.slot &gt; finalized_slot\n    # Check block is a descendant of the finalized block at the checkpoint finalized slot\n    finalized_checkpoint_block = get_checkpoint_block(\n        store,\n        block.parent_root,\n        store.finalized_checkpoint.epoch,\n    )\n    assert store.finalized_checkpoint.root == finalized_checkpoint_block\n\n    # Check the block is valid and compute the post-state\n    # Make a copy of the state to avoid mutability issues\n    state = copy(store.block_states[block.parent_root])\n    block_root = hash_tree_root(block)\n    state_transition(state, signed_block, True)\n\n    # Add new block to the store\n    store.blocks[block_root] = block\n    # Add new state for this block to the store\n    store.block_states[block_root] = state\n\n    # Add block timeliness to the store\n    seconds_since_genesis = store.time - store.genesis_time\n    time_into_slot_ms = seconds_to_milliseconds(seconds_since_genesis) % SLOT_DURATION_MS\n    attestation_threshold_ms = get_slot_component_duration_ms(ATTESTATION_DUE_BPS)\n    is_before_attesting_interval = time_into_slot_ms &lt; attestation_threshold_ms\n    is_timely = get_current_slot(store) == block.slot and is_before_attesting_interval\n    store.block_timeliness[hash_tree_root(block)] = is_timely\n\n    # Add proposer score boost if the block is timely and not conflicting with an existing block\n    is_first_block = store.proposer_boost_root == Root()\n    if is_timely and is_first_block:\n        store.proposer_boost_root = hash_tree_root(block)\n\n    # Update checkpoints in store if necessary\n    update_checkpoints(store, state.current_justified_checkpoint, state.finalized_checkpoint)\n\n    # Eagerly compute unrealized justification and finality.\n    compute_pulled_up_tip(store, block_root)\n</code></pre>"},{"location":"specs/capella/fork/","title":"Capella -- Fork Logic","text":"<ul> <li>Introduction</li> <li>Configuration</li> <li>Fork to Capella</li> <li>Fork trigger</li> <li>Upgrading the state</li> </ul>"},{"location":"specs/capella/fork/#introduction","title":"Introduction","text":"<p>This document describes the process of the Capella upgrade.</p>"},{"location":"specs/capella/fork/#configuration","title":"Configuration","text":"Name Value <code>CAPELLA_FORK_VERSION</code> <code>Version('0x03000000')</code> <code>CAPELLA_FORK_EPOCH</code> <code>Epoch(194048)</code> (April 12, 2023, 10:27:35pm UTC)"},{"location":"specs/capella/fork/#fork-to-capella","title":"Fork to Capella","text":""},{"location":"specs/capella/fork/#fork-trigger","title":"Fork trigger","text":"<p>The fork is triggered at epoch <code>CAPELLA_FORK_EPOCH</code>.</p> <p>Note that for the pure Capella networks, we don't apply <code>upgrade_to_capella</code> since it starts with Capella version logic.</p>"},{"location":"specs/capella/fork/#upgrading-the-state","title":"Upgrading the state","text":"<p>If <code>state.slot % SLOTS_PER_EPOCH == 0</code> and <code>compute_epoch_at_slot(state.slot) == CAPELLA_FORK_EPOCH</code>, an irregular state change is made to upgrade to Capella.</p> <p>The upgrade occurs after the completion of the inner loop of <code>process_slots</code> that sets <code>state.slot</code> equal to <code>CAPELLA_FORK_EPOCH * SLOTS_PER_EPOCH</code>. Care must be taken when transitioning through the fork boundary as implementations will need a modified state transition function that deviates from the Phase 0 document. In particular, the outer <code>state_transition</code> function defined in the Phase 0 document will not expose the precise fork slot to execute the upgrade in the presence of skipped slots at the fork boundary. Instead, the logic must be within <code>process_slots</code>.</p> <pre><code>def upgrade_to_capella(pre: bellatrix.BeaconState) -&gt; BeaconState:\n    epoch = bellatrix.get_current_epoch(pre)\n    latest_execution_payload_header = ExecutionPayloadHeader(\n        parent_hash=pre.latest_execution_payload_header.parent_hash,\n        fee_recipient=pre.latest_execution_payload_header.fee_recipient,\n        state_root=pre.latest_execution_payload_header.state_root,\n        receipts_root=pre.latest_execution_payload_header.receipts_root,\n        logs_bloom=pre.latest_execution_payload_header.logs_bloom,\n        prev_randao=pre.latest_execution_payload_header.prev_randao,\n        block_number=pre.latest_execution_payload_header.block_number,\n        gas_limit=pre.latest_execution_payload_header.gas_limit,\n        gas_used=pre.latest_execution_payload_header.gas_used,\n        timestamp=pre.latest_execution_payload_header.timestamp,\n        extra_data=pre.latest_execution_payload_header.extra_data,\n        base_fee_per_gas=pre.latest_execution_payload_header.base_fee_per_gas,\n        block_hash=pre.latest_execution_payload_header.block_hash,\n        transactions_root=pre.latest_execution_payload_header.transactions_root,\n        # [New in Capella]\n        withdrawals_root=Root(),\n    )\n    post = BeaconState(\n        genesis_time=pre.genesis_time,\n        genesis_validators_root=pre.genesis_validators_root,\n        slot=pre.slot,\n        fork=Fork(\n            previous_version=pre.fork.current_version,\n            current_version=CAPELLA_FORK_VERSION,\n            epoch=epoch,\n        ),\n        latest_block_header=pre.latest_block_header,\n        block_roots=pre.block_roots,\n        state_roots=pre.state_roots,\n        historical_roots=pre.historical_roots,\n        eth1_data=pre.eth1_data,\n        eth1_data_votes=pre.eth1_data_votes,\n        eth1_deposit_index=pre.eth1_deposit_index,\n        validators=pre.validators,\n        balances=pre.balances,\n        randao_mixes=pre.randao_mixes,\n        slashings=pre.slashings,\n        previous_epoch_participation=pre.previous_epoch_participation,\n        current_epoch_participation=pre.current_epoch_participation,\n        justification_bits=pre.justification_bits,\n        previous_justified_checkpoint=pre.previous_justified_checkpoint,\n        current_justified_checkpoint=pre.current_justified_checkpoint,\n        finalized_checkpoint=pre.finalized_checkpoint,\n        inactivity_scores=pre.inactivity_scores,\n        current_sync_committee=pre.current_sync_committee,\n        next_sync_committee=pre.next_sync_committee,\n        latest_execution_payload_header=latest_execution_payload_header,\n        # [New in Capella]\n        next_withdrawal_index=WithdrawalIndex(0),\n        # [New in Capella]\n        next_withdrawal_validator_index=ValidatorIndex(0),\n        # [New in Capella]\n        historical_summaries=List[HistoricalSummary, HISTORICAL_ROOTS_LIMIT]([]),\n    )\n\n    return post\n</code></pre>"},{"location":"specs/capella/p2p-interface/","title":"Capella -- Networking","text":"<ul> <li>Introduction</li> <li>Modifications in Capella</li> <li>Helper functions<ul> <li>Modified <code>compute_fork_version</code></li> </ul> </li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>beacon_block</code></li> <li><code>bls_to_execution_change</code></li> </ul> </li> <li>Transitioning the gossip</li> </ul> </li> <li>The Req/Resp domain<ul> <li>Messages</li> <li>BeaconBlocksByRange v2</li> <li>BeaconBlocksByRoot v2</li> </ul> </li> </ul>"},{"location":"specs/capella/p2p-interface/#introduction","title":"Introduction","text":"<p>This document contains the networking specification for Capella.</p> <p>The specification of these changes continues in the same format as the network specifications of previous upgrades, and assumes them as pre-requisite.</p>"},{"location":"specs/capella/p2p-interface/#modifications-in-capella","title":"Modifications in Capella","text":""},{"location":"specs/capella/p2p-interface/#helper-functions","title":"Helper functions","text":""},{"location":"specs/capella/p2p-interface/#modified-compute_fork_version","title":"Modified <code>compute_fork_version</code>","text":"<pre><code>def compute_fork_version(epoch: Epoch) -&gt; Version:\n    \"\"\"\n    Return the fork version at the given ``epoch``.\n    \"\"\"\n    if epoch &gt;= CAPELLA_FORK_EPOCH:\n        return CAPELLA_FORK_VERSION\n    if epoch &gt;= BELLATRIX_FORK_EPOCH:\n        return BELLATRIX_FORK_VERSION\n    if epoch &gt;= ALTAIR_FORK_EPOCH:\n        return ALTAIR_FORK_VERSION\n    return GENESIS_FORK_VERSION\n</code></pre>"},{"location":"specs/capella/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":"<p>A new topic is added to support the gossip of withdrawal credential change messages. And an existing topic is upgraded for updated types in Capella.</p>"},{"location":"specs/capella/p2p-interface/#topics-and-messages","title":"Topics and messages","text":"<p>Topics follow the same specification as in prior upgrades. All existing topics remain stable except the beacon block topic which is updated with the modified type.</p> <p>The new topics along with the type of the <code>data</code> field of a gossipsub message are given in this table:</p> Name Message Type <code>beacon_block</code> <code>SignedBeaconBlock</code> (modified) <code>bls_to_execution_change</code> <code>SignedBLSToExecutionChange</code> <p>Note that the <code>ForkDigestValue</code> path segment of the topic separates the old and the new <code>beacon_block</code> topics.</p>"},{"location":"specs/capella/p2p-interface/#global-topics","title":"Global topics","text":"<p>Capella changes the type of the global beacon block topic and adds one global topic to propagate withdrawal credential change messages to all potential proposers of beacon blocks.</p>"},{"location":"specs/capella/p2p-interface/#beacon_block","title":"<code>beacon_block</code>","text":"<p>The type of the payload of this topic changes to the (modified) <code>SignedBeaconBlock</code> found in Capella. Specifically, this type changes with the addition of <code>bls_to_execution_changes</code> to the inner <code>BeaconBlockBody</code>. See Capella state transition document for further details.</p>"},{"location":"specs/capella/p2p-interface/#bls_to_execution_change","title":"<code>bls_to_execution_change</code>","text":"<p>This topic is used to propagate signed bls to execution change messages to be included in future blocks.</p> <p>The following validations MUST pass before forwarding the <code>signed_bls_to_execution_change</code> on the network:</p> <ul> <li>[IGNORE] <code>current_epoch &gt;= CAPELLA_FORK_EPOCH</code>, where <code>current_epoch</code> is   defined by the current wall-clock time.</li> <li>[IGNORE] The <code>signed_bls_to_execution_change</code> is the first valid signed bls   to execution change received for the validator with index   <code>signed_bls_to_execution_change.message.validator_index</code>.</li> <li>[REJECT] All of the conditions within <code>process_bls_to_execution_change</code> pass   validation.</li> </ul>"},{"location":"specs/capella/p2p-interface/#transitioning-the-gossip","title":"Transitioning the gossip","text":"<p>See gossip transition details found in the Altair document for details on how to handle transitioning gossip topics for Capella.</p>"},{"location":"specs/capella/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/capella/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/capella/p2p-interface/#beaconblocksbyrange-v2","title":"BeaconBlocksByRange v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_range/2/</code></p> <p>The Capella fork-digest is introduced to the <code>context</code> enum to specify Capella block type.</p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code> <code>BELLATRIX_FORK_VERSION</code> <code>bellatrix.SignedBeaconBlock</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.SignedBeaconBlock</code>"},{"location":"specs/capella/p2p-interface/#beaconblocksbyroot-v2","title":"BeaconBlocksByRoot v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_root/2/</code></p> <p>The Capella fork-digest is introduced to the <code>context</code> enum to specify Capella block type.</p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code> <code>BELLATRIX_FORK_VERSION</code> <code>bellatrix.SignedBeaconBlock</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.SignedBeaconBlock</code>"},{"location":"specs/capella/validator/","title":"Capella -- Honest Validator","text":"<ul> <li>Introduction</li> <li>Prerequisites</li> <li>Helpers</li> <li>Modified <code>GetPayloadResponse</code></li> <li>Protocols</li> <li><code>ExecutionEngine</code><ul> <li>Modified <code>get_payload</code></li> </ul> </li> <li>Beacon chain responsibilities</li> <li>Block proposal<ul> <li>Constructing the <code>BeaconBlockBody</code></li> <li>ExecutionPayload</li> <li>BLS to execution changes</li> </ul> </li> <li>Enabling validator withdrawals</li> <li>Changing from BLS to execution withdrawal credentials</li> </ul>"},{"location":"specs/capella/validator/#introduction","title":"Introduction","text":"<p>This document represents the changes to be made in the code of an \"honest validator\" to implement the Capella upgrade.</p>"},{"location":"specs/capella/validator/#prerequisites","title":"Prerequisites","text":"<p>This document is an extension of the Bellatrix -- Honest Validator guide. All behaviors and definitions defined in this document, and documents it extends, carry over unless explicitly noted or overridden.</p> <p>All terminology, constants, functions, and protocol mechanics defined in the updated Beacon Chain doc of Capella are requisite for this document and used throughout. Please see related Beacon Chain doc before continuing and use them as a reference throughout.</p>"},{"location":"specs/capella/validator/#helpers","title":"Helpers","text":""},{"location":"specs/capella/validator/#modified-getpayloadresponse","title":"Modified <code>GetPayloadResponse</code>","text":"<pre><code>@dataclass\nclass GetPayloadResponse(object):\n    execution_payload: ExecutionPayload\n    block_value: uint256\n</code></pre>"},{"location":"specs/capella/validator/#protocols","title":"Protocols","text":""},{"location":"specs/capella/validator/#executionengine","title":"<code>ExecutionEngine</code>","text":""},{"location":"specs/capella/validator/#modified-get_payload","title":"Modified <code>get_payload</code>","text":"<p><code>get_payload</code> returns the upgraded Capella <code>ExecutionPayload</code> type.</p>"},{"location":"specs/capella/validator/#beacon-chain-responsibilities","title":"Beacon chain responsibilities","text":"<p>All validator responsibilities remain unchanged other than those noted below.</p>"},{"location":"specs/capella/validator/#block-proposal","title":"Block proposal","text":""},{"location":"specs/capella/validator/#constructing-the-beaconblockbody","title":"Constructing the <code>BeaconBlockBody</code>","text":""},{"location":"specs/capella/validator/#executionpayload","title":"ExecutionPayload","text":"<p><code>ExecutionPayload</code>s are constructed as they were in Bellatrix, except that the expected withdrawals for the slot must be gathered from the <code>state</code> (utilizing the helper <code>get_expected_withdrawals</code>) and passed into the <code>ExecutionEngine</code> within <code>prepare_execution_payload</code>.</p> <p>Note: In this section, <code>state</code> is the state of the slot for the block proposal without the block yet applied. That is, <code>state</code> is the <code>previous_state</code> processed through any empty slots up to the assigned slot using <code>process_slots(previous_state, slot)</code>.</p> <p>Note: The only change made to <code>prepare_execution_payload</code> is to call <code>get_expected_withdrawals()</code> to set the new <code>withdrawals</code> field of <code>PayloadAttributes</code>.</p> <pre><code>def prepare_execution_payload(\n    state: BeaconState,\n    safe_block_hash: Hash32,\n    finalized_block_hash: Hash32,\n    suggested_fee_recipient: ExecutionAddress,\n    execution_engine: ExecutionEngine,\n) -&gt; Optional[PayloadId]:\n    # [Modified in Capella]\n    # Removed `is_merge_transition_complete` check\n    parent_hash = state.latest_execution_payload_header.block_hash\n\n    # Set the forkchoice head and initiate the payload build process\n    payload_attributes = PayloadAttributes(\n        timestamp=compute_time_at_slot(state, state.slot),\n        prev_randao=get_randao_mix(state, get_current_epoch(state)),\n        suggested_fee_recipient=suggested_fee_recipient,\n        # [New in Capella]\n        withdrawals=get_expected_withdrawals(state),\n    )\n    return execution_engine.notify_forkchoice_updated(\n        head_block_hash=parent_hash,\n        safe_block_hash=safe_block_hash,\n        finalized_block_hash=finalized_block_hash,\n        payload_attributes=payload_attributes,\n    )\n</code></pre>"},{"location":"specs/capella/validator/#bls-to-execution-changes","title":"BLS to execution changes","text":"<p>Up to <code>MAX_BLS_TO_EXECUTION_CHANGES</code>, <code>BLSToExecutionChange</code> objects can be included in the <code>block</code>. The BLS to execution changes must satisfy the verification conditions found in BLS to execution change processing.</p>"},{"location":"specs/capella/validator/#enabling-validator-withdrawals","title":"Enabling validator withdrawals","text":"<p>Validator balances are withdrawn periodically via an automatic process. For exited validators, the full balance is withdrawn. For active validators, the balance in excess of <code>MAX_EFFECTIVE_BALANCE</code> is withdrawn.</p> <p>There is one prerequisite for this automated process: the validator's withdrawal credentials pointing to an execution layer address, i.e. having an <code>ETH1_ADDRESS_WITHDRAWAL_PREFIX</code>.</p> <p>If a validator has a <code>BLS_WITHDRAWAL_PREFIX</code> withdrawal credential prefix, to participate in withdrawals the validator must create a one-time message to change their withdrawal credential from the version authenticated with a BLS key to the version compatible with the execution layer. This message -- a <code>BLSToExecutionChange</code> -- is available starting in Capella</p> <p>Validators who wish to enable withdrawals MUST assemble, sign, and broadcast this message so that it is accepted on the beacon chain. Validators who do not want to enable withdrawals and have the <code>BLS_WITHDRAWAL_PREFIX</code> version of withdrawal credentials can delay creating this message until they are ready to enable withdrawals.</p>"},{"location":"specs/capella/validator/#changing-from-bls-to-execution-withdrawal-credentials","title":"Changing from BLS to execution withdrawal credentials","text":"<p>First, the validator must construct a valid <code>BLSToExecutionChange</code> <code>message</code>. This <code>message</code> contains the <code>validator_index</code> for the validator who wishes to change their credentials, the <code>from_bls_pubkey</code> -- the BLS public key corresponding to the withdrawal BLS secret key used to form the <code>BLS_WITHDRAWAL_PREFIX</code> withdrawal credential, and the <code>to_execution_address</code> specifying the execution layer address to which the validator's balances will be withdrawn.</p> <p>Note: The withdrawal key pair used to construct the <code>BLS_WITHDRAWAL_PREFIX</code> withdrawal credential should be distinct from the signing key pair used to operate the validator under typical circumstances. Consult your validator deposit tooling documentation for further details if you are not aware of the difference.</p> <p>Warning: This message can only be included on-chain once and is irreversible so ensure the correctness and accessibility to <code>to_execution_address</code>.</p> <p>Next, the validator signs the assembled <code>message: BLSToExecutionChange</code> with the withdrawal BLS secret key and this <code>signature</code> is placed into a <code>SignedBLSToExecutionChange</code> message along with the inner <code>BLSToExecutionChange</code> <code>message</code>. Note that the <code>SignedBLSToExecutionChange</code> message should pass all of the validations in <code>process_bls_to_execution_change</code>.</p> <p>The <code>SignedBLSToExecutionChange</code> message should then be submitted to the consensus layer network. Once included on-chain, the withdrawal credential change takes effect. No further action is required for a validator to enter into the automated withdrawal process.</p> <p>Note: A node should prioritize locally received <code>BLSToExecutionChange</code> operations to ensure these changes make it on-chain through self published blocks even if the rest of the network censors.</p>"},{"location":"specs/capella/light-client/fork/","title":"Capella Light Client -- Fork Logic","text":"<ul> <li>Introduction</li> <li>Upgrading light client data</li> <li>Upgrading the store</li> </ul>"},{"location":"specs/capella/light-client/fork/#introduction","title":"Introduction","text":"<p>This document describes how to upgrade existing light client objects based on the Altair specification to Capella. This is necessary when processing pre-Capella data with a post-Capella <code>LightClientStore</code>. Note that the data being exchanged over the network protocols uses the original format.</p>"},{"location":"specs/capella/light-client/fork/#upgrading-light-client-data","title":"Upgrading light client data","text":"<p>A Capella <code>LightClientStore</code> can still process earlier light client data. In order to do so, that pre-Capella data needs to be locally upgraded to Capella before processing.</p> <pre><code>def upgrade_lc_header_to_capella(pre: bellatrix.LightClientHeader) -&gt; LightClientHeader:\n    return LightClientHeader(\n        beacon=pre.beacon,\n    )\n</code></pre> <pre><code>def upgrade_lc_bootstrap_to_capella(pre: bellatrix.LightClientBootstrap) -&gt; LightClientBootstrap:\n    return LightClientBootstrap(\n        header=upgrade_lc_header_to_capella(pre.header),\n        current_sync_committee=pre.current_sync_committee,\n        current_sync_committee_branch=pre.current_sync_committee_branch,\n    )\n</code></pre> <pre><code>def upgrade_lc_update_to_capella(pre: bellatrix.LightClientUpdate) -&gt; LightClientUpdate:\n    return LightClientUpdate(\n        attested_header=upgrade_lc_header_to_capella(pre.attested_header),\n        next_sync_committee=pre.next_sync_committee,\n        next_sync_committee_branch=pre.next_sync_committee_branch,\n        finalized_header=upgrade_lc_header_to_capella(pre.finalized_header),\n        finality_branch=pre.finality_branch,\n        sync_aggregate=pre.sync_aggregate,\n        signature_slot=pre.signature_slot,\n    )\n</code></pre> <pre><code>def upgrade_lc_finality_update_to_capella(\n    pre: bellatrix.LightClientFinalityUpdate,\n) -&gt; LightClientFinalityUpdate:\n    return LightClientFinalityUpdate(\n        attested_header=upgrade_lc_header_to_capella(pre.attested_header),\n        finalized_header=upgrade_lc_header_to_capella(pre.finalized_header),\n        finality_branch=pre.finality_branch,\n        sync_aggregate=pre.sync_aggregate,\n        signature_slot=pre.signature_slot,\n    )\n</code></pre> <pre><code>def upgrade_lc_optimistic_update_to_capella(\n    pre: bellatrix.LightClientOptimisticUpdate,\n) -&gt; LightClientOptimisticUpdate:\n    return LightClientOptimisticUpdate(\n        attested_header=upgrade_lc_header_to_capella(pre.attested_header),\n        sync_aggregate=pre.sync_aggregate,\n        signature_slot=pre.signature_slot,\n    )\n</code></pre>"},{"location":"specs/capella/light-client/fork/#upgrading-the-store","title":"Upgrading the store","text":"<p>Existing <code>LightClientStore</code> objects based on Altair MUST be upgraded to Capella before Capella based light client data can be processed. The <code>LightClientStore</code> upgrade MAY be performed before <code>CAPELLA_FORK_EPOCH</code>.</p> <pre><code>def upgrade_lc_store_to_capella(pre: bellatrix.LightClientStore) -&gt; LightClientStore:\n    if pre.best_valid_update is None:\n        best_valid_update = None\n    else:\n        best_valid_update = upgrade_lc_update_to_capella(pre.best_valid_update)\n    return LightClientStore(\n        finalized_header=upgrade_lc_header_to_capella(pre.finalized_header),\n        current_sync_committee=pre.current_sync_committee,\n        next_sync_committee=pre.next_sync_committee,\n        best_valid_update=best_valid_update,\n        optimistic_header=upgrade_lc_header_to_capella(pre.optimistic_header),\n        previous_max_active_participants=pre.previous_max_active_participants,\n        current_max_active_participants=pre.current_max_active_participants,\n    )\n</code></pre>"},{"location":"specs/capella/light-client/full-node/","title":"Capella Light Client -- Full Node","text":"<ul> <li>Introduction</li> <li>Helper functions</li> <li>Modified <code>block_to_light_client_header</code></li> </ul>"},{"location":"specs/capella/light-client/full-node/#introduction","title":"Introduction","text":"<p>This upgrade adds information about the execution payload to light client data as part of the Capella upgrade.</p>"},{"location":"specs/capella/light-client/full-node/#helper-functions","title":"Helper functions","text":""},{"location":"specs/capella/light-client/full-node/#modified-block_to_light_client_header","title":"Modified <code>block_to_light_client_header</code>","text":"<pre><code>def block_to_light_client_header(block: SignedBeaconBlock) -&gt; LightClientHeader:\n    epoch = compute_epoch_at_slot(block.message.slot)\n\n    if epoch &gt;= CAPELLA_FORK_EPOCH:\n        payload = block.message.body.execution_payload\n        execution_header = ExecutionPayloadHeader(\n            parent_hash=payload.parent_hash,\n            fee_recipient=payload.fee_recipient,\n            state_root=payload.state_root,\n            receipts_root=payload.receipts_root,\n            logs_bloom=payload.logs_bloom,\n            prev_randao=payload.prev_randao,\n            block_number=payload.block_number,\n            gas_limit=payload.gas_limit,\n            gas_used=payload.gas_used,\n            timestamp=payload.timestamp,\n            extra_data=payload.extra_data,\n            base_fee_per_gas=payload.base_fee_per_gas,\n            block_hash=payload.block_hash,\n            transactions_root=hash_tree_root(payload.transactions),\n            withdrawals_root=hash_tree_root(payload.withdrawals),\n        )\n        execution_branch = ExecutionBranch(\n            compute_merkle_proof(block.message.body, EXECUTION_PAYLOAD_GINDEX)\n        )\n    else:\n        # Note that during fork transitions, `finalized_header` may still point to earlier forks.\n        # While Bellatrix blocks also contain an `ExecutionPayload` (minus `withdrawals_root`),\n        # it was not included in the corresponding light client data. To ensure compatibility\n        # with legacy data going through `upgrade_lc_header_to_capella`, leave out execution data.\n        execution_header = ExecutionPayloadHeader()\n        execution_branch = ExecutionBranch()\n\n    return LightClientHeader(\n        beacon=BeaconBlockHeader(\n            slot=block.message.slot,\n            proposer_index=block.message.proposer_index,\n            parent_root=block.message.parent_root,\n            state_root=block.message.state_root,\n            body_root=hash_tree_root(block.message.body),\n        ),\n        execution=execution_header,\n        execution_branch=execution_branch,\n    )\n</code></pre>"},{"location":"specs/capella/light-client/p2p-interface/","title":"Capella Light Client -- Networking","text":"<ul> <li>Networking</li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>light_client_finality_update</code></li> <li><code>light_client_optimistic_update</code></li> </ul> </li> </ul> </li> <li>The Req/Resp domain<ul> <li>Messages</li> <li>GetLightClientBootstrap</li> <li>LightClientUpdatesByRange</li> <li>GetLightClientFinalityUpdate</li> <li>GetLightClientOptimisticUpdate</li> </ul> </li> </ul>"},{"location":"specs/capella/light-client/p2p-interface/#networking","title":"Networking","text":"<p>The Altair light client networking specification is extended to exchange Capella light client data.</p>"},{"location":"specs/capella/light-client/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":""},{"location":"specs/capella/light-client/p2p-interface/#topics-and-messages","title":"Topics and messages","text":""},{"location":"specs/capella/light-client/p2p-interface/#global-topics","title":"Global topics","text":""},{"location":"specs/capella/light-client/p2p-interface/#light_client_finality_update","title":"<code>light_client_finality_update</code>","text":"<code>fork_version</code> Message SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientFinalityUpdate</code> <code>CAPELLA_FORK_VERSION</code> and later <code>capella.LightClientFinalityUpdate</code>"},{"location":"specs/capella/light-client/p2p-interface/#light_client_optimistic_update","title":"<code>light_client_optimistic_update</code>","text":"<code>fork_version</code> Message SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientOptimisticUpdate</code> <code>CAPELLA_FORK_VERSION</code> and later <code>capella.LightClientOptimisticUpdate</code>"},{"location":"specs/capella/light-client/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/capella/light-client/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/capella/light-client/p2p-interface/#getlightclientbootstrap","title":"GetLightClientBootstrap","text":"<code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientBootstrap</code> <code>CAPELLA_FORK_VERSION</code> and later <code>capella.LightClientBootstrap</code>"},{"location":"specs/capella/light-client/p2p-interface/#lightclientupdatesbyrange","title":"LightClientUpdatesByRange","text":"<code>fork_version</code> Response chunk SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientUpdate</code> <code>CAPELLA_FORK_VERSION</code> and later <code>capella.LightClientUpdate</code>"},{"location":"specs/capella/light-client/p2p-interface/#getlightclientfinalityupdate","title":"GetLightClientFinalityUpdate","text":"<code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientFinalityUpdate</code> <code>CAPELLA_FORK_VERSION</code> and later <code>capella.LightClientFinalityUpdate</code>"},{"location":"specs/capella/light-client/p2p-interface/#getlightclientoptimisticupdate","title":"GetLightClientOptimisticUpdate","text":"<code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientOptimisticUpdate</code> <code>CAPELLA_FORK_VERSION</code> and later <code>capella.LightClientOptimisticUpdate</code>"},{"location":"specs/capella/light-client/sync-protocol/","title":"Capella Light Client -- Sync Protocol","text":"<ul> <li>Introduction</li> <li>Custom types</li> <li>Constants</li> <li>Containers</li> <li>Modified <code>LightClientHeader</code></li> <li>Helper functions</li> <li><code>get_lc_execution_root</code></li> <li>Modified <code>is_valid_light_client_header</code></li> </ul>"},{"location":"specs/capella/light-client/sync-protocol/#introduction","title":"Introduction","text":"<p>This upgrade adds information about the execution payload to light client data as part of the Capella upgrade. It extends the Altair Light Client specifications. The fork document explains how to upgrade existing Altair based deployments to Capella.</p> <p>Additional documents describes the impact of the upgrade on certain roles:</p> <ul> <li>Full node</li> <li>Networking</li> </ul>"},{"location":"specs/capella/light-client/sync-protocol/#custom-types","title":"Custom types","text":"Name SSZ equivalent Description <code>ExecutionBranch</code> <code>Vector[Bytes32, floorlog2(EXECUTION_PAYLOAD_GINDEX)]</code> Merkle branch of <code>execution_payload</code> within <code>BeaconBlockBody</code>"},{"location":"specs/capella/light-client/sync-protocol/#constants","title":"Constants","text":"Name Value <code>EXECUTION_PAYLOAD_GINDEX</code> <code>get_generalized_index(BeaconBlockBody, 'execution_payload')</code> (= 25)"},{"location":"specs/capella/light-client/sync-protocol/#containers","title":"Containers","text":""},{"location":"specs/capella/light-client/sync-protocol/#modified-lightclientheader","title":"Modified <code>LightClientHeader</code>","text":"<pre><code>class LightClientHeader(Container):\n    # Beacon block header\n    beacon: BeaconBlockHeader\n    # Execution payload header corresponding to `beacon.body_root` (from Capella onward)\n    execution: ExecutionPayloadHeader\n    execution_branch: ExecutionBranch\n</code></pre>"},{"location":"specs/capella/light-client/sync-protocol/#helper-functions","title":"Helper functions","text":""},{"location":"specs/capella/light-client/sync-protocol/#get_lc_execution_root","title":"<code>get_lc_execution_root</code>","text":"<pre><code>def get_lc_execution_root(header: LightClientHeader) -&gt; Root:\n    epoch = compute_epoch_at_slot(header.beacon.slot)\n\n    if epoch &gt;= CAPELLA_FORK_EPOCH:\n        return hash_tree_root(header.execution)\n\n    return Root()\n</code></pre>"},{"location":"specs/capella/light-client/sync-protocol/#modified-is_valid_light_client_header","title":"Modified <code>is_valid_light_client_header</code>","text":"<pre><code>def is_valid_light_client_header(header: LightClientHeader) -&gt; bool:\n    epoch = compute_epoch_at_slot(header.beacon.slot)\n\n    if epoch &lt; CAPELLA_FORK_EPOCH:\n        return (\n            header.execution == ExecutionPayloadHeader()\n            and header.execution_branch == ExecutionBranch()\n        )\n\n    return is_valid_merkle_branch(\n        leaf=get_lc_execution_root(header),\n        branch=header.execution_branch,\n        depth=floorlog2(EXECUTION_PAYLOAD_GINDEX),\n        index=get_subtree_index(EXECUTION_PAYLOAD_GINDEX),\n        root=header.beacon.body_root,\n    )\n</code></pre>"},{"location":"specs/deneb/","title":"Index","text":""},{"location":"specs/deneb/#core","title":"Core","text":"<ul> <li>Beacon Chain</li> <li>Fork Choice</li> <li>Fork</li> <li>P2P Interface</li> <li>Polynomial Commitments</li> <li>Validator</li> </ul>"},{"location":"specs/deneb/#light-client","title":"Light Client","text":"<ul> <li>Fork</li> <li>Full Node</li> <li>P2P Interface</li> <li>Sync Protocol</li> </ul>"},{"location":"specs/deneb/beacon-chain/","title":"Deneb -- The Beacon Chain","text":"<ul> <li>Introduction</li> <li>Custom types</li> <li>Constants</li> <li>Blob</li> <li>Preset</li> <li>Execution</li> <li>Configuration</li> <li>Execution</li> <li>Validator cycle</li> <li>Containers</li> <li>Modified containers<ul> <li><code>BeaconBlockBody</code></li> <li><code>ExecutionPayload</code></li> <li><code>ExecutionPayloadHeader</code></li> <li><code>BeaconState</code></li> </ul> </li> <li>Helper functions</li> <li>Misc<ul> <li><code>kzg_commitment_to_versioned_hash</code></li> </ul> </li> <li>Beacon state accessors<ul> <li>Modified <code>get_attestation_participation_flag_indices</code></li> <li>New <code>get_validator_activation_churn_limit</code></li> </ul> </li> <li>Beacon chain state transition function</li> <li>Execution engine<ul> <li>Request data</li> <li>Modified <code>NewPayloadRequest</code></li> <li>Engine APIs</li> <li><code>is_valid_block_hash</code></li> <li><code>is_valid_versioned_hashes</code></li> <li>Modified <code>notify_new_payload</code></li> <li>Modified <code>verify_and_notify_new_payload</code></li> </ul> </li> <li>Block processing<ul> <li>Modified <code>process_attestation</code></li> <li>Execution payload</li> <li>Modified <code>process_execution_payload</code></li> <li>Modified <code>process_voluntary_exit</code></li> </ul> </li> <li>Epoch processing<ul> <li>Registry updates</li> </ul> </li> </ul>"},{"location":"specs/deneb/beacon-chain/#introduction","title":"Introduction","text":"<p>Deneb is a consensus-layer upgrade containing a number of features. Including:</p> <ul> <li>EIP-4788: Beacon block root in the   EVM</li> <li>EIP-4844: Shard Blob Transactions   scale data-availability of Ethereum in a simple, forwards-compatible manner</li> <li>EIP-7044: Perpetually Valid Signed   Voluntary Exits</li> <li>EIP-7045: Increase Max Attestation   Inclusion Slot</li> <li>EIP-7514: Add Max Epoch Churn Limit</li> </ul>"},{"location":"specs/deneb/beacon-chain/#custom-types","title":"Custom types","text":"Name SSZ equivalent Description <code>VersionedHash</code> <code>Bytes32</code> [New in Deneb:EIP4844] <code>BlobIndex</code> <code>uint64</code> [New in Deneb:EIP4844]"},{"location":"specs/deneb/beacon-chain/#constants","title":"Constants","text":""},{"location":"specs/deneb/beacon-chain/#blob","title":"Blob","text":"Name Value <code>VERSIONED_HASH_VERSION_KZG</code> <code>Bytes1('0x01')</code>"},{"location":"specs/deneb/beacon-chain/#preset","title":"Preset","text":""},{"location":"specs/deneb/beacon-chain/#execution","title":"Execution","text":"Name Value Description <code>MAX_BLOB_COMMITMENTS_PER_BLOCK</code> <code>uint64(2**12)</code> (= 4096) [New in Deneb:EIP4844] hardfork independent fixed theoretical limit same as <code>TARGET_BLOB_GAS_PER_BLOCK</code> (see EIP 4844)"},{"location":"specs/deneb/beacon-chain/#configuration","title":"Configuration","text":""},{"location":"specs/deneb/beacon-chain/#execution_1","title":"Execution","text":"Name Value Description <code>MAX_BLOBS_PER_BLOCK</code> <code>uint64(6)</code> [New in Deneb:EIP4844] maximum number of blobs in a single block limited by <code>MAX_BLOB_COMMITMENTS_PER_BLOCK</code> <p>Note: The blob transactions are packed into the execution payload by the EL/builder with their corresponding blobs being independently transmitted and are limited by <code>MAX_BLOB_GAS_PER_BLOCK // GAS_PER_BLOB</code>. However the CL limit is independently defined by <code>MAX_BLOBS_PER_BLOCK</code>.</p>"},{"location":"specs/deneb/beacon-chain/#validator-cycle","title":"Validator cycle","text":"Name Value <code>MAX_PER_EPOCH_ACTIVATION_CHURN_LIMIT</code> <code>uint64(2**3)</code> (= 8)"},{"location":"specs/deneb/beacon-chain/#containers","title":"Containers","text":""},{"location":"specs/deneb/beacon-chain/#modified-containers","title":"Modified containers","text":""},{"location":"specs/deneb/beacon-chain/#beaconblockbody","title":"<code>BeaconBlockBody</code>","text":"<p>Note: <code>BeaconBlock</code> and <code>SignedBeaconBlock</code> types are updated indirectly.</p> <pre><code>class BeaconBlockBody(Container):\n    randao_reveal: BLSSignature\n    eth1_data: Eth1Data\n    graffiti: Bytes32\n    proposer_slashings: List[ProposerSlashing, MAX_PROPOSER_SLASHINGS]\n    attester_slashings: List[AttesterSlashing, MAX_ATTESTER_SLASHINGS]\n    attestations: List[Attestation, MAX_ATTESTATIONS]\n    deposits: List[Deposit, MAX_DEPOSITS]\n    voluntary_exits: List[SignedVoluntaryExit, MAX_VOLUNTARY_EXITS]\n    sync_aggregate: SyncAggregate\n    # [Modified in Deneb:EIP4844]\n    execution_payload: ExecutionPayload\n    bls_to_execution_changes: List[SignedBLSToExecutionChange, MAX_BLS_TO_EXECUTION_CHANGES]\n    # [New in Deneb:EIP4844]\n    blob_kzg_commitments: List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#executionpayload","title":"<code>ExecutionPayload</code>","text":"<pre><code>class ExecutionPayload(Container):\n    parent_hash: Hash32\n    fee_recipient: ExecutionAddress\n    state_root: Bytes32\n    receipts_root: Bytes32\n    logs_bloom: ByteVector[BYTES_PER_LOGS_BLOOM]\n    prev_randao: Bytes32\n    block_number: uint64\n    gas_limit: uint64\n    gas_used: uint64\n    timestamp: uint64\n    extra_data: ByteList[MAX_EXTRA_DATA_BYTES]\n    base_fee_per_gas: uint256\n    block_hash: Hash32\n    transactions: List[Transaction, MAX_TRANSACTIONS_PER_PAYLOAD]\n    withdrawals: List[Withdrawal, MAX_WITHDRAWALS_PER_PAYLOAD]\n    # [New in Deneb:EIP4844]\n    blob_gas_used: uint64\n    # [New in Deneb:EIP4844]\n    excess_blob_gas: uint64\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#executionpayloadheader","title":"<code>ExecutionPayloadHeader</code>","text":"<pre><code>class ExecutionPayloadHeader(Container):\n    parent_hash: Hash32\n    fee_recipient: ExecutionAddress\n    state_root: Bytes32\n    receipts_root: Bytes32\n    logs_bloom: ByteVector[BYTES_PER_LOGS_BLOOM]\n    prev_randao: Bytes32\n    block_number: uint64\n    gas_limit: uint64\n    gas_used: uint64\n    timestamp: uint64\n    extra_data: ByteList[MAX_EXTRA_DATA_BYTES]\n    base_fee_per_gas: uint256\n    block_hash: Hash32\n    transactions_root: Root\n    withdrawals_root: Root\n    # [New in Deneb:EIP4844]\n    blob_gas_used: uint64\n    # [New in Deneb:EIP4844]\n    excess_blob_gas: uint64\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#beaconstate","title":"<code>BeaconState</code>","text":"<pre><code>class BeaconState(Container):\n    genesis_time: uint64\n    genesis_validators_root: Root\n    slot: Slot\n    fork: Fork\n    latest_block_header: BeaconBlockHeader\n    block_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    state_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    historical_roots: List[Root, HISTORICAL_ROOTS_LIMIT]\n    eth1_data: Eth1Data\n    eth1_data_votes: List[Eth1Data, EPOCHS_PER_ETH1_VOTING_PERIOD * SLOTS_PER_EPOCH]\n    eth1_deposit_index: uint64\n    validators: List[Validator, VALIDATOR_REGISTRY_LIMIT]\n    balances: List[Gwei, VALIDATOR_REGISTRY_LIMIT]\n    randao_mixes: Vector[Bytes32, EPOCHS_PER_HISTORICAL_VECTOR]\n    slashings: Vector[Gwei, EPOCHS_PER_SLASHINGS_VECTOR]\n    previous_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    current_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    justification_bits: Bitvector[JUSTIFICATION_BITS_LENGTH]\n    previous_justified_checkpoint: Checkpoint\n    current_justified_checkpoint: Checkpoint\n    finalized_checkpoint: Checkpoint\n    inactivity_scores: List[uint64, VALIDATOR_REGISTRY_LIMIT]\n    current_sync_committee: SyncCommittee\n    next_sync_committee: SyncCommittee\n    # [Modified in Deneb:EIP4844]\n    latest_execution_payload_header: ExecutionPayloadHeader\n    next_withdrawal_index: WithdrawalIndex\n    next_withdrawal_validator_index: ValidatorIndex\n    historical_summaries: List[HistoricalSummary, HISTORICAL_ROOTS_LIMIT]\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#helper-functions","title":"Helper functions","text":""},{"location":"specs/deneb/beacon-chain/#misc","title":"Misc","text":""},{"location":"specs/deneb/beacon-chain/#kzg_commitment_to_versioned_hash","title":"<code>kzg_commitment_to_versioned_hash</code>","text":"<pre><code>def kzg_commitment_to_versioned_hash(kzg_commitment: KZGCommitment) -&gt; VersionedHash:\n    return VERSIONED_HASH_VERSION_KZG + hash(kzg_commitment)[1:]\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#beacon-state-accessors","title":"Beacon state accessors","text":""},{"location":"specs/deneb/beacon-chain/#modified-get_attestation_participation_flag_indices","title":"Modified <code>get_attestation_participation_flag_indices</code>","text":"<p>Note: The function <code>get_attestation_participation_flag_indices</code> is modified to set the <code>TIMELY_TARGET_FLAG</code> for any correct target attestation, regardless of <code>inclusion_delay</code> as a baseline reward for any speed of inclusion of an attestation that contributes to justification of the contained chain for EIP-7045.</p> <pre><code>def get_attestation_participation_flag_indices(\n    state: BeaconState, data: AttestationData, inclusion_delay: uint64\n) -&gt; Sequence[int]:\n    \"\"\"\n    Return the flag indices that are satisfied by an attestation.\n    \"\"\"\n    if data.target.epoch == get_current_epoch(state):\n        justified_checkpoint = state.current_justified_checkpoint\n    else:\n        justified_checkpoint = state.previous_justified_checkpoint\n\n    # Matching roots\n    is_matching_source = data.source == justified_checkpoint\n    is_matching_target = is_matching_source and data.target.root == get_block_root(\n        state, data.target.epoch\n    )\n    is_matching_head = is_matching_target and data.beacon_block_root == get_block_root_at_slot(\n        state, data.slot\n    )\n    assert is_matching_source\n\n    participation_flag_indices = []\n    if is_matching_source and inclusion_delay &lt;= integer_squareroot(SLOTS_PER_EPOCH):\n        participation_flag_indices.append(TIMELY_SOURCE_FLAG_INDEX)\n    # [Modified in Deneb:EIP7045]\n    if is_matching_target:\n        participation_flag_indices.append(TIMELY_TARGET_FLAG_INDEX)\n    if is_matching_head and inclusion_delay == MIN_ATTESTATION_INCLUSION_DELAY:\n        participation_flag_indices.append(TIMELY_HEAD_FLAG_INDEX)\n\n    return participation_flag_indices\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#new-get_validator_activation_churn_limit","title":"New <code>get_validator_activation_churn_limit</code>","text":"<pre><code>def get_validator_activation_churn_limit(state: BeaconState) -&gt; uint64:\n    \"\"\"\n    Return the validator activation churn limit for the current epoch.\n    \"\"\"\n    return min(MAX_PER_EPOCH_ACTIVATION_CHURN_LIMIT, get_validator_churn_limit(state))\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#beacon-chain-state-transition-function","title":"Beacon chain state transition function","text":""},{"location":"specs/deneb/beacon-chain/#execution-engine","title":"Execution engine","text":""},{"location":"specs/deneb/beacon-chain/#request-data","title":"Request data","text":""},{"location":"specs/deneb/beacon-chain/#modified-newpayloadrequest","title":"Modified <code>NewPayloadRequest</code>","text":"<pre><code>@dataclass\nclass NewPayloadRequest(object):\n    execution_payload: ExecutionPayload\n    versioned_hashes: Sequence[VersionedHash]\n    parent_beacon_block_root: Root\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#engine-apis","title":"Engine APIs","text":""},{"location":"specs/deneb/beacon-chain/#is_valid_block_hash","title":"<code>is_valid_block_hash</code>","text":"<p>Note: The function <code>is_valid_block_hash</code> is modified to include the additional <code>parent_beacon_block_root</code> parameter for EIP-4788.</p> <pre><code>def is_valid_block_hash(\n    self: ExecutionEngine, execution_payload: ExecutionPayload, parent_beacon_block_root: Root\n) -&gt; bool:\n    \"\"\"\n    Return ``True`` if and only if ``execution_payload.block_hash`` is computed correctly.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#is_valid_versioned_hashes","title":"<code>is_valid_versioned_hashes</code>","text":"<pre><code>def is_valid_versioned_hashes(\n    self: ExecutionEngine, new_payload_request: NewPayloadRequest\n) -&gt; bool:\n    \"\"\"\n    Return ``True`` if and only if the version hashes computed by the blob transactions of\n    ``new_payload_request.execution_payload`` matches ``new_payload_request.versioned_hashes``.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#modified-notify_new_payload","title":"Modified <code>notify_new_payload</code>","text":"<p>Note: The function <code>notify_new_payload</code> is modified to include the additional <code>parent_beacon_block_root</code> parameter for EIP-4788.</p> <pre><code>def notify_new_payload(\n    self: ExecutionEngine, execution_payload: ExecutionPayload, parent_beacon_block_root: Root\n) -&gt; bool:\n    \"\"\"\n    Return ``True`` if and only if ``execution_payload`` is valid with respect to ``self.execution_state``.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#modified-verify_and_notify_new_payload","title":"Modified <code>verify_and_notify_new_payload</code>","text":"<pre><code>def verify_and_notify_new_payload(\n    self: ExecutionEngine, new_payload_request: NewPayloadRequest\n) -&gt; bool:\n    \"\"\"\n    Return ``True`` if and only if ``new_payload_request`` is valid with respect to ``self.execution_state``.\n    \"\"\"\n    execution_payload = new_payload_request.execution_payload\n    # [New in Deneb:EIP4788]\n    parent_beacon_block_root = new_payload_request.parent_beacon_block_root\n\n    if b\"\" in execution_payload.transactions:\n        return False\n\n    # [Modified in Deneb:EIP4788]\n    if not self.is_valid_block_hash(execution_payload, parent_beacon_block_root):\n        return False\n\n    # [New in Deneb:EIP4844]\n    if not self.is_valid_versioned_hashes(new_payload_request):\n        return False\n\n    # [Modified in Deneb:EIP4788]\n    if not self.notify_new_payload(execution_payload, parent_beacon_block_root):\n        return False\n\n    return True\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#block-processing","title":"Block processing","text":""},{"location":"specs/deneb/beacon-chain/#modified-process_attestation","title":"Modified <code>process_attestation</code>","text":"<p>Note: The function <code>process_attestation</code> is modified to expand valid slots for inclusion to those in both <code>target.epoch</code> epoch and <code>target.epoch + 1</code> epoch for EIP-7045. Additionally, it utilizes an updated version of <code>get_attestation_participation_flag_indices</code> to ensure rewards are available for the extended attestation inclusion range for EIP-7045.</p> <pre><code>def process_attestation(state: BeaconState, attestation: Attestation) -&gt; None:\n    data = attestation.data\n    assert data.target.epoch in (get_previous_epoch(state), get_current_epoch(state))\n    assert data.target.epoch == compute_epoch_at_slot(data.slot)\n    # [Modified in Deneb:EIP7045]\n    assert data.slot + MIN_ATTESTATION_INCLUSION_DELAY &lt;= state.slot\n    assert data.index &lt; get_committee_count_per_slot(state, data.target.epoch)\n\n    committee = get_beacon_committee(state, data.slot, data.index)\n    assert len(attestation.aggregation_bits) == len(committee)\n\n    # Participation flag indices\n    participation_flag_indices = get_attestation_participation_flag_indices(\n        state, data, state.slot - data.slot\n    )\n\n    # Verify signature\n    assert is_valid_indexed_attestation(state, get_indexed_attestation(state, attestation))\n\n    # Update epoch participation flags\n    if data.target.epoch == get_current_epoch(state):\n        epoch_participation = state.current_epoch_participation\n    else:\n        epoch_participation = state.previous_epoch_participation\n\n    proposer_reward_numerator = 0\n    for index in get_attesting_indices(state, attestation):\n        for flag_index, weight in enumerate(PARTICIPATION_FLAG_WEIGHTS):\n            if flag_index in participation_flag_indices and not has_flag(\n                epoch_participation[index], flag_index\n            ):\n                epoch_participation[index] = add_flag(epoch_participation[index], flag_index)\n                proposer_reward_numerator += get_base_reward(state, index) * weight\n\n    # Reward proposer\n    proposer_reward_denominator = (\n        (WEIGHT_DENOMINATOR - PROPOSER_WEIGHT) * WEIGHT_DENOMINATOR // PROPOSER_WEIGHT\n    )\n    proposer_reward = Gwei(proposer_reward_numerator // proposer_reward_denominator)\n    increase_balance(state, get_beacon_proposer_index(state), proposer_reward)\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#execution-payload","title":"Execution payload","text":""},{"location":"specs/deneb/beacon-chain/#modified-process_execution_payload","title":"Modified <code>process_execution_payload</code>","text":"<p>Note: The function <code>process_execution_payload</code> is modified to pass <code>versioned_hashes</code> into <code>execution_engine.verify_and_notify_new_payload</code> and to assign the new fields in <code>ExecutionPayloadHeader</code> for EIP-4844. It is also modified to pass in the parent beacon block root to support EIP-4788.</p> <pre><code>def process_execution_payload(\n    state: BeaconState, body: BeaconBlockBody, execution_engine: ExecutionEngine\n) -&gt; None:\n    payload = body.execution_payload\n\n    # Verify consistency of the parent hash with respect to the previous execution payload header\n    assert payload.parent_hash == state.latest_execution_payload_header.block_hash\n    # Verify prev_randao\n    assert payload.prev_randao == get_randao_mix(state, get_current_epoch(state))\n    # Verify timestamp\n    assert payload.timestamp == compute_time_at_slot(state, state.slot)\n\n    # [New in Deneb:EIP4844] Verify commitments are under limit\n    assert len(body.blob_kzg_commitments) &lt;= MAX_BLOBS_PER_BLOCK\n\n    # Verify the execution payload is valid\n    # [Modified in Deneb:EIP4844] Pass `versioned_hashes` to Execution Engine\n    # [Modified in Deneb:EIP4788] Pass `parent_beacon_block_root` to Execution Engine\n    versioned_hashes = [\n        kzg_commitment_to_versioned_hash(commitment) for commitment in body.blob_kzg_commitments\n    ]\n    assert execution_engine.verify_and_notify_new_payload(\n        NewPayloadRequest(\n            execution_payload=payload,\n            versioned_hashes=versioned_hashes,\n            parent_beacon_block_root=state.latest_block_header.parent_root,\n        )\n    )\n\n    # Cache execution payload header\n    state.latest_execution_payload_header = ExecutionPayloadHeader(\n        parent_hash=payload.parent_hash,\n        fee_recipient=payload.fee_recipient,\n        state_root=payload.state_root,\n        receipts_root=payload.receipts_root,\n        logs_bloom=payload.logs_bloom,\n        prev_randao=payload.prev_randao,\n        block_number=payload.block_number,\n        gas_limit=payload.gas_limit,\n        gas_used=payload.gas_used,\n        timestamp=payload.timestamp,\n        extra_data=payload.extra_data,\n        base_fee_per_gas=payload.base_fee_per_gas,\n        block_hash=payload.block_hash,\n        transactions_root=hash_tree_root(payload.transactions),\n        withdrawals_root=hash_tree_root(payload.withdrawals),\n        # [New in Deneb:EIP4844]\n        blob_gas_used=payload.blob_gas_used,\n        # [New in Deneb:EIP4844]\n        excess_blob_gas=payload.excess_blob_gas,\n    )\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#modified-process_voluntary_exit","title":"Modified <code>process_voluntary_exit</code>","text":"<p>Note: The function <code>process_voluntary_exit</code> is modified to use the fixed fork version -- <code>CAPELLA_FORK_VERSION</code> -- for EIP-7044.</p> <pre><code>def process_voluntary_exit(state: BeaconState, signed_voluntary_exit: SignedVoluntaryExit) -&gt; None:\n    voluntary_exit = signed_voluntary_exit.message\n    validator = state.validators[voluntary_exit.validator_index]\n    # Verify the validator is active\n    assert is_active_validator(validator, get_current_epoch(state))\n    # Verify exit has not been initiated\n    assert validator.exit_epoch == FAR_FUTURE_EPOCH\n    # Exits must specify an epoch when they become valid; they are not valid before then\n    assert get_current_epoch(state) &gt;= voluntary_exit.epoch\n    # Verify the validator has been active long enough\n    assert get_current_epoch(state) &gt;= validator.activation_epoch + SHARD_COMMITTEE_PERIOD\n    # Verify signature\n    # [Modified in Deneb:EIP7044]\n    domain = compute_domain(\n        DOMAIN_VOLUNTARY_EXIT, CAPELLA_FORK_VERSION, state.genesis_validators_root\n    )\n    signing_root = compute_signing_root(voluntary_exit, domain)\n    assert bls.Verify(validator.pubkey, signing_root, signed_voluntary_exit.signature)\n    # Initiate exit\n    initiate_validator_exit(state, voluntary_exit.validator_index)\n</code></pre>"},{"location":"specs/deneb/beacon-chain/#epoch-processing","title":"Epoch processing","text":""},{"location":"specs/deneb/beacon-chain/#registry-updates","title":"Registry updates","text":"<p>Note: The function <code>process_registry_updates</code> is modified to utilize <code>get_validator_activation_churn_limit()</code> to rate limit the activation queue for EIP-7514.</p> <pre><code>def process_registry_updates(state: BeaconState) -&gt; None:\n    # Process activation eligibility and ejections\n    for index, validator in enumerate(state.validators):\n        if is_eligible_for_activation_queue(validator):\n            validator.activation_eligibility_epoch = get_current_epoch(state) + 1\n\n        if (\n            is_active_validator(validator, get_current_epoch(state))\n            and validator.effective_balance &lt;= EJECTION_BALANCE\n        ):\n            initiate_validator_exit(state, ValidatorIndex(index))\n\n    # Queue validators eligible for activation and not yet dequeued for activation\n    activation_queue = sorted(\n        [\n            index\n            for index, validator in enumerate(state.validators)\n            if is_eligible_for_activation(state, validator)\n        ],\n        # Order by the sequence of activation_eligibility_epoch setting and then index\n        key=lambda index: (state.validators[index].activation_eligibility_epoch, index),\n    )\n    # Dequeued validators for activation up to activation churn limit\n    # [Modified in Deneb:EIP7514]\n    for index in activation_queue[: get_validator_activation_churn_limit(state)]:\n        validator = state.validators[index]\n        validator.activation_epoch = compute_activation_exit_epoch(get_current_epoch(state))\n</code></pre>"},{"location":"specs/deneb/fork-choice/","title":"Deneb -- Fork Choice","text":"<ul> <li>Introduction</li> <li>Helpers</li> <li>Modified <code>PayloadAttributes</code></li> <li><code>is_data_available</code></li> <li>Updated fork-choice handlers</li> <li><code>on_block</code></li> </ul>"},{"location":"specs/deneb/fork-choice/#introduction","title":"Introduction","text":"<p>This is the modification of the fork choice accompanying the Deneb upgrade.</p>"},{"location":"specs/deneb/fork-choice/#helpers","title":"Helpers","text":""},{"location":"specs/deneb/fork-choice/#modified-payloadattributes","title":"Modified <code>PayloadAttributes</code>","text":"<p><code>PayloadAttributes</code> is extended with the parent beacon block root for EIP-4788.</p> <pre><code>@dataclass\nclass PayloadAttributes(object):\n    timestamp: uint64\n    prev_randao: Bytes32\n    suggested_fee_recipient: ExecutionAddress\n    withdrawals: Sequence[Withdrawal]\n    # [New in Deneb:EIP4788]\n    parent_beacon_block_root: Root\n</code></pre>"},{"location":"specs/deneb/fork-choice/#is_data_available","title":"<code>is_data_available</code>","text":"<p>[New in Deneb:EIP4844]</p> <p>The implementation of <code>is_data_available</code> will become more sophisticated during later scaling upgrades. Initially, verification requires every verifying actor to retrieve all matching <code>Blob</code>s and <code>KZGProof</code>s, and validate them with <code>verify_blob_kzg_proof_batch</code>.</p> <p>The block MUST NOT be considered valid until all valid <code>Blob</code>s have been downloaded. Blocks that have been previously validated as available SHOULD be considered available even if the associated <code>Blob</code>s have subsequently been pruned.</p> <p>Note: Extraneous or invalid Blobs (in addition to KZG expected/referenced valid blobs) received on the p2p network MUST NOT invalidate a block that is otherwise valid and available.</p> <pre><code>def is_data_available(\n    beacon_block_root: Root, blob_kzg_commitments: Sequence[KZGCommitment]\n) -&gt; bool:\n    # `retrieve_blobs_and_proofs` is implementation and context dependent\n    # It returns all the blobs for the given block root, and raises an exception if not available\n    # Note: the p2p network does not guarantee sidecar retrieval outside of\n    # `MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS`\n    blobs, proofs = retrieve_blobs_and_proofs(beacon_block_root)\n\n    return verify_blob_kzg_proof_batch(blobs, blob_kzg_commitments, proofs)\n</code></pre>"},{"location":"specs/deneb/fork-choice/#updated-fork-choice-handlers","title":"Updated fork-choice handlers","text":""},{"location":"specs/deneb/fork-choice/#on_block","title":"<code>on_block</code>","text":"<p>Note: The only modification is the addition of the blob data availability check.</p> <pre><code>def on_block(store: Store, signed_block: SignedBeaconBlock) -&gt; None:\n    \"\"\"\n    Run ``on_block`` upon receiving a new block.\n    \"\"\"\n    block = signed_block.message\n    # Parent block must be known\n    assert block.parent_root in store.block_states\n    # Blocks cannot be in the future. If they are, their consideration must be delayed until they are in the past.\n    assert get_current_slot(store) &gt;= block.slot\n\n    # Check that block is later than the finalized epoch slot (optimization to reduce calls to get_ancestor)\n    finalized_slot = compute_start_slot_at_epoch(store.finalized_checkpoint.epoch)\n    assert block.slot &gt; finalized_slot\n    # Check block is a descendant of the finalized block at the checkpoint finalized slot\n    finalized_checkpoint_block = get_checkpoint_block(\n        store,\n        block.parent_root,\n        store.finalized_checkpoint.epoch,\n    )\n    assert store.finalized_checkpoint.root == finalized_checkpoint_block\n\n    # [New in Deneb:EIP4844]\n    # Check if blob data is available\n    # If not, this payload MAY be queued and subsequently considered when blob data becomes available\n    assert is_data_available(hash_tree_root(block), block.body.blob_kzg_commitments)\n\n    # Check the block is valid and compute the post-state\n    # Make a copy of the state to avoid mutability issues\n    state = copy(store.block_states[block.parent_root])\n    block_root = hash_tree_root(block)\n    state_transition(state, signed_block, True)\n\n    # Add new block to the store\n    store.blocks[block_root] = block\n    # Add new state for this block to the store\n    store.block_states[block_root] = state\n\n    # Add block timeliness to the store\n    seconds_since_genesis = store.time - store.genesis_time\n    time_into_slot_ms = seconds_to_milliseconds(seconds_since_genesis) % SLOT_DURATION_MS\n    attestation_threshold_ms = get_slot_component_duration_ms(ATTESTATION_DUE_BPS)\n    is_before_attesting_interval = time_into_slot_ms &lt; attestation_threshold_ms\n    is_timely = get_current_slot(store) == block.slot and is_before_attesting_interval\n    store.block_timeliness[hash_tree_root(block)] = is_timely\n\n    # Add proposer score boost if the block is timely and not conflicting with an existing block\n    is_first_block = store.proposer_boost_root == Root()\n    if is_timely and is_first_block:\n        store.proposer_boost_root = hash_tree_root(block)\n\n    # Update checkpoints in store if necessary\n    update_checkpoints(store, state.current_justified_checkpoint, state.finalized_checkpoint)\n\n    # Eagerly compute unrealized justification and finality.\n    compute_pulled_up_tip(store, block_root)\n</code></pre>"},{"location":"specs/deneb/fork/","title":"Deneb -- Fork Logic","text":"<ul> <li>Introduction</li> <li>Configuration</li> <li>Fork to Deneb</li> <li>Fork trigger</li> <li>Upgrading the state</li> </ul>"},{"location":"specs/deneb/fork/#introduction","title":"Introduction","text":"<p>This document describes the process of Deneb upgrade.</p>"},{"location":"specs/deneb/fork/#configuration","title":"Configuration","text":"<p>Warning: this configuration is not definitive.</p> Name Value <code>DENEB_FORK_VERSION</code> <code>Version('0x04000000')</code> <code>DENEB_FORK_EPOCH</code> <code>Epoch(269568)</code> (March 13, 2024, 01:55:35pm UTC)"},{"location":"specs/deneb/fork/#fork-to-deneb","title":"Fork to Deneb","text":""},{"location":"specs/deneb/fork/#fork-trigger","title":"Fork trigger","text":"<p>The fork is triggered at epoch <code>DENEB_FORK_EPOCH</code>.</p> <p>Note that for the pure Deneb networks, we don't apply <code>upgrade_to_deneb</code> since it starts with Deneb version logic.</p>"},{"location":"specs/deneb/fork/#upgrading-the-state","title":"Upgrading the state","text":"<pre><code>def upgrade_to_deneb(pre: capella.BeaconState) -&gt; BeaconState:\n    epoch = capella.get_current_epoch(pre)\n    latest_execution_payload_header = ExecutionPayloadHeader(\n        parent_hash=pre.latest_execution_payload_header.parent_hash,\n        fee_recipient=pre.latest_execution_payload_header.fee_recipient,\n        state_root=pre.latest_execution_payload_header.state_root,\n        receipts_root=pre.latest_execution_payload_header.receipts_root,\n        logs_bloom=pre.latest_execution_payload_header.logs_bloom,\n        prev_randao=pre.latest_execution_payload_header.prev_randao,\n        block_number=pre.latest_execution_payload_header.block_number,\n        gas_limit=pre.latest_execution_payload_header.gas_limit,\n        gas_used=pre.latest_execution_payload_header.gas_used,\n        timestamp=pre.latest_execution_payload_header.timestamp,\n        extra_data=pre.latest_execution_payload_header.extra_data,\n        base_fee_per_gas=pre.latest_execution_payload_header.base_fee_per_gas,\n        block_hash=pre.latest_execution_payload_header.block_hash,\n        transactions_root=pre.latest_execution_payload_header.transactions_root,\n        withdrawals_root=pre.latest_execution_payload_header.withdrawals_root,\n        # [New in Deneb:EIP4844]\n        blob_gas_used=uint64(0),\n        # [New in Deneb:EIP4844]\n        excess_blob_gas=uint64(0),\n    )\n    post = BeaconState(\n        genesis_time=pre.genesis_time,\n        genesis_validators_root=pre.genesis_validators_root,\n        slot=pre.slot,\n        fork=Fork(\n            previous_version=pre.fork.current_version,\n            # [Modified in Deneb]\n            current_version=DENEB_FORK_VERSION,\n            epoch=epoch,\n        ),\n        latest_block_header=pre.latest_block_header,\n        block_roots=pre.block_roots,\n        state_roots=pre.state_roots,\n        historical_roots=pre.historical_roots,\n        eth1_data=pre.eth1_data,\n        eth1_data_votes=pre.eth1_data_votes,\n        eth1_deposit_index=pre.eth1_deposit_index,\n        validators=pre.validators,\n        balances=pre.balances,\n        randao_mixes=pre.randao_mixes,\n        slashings=pre.slashings,\n        previous_epoch_participation=pre.previous_epoch_participation,\n        current_epoch_participation=pre.current_epoch_participation,\n        justification_bits=pre.justification_bits,\n        previous_justified_checkpoint=pre.previous_justified_checkpoint,\n        current_justified_checkpoint=pre.current_justified_checkpoint,\n        finalized_checkpoint=pre.finalized_checkpoint,\n        inactivity_scores=pre.inactivity_scores,\n        current_sync_committee=pre.current_sync_committee,\n        next_sync_committee=pre.next_sync_committee,\n        # [Modified in Deneb:EIP4844]\n        latest_execution_payload_header=latest_execution_payload_header,\n        next_withdrawal_index=pre.next_withdrawal_index,\n        next_withdrawal_validator_index=pre.next_withdrawal_validator_index,\n        historical_summaries=pre.historical_summaries,\n    )\n\n    return post\n</code></pre>"},{"location":"specs/deneb/p2p-interface/","title":"Deneb -- Networking","text":"<ul> <li>Introduction</li> <li>Modifications in Deneb</li> <li>Helper functions<ul> <li>Modified <code>compute_fork_version</code></li> </ul> </li> <li>Constant</li> <li>Preset</li> <li>Configuration</li> <li>Containers<ul> <li><code>BlobSidecar</code></li> <li><code>BlobIdentifier</code></li> <li>Helpers</li> <li><code>verify_blob_sidecar_inclusion_proof</code></li> </ul> </li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>beacon_block</code></li> <li><code>beacon_aggregate_and_proof</code></li> </ul> </li> <li>Blob subnets<ul> <li><code>blob_sidecar_{subnet_id}</code></li> <li>Blob retrieval via local execution layer client</li> </ul> </li> <li>Attestation subnets<ul> <li><code>beacon_attestation_{subnet_id}</code></li> </ul> </li> <li>Transitioning the gossip</li> </ul> </li> <li>The Req/Resp domain<ul> <li>Messages</li> <li>BeaconBlocksByRange v2</li> <li>BeaconBlocksByRoot v2</li> <li>BlobSidecarsByRange v1</li> <li>BlobSidecarsByRoot v1</li> </ul> </li> <li>Design decision rationale</li> <li>Why are blobs relayed as a sidecar, separate from beacon blocks?</li> </ul>"},{"location":"specs/deneb/p2p-interface/#introduction","title":"Introduction","text":"<p>This document contains the consensus-layer networking specification for Deneb.</p> <p>The specification of these changes continues in the same format as the network specifications of previous upgrades, and assumes them as pre-requisite.</p>"},{"location":"specs/deneb/p2p-interface/#modifications-in-deneb","title":"Modifications in Deneb","text":""},{"location":"specs/deneb/p2p-interface/#helper-functions","title":"Helper functions","text":""},{"location":"specs/deneb/p2p-interface/#modified-compute_fork_version","title":"Modified <code>compute_fork_version</code>","text":"<pre><code>def compute_fork_version(epoch: Epoch) -&gt; Version:\n    \"\"\"\n    Return the fork version at the given ``epoch``.\n    \"\"\"\n    if epoch &gt;= DENEB_FORK_EPOCH:\n        return DENEB_FORK_VERSION\n    if epoch &gt;= CAPELLA_FORK_EPOCH:\n        return CAPELLA_FORK_VERSION\n    if epoch &gt;= BELLATRIX_FORK_EPOCH:\n        return BELLATRIX_FORK_VERSION\n    if epoch &gt;= ALTAIR_FORK_EPOCH:\n        return ALTAIR_FORK_VERSION\n    return GENESIS_FORK_VERSION\n</code></pre>"},{"location":"specs/deneb/p2p-interface/#constant","title":"Constant","text":"<p>[New in Deneb:EIP4844]</p>"},{"location":"specs/deneb/p2p-interface/#preset","title":"Preset","text":"<p>[New in Deneb:EIP4844]</p> Name Value Description <code>KZG_COMMITMENT_INCLUSION_PROOF_DEPTH</code> <code>uint64(floorlog2(get_generalized_index(BeaconBlockBody, 'blob_kzg_commitments')) + 1 + ceillog2(MAX_BLOB_COMMITMENTS_PER_BLOCK))</code> (= 17)  Merkle proof depth for <code>blob_kzg_commitments</code> list item"},{"location":"specs/deneb/p2p-interface/#configuration","title":"Configuration","text":"<p>[New in Deneb:EIP4844]</p> Name Value Description <code>MAX_REQUEST_BLOCKS_DENEB</code> <code>2**7</code> (= 128) Maximum number of blocks in a single request <code>MAX_REQUEST_BLOB_SIDECARS</code> <code>MAX_REQUEST_BLOCKS_DENEB * MAX_BLOBS_PER_BLOCK</code> Maximum number of blob sidecars in a single request <code>MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS</code> <code>2**12</code> (= 4096 epochs, ~18 days) The minimum epoch range over which a node must serve blob sidecars <code>BLOB_SIDECAR_SUBNET_COUNT</code> <code>6</code> The number of blob sidecar subnets used in the gossipsub protocol."},{"location":"specs/deneb/p2p-interface/#containers","title":"Containers","text":""},{"location":"specs/deneb/p2p-interface/#blobsidecar","title":"<code>BlobSidecar</code>","text":"<p>[New in Deneb:EIP4844]</p> <p>Note: <code>index</code> is the index of the blob in the block.</p> <pre><code>class BlobSidecar(Container):\n    index: BlobIndex\n    blob: Blob\n    kzg_commitment: KZGCommitment\n    kzg_proof: KZGProof\n    signed_block_header: SignedBeaconBlockHeader\n    kzg_commitment_inclusion_proof: Vector[Bytes32, KZG_COMMITMENT_INCLUSION_PROOF_DEPTH]\n</code></pre>"},{"location":"specs/deneb/p2p-interface/#blobidentifier","title":"<code>BlobIdentifier</code>","text":"<p>[New in Deneb:EIP4844]</p> <pre><code>class BlobIdentifier(Container):\n    block_root: Root\n    index: BlobIndex\n</code></pre>"},{"location":"specs/deneb/p2p-interface/#helpers","title":"Helpers","text":""},{"location":"specs/deneb/p2p-interface/#verify_blob_sidecar_inclusion_proof","title":"<code>verify_blob_sidecar_inclusion_proof</code>","text":"<pre><code>def verify_blob_sidecar_inclusion_proof(blob_sidecar: BlobSidecar) -&gt; bool:\n    gindex = get_subtree_index(\n        get_generalized_index(BeaconBlockBody, \"blob_kzg_commitments\", blob_sidecar.index)\n    )\n    return is_valid_merkle_branch(\n        leaf=blob_sidecar.kzg_commitment.hash_tree_root(),\n        branch=blob_sidecar.kzg_commitment_inclusion_proof,\n        depth=KZG_COMMITMENT_INCLUSION_PROOF_DEPTH,\n        index=gindex,\n        root=blob_sidecar.signed_block_header.message.body_root,\n    )\n</code></pre>"},{"location":"specs/deneb/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":"<p>Some gossip meshes are upgraded in the fork of Deneb to support upgraded types.</p>"},{"location":"specs/deneb/p2p-interface/#topics-and-messages","title":"Topics and messages","text":"<p>Topics follow the same specification as in prior upgrades.</p> <p>The <code>beacon_block</code> topic is modified to also support Deneb blocks and new topics are added per table below.</p> <p>The <code>voluntary_exit</code> topic is implicitly modified despite the lock-in use of <code>CAPELLA_FORK_VERSION</code> for this message signature validation for EIP-7044.</p> <p>The <code>beacon_aggregate_and_proof</code> and <code>beacon_attestation_{subnet_id}</code> topics are modified to support the gossip of attestations created in epoch <code>N</code> to be gossiped through the entire range of slots in epoch <code>N+1</code> rather than only through one epoch of slots for EIP-7045.</p> <p>The specification around the creation, validation, and dissemination of messages has not changed from the Capella document unless explicitly noted here.</p> <p>The derivation of the <code>message-id</code> remains stable.</p> <p>The new topics along with the type of the <code>data</code> field of a gossipsub message are given in this table:</p> Name Message Type <code>blob_sidecar_{subnet_id}</code> <code>BlobSidecar</code> [New in Deneb:EIP4844]"},{"location":"specs/deneb/p2p-interface/#global-topics","title":"Global topics","text":""},{"location":"specs/deneb/p2p-interface/#beacon_block","title":"<code>beacon_block</code>","text":"<p>The type of the payload of this topic changes to the (modified) <code>SignedBeaconBlock</code> found in Deneb.</p> <p>[Modified in Deneb:EIP4844]</p> <p>New validation:</p> <ul> <li>[REJECT] The length of KZG commitments is less than or equal to the   limitation defined in Consensus Layer -- i.e. validate that   <code>len(signed_beacon_block.message.body.blob_kzg_commitments) &lt;= MAX_BLOBS_PER_BLOCK</code></li> </ul>"},{"location":"specs/deneb/p2p-interface/#beacon_aggregate_and_proof","title":"<code>beacon_aggregate_and_proof</code>","text":"<p>[Modified in Deneb:EIP7045]</p> <p>The following validation is removed:</p> <ul> <li>[IGNORE] <code>aggregate.data.slot</code> is within the last   <code>ATTESTATION_PROPAGATION_SLOT_RANGE</code> slots (with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e.   <code>aggregate.data.slot + ATTESTATION_PROPAGATION_SLOT_RANGE &gt;= current_slot &gt;= aggregate.data.slot</code>   (a client MAY queue future aggregates for processing at the appropriate slot).</li> </ul> <p>The following validations are added in its place:</p> <ul> <li>[IGNORE] <code>aggregate.data.slot</code> is equal to or earlier than the   <code>current_slot</code> (with a <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e.   <code>aggregate.data.slot &lt;= current_slot</code> (a client MAY queue future aggregates   for processing at the appropriate slot).</li> <li>[IGNORE] the epoch of <code>aggregate.data.slot</code> is either the current or   previous epoch (with a <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e.   <code>compute_epoch_at_slot(aggregate.data.slot) in (get_previous_epoch(state), get_current_epoch(state))</code></li> </ul>"},{"location":"specs/deneb/p2p-interface/#blob-subnets","title":"Blob subnets","text":""},{"location":"specs/deneb/p2p-interface/#blob_sidecar_subnet_id","title":"<code>blob_sidecar_{subnet_id}</code>","text":"<p>[New in Deneb:EIP4844]</p> <p>This topic is used to propagate blob sidecars, where each blob index maps to some <code>subnet_id</code>.</p> <p>The following validations MUST pass before forwarding the <code>blob_sidecar</code> on the network, assuming the alias <code>block_header = blob_sidecar.signed_block_header.message</code>:</p> <ul> <li>[REJECT] The sidecar's index is consistent with <code>MAX_BLOBS_PER_BLOCK</code> --   i.e. <code>blob_sidecar.index &lt; MAX_BLOBS_PER_BLOCK</code>.</li> <li>[REJECT] The sidecar is for the correct subnet -- i.e.   <code>compute_subnet_for_blob_sidecar(blob_sidecar.index) == subnet_id</code>.</li> <li>[IGNORE] The sidecar is not from a future slot (with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e. validate that   <code>block_header.slot &lt;= current_slot</code> (a client MAY queue future sidecars for   processing at the appropriate slot).</li> <li>[IGNORE] The sidecar is from a slot greater than the latest finalized slot   -- i.e. validate that   <code>block_header.slot &gt; compute_start_slot_at_epoch(store.finalized_checkpoint.epoch)</code></li> <li>[REJECT] The proposer signature of <code>blob_sidecar.signed_block_header</code>, is   valid with respect to the <code>block_header.proposer_index</code> pubkey.</li> <li>[IGNORE] The sidecar's block's parent (defined by   <code>block_header.parent_root</code>) has been seen (via gossip or non-gossip sources)   (a client MAY queue sidecars for processing once the parent block is   retrieved).</li> <li>[REJECT] The sidecar's block's parent (defined by   <code>block_header.parent_root</code>) passes validation.</li> <li>[REJECT] The sidecar is from a higher slot than the sidecar's block's parent   (defined by <code>block_header.parent_root</code>).</li> <li>[REJECT] The current finalized_checkpoint is an ancestor of the sidecar's   block -- i.e.   <code>get_checkpoint_block(store, block_header.parent_root, store.finalized_checkpoint.epoch) == store.finalized_checkpoint.root</code>.</li> <li>[REJECT] The sidecar's inclusion proof is valid as verified by   <code>verify_blob_sidecar_inclusion_proof(blob_sidecar)</code>.</li> <li>[REJECT] The sidecar's blob is valid as verified by   <code>verify_blob_kzg_proof(blob_sidecar.blob, blob_sidecar.kzg_commitment, blob_sidecar.kzg_proof)</code>.</li> <li>[IGNORE] The sidecar is the first sidecar for the tuple   <code>(block_header.slot, block_header.proposer_index, blob_sidecar.index)</code> with   valid header signature, sidecar inclusion proof, and kzg proof.</li> <li>[REJECT] The sidecar is proposed by the expected <code>proposer_index</code> for the   block's slot in the context of the current shuffling (defined by   <code>block_header.parent_root</code>/<code>block_header.slot</code>). If the <code>proposer_index</code>   cannot immediately be verified against the expected shuffling, the sidecar MAY   be queued for later processing while proposers for the block's branch are   calculated -- in such a case do not <code>REJECT</code>, instead <code>IGNORE</code> this message.</li> </ul> <p>The <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(blob_sidecar.signed_block_header.message.slot)</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Chunk SSZ type <code>DENEB_FORK_VERSION</code> and later <code>deneb.BlobSidecar</code>"},{"location":"specs/deneb/p2p-interface/#blob-retrieval-via-local-execution-layer-client","title":"Blob retrieval via local execution layer client","text":"<p>In addition to <code>BlobSidecarsByRoot</code> requests, recent blobs MAY be retrieved by querying the Execution Layer (i.e. via <code>engine_getBlobsV1</code>). Honest nodes SHOULD query <code>engine_getBlobsV1</code> as soon as they receive a valid gossip block that contains data, and import the returned blobs.</p> <p>When clients use the local execution layer to retrieve blobs, they MUST behave as if the corresponding <code>blob_sidecar</code> had been received via gossip. In particular they MUST:</p> <ul> <li>Publish the corresponding <code>blob_sidecar</code> on the <code>blob_sidecar_{subnet_id}</code>   subnet.</li> <li>Update gossip rule related data structures (i.e. update the anti-equivocation   cache).</li> </ul>"},{"location":"specs/deneb/p2p-interface/#attestation-subnets","title":"Attestation subnets","text":""},{"location":"specs/deneb/p2p-interface/#beacon_attestation_subnet_id","title":"<code>beacon_attestation_{subnet_id}</code>","text":"<p>[Modified in Deneb:EIP7045]</p> <p>The following validation is removed:</p> <ul> <li>[IGNORE] <code>attestation.data.slot</code> is within the last   <code>ATTESTATION_PROPAGATION_SLOT_RANGE</code> slots (with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e.   <code>attestation.data.slot + ATTESTATION_PROPAGATION_SLOT_RANGE &gt;= current_slot &gt;= attestation.data.slot</code>   (a client MAY queue future attestations for processing at the appropriate   slot).</li> </ul> <p>The following validations are added in its place:</p> <ul> <li>[IGNORE] <code>attestation.data.slot</code> is equal to or earlier than the   <code>current_slot</code> (with a <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e.   <code>attestation.data.slot &lt;= current_slot</code> (a client MAY queue future attestation   for processing at the appropriate slot).</li> <li>[IGNORE] the epoch of <code>attestation.data.slot</code> is either the current or   previous epoch (with a <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e.   <code>compute_epoch_at_slot(attestation.data.slot) in (get_previous_epoch(state), get_current_epoch(state))</code></li> </ul>"},{"location":"specs/deneb/p2p-interface/#transitioning-the-gossip","title":"Transitioning the gossip","text":"<p>See gossip transition details found in the Altair document for details on how to handle transitioning gossip topics for this upgrade.</p>"},{"location":"specs/deneb/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/deneb/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/deneb/p2p-interface/#beaconblocksbyrange-v2","title":"BeaconBlocksByRange v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_range/2/</code></p> <p>The Deneb fork-digest is introduced to the <code>context</code> enum to specify Deneb beacon block type.</p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code> <code>BELLATRIX_FORK_VERSION</code> <code>bellatrix.SignedBeaconBlock</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.SignedBeaconBlock</code> <code>DENEB_FORK_VERSION</code> <code>deneb.SignedBeaconBlock</code> <p>No more than <code>MAX_REQUEST_BLOCKS_DENEB</code> may be requested at a time.</p>"},{"location":"specs/deneb/p2p-interface/#beaconblocksbyroot-v2","title":"BeaconBlocksByRoot v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_root/2/</code></p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code> <code>BELLATRIX_FORK_VERSION</code> <code>bellatrix.SignedBeaconBlock</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.SignedBeaconBlock</code> <code>DENEB_FORK_VERSION</code> <code>deneb.SignedBeaconBlock</code> <p>No more than <code>MAX_REQUEST_BLOCKS_DENEB</code> may be requested at a time.</p> <p>[Modified in Deneb:EIP4844] Clients SHOULD include a block in the response as soon as it passes the gossip validation rules. Clients SHOULD NOT respond with blocks that fail the beacon chain state transition.</p>"},{"location":"specs/deneb/p2p-interface/#blobsidecarsbyrange-v1","title":"BlobSidecarsByRange v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/blob_sidecars_by_range/1/</code></p> <p>[New in Deneb:EIP4844]</p> <p>Request Content:</p> <pre><code>(\n  start_slot: Slot\n  count: uint64\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[BlobSidecar, MAX_REQUEST_BLOB_SIDECARS]\n)\n</code></pre> <p>Requests blob sidecars in the slot range <code>[start_slot, start_slot + count)</code>, leading up to the current head block as selected by fork choice.</p> <p>Before consuming the next response chunk, the response reader SHOULD verify the blob sidecar is well-formatted, has valid inclusion proof, and is correct w.r.t. the expected KZG commitments through <code>verify_blob_kzg_proof</code>.</p> <p><code>BlobSidecarsByRange</code> is primarily used to sync blobs that may have been missed on gossip and to sync within the <code>MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS</code> window.</p> <p>The request MUST be encoded as an SSZ-container.</p> <p>The response MUST consist of zero or more <code>response_chunk</code>. Each successful <code>response_chunk</code> MUST contain a single <code>BlobSidecar</code> payload.</p> <p>Let <code>blob_serve_range</code> be <code>[max(current_epoch - MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS, DENEB_FORK_EPOCH), current_epoch]</code>. Clients MUST keep a record of blob sidecars seen on the epoch range <code>blob_serve_range</code> where <code>current_epoch</code> is defined by the current wall-clock time, and clients MUST support serving requests of blobs on this range.</p> <p>Peers that are unable to reply to blob sidecar requests within the range <code>blob_serve_range</code> SHOULD respond with error code <code>3: ResourceUnavailable</code>. Such peers that are unable to successfully reply to this range of requests MAY get descored or disconnected at any time.</p> <p>Note: The above requirement implies that nodes that start from a recent weak subjectivity checkpoint MUST backfill the local blobs database to at least the range <code>blob_serve_range</code> to be fully compliant with <code>BlobSidecarsByRange</code> requests.</p> <p>Note: Although clients that bootstrap from a weak subjectivity checkpoint can begin participating in the networking immediately, other peers MAY disconnect and/or temporarily ban such an un-synced or semi-synced client.</p> <p>Clients MUST respond with at least the blob sidecars of the first blob-carrying block that exists in the range, if they have it, and no more than <code>MAX_REQUEST_BLOB_SIDECARS</code> sidecars.</p> <p>Clients MUST include all blob sidecars of each block from which they include blob sidecars.</p> <p>The following blob sidecars, where they exist, MUST be sent in consecutive <code>(slot, index)</code> order.</p> <p>Slots that do not contain known blobs MUST be skipped, mimicking the behaviour of the <code>BlocksByRange</code> request. Only response chunks with known blobs should therefore be sent.</p> <p>Clients MAY limit the number of blob sidecars in the response.</p> <p>The response MUST contain no more than <code>count * MAX_BLOBS_PER_BLOCK</code> blob sidecars.</p> <p>Clients MUST respond with blob sidecars from their view of the current fork choice -- that is, blob sidecars as included by blocks from the single chain defined by the current head. Of note, blocks from slots before the finalization MUST lead to the finalized block reported in the <code>Status</code> handshake.</p> <p>Clients MUST respond with blob sidecars that are consistent from a single chain within the context of the request.</p> <p>After the initial blob sidecar, clients MAY stop in the process of responding if their fork choice changes the view of the chain in the context of the request.</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(blob_sidecar.signed_block_header.message.slot)</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Chunk SSZ type <code>DENEB_FORK_VERSION</code> and later <code>deneb.BlobSidecar</code>"},{"location":"specs/deneb/p2p-interface/#blobsidecarsbyroot-v1","title":"BlobSidecarsByRoot v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/blob_sidecars_by_root/1/</code></p> <p>[New in Deneb:EIP4844]</p> <p>Request Content:</p> <pre><code>(\n  List[BlobIdentifier, MAX_REQUEST_BLOB_SIDECARS]\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[BlobSidecar, MAX_REQUEST_BLOB_SIDECARS]\n)\n</code></pre> <p>Requests sidecars by block root and index. The response is a list of <code>BlobSidecar</code> whose length is less than or equal to the number of requests. It may be less in the case that the responding peer is missing blocks or sidecars.</p> <p>Before consuming the next response chunk, the response reader SHOULD verify the blob sidecar is well-formatted, has valid inclusion proof, and is correct w.r.t. the expected KZG commitments through <code>verify_blob_kzg_proof</code>.</p> <p>No more than <code>MAX_REQUEST_BLOB_SIDECARS</code> may be requested at a time.</p> <p><code>BlobSidecarsByRoot</code> is primarily used to recover recent blobs (e.g. when receiving a block with a transaction whose corresponding blob is missing).</p> <p>The response MUST consist of zero or more <code>response_chunk</code>. Each successful <code>response_chunk</code> MUST contain a single <code>BlobSidecar</code> payload.</p> <p>Clients MUST support requesting sidecars since <code>minimum_request_epoch</code>, where <code>minimum_request_epoch = max(finalized_epoch, current_epoch - MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS, DENEB_FORK_EPOCH)</code>. If any root in the request content references a block earlier than <code>minimum_request_epoch</code>, peers MAY respond with error code <code>3: ResourceUnavailable</code> or not include the blob sidecar in the response.</p> <p>Clients MUST respond with at least one sidecar, if they have it. Clients MAY limit the number of blocks and sidecars in the response.</p> <p>Clients SHOULD include a sidecar in the response as soon as it passes the gossip validation rules. Clients SHOULD NOT respond with sidecars related to blocks that fail gossip validation rules. Clients SHOULD NOT respond with sidecars related to blocks that fail the beacon chain state transition</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(blob_sidecar.signed_block_header.message.slot)</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Chunk SSZ type <code>DENEB_FORK_VERSION</code> and later <code>deneb.BlobSidecar</code>"},{"location":"specs/deneb/p2p-interface/#design-decision-rationale","title":"Design decision rationale","text":""},{"location":"specs/deneb/p2p-interface/#why-are-blobs-relayed-as-a-sidecar-separate-from-beacon-blocks","title":"Why are blobs relayed as a sidecar, separate from beacon blocks?","text":"<p>This \"sidecar\" design provides forward compatibility for further data increases by black-boxing <code>is_data_available()</code>: with full sharding <code>is_data_available()</code> can be replaced by data-availability-sampling (DAS) thus avoiding all blobs being downloaded by all beacon nodes on the network.</p> <p>Such sharding design may introduce an updated <code>BlobSidecar</code> to identify the shard, but does not affect the <code>BeaconBlock</code> structure.</p>"},{"location":"specs/deneb/polynomial-commitments/","title":"Deneb -- Polynomial Commitments","text":"<ul> <li>Introduction</li> <li>Custom types</li> <li>Cryptographic types</li> <li>Constants</li> <li>Preset</li> <li>Blob</li> <li>Trusted setup</li> <li>Helper functions</li> <li>Bit-reversal permutation<ul> <li><code>is_power_of_two</code></li> <li><code>reverse_bits</code></li> <li><code>bit_reversal_permutation</code></li> </ul> </li> <li>BLS12-381 helpers<ul> <li><code>multi_exp</code></li> <li><code>hash_to_bls_field</code></li> <li><code>bytes_to_bls_field</code></li> <li><code>bls_field_to_bytes</code></li> <li><code>validate_kzg_g1</code></li> <li><code>bytes_to_kzg_commitment</code></li> <li><code>bytes_to_kzg_proof</code></li> <li><code>blob_to_polynomial</code></li> <li><code>compute_challenge</code></li> <li><code>g1_lincomb</code></li> <li><code>compute_powers</code></li> <li><code>compute_roots_of_unity</code></li> </ul> </li> <li>Polynomials<ul> <li><code>evaluate_polynomial_in_evaluation_form</code></li> </ul> </li> <li>KZG<ul> <li><code>blob_to_kzg_commitment</code></li> <li><code>verify_kzg_proof</code></li> <li><code>verify_kzg_proof_impl</code></li> <li><code>verify_kzg_proof_batch</code></li> <li><code>compute_kzg_proof</code></li> <li><code>compute_quotient_eval_within_domain</code></li> <li><code>compute_kzg_proof_impl</code></li> <li><code>compute_blob_kzg_proof</code></li> <li><code>verify_blob_kzg_proof</code></li> <li><code>verify_blob_kzg_proof_batch</code></li> </ul> </li> </ul>"},{"location":"specs/deneb/polynomial-commitments/#introduction","title":"Introduction","text":"<p>This document specifies basic polynomial operations and KZG polynomial commitment operations that are essential for the implementation of the EIP-4844 feature in the Deneb specification. The implementations are not optimized for performance, but readability. All practical implementations should optimize the polynomial operations.</p> <p>Functions flagged as \"Public method\" MUST be provided by the underlying KZG library as public functions. All other functions are private functions used internally by the KZG library.</p> <p>Public functions MUST accept raw bytes as input and perform the required cryptographic normalization before invoking any internal functions.</p>"},{"location":"specs/deneb/polynomial-commitments/#custom-types","title":"Custom types","text":"Name SSZ equivalent Description <code>G1Point</code> <code>Bytes48</code> <code>G2Point</code> <code>Bytes96</code> <code>KZGCommitment</code> <code>Bytes48</code> Validation: Perform BLS standard's \"KeyValidate\" check but do allow the identity point <code>KZGProof</code> <code>Bytes48</code> Same as for <code>KZGCommitment</code> <code>Blob</code> <code>ByteVector[BYTES_PER_FIELD_ELEMENT * FIELD_ELEMENTS_PER_BLOB]</code> A basic data blob"},{"location":"specs/deneb/polynomial-commitments/#cryptographic-types","title":"Cryptographic types","text":"Name SSZ equivalent Description <code>BLSFieldElement</code> <code>uint256</code>  A value in the finite field defined by <code>BLS_MODULUS</code> <code>Polynomial</code> <code>Vector[BLSFieldElement, FIELD_ELEMENTS_PER_BLOB]</code>  A polynomial in evaluation form"},{"location":"specs/deneb/polynomial-commitments/#constants","title":"Constants","text":"Name Value Notes <code>BLS_MODULUS</code> <code>52435875175126190479447740508185965837690552500527637822603658699938581184513</code> Scalar field modulus of BLS12-381 <code>BYTES_PER_COMMITMENT</code> <code>uint64(48)</code> The number of bytes in a KZG commitment <code>BYTES_PER_PROOF</code> <code>uint64(48)</code> The number of bytes in a KZG proof <code>BYTES_PER_FIELD_ELEMENT</code> <code>uint64(32)</code> Bytes used to encode a BLS scalar field element <code>BYTES_PER_BLOB</code> <code>uint64(BYTES_PER_FIELD_ELEMENT * FIELD_ELEMENTS_PER_BLOB)</code> The number of bytes in a blob <code>G1_POINT_AT_INFINITY</code> <code>Bytes48(b'\\xc0' + b'\\x00' * 47)</code> Serialized form of the point at infinity on the G1 group <code>KZG_ENDIANNESS</code> <code>'big'</code> The endianness of the field elements including blobs <code>PRIMITIVE_ROOT_OF_UNITY</code> <code>7</code> The primitive root of unity from which all roots of unity should be derived"},{"location":"specs/deneb/polynomial-commitments/#preset","title":"Preset","text":""},{"location":"specs/deneb/polynomial-commitments/#blob","title":"Blob","text":"Name Value <code>FIELD_ELEMENTS_PER_BLOB</code> <code>uint64(4096)</code> <code>FIAT_SHAMIR_PROTOCOL_DOMAIN</code> <code>b'FSBLOBVERIFY_V1_'</code> <code>RANDOM_CHALLENGE_KZG_BATCH_DOMAIN</code> <code>b'RCKZGBATCH___V1_'</code>"},{"location":"specs/deneb/polynomial-commitments/#trusted-setup","title":"Trusted setup","text":"Name Value <code>KZG_SETUP_G2_LENGTH</code> <code>65</code> <code>KZG_SETUP_G1_MONOMIAL</code> <code>Vector[G1Point, FIELD_ELEMENTS_PER_BLOB]</code> <code>KZG_SETUP_G1_LAGRANGE</code> <code>Vector[G1Point, FIELD_ELEMENTS_PER_BLOB]</code> <code>KZG_SETUP_G2_MONOMIAL</code> <code>Vector[G2Point, KZG_SETUP_G2_LENGTH]</code>"},{"location":"specs/deneb/polynomial-commitments/#helper-functions","title":"Helper functions","text":""},{"location":"specs/deneb/polynomial-commitments/#bit-reversal-permutation","title":"Bit-reversal permutation","text":"<p>All polynomials (which are always given in Lagrange form) should be interpreted as being in bit-reversal permutation. In practice, clients can implement this by storing the lists <code>KZG_SETUP_G1_LAGRANGE</code> and roots of unity in bit-reversal permutation, so these functions only have to be called once at startup.</p>"},{"location":"specs/deneb/polynomial-commitments/#is_power_of_two","title":"<code>is_power_of_two</code>","text":"<pre><code>def is_power_of_two(value: int) -&gt; bool:\n    \"\"\"\n    Check if ``value`` is a power of two integer.\n    \"\"\"\n    return (value &gt; 0) and (value &amp; (value - 1) == 0)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#reverse_bits","title":"<code>reverse_bits</code>","text":"<pre><code>def reverse_bits(n: int, order: int) -&gt; int:\n    \"\"\"\n    Reverse the bit order of an integer ``n``.\n    \"\"\"\n    assert is_power_of_two(order)\n    # Convert n to binary with the same number of bits as \"order\" - 1, then reverse its bit order\n    return int((\"{:0\" + str(order.bit_length() - 1) + \"b}\").format(n)[::-1], 2)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#bit_reversal_permutation","title":"<code>bit_reversal_permutation</code>","text":"<pre><code>def bit_reversal_permutation(sequence: Sequence[T]) -&gt; Sequence[T]:\n    \"\"\"\n    Return a copy with bit-reversed permutation. The permutation is an involution (inverts itself).\n\n    The input and output are a sequence of generic type ``T`` objects.\n    \"\"\"\n    return [sequence[reverse_bits(i, len(sequence))] for i in range(len(sequence))]\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#bls12-381-helpers","title":"BLS12-381 helpers","text":""},{"location":"specs/deneb/polynomial-commitments/#multi_exp","title":"<code>multi_exp</code>","text":"<p>This function performs a multi-scalar multiplication between <code>points</code> and <code>integers</code>. <code>points</code> can either be in G1 or G2.</p> <pre><code>def multi_exp(_points: Sequence[TPoint], _integers: Sequence[uint64]) -&gt; Sequence[TPoint]: ...\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#hash_to_bls_field","title":"<code>hash_to_bls_field</code>","text":"<pre><code>def hash_to_bls_field(data: bytes) -&gt; BLSFieldElement:\n    \"\"\"\n    Hash ``data`` and convert the output to a BLS scalar field element.\n    The output is not uniform over the BLS field.\n    \"\"\"\n    hashed_data = hash(data)\n    return BLSFieldElement(int.from_bytes(hashed_data, KZG_ENDIANNESS) % BLS_MODULUS)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#bytes_to_bls_field","title":"<code>bytes_to_bls_field</code>","text":"<pre><code>def bytes_to_bls_field(b: Bytes32) -&gt; BLSFieldElement:\n    \"\"\"\n    Convert untrusted bytes to a trusted and validated BLS scalar field element.\n    This function does not accept inputs greater than the BLS modulus.\n    \"\"\"\n    field_element = int.from_bytes(b, KZG_ENDIANNESS)\n    assert field_element &lt; BLS_MODULUS\n    return BLSFieldElement(field_element)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#bls_field_to_bytes","title":"<code>bls_field_to_bytes</code>","text":"<pre><code>def bls_field_to_bytes(x: BLSFieldElement) -&gt; Bytes32:\n    return int.to_bytes(int(x), 32, KZG_ENDIANNESS)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#validate_kzg_g1","title":"<code>validate_kzg_g1</code>","text":"<pre><code>def validate_kzg_g1(b: Bytes48) -&gt; None:\n    \"\"\"\n    Perform BLS validation required by the types `KZGProof` and `KZGCommitment`.\n    \"\"\"\n    if b == G1_POINT_AT_INFINITY:\n        return\n\n    assert bls.KeyValidate(b)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#bytes_to_kzg_commitment","title":"<code>bytes_to_kzg_commitment</code>","text":"<pre><code>def bytes_to_kzg_commitment(b: Bytes48) -&gt; KZGCommitment:\n    \"\"\"\n    Convert untrusted bytes into a trusted and validated KZGCommitment.\n    \"\"\"\n    validate_kzg_g1(b)\n    return KZGCommitment(b)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#bytes_to_kzg_proof","title":"<code>bytes_to_kzg_proof</code>","text":"<pre><code>def bytes_to_kzg_proof(b: Bytes48) -&gt; KZGProof:\n    \"\"\"\n    Convert untrusted bytes into a trusted and validated KZGProof.\n    \"\"\"\n    validate_kzg_g1(b)\n    return KZGProof(b)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#blob_to_polynomial","title":"<code>blob_to_polynomial</code>","text":"<pre><code>def blob_to_polynomial(blob: Blob) -&gt; Polynomial:\n    \"\"\"\n    Convert a blob to list of BLS field scalars.\n    \"\"\"\n    polynomial = Polynomial()\n    for i in range(FIELD_ELEMENTS_PER_BLOB):\n        value = bytes_to_bls_field(\n            blob[i * BYTES_PER_FIELD_ELEMENT : (i + 1) * BYTES_PER_FIELD_ELEMENT]\n        )\n        polynomial[i] = value\n    return polynomial\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#compute_challenge","title":"<code>compute_challenge</code>","text":"<pre><code>def compute_challenge(blob: Blob, commitment: KZGCommitment) -&gt; BLSFieldElement:\n    \"\"\"\n    Return the Fiat-Shamir challenge required by the rest of the protocol.\n    \"\"\"\n\n    # Append the degree of the polynomial as a domain separator\n    degree_poly = int.to_bytes(FIELD_ELEMENTS_PER_BLOB, 16, KZG_ENDIANNESS)\n    data = FIAT_SHAMIR_PROTOCOL_DOMAIN + degree_poly\n\n    data += blob\n    data += commitment\n\n    # Transcript has been prepared: time to create the challenge\n    return hash_to_bls_field(data)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#g1_lincomb","title":"<code>g1_lincomb</code>","text":"<pre><code>def g1_lincomb(\n    points: Sequence[KZGCommitment], scalars: Sequence[BLSFieldElement]\n) -&gt; KZGCommitment:\n    \"\"\"\n    BLS multiscalar multiplication in G1. This can be naively implemented using double-and-add.\n    \"\"\"\n    assert len(points) == len(scalars)\n\n    if len(points) == 0:\n        return bls.G1_to_bytes48(bls.Z1())\n\n    points_g1 = []\n    for point in points:\n        points_g1.append(bls.bytes48_to_G1(point))\n\n    result = bls.multi_exp(points_g1, scalars)\n    return KZGCommitment(bls.G1_to_bytes48(result))\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#compute_powers","title":"<code>compute_powers</code>","text":"<pre><code>def compute_powers(x: BLSFieldElement, n: uint64) -&gt; Sequence[BLSFieldElement]:\n    \"\"\"\n    Return ``x`` to power of [0, n-1], if n &gt; 0. When n==0, an empty array is returned.\n    \"\"\"\n    current_power = BLSFieldElement(1)\n    powers = []\n    for _ in range(n):\n        powers.append(current_power)\n        current_power = current_power * x\n    return powers\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#compute_roots_of_unity","title":"<code>compute_roots_of_unity</code>","text":"<pre><code>def compute_roots_of_unity(order: uint64) -&gt; Sequence[BLSFieldElement]:\n    \"\"\"\n    Return roots of unity of ``order``.\n    \"\"\"\n    assert (BLS_MODULUS - 1) % int(order) == 0\n    root_of_unity = BLSFieldElement(\n        pow(PRIMITIVE_ROOT_OF_UNITY, (BLS_MODULUS - 1) // int(order), BLS_MODULUS)\n    )\n    return compute_powers(root_of_unity, order)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#polynomials","title":"Polynomials","text":""},{"location":"specs/deneb/polynomial-commitments/#evaluate_polynomial_in_evaluation_form","title":"<code>evaluate_polynomial_in_evaluation_form</code>","text":"<pre><code>def evaluate_polynomial_in_evaluation_form(\n    polynomial: Polynomial, z: BLSFieldElement\n) -&gt; BLSFieldElement:\n    \"\"\"\n    Evaluate a polynomial (in evaluation form) at an arbitrary point ``z``.\n    - When ``z`` is in the domain, the evaluation can be found by indexing the polynomial at the\n    position that ``z`` is in the domain.\n    - When ``z`` is not in the domain, the barycentric formula is used:\n       f(z) = (z**WIDTH - 1) / WIDTH  *  sum_(i=0)^WIDTH  (f(DOMAIN[i]) * DOMAIN[i]) / (z - DOMAIN[i])\n    \"\"\"\n    width = len(polynomial)\n    assert width == FIELD_ELEMENTS_PER_BLOB\n    inverse_width = BLSFieldElement(width).inverse()\n\n    roots_of_unity_brp = bit_reversal_permutation(compute_roots_of_unity(FIELD_ELEMENTS_PER_BLOB))\n\n    # If we are asked to evaluate within the domain, we already know the answer\n    if z in roots_of_unity_brp:\n        eval_index = roots_of_unity_brp.index(z)\n        return polynomial[eval_index]\n\n    result = BLSFieldElement(0)\n    for i in range(width):\n        a = polynomial[i] * roots_of_unity_brp[i]\n        b = z - roots_of_unity_brp[i]\n        result += a / b\n    r = z.pow(BLSFieldElement(width)) - BLSFieldElement(1)\n    result = result * r * inverse_width\n    return result\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#kzg","title":"KZG","text":"<p>KZG core functions. These are also defined in Deneb execution specs.</p>"},{"location":"specs/deneb/polynomial-commitments/#blob_to_kzg_commitment","title":"<code>blob_to_kzg_commitment</code>","text":"<pre><code>def blob_to_kzg_commitment(blob: Blob) -&gt; KZGCommitment:\n    \"\"\"\n    Public method.\n    \"\"\"\n    assert len(blob) == BYTES_PER_BLOB\n    return g1_lincomb(bit_reversal_permutation(KZG_SETUP_G1_LAGRANGE), blob_to_polynomial(blob))\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#verify_kzg_proof","title":"<code>verify_kzg_proof</code>","text":"<pre><code>def verify_kzg_proof(\n    commitment_bytes: Bytes48, z_bytes: Bytes32, y_bytes: Bytes32, proof_bytes: Bytes48\n) -&gt; bool:\n    \"\"\"\n    Verify KZG proof that ``p(z) == y`` where ``p(z)`` is the polynomial represented by ``polynomial_kzg``.\n    Receives inputs as bytes.\n    Public method.\n    \"\"\"\n    assert len(commitment_bytes) == BYTES_PER_COMMITMENT\n    assert len(z_bytes) == BYTES_PER_FIELD_ELEMENT\n    assert len(y_bytes) == BYTES_PER_FIELD_ELEMENT\n    assert len(proof_bytes) == BYTES_PER_PROOF\n\n    return verify_kzg_proof_impl(\n        bytes_to_kzg_commitment(commitment_bytes),\n        bytes_to_bls_field(z_bytes),\n        bytes_to_bls_field(y_bytes),\n        bytes_to_kzg_proof(proof_bytes),\n    )\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#verify_kzg_proof_impl","title":"<code>verify_kzg_proof_impl</code>","text":"<pre><code>def verify_kzg_proof_impl(\n    commitment: KZGCommitment, z: BLSFieldElement, y: BLSFieldElement, proof: KZGProof\n) -&gt; bool:\n    \"\"\"\n    Verify KZG proof that ``p(z) == y`` where ``p(z)`` is the polynomial represented by ``polynomial_kzg``.\n    \"\"\"\n    # Verify: P - y = Q * (X - z)\n    X_minus_z = bls.add(\n        bls.bytes96_to_G2(KZG_SETUP_G2_MONOMIAL[1]),\n        bls.multiply(bls.G2(), -z),\n    )\n    P_minus_y = bls.add(bls.bytes48_to_G1(commitment), bls.multiply(bls.G1(), -y))\n    return bls.pairing_check(\n        [[P_minus_y, bls.neg(bls.G2())], [bls.bytes48_to_G1(proof), X_minus_z]]\n    )\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#verify_kzg_proof_batch","title":"<code>verify_kzg_proof_batch</code>","text":"<pre><code>def verify_kzg_proof_batch(\n    commitments: Sequence[KZGCommitment],\n    zs: Sequence[BLSFieldElement],\n    ys: Sequence[BLSFieldElement],\n    proofs: Sequence[KZGProof],\n) -&gt; bool:\n    \"\"\"\n    Verify multiple KZG proofs efficiently.\n    \"\"\"\n\n    assert len(commitments) == len(zs) == len(ys) == len(proofs)\n\n    # Compute a random challenge. Note that it does not have to be computed from a hash,\n    # r just has to be random.\n    degree_poly = int.to_bytes(FIELD_ELEMENTS_PER_BLOB, 8, KZG_ENDIANNESS)\n    num_commitments = int.to_bytes(len(commitments), 8, KZG_ENDIANNESS)\n    data = RANDOM_CHALLENGE_KZG_BATCH_DOMAIN + degree_poly + num_commitments\n\n    # Append all inputs to the transcript before we hash\n    for commitment, z, y, proof in zip(commitments, zs, ys, proofs):\n        data += commitment + bls_field_to_bytes(z) + bls_field_to_bytes(y) + proof\n\n    r = hash_to_bls_field(data)\n    r_powers = compute_powers(r, len(commitments))\n\n    # Verify: e(sum r^i proof_i, [s]) ==\n    # e(sum r^i (commitment_i - [y_i]) + sum r^i z_i proof_i, [1])\n    proof_lincomb = g1_lincomb(proofs, r_powers)\n    proof_z_lincomb = g1_lincomb(proofs, [z * r_power for z, r_power in zip(zs, r_powers)])\n    C_minus_ys = [\n        bls.add(bls.bytes48_to_G1(commitment), bls.multiply(bls.G1(), -y))\n        for commitment, y in zip(commitments, ys)\n    ]\n    C_minus_y_as_KZGCommitments = [KZGCommitment(bls.G1_to_bytes48(x)) for x in C_minus_ys]\n    C_minus_y_lincomb = g1_lincomb(C_minus_y_as_KZGCommitments, r_powers)\n\n    return bls.pairing_check(\n        [\n            [\n                bls.bytes48_to_G1(proof_lincomb),\n                bls.neg(bls.bytes96_to_G2(KZG_SETUP_G2_MONOMIAL[1])),\n            ],\n            [\n                bls.add(bls.bytes48_to_G1(C_minus_y_lincomb), bls.bytes48_to_G1(proof_z_lincomb)),\n                bls.G2(),\n            ],\n        ]\n    )\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#compute_kzg_proof","title":"<code>compute_kzg_proof</code>","text":"<pre><code>def compute_kzg_proof(blob: Blob, z_bytes: Bytes32) -&gt; Tuple[KZGProof, Bytes32]:\n    \"\"\"\n    Compute KZG proof at point `z` for the polynomial represented by `blob`.\n    Do this by computing the quotient polynomial in evaluation form: q(x) = (p(x) - p(z)) / (x - z).\n    Public method.\n    \"\"\"\n    assert len(blob) == BYTES_PER_BLOB\n    assert len(z_bytes) == BYTES_PER_FIELD_ELEMENT\n    polynomial = blob_to_polynomial(blob)\n    proof, y = compute_kzg_proof_impl(polynomial, bytes_to_bls_field(z_bytes))\n    return proof, int(y).to_bytes(BYTES_PER_FIELD_ELEMENT, KZG_ENDIANNESS)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#compute_quotient_eval_within_domain","title":"<code>compute_quotient_eval_within_domain</code>","text":"<pre><code>def compute_quotient_eval_within_domain(\n    z: BLSFieldElement, polynomial: Polynomial, y: BLSFieldElement\n) -&gt; BLSFieldElement:\n    \"\"\"\n    Given `y == p(z)` for a polynomial `p(x)`, compute `q(z)`: the KZG quotient polynomial evaluated at `z` for the\n    special case where `z` is in roots of unity.\n\n    For more details, read https://dankradfeist.de/ethereum/2021/06/18/pcs-multiproofs.html section \"Dividing\n    when one of the points is zero\". The code below computes q(x_m) for the roots of unity special case.\n    \"\"\"\n    roots_of_unity_brp = bit_reversal_permutation(compute_roots_of_unity(FIELD_ELEMENTS_PER_BLOB))\n    result = BLSFieldElement(0)\n    for i, omega_i in enumerate(roots_of_unity_brp):\n        if omega_i == z:  # skip the evaluation point in the sum\n            continue\n\n        f_i = polynomial[i] - y\n        numerator = f_i * omega_i\n        denominator = z * (z - omega_i)\n        result += numerator / denominator\n\n    return result\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#compute_kzg_proof_impl","title":"<code>compute_kzg_proof_impl</code>","text":"<pre><code>def compute_kzg_proof_impl(\n    polynomial: Polynomial, z: BLSFieldElement\n) -&gt; Tuple[KZGProof, BLSFieldElement]:\n    \"\"\"\n    Helper function for `compute_kzg_proof()` and `compute_blob_kzg_proof()`.\n    \"\"\"\n    roots_of_unity_brp = bit_reversal_permutation(compute_roots_of_unity(FIELD_ELEMENTS_PER_BLOB))\n\n    # For all x_i, compute p(x_i) - p(z)\n    y = evaluate_polynomial_in_evaluation_form(polynomial, z)\n    polynomial_shifted = [p - y for p in polynomial]\n\n    # For all x_i, compute (x_i - z)\n    denominator_poly = [x - z for x in roots_of_unity_brp]\n\n    # Compute the quotient polynomial directly in evaluation form\n    quotient_polynomial = [BLSFieldElement(0)] * FIELD_ELEMENTS_PER_BLOB\n    for i, (a, b) in enumerate(zip(polynomial_shifted, denominator_poly)):\n        if b == BLSFieldElement(0):\n            # The denominator is zero hence `z` is a root of unity: we must handle it as a special case\n            quotient_polynomial[i] = compute_quotient_eval_within_domain(\n                roots_of_unity_brp[i], polynomial, y\n            )\n        else:\n            # Compute: q(x_i) = (p(x_i) - p(z)) / (x_i - z).\n            quotient_polynomial[i] = a / b\n\n    return KZGProof(\n        g1_lincomb(bit_reversal_permutation(KZG_SETUP_G1_LAGRANGE), quotient_polynomial)\n    ), y\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#compute_blob_kzg_proof","title":"<code>compute_blob_kzg_proof</code>","text":"<pre><code>def compute_blob_kzg_proof(blob: Blob, commitment_bytes: Bytes48) -&gt; KZGProof:\n    \"\"\"\n    Given a blob, return the KZG proof that is used to verify it against the commitment.\n    This method does not verify that the commitment is correct with respect to `blob`.\n    Public method.\n    \"\"\"\n    assert len(blob) == BYTES_PER_BLOB\n    assert len(commitment_bytes) == BYTES_PER_COMMITMENT\n    commitment = bytes_to_kzg_commitment(commitment_bytes)\n    polynomial = blob_to_polynomial(blob)\n    evaluation_challenge = compute_challenge(blob, commitment)\n    proof, _ = compute_kzg_proof_impl(polynomial, evaluation_challenge)\n    return proof\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#verify_blob_kzg_proof","title":"<code>verify_blob_kzg_proof</code>","text":"<pre><code>def verify_blob_kzg_proof(blob: Blob, commitment_bytes: Bytes48, proof_bytes: Bytes48) -&gt; bool:\n    \"\"\"\n    Given a blob and a KZG proof, verify that the blob data corresponds to the provided commitment.\n\n    Public method.\n    \"\"\"\n    assert len(blob) == BYTES_PER_BLOB\n    assert len(commitment_bytes) == BYTES_PER_COMMITMENT\n    assert len(proof_bytes) == BYTES_PER_PROOF\n\n    commitment = bytes_to_kzg_commitment(commitment_bytes)\n\n    polynomial = blob_to_polynomial(blob)\n    evaluation_challenge = compute_challenge(blob, commitment)\n\n    # Evaluate polynomial at `evaluation_challenge`\n    y = evaluate_polynomial_in_evaluation_form(polynomial, evaluation_challenge)\n\n    # Verify proof\n    proof = bytes_to_kzg_proof(proof_bytes)\n    return verify_kzg_proof_impl(commitment, evaluation_challenge, y, proof)\n</code></pre>"},{"location":"specs/deneb/polynomial-commitments/#verify_blob_kzg_proof_batch","title":"<code>verify_blob_kzg_proof_batch</code>","text":"<pre><code>def verify_blob_kzg_proof_batch(\n    blobs: Sequence[Blob], commitments_bytes: Sequence[Bytes48], proofs_bytes: Sequence[Bytes48]\n) -&gt; bool:\n    \"\"\"\n    Given a list of blobs and blob KZG proofs, verify that they correspond to the provided commitments.\n    Will return True if there are zero blobs/commitments/proofs.\n    Public method.\n    \"\"\"\n\n    assert len(blobs) == len(commitments_bytes) == len(proofs_bytes)\n\n    commitments, evaluation_challenges, ys, proofs = [], [], [], []\n    for blob, commitment_bytes, proof_bytes in zip(blobs, commitments_bytes, proofs_bytes):\n        assert len(blob) == BYTES_PER_BLOB\n        assert len(commitment_bytes) == BYTES_PER_COMMITMENT\n        assert len(proof_bytes) == BYTES_PER_PROOF\n        commitment = bytes_to_kzg_commitment(commitment_bytes)\n        commitments.append(commitment)\n        polynomial = blob_to_polynomial(blob)\n        evaluation_challenge = compute_challenge(blob, commitment)\n        evaluation_challenges.append(evaluation_challenge)\n        ys.append(evaluate_polynomial_in_evaluation_form(polynomial, evaluation_challenge))\n        proofs.append(bytes_to_kzg_proof(proof_bytes))\n\n    return verify_kzg_proof_batch(commitments, evaluation_challenges, ys, proofs)\n</code></pre>"},{"location":"specs/deneb/validator/","title":"Deneb -- Honest Validator","text":"<ul> <li>Introduction</li> <li>Prerequisites</li> <li>Helpers</li> <li><code>BlobsBundle</code></li> <li>Modified <code>GetPayloadResponse</code></li> <li>Protocols</li> <li><code>ExecutionEngine</code><ul> <li>Modified <code>get_payload</code></li> </ul> </li> <li>Beacon chain responsibilities</li> <li>Block and sidecar proposal<ul> <li>Constructing the <code>BeaconBlockBody</code></li> <li>ExecutionPayload</li> <li>Blob KZG commitments</li> <li>Constructing the <code>BlobSidecar</code>s</li> <li>Sidecar</li> </ul> </li> </ul>"},{"location":"specs/deneb/validator/#introduction","title":"Introduction","text":"<p>This document represents the changes to be made in the code of an \"honest validator\" to implement Deneb.</p>"},{"location":"specs/deneb/validator/#prerequisites","title":"Prerequisites","text":"<p>This document is an extension of the Capella -- Honest Validator guide. All behaviors and definitions defined in this document, and documents it extends, carry over unless explicitly noted or overridden.</p> <p>All terminology, constants, functions, and protocol mechanics defined in the updated Beacon Chain doc of Deneb are requisite for this document and used throughout. Please see related Beacon Chain doc before continuing and use them as a reference throughout.</p>"},{"location":"specs/deneb/validator/#helpers","title":"Helpers","text":""},{"location":"specs/deneb/validator/#blobsbundle","title":"<code>BlobsBundle</code>","text":"<p>[New in Deneb:EIP4844]</p> <pre><code>@dataclass\nclass BlobsBundle(object):\n    commitments: List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    proofs: List[KZGProof, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    blobs: List[Blob, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n</code></pre>"},{"location":"specs/deneb/validator/#modified-getpayloadresponse","title":"Modified <code>GetPayloadResponse</code>","text":"<pre><code>@dataclass\nclass GetPayloadResponse(object):\n    execution_payload: ExecutionPayload\n    block_value: uint256\n    # [New in Deneb:EIP4844]\n    blobs_bundle: BlobsBundle\n</code></pre> <pre><code>def compute_signed_block_header(signed_block: SignedBeaconBlock) -&gt; SignedBeaconBlockHeader:\n    block = signed_block.message\n    block_header = BeaconBlockHeader(\n        slot=block.slot,\n        proposer_index=block.proposer_index,\n        parent_root=block.parent_root,\n        state_root=block.state_root,\n        body_root=hash_tree_root(block.body),\n    )\n    return SignedBeaconBlockHeader(message=block_header, signature=signed_block.signature)\n</code></pre>"},{"location":"specs/deneb/validator/#protocols","title":"Protocols","text":""},{"location":"specs/deneb/validator/#executionengine","title":"<code>ExecutionEngine</code>","text":""},{"location":"specs/deneb/validator/#modified-get_payload","title":"Modified <code>get_payload</code>","text":"<p>Given the <code>payload_id</code>, <code>get_payload</code> returns the most recent version of the execution payload that has been built since the corresponding call to <code>notify_forkchoice_updated</code> method.</p> <pre><code>def get_payload(self: ExecutionEngine, payload_id: PayloadId) -&gt; GetPayloadResponse:\n    \"\"\"\n    Return ExecutionPayload, uint256, BlobsBundle objects.\n    \"\"\"\n    # pylint: disable=unused-argument\n    ...\n</code></pre>"},{"location":"specs/deneb/validator/#beacon-chain-responsibilities","title":"Beacon chain responsibilities","text":"<p>All validator responsibilities remain unchanged other than those noted below.</p>"},{"location":"specs/deneb/validator/#block-and-sidecar-proposal","title":"Block and sidecar proposal","text":""},{"location":"specs/deneb/validator/#constructing-the-beaconblockbody","title":"Constructing the <code>BeaconBlockBody</code>","text":""},{"location":"specs/deneb/validator/#executionpayload","title":"ExecutionPayload","text":"<p><code>prepare_execution_payload</code> is updated from the Capella specs to provide the parent beacon block root.</p> <p>Note: In this section, <code>state</code> is the state of the slot for the block proposal without the block yet applied. That is, <code>state</code> is the <code>previous_state</code> processed through any empty slots up to the assigned slot using <code>process_slots(previous_state, slot)</code>.</p> <p>Note: The only change made to <code>prepare_execution_payload</code> is to add the parent beacon block root as an additional parameter to the <code>PayloadAttributes</code>.</p> <pre><code>def prepare_execution_payload(\n    state: BeaconState,\n    safe_block_hash: Hash32,\n    finalized_block_hash: Hash32,\n    suggested_fee_recipient: ExecutionAddress,\n    execution_engine: ExecutionEngine,\n) -&gt; Optional[PayloadId]:\n    # Verify consistency of the parent hash with respect to the previous execution payload header\n    parent_hash = state.latest_execution_payload_header.block_hash\n\n    # Set the forkchoice head and initiate the payload build process\n    payload_attributes = PayloadAttributes(\n        timestamp=compute_time_at_slot(state, state.slot),\n        prev_randao=get_randao_mix(state, get_current_epoch(state)),\n        suggested_fee_recipient=suggested_fee_recipient,\n        withdrawals=get_expected_withdrawals(state),\n        # [New in Deneb:EIP4788]\n        parent_beacon_block_root=hash_tree_root(state.latest_block_header),\n    )\n    return execution_engine.notify_forkchoice_updated(\n        head_block_hash=parent_hash,\n        safe_block_hash=safe_block_hash,\n        finalized_block_hash=finalized_block_hash,\n        payload_attributes=payload_attributes,\n    )\n</code></pre>"},{"location":"specs/deneb/validator/#blob-kzg-commitments","title":"Blob KZG commitments","text":"<p>[New in Deneb:EIP4844]</p> <ol> <li>The execution payload is obtained from the execution engine as defined above    using <code>payload_id</code>. The response also includes a <code>blobs_bundle</code> entry    containing the corresponding <code>blobs</code>, <code>commitments</code>, and <code>proofs</code>.</li> <li>Set <code>block.body.blob_kzg_commitments = commitments</code>.</li> </ol>"},{"location":"specs/deneb/validator/#constructing-the-blobsidecars","title":"Constructing the <code>BlobSidecar</code>s","text":"<p>[New in Deneb:EIP4844]</p> <p>To construct a <code>BlobSidecar</code>, a <code>blob_sidecar</code> is defined with the necessary context for block and sidecar proposal.</p>"},{"location":"specs/deneb/validator/#sidecar","title":"Sidecar","text":"<p>Blobs associated with a block are packaged into sidecar objects for distribution to the associated sidecar topic, the <code>blob_sidecar_{subnet_id}</code> pubsub topic.</p> <p>Each <code>sidecar</code> is obtained from:</p> <pre><code>def get_blob_sidecars(\n    signed_block: SignedBeaconBlock, blobs: Sequence[Blob], blob_kzg_proofs: Sequence[KZGProof]\n) -&gt; Sequence[BlobSidecar]:\n    block = signed_block.message\n    signed_block_header = compute_signed_block_header(signed_block)\n    return [\n        BlobSidecar(\n            index=index,\n            blob=blob,\n            kzg_commitment=block.body.blob_kzg_commitments[index],\n            kzg_proof=blob_kzg_proofs[index],\n            signed_block_header=signed_block_header,\n            kzg_commitment_inclusion_proof=compute_merkle_proof(\n                block.body,\n                get_generalized_index(BeaconBlockBody, \"blob_kzg_commitments\", index),\n            ),\n        )\n        for index, blob in enumerate(blobs)\n    ]\n</code></pre> <p>The <code>subnet_id</code> for the <code>blob_sidecar</code> is calculated with:</p> <ul> <li>Let <code>blob_index = blob_sidecar.index</code>.</li> <li>Let <code>subnet_id = compute_subnet_for_blob_sidecar(blob_index)</code>.</li> </ul> <pre><code>def compute_subnet_for_blob_sidecar(blob_index: BlobIndex) -&gt; SubnetID:\n    return SubnetID(blob_index % BLOB_SIDECAR_SUBNET_COUNT)\n</code></pre> <p>After publishing the peers on the network may request the sidecar through sync-requests, or a local user may be interested.</p> <p>The validator MUST hold on to sidecars for <code>MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS</code> epochs and serve when capable, to ensure the data-availability of these blobs throughout the network.</p> <p>After <code>MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS</code> nodes MAY prune the sidecars and/or stop serving them.</p>"},{"location":"specs/deneb/light-client/fork/","title":"Deneb Light Client -- Fork Logic","text":"<ul> <li>Introduction</li> <li>Upgrading light client data</li> <li>Upgrading the store</li> </ul>"},{"location":"specs/deneb/light-client/fork/#introduction","title":"Introduction","text":"<p>This document describes how to upgrade existing light client objects based on the Capella specification to Deneb. This is necessary when processing pre-Deneb data with a post-Deneb <code>LightClientStore</code>. Note that the data being exchanged over the network protocols uses the original format.</p>"},{"location":"specs/deneb/light-client/fork/#upgrading-light-client-data","title":"Upgrading light client data","text":"<p>A Deneb <code>LightClientStore</code> can still process earlier light client data. In order to do so, that pre-Deneb data needs to be locally upgraded to Deneb before processing.</p> <pre><code>def upgrade_lc_header_to_deneb(pre: capella.LightClientHeader) -&gt; LightClientHeader:\n    return LightClientHeader(\n        beacon=pre.beacon,\n        execution=ExecutionPayloadHeader(\n            parent_hash=pre.execution.parent_hash,\n            fee_recipient=pre.execution.fee_recipient,\n            state_root=pre.execution.state_root,\n            receipts_root=pre.execution.receipts_root,\n            logs_bloom=pre.execution.logs_bloom,\n            prev_randao=pre.execution.prev_randao,\n            block_number=pre.execution.block_number,\n            gas_limit=pre.execution.gas_limit,\n            gas_used=pre.execution.gas_used,\n            timestamp=pre.execution.timestamp,\n            extra_data=pre.execution.extra_data,\n            base_fee_per_gas=pre.execution.base_fee_per_gas,\n            block_hash=pre.execution.block_hash,\n            transactions_root=pre.execution.transactions_root,\n            withdrawals_root=pre.execution.withdrawals_root,\n            # [New in Deneb:EIP4844]\n            blob_gas_used=uint64(0),\n            # [New in Deneb:EIP4844]\n            excess_blob_gas=uint64(0),\n        ),\n        execution_branch=pre.execution_branch,\n    )\n</code></pre> <pre><code>def upgrade_lc_bootstrap_to_deneb(pre: capella.LightClientBootstrap) -&gt; LightClientBootstrap:\n    return LightClientBootstrap(\n        header=upgrade_lc_header_to_deneb(pre.header),\n        current_sync_committee=pre.current_sync_committee,\n        current_sync_committee_branch=pre.current_sync_committee_branch,\n    )\n</code></pre> <pre><code>def upgrade_lc_update_to_deneb(pre: capella.LightClientUpdate) -&gt; LightClientUpdate:\n    return LightClientUpdate(\n        attested_header=upgrade_lc_header_to_deneb(pre.attested_header),\n        next_sync_committee=pre.next_sync_committee,\n        next_sync_committee_branch=pre.next_sync_committee_branch,\n        finalized_header=upgrade_lc_header_to_deneb(pre.finalized_header),\n        finality_branch=pre.finality_branch,\n        sync_aggregate=pre.sync_aggregate,\n        signature_slot=pre.signature_slot,\n    )\n</code></pre> <pre><code>def upgrade_lc_finality_update_to_deneb(\n    pre: capella.LightClientFinalityUpdate,\n) -&gt; LightClientFinalityUpdate:\n    return LightClientFinalityUpdate(\n        attested_header=upgrade_lc_header_to_deneb(pre.attested_header),\n        finalized_header=upgrade_lc_header_to_deneb(pre.finalized_header),\n        finality_branch=pre.finality_branch,\n        sync_aggregate=pre.sync_aggregate,\n        signature_slot=pre.signature_slot,\n    )\n</code></pre> <pre><code>def upgrade_lc_optimistic_update_to_deneb(\n    pre: capella.LightClientOptimisticUpdate,\n) -&gt; LightClientOptimisticUpdate:\n    return LightClientOptimisticUpdate(\n        attested_header=upgrade_lc_header_to_deneb(pre.attested_header),\n        sync_aggregate=pre.sync_aggregate,\n        signature_slot=pre.signature_slot,\n    )\n</code></pre>"},{"location":"specs/deneb/light-client/fork/#upgrading-the-store","title":"Upgrading the store","text":"<p>Existing <code>LightClientStore</code> objects based on Capella MUST be upgraded to Deneb before Deneb based light client data can be processed. The <code>LightClientStore</code> upgrade MAY be performed before <code>DENEB_FORK_EPOCH</code>.</p> <pre><code>def upgrade_lc_store_to_deneb(pre: capella.LightClientStore) -&gt; LightClientStore:\n    if pre.best_valid_update is None:\n        best_valid_update = None\n    else:\n        best_valid_update = upgrade_lc_update_to_deneb(pre.best_valid_update)\n    return LightClientStore(\n        finalized_header=upgrade_lc_header_to_deneb(pre.finalized_header),\n        current_sync_committee=pre.current_sync_committee,\n        next_sync_committee=pre.next_sync_committee,\n        best_valid_update=best_valid_update,\n        optimistic_header=upgrade_lc_header_to_deneb(pre.optimistic_header),\n        previous_max_active_participants=pre.previous_max_active_participants,\n        current_max_active_participants=pre.current_max_active_participants,\n    )\n</code></pre>"},{"location":"specs/deneb/light-client/full-node/","title":"Deneb Light Client -- Full Node","text":"<ul> <li>Introduction</li> <li>Helper functions</li> <li>Modified <code>block_to_light_client_header</code></li> </ul>"},{"location":"specs/deneb/light-client/full-node/#introduction","title":"Introduction","text":"<p>Execution payload data is updated to account for the Deneb upgrade.</p>"},{"location":"specs/deneb/light-client/full-node/#helper-functions","title":"Helper functions","text":""},{"location":"specs/deneb/light-client/full-node/#modified-block_to_light_client_header","title":"Modified <code>block_to_light_client_header</code>","text":"<pre><code>def block_to_light_client_header(block: SignedBeaconBlock) -&gt; LightClientHeader:\n    epoch = compute_epoch_at_slot(block.message.slot)\n\n    if epoch &gt;= CAPELLA_FORK_EPOCH:\n        payload = block.message.body.execution_payload\n        execution_header = ExecutionPayloadHeader(\n            parent_hash=payload.parent_hash,\n            fee_recipient=payload.fee_recipient,\n            state_root=payload.state_root,\n            receipts_root=payload.receipts_root,\n            logs_bloom=payload.logs_bloom,\n            prev_randao=payload.prev_randao,\n            block_number=payload.block_number,\n            gas_limit=payload.gas_limit,\n            gas_used=payload.gas_used,\n            timestamp=payload.timestamp,\n            extra_data=payload.extra_data,\n            base_fee_per_gas=payload.base_fee_per_gas,\n            block_hash=payload.block_hash,\n            transactions_root=hash_tree_root(payload.transactions),\n            withdrawals_root=hash_tree_root(payload.withdrawals),\n        )\n\n        # [New in Deneb:EIP4844]\n        if epoch &gt;= DENEB_FORK_EPOCH:\n            execution_header.blob_gas_used = payload.blob_gas_used\n            execution_header.excess_blob_gas = payload.excess_blob_gas\n\n        execution_branch = ExecutionBranch(\n            compute_merkle_proof(block.message.body, EXECUTION_PAYLOAD_GINDEX)\n        )\n    else:\n        # Note that during fork transitions, `finalized_header` may still point to earlier forks.\n        # While Bellatrix blocks also contain an `ExecutionPayload` (minus `withdrawals_root`),\n        # it was not included in the corresponding light client data. To ensure compatibility\n        # with legacy data going through `upgrade_lc_header_to_capella`, leave out execution data.\n        execution_header = ExecutionPayloadHeader()\n        execution_branch = ExecutionBranch()\n\n    return LightClientHeader(\n        beacon=BeaconBlockHeader(\n            slot=block.message.slot,\n            proposer_index=block.message.proposer_index,\n            parent_root=block.message.parent_root,\n            state_root=block.message.state_root,\n            body_root=hash_tree_root(block.message.body),\n        ),\n        execution=execution_header,\n        execution_branch=execution_branch,\n    )\n</code></pre>"},{"location":"specs/deneb/light-client/p2p-interface/","title":"Deneb Light Client -- Networking","text":"<ul> <li>Networking</li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>light_client_finality_update</code></li> <li><code>light_client_optimistic_update</code></li> </ul> </li> </ul> </li> <li>The Req/Resp domain<ul> <li>Messages</li> <li>GetLightClientBootstrap</li> <li>LightClientUpdatesByRange</li> <li>GetLightClientFinalityUpdate</li> <li>GetLightClientOptimisticUpdate</li> </ul> </li> </ul>"},{"location":"specs/deneb/light-client/p2p-interface/#networking","title":"Networking","text":"<p>The Capella light client networking specification is extended to exchange Deneb light client data.</p>"},{"location":"specs/deneb/light-client/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":""},{"location":"specs/deneb/light-client/p2p-interface/#topics-and-messages","title":"Topics and messages","text":""},{"location":"specs/deneb/light-client/p2p-interface/#global-topics","title":"Global topics","text":""},{"location":"specs/deneb/light-client/p2p-interface/#light_client_finality_update","title":"<code>light_client_finality_update</code>","text":"<code>fork_version</code> Message SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientFinalityUpdate</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientFinalityUpdate</code> <code>DENEB_FORK_VERSION</code> and later <code>deneb.LightClientFinalityUpdate</code>"},{"location":"specs/deneb/light-client/p2p-interface/#light_client_optimistic_update","title":"<code>light_client_optimistic_update</code>","text":"<code>fork_version</code> Message SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientOptimisticUpdate</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientOptimisticUpdate</code> <code>DENEB_FORK_VERSION</code> and later <code>deneb.LightClientOptimisticUpdate</code>"},{"location":"specs/deneb/light-client/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/deneb/light-client/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/deneb/light-client/p2p-interface/#getlightclientbootstrap","title":"GetLightClientBootstrap","text":"<code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientBootstrap</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientBootstrap</code> <code>DENEB_FORK_VERSION</code> and later <code>deneb.LightClientBootstrap</code>"},{"location":"specs/deneb/light-client/p2p-interface/#lightclientupdatesbyrange","title":"LightClientUpdatesByRange","text":"<code>fork_version</code> Response chunk SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientUpdate</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientUpdate</code> <code>DENEB_FORK_VERSION</code> and later <code>deneb.LightClientUpdate</code>"},{"location":"specs/deneb/light-client/p2p-interface/#getlightclientfinalityupdate","title":"GetLightClientFinalityUpdate","text":"<code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientFinalityUpdate</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientFinalityUpdate</code> <code>DENEB_FORK_VERSION</code> and later <code>deneb.LightClientFinalityUpdate</code>"},{"location":"specs/deneb/light-client/p2p-interface/#getlightclientoptimisticupdate","title":"GetLightClientOptimisticUpdate","text":"<code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientOptimisticUpdate</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientOptimisticUpdate</code> <code>DENEB_FORK_VERSION</code> and later <code>deneb.LightClientOptimisticUpdate</code>"},{"location":"specs/deneb/light-client/sync-protocol/","title":"Deneb Light Client -- Sync Protocol","text":"<ul> <li>Introduction</li> <li>Helper functions</li> <li>Modified <code>get_lc_execution_root</code></li> <li>Modified <code>is_valid_light_client_header</code></li> </ul>"},{"location":"specs/deneb/light-client/sync-protocol/#introduction","title":"Introduction","text":"<p>This upgrade updates light client data to include the Deneb changes to the <code>ExecutionPayload</code> structure. It extends the Capella Light Client specifications. The fork document explains how to upgrade existing Capella based deployments to Deneb.</p> <p>Additional documents describes the impact of the upgrade on certain roles:</p> <ul> <li>Full node</li> <li>Networking</li> </ul>"},{"location":"specs/deneb/light-client/sync-protocol/#helper-functions","title":"Helper functions","text":""},{"location":"specs/deneb/light-client/sync-protocol/#modified-get_lc_execution_root","title":"Modified <code>get_lc_execution_root</code>","text":"<pre><code>def get_lc_execution_root(header: LightClientHeader) -&gt; Root:\n    epoch = compute_epoch_at_slot(header.beacon.slot)\n\n    # [New in Deneb]\n    if epoch &gt;= DENEB_FORK_EPOCH:\n        return hash_tree_root(header.execution)\n\n    # [Modified in Deneb]\n    if epoch &gt;= CAPELLA_FORK_EPOCH:\n        execution_header = capella.ExecutionPayloadHeader(\n            parent_hash=header.execution.parent_hash,\n            fee_recipient=header.execution.fee_recipient,\n            state_root=header.execution.state_root,\n            receipts_root=header.execution.receipts_root,\n            logs_bloom=header.execution.logs_bloom,\n            prev_randao=header.execution.prev_randao,\n            block_number=header.execution.block_number,\n            gas_limit=header.execution.gas_limit,\n            gas_used=header.execution.gas_used,\n            timestamp=header.execution.timestamp,\n            extra_data=header.execution.extra_data,\n            base_fee_per_gas=header.execution.base_fee_per_gas,\n            block_hash=header.execution.block_hash,\n            transactions_root=header.execution.transactions_root,\n            withdrawals_root=header.execution.withdrawals_root,\n        )\n        return hash_tree_root(execution_header)\n\n    return Root()\n</code></pre>"},{"location":"specs/deneb/light-client/sync-protocol/#modified-is_valid_light_client_header","title":"Modified <code>is_valid_light_client_header</code>","text":"<pre><code>def is_valid_light_client_header(header: LightClientHeader) -&gt; bool:\n    epoch = compute_epoch_at_slot(header.beacon.slot)\n\n    # [New in Deneb:EIP4844]\n    if epoch &lt; DENEB_FORK_EPOCH:\n        if header.execution.blob_gas_used != uint64(0):\n            return False\n        if header.execution.excess_blob_gas != uint64(0):\n            return False\n\n    if epoch &lt; CAPELLA_FORK_EPOCH:\n        return (\n            header.execution == ExecutionPayloadHeader()\n            and header.execution_branch == ExecutionBranch()\n        )\n\n    return is_valid_merkle_branch(\n        leaf=get_lc_execution_root(header),\n        branch=header.execution_branch,\n        depth=floorlog2(EXECUTION_PAYLOAD_GINDEX),\n        index=get_subtree_index(EXECUTION_PAYLOAD_GINDEX),\n        root=header.beacon.body_root,\n    )\n</code></pre>"},{"location":"specs/electra/","title":"Index","text":""},{"location":"specs/electra/#core","title":"Core","text":"<ul> <li>Beacon Chain</li> <li>Fork</li> <li>P2P Interface</li> <li>Validator</li> <li>Weak Subjectivity</li> </ul>"},{"location":"specs/electra/#light-client","title":"Light Client","text":"<ul> <li>Fork</li> <li>P2P Interface</li> <li>Sync Protocol</li> </ul>"},{"location":"specs/electra/beacon-chain/","title":"Electra -- The Beacon Chain","text":"<ul> <li>Introduction</li> <li>Constants</li> <li>Misc</li> <li>Withdrawal prefixes</li> <li>Execution layer triggered requests</li> <li>Preset</li> <li>Gwei values</li> <li>Rewards and penalties</li> <li>State list lengths</li> <li>Max operations per block</li> <li>Execution</li> <li>Withdrawals processing</li> <li>Pending deposits processing</li> <li>Configuration</li> <li>Execution</li> <li>Validator cycle</li> <li>Containers</li> <li>New containers<ul> <li><code>PendingDeposit</code></li> <li><code>PendingPartialWithdrawal</code></li> <li><code>PendingConsolidation</code></li> <li><code>DepositRequest</code></li> <li><code>WithdrawalRequest</code></li> <li><code>ConsolidationRequest</code></li> <li><code>ExecutionRequests</code></li> <li><code>SingleAttestation</code></li> </ul> </li> <li>Modified containers<ul> <li><code>AttesterSlashing</code></li> <li><code>BeaconBlockBody</code></li> </ul> </li> <li>Modified containers<ul> <li><code>Attestation</code></li> <li><code>IndexedAttestation</code></li> <li><code>BeaconState</code></li> </ul> </li> <li>Helper functions</li> <li>Predicates<ul> <li>Modified <code>compute_proposer_index</code></li> <li>Modified <code>is_eligible_for_activation_queue</code></li> <li>New <code>is_compounding_withdrawal_credential</code></li> <li>New <code>has_compounding_withdrawal_credential</code></li> <li>New <code>has_execution_withdrawal_credential</code></li> <li>Modified <code>is_fully_withdrawable_validator</code></li> <li>Modified <code>is_partially_withdrawable_validator</code></li> </ul> </li> <li>Misc<ul> <li>New <code>get_committee_indices</code></li> <li>New <code>get_max_effective_balance</code></li> </ul> </li> <li>Beacon state accessors<ul> <li>New <code>get_balance_churn_limit</code></li> <li>New <code>get_activation_exit_churn_limit</code></li> <li>New <code>get_consolidation_churn_limit</code></li> <li>New <code>get_pending_balance_to_withdraw</code></li> <li>Modified <code>get_attesting_indices</code></li> <li>Modified <code>get_next_sync_committee_indices</code></li> </ul> </li> <li>Beacon state mutators<ul> <li>Modified <code>initiate_validator_exit</code></li> <li>New <code>switch_to_compounding_validator</code></li> <li>New <code>queue_excess_active_balance</code></li> <li>New <code>compute_exit_epoch_and_update_churn</code></li> <li>New <code>compute_consolidation_epoch_and_update_churn</code></li> <li>Modified <code>slash_validator</code></li> </ul> </li> <li>Beacon chain state transition function</li> <li>Epoch processing<ul> <li>Modified <code>process_epoch</code></li> <li>Modified <code>process_registry_updates</code></li> <li>Modified <code>process_slashings</code></li> <li>New <code>apply_pending_deposit</code></li> <li>New <code>process_pending_deposits</code></li> <li>New <code>process_pending_consolidations</code></li> <li>Modified <code>process_effective_balance_updates</code></li> </ul> </li> <li>Execution engine<ul> <li>Request data</li> <li>Modified <code>NewPayloadRequest</code></li> <li>Engine APIs</li> <li>Modified <code>is_valid_block_hash</code></li> <li>Modified <code>notify_new_payload</code></li> <li>Modified <code>verify_and_notify_new_payload</code></li> </ul> </li> <li>Block processing<ul> <li>Withdrawals</li> <li>Modified <code>get_expected_withdrawals</code></li> <li>Modified <code>process_withdrawals</code></li> <li>Execution payload</li> <li>New <code>get_execution_requests_list</code></li> <li>Modified <code>process_execution_payload</code></li> <li>Operations</li> <li>Modified <code>process_operations</code></li> <li>Attestations<ul> <li>Modified <code>process_attestation</code></li> </ul> </li> <li>Deposits<ul> <li>Modified <code>get_validator_from_deposit</code></li> <li>Modified <code>add_validator_to_registry</code></li> <li>Modified <code>apply_deposit</code></li> <li>New <code>is_valid_deposit_signature</code></li> <li>Modified <code>process_deposit</code></li> </ul> </li> <li>Voluntary exits<ul> <li>Modified <code>process_voluntary_exit</code></li> </ul> </li> <li>Execution layer withdrawal requests<ul> <li>New <code>process_withdrawal_request</code></li> </ul> </li> <li>Deposit requests<ul> <li>New <code>process_deposit_request</code></li> </ul> </li> <li>Execution layer consolidation requests<ul> <li>New <code>is_valid_switch_to_compounding_request</code></li> <li>New <code>process_consolidation_request</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"specs/electra/beacon-chain/#introduction","title":"Introduction","text":"<p>Electra is a consensus-layer upgrade containing a number of features. Including:</p> <ul> <li>EIP-6110: Supply validator deposits   on chain</li> <li>EIP-7002: Execution layer   triggerable exits</li> <li>EIP-7251: Increase the   MAX_EFFECTIVE_BALANCE</li> <li>EIP-7549: Move committee index   outside Attestation</li> <li>EIP-7691: Blob throughput increase</li> </ul> <p>Note: This specification is built upon Deneb and is under active development.</p>"},{"location":"specs/electra/beacon-chain/#constants","title":"Constants","text":"<p>The following values are (non-configurable) constants used throughout the specification.</p>"},{"location":"specs/electra/beacon-chain/#misc","title":"Misc","text":"Name Value Description <code>UNSET_DEPOSIT_REQUESTS_START_INDEX</code> <code>uint64(2**64 - 1)</code> [New in Electra:EIP6110] Value which indicates no start index has been assigned <code>FULL_EXIT_REQUEST_AMOUNT</code> <code>uint64(0)</code> [New in Electra:EIP7002] Withdrawal amount used to signal a full validator exit"},{"location":"specs/electra/beacon-chain/#withdrawal-prefixes","title":"Withdrawal prefixes","text":"Name Value Description <code>COMPOUNDING_WITHDRAWAL_PREFIX</code> <code>Bytes1('0x02')</code> [New in Electra:EIP7251] Withdrawal credential prefix for a compounding validator"},{"location":"specs/electra/beacon-chain/#execution-layer-triggered-requests","title":"Execution layer triggered requests","text":"Name Value <code>DEPOSIT_REQUEST_TYPE</code> <code>Bytes1('0x00')</code> <code>WITHDRAWAL_REQUEST_TYPE</code> <code>Bytes1('0x01')</code> <code>CONSOLIDATION_REQUEST_TYPE</code> <code>Bytes1('0x02')</code>"},{"location":"specs/electra/beacon-chain/#preset","title":"Preset","text":""},{"location":"specs/electra/beacon-chain/#gwei-values","title":"Gwei values","text":"Name Value Description <code>MIN_ACTIVATION_BALANCE</code> <code>Gwei(2**5 * 10**9)</code> (= 32,000,000,000) [New in Electra:EIP7251] Minimum balance for a validator to become active <code>MAX_EFFECTIVE_BALANCE_ELECTRA</code> <code>Gwei(2**11 * 10**9)</code> (= 2048,000,000,000) [New in Electra:EIP7251] Maximum effective balance for a compounding validator"},{"location":"specs/electra/beacon-chain/#rewards-and-penalties","title":"Rewards and penalties","text":"Name Value <code>MIN_SLASHING_PENALTY_QUOTIENT_ELECTRA</code> <code>uint64(2**12)</code> (= 4,096) <code>WHISTLEBLOWER_REWARD_QUOTIENT_ELECTRA</code> <code>uint64(2**12)</code> (= 4,096)"},{"location":"specs/electra/beacon-chain/#state-list-lengths","title":"State list lengths","text":"Name Value Unit <code>PENDING_DEPOSITS_LIMIT</code> <code>uint64(2**27)</code> (= 134,217,728) pending deposits <code>PENDING_PARTIAL_WITHDRAWALS_LIMIT</code> <code>uint64(2**27)</code> (= 134,217,728) pending partial withdrawals <code>PENDING_CONSOLIDATIONS_LIMIT</code> <code>uint64(2**18)</code> (= 262,144) pending consolidations"},{"location":"specs/electra/beacon-chain/#max-operations-per-block","title":"Max operations per block","text":"Name Value <code>MAX_ATTESTER_SLASHINGS_ELECTRA</code> <code>2**0</code> (= 1) <code>MAX_ATTESTATIONS_ELECTRA</code> <code>2**3</code> (= 8)"},{"location":"specs/electra/beacon-chain/#execution","title":"Execution","text":"Name Value Description <code>MAX_DEPOSIT_REQUESTS_PER_PAYLOAD</code> <code>uint64(2**13)</code> (= 8,192) [New in Electra:EIP6110] Maximum number of execution layer deposit requests in each payload <code>MAX_WITHDRAWAL_REQUESTS_PER_PAYLOAD</code> <code>uint64(2**4)</code> (= 16) [New in Electra:EIP7002] Maximum number of execution layer withdrawal requests in each payload <code>MAX_CONSOLIDATION_REQUESTS_PER_PAYLOAD</code> <code>uint64(2**1)</code> (= 2) [New in Electra:EIP7251] Maximum number of execution layer consolidation requests in each payload"},{"location":"specs/electra/beacon-chain/#withdrawals-processing","title":"Withdrawals processing","text":"Name Value Description <code>MAX_PENDING_PARTIALS_PER_WITHDRAWALS_SWEEP</code> <code>uint64(2**3)</code> (= 8) [New in Electra:EIP7002] Maximum number of pending partial withdrawals to process per payload"},{"location":"specs/electra/beacon-chain/#pending-deposits-processing","title":"Pending deposits processing","text":"Name Value Description <code>MAX_PENDING_DEPOSITS_PER_EPOCH</code> <code>uint64(2**4)</code> (= 16) [New in Electra:EIP6110] Maximum number of pending deposits to process per epoch"},{"location":"specs/electra/beacon-chain/#configuration","title":"Configuration","text":""},{"location":"specs/electra/beacon-chain/#execution_1","title":"Execution","text":"Name Value Description <code>MAX_BLOBS_PER_BLOCK_ELECTRA</code> <code>uint64(9)</code> [New in Electra:EIP7691] Maximum number of blobs in a single block limited by <code>MAX_BLOB_COMMITMENTS_PER_BLOCK</code>"},{"location":"specs/electra/beacon-chain/#validator-cycle","title":"Validator cycle","text":"Name Value <code>MIN_PER_EPOCH_CHURN_LIMIT_ELECTRA</code> <code>Gwei(2**7 * 10**9)</code> (= 128,000,000,000) <code>MAX_PER_EPOCH_ACTIVATION_EXIT_CHURN_LIMIT</code> <code>Gwei(2**8 * 10**9)</code> (= 256,000,000,000)"},{"location":"specs/electra/beacon-chain/#containers","title":"Containers","text":""},{"location":"specs/electra/beacon-chain/#new-containers","title":"New containers","text":""},{"location":"specs/electra/beacon-chain/#pendingdeposit","title":"<code>PendingDeposit</code>","text":"<p>Note: The container is new in EIP7251.</p> <pre><code>class PendingDeposit(Container):\n    pubkey: BLSPubkey\n    withdrawal_credentials: Bytes32\n    amount: Gwei\n    signature: BLSSignature\n    slot: Slot\n</code></pre>"},{"location":"specs/electra/beacon-chain/#pendingpartialwithdrawal","title":"<code>PendingPartialWithdrawal</code>","text":"<p>Note: The container is new in EIP7251.</p> <pre><code>class PendingPartialWithdrawal(Container):\n    validator_index: ValidatorIndex\n    amount: Gwei\n    withdrawable_epoch: Epoch\n</code></pre>"},{"location":"specs/electra/beacon-chain/#pendingconsolidation","title":"<code>PendingConsolidation</code>","text":"<p>Note: The container is new in EIP7251.</p> <pre><code>class PendingConsolidation(Container):\n    source_index: ValidatorIndex\n    target_index: ValidatorIndex\n</code></pre>"},{"location":"specs/electra/beacon-chain/#depositrequest","title":"<code>DepositRequest</code>","text":"<p>Note: The container is new in EIP6110.</p> <pre><code>class DepositRequest(Container):\n    pubkey: BLSPubkey\n    withdrawal_credentials: Bytes32\n    amount: Gwei\n    signature: BLSSignature\n    index: uint64\n</code></pre>"},{"location":"specs/electra/beacon-chain/#withdrawalrequest","title":"<code>WithdrawalRequest</code>","text":"<p>Note: The container is new in EIP7251:EIP7002.</p> <pre><code>class WithdrawalRequest(Container):\n    source_address: ExecutionAddress\n    validator_pubkey: BLSPubkey\n    amount: Gwei\n</code></pre>"},{"location":"specs/electra/beacon-chain/#consolidationrequest","title":"<code>ConsolidationRequest</code>","text":"<p>Note: The container is new in EIP7251.</p> <pre><code>class ConsolidationRequest(Container):\n    source_address: ExecutionAddress\n    source_pubkey: BLSPubkey\n    target_pubkey: BLSPubkey\n</code></pre>"},{"location":"specs/electra/beacon-chain/#executionrequests","title":"<code>ExecutionRequests</code>","text":"<pre><code>class ExecutionRequests(Container):\n    # [New in Electra:EIP6110]\n    deposits: List[DepositRequest, MAX_DEPOSIT_REQUESTS_PER_PAYLOAD]\n    # [New in Electra:EIP7002:EIP7251]\n    withdrawals: List[WithdrawalRequest, MAX_WITHDRAWAL_REQUESTS_PER_PAYLOAD]\n    # [New in Electra:EIP7251]\n    consolidations: List[ConsolidationRequest, MAX_CONSOLIDATION_REQUESTS_PER_PAYLOAD]\n</code></pre>"},{"location":"specs/electra/beacon-chain/#singleattestation","title":"<code>SingleAttestation</code>","text":"<pre><code>class SingleAttestation(Container):\n    committee_index: CommitteeIndex\n    attester_index: ValidatorIndex\n    data: AttestationData\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-containers","title":"Modified containers","text":""},{"location":"specs/electra/beacon-chain/#attesterslashing","title":"<code>AttesterSlashing</code>","text":"<pre><code>class AttesterSlashing(Container):\n    # [Modified in Electra:EIP7549]\n    attestation_1: IndexedAttestation\n    # [Modified in Electra:EIP7549]\n    attestation_2: IndexedAttestation\n</code></pre>"},{"location":"specs/electra/beacon-chain/#beaconblockbody","title":"<code>BeaconBlockBody</code>","text":"<pre><code>class BeaconBlockBody(Container):\n    randao_reveal: BLSSignature\n    eth1_data: Eth1Data\n    graffiti: Bytes32\n    proposer_slashings: List[ProposerSlashing, MAX_PROPOSER_SLASHINGS]\n    # [Modified in Electra:EIP7549]\n    attester_slashings: List[AttesterSlashing, MAX_ATTESTER_SLASHINGS_ELECTRA]\n    # [Modified in Electra:EIP7549]\n    attestations: List[Attestation, MAX_ATTESTATIONS_ELECTRA]\n    deposits: List[Deposit, MAX_DEPOSITS]\n    voluntary_exits: List[SignedVoluntaryExit, MAX_VOLUNTARY_EXITS]\n    sync_aggregate: SyncAggregate\n    execution_payload: ExecutionPayload\n    bls_to_execution_changes: List[SignedBLSToExecutionChange, MAX_BLS_TO_EXECUTION_CHANGES]\n    blob_kzg_commitments: List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    # [New in Electra]\n    execution_requests: ExecutionRequests\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-containers_1","title":"Modified containers","text":""},{"location":"specs/electra/beacon-chain/#attestation","title":"<code>Attestation</code>","text":"<pre><code>class Attestation(Container):\n    # [Modified in Electra:EIP7549]\n    aggregation_bits: Bitlist[MAX_VALIDATORS_PER_COMMITTEE * MAX_COMMITTEES_PER_SLOT]\n    data: AttestationData\n    signature: BLSSignature\n    # [New in Electra:EIP7549]\n    committee_bits: Bitvector[MAX_COMMITTEES_PER_SLOT]\n</code></pre>"},{"location":"specs/electra/beacon-chain/#indexedattestation","title":"<code>IndexedAttestation</code>","text":"<pre><code>class IndexedAttestation(Container):\n    # [Modified in Electra:EIP7549]\n    attesting_indices: List[ValidatorIndex, MAX_VALIDATORS_PER_COMMITTEE * MAX_COMMITTEES_PER_SLOT]\n    data: AttestationData\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/electra/beacon-chain/#beaconstate","title":"<code>BeaconState</code>","text":"<pre><code>class BeaconState(Container):\n    genesis_time: uint64\n    genesis_validators_root: Root\n    slot: Slot\n    fork: Fork\n    latest_block_header: BeaconBlockHeader\n    block_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    state_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    historical_roots: List[Root, HISTORICAL_ROOTS_LIMIT]\n    eth1_data: Eth1Data\n    eth1_data_votes: List[Eth1Data, EPOCHS_PER_ETH1_VOTING_PERIOD * SLOTS_PER_EPOCH]\n    eth1_deposit_index: uint64\n    validators: List[Validator, VALIDATOR_REGISTRY_LIMIT]\n    balances: List[Gwei, VALIDATOR_REGISTRY_LIMIT]\n    randao_mixes: Vector[Bytes32, EPOCHS_PER_HISTORICAL_VECTOR]\n    slashings: Vector[Gwei, EPOCHS_PER_SLASHINGS_VECTOR]\n    previous_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    current_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    justification_bits: Bitvector[JUSTIFICATION_BITS_LENGTH]\n    previous_justified_checkpoint: Checkpoint\n    current_justified_checkpoint: Checkpoint\n    finalized_checkpoint: Checkpoint\n    inactivity_scores: List[uint64, VALIDATOR_REGISTRY_LIMIT]\n    current_sync_committee: SyncCommittee\n    next_sync_committee: SyncCommittee\n    latest_execution_payload_header: ExecutionPayloadHeader\n    next_withdrawal_index: WithdrawalIndex\n    next_withdrawal_validator_index: ValidatorIndex\n    historical_summaries: List[HistoricalSummary, HISTORICAL_ROOTS_LIMIT]\n    # [New in Electra:EIP6110]\n    deposit_requests_start_index: uint64\n    # [New in Electra:EIP7251]\n    deposit_balance_to_consume: Gwei\n    # [New in Electra:EIP7251]\n    exit_balance_to_consume: Gwei\n    # [New in Electra:EIP7251]\n    earliest_exit_epoch: Epoch\n    # [New in Electra:EIP7251]\n    consolidation_balance_to_consume: Gwei\n    # [New in Electra:EIP7251]\n    earliest_consolidation_epoch: Epoch\n    # [New in Electra:EIP7251]\n    pending_deposits: List[PendingDeposit, PENDING_DEPOSITS_LIMIT]\n    # [New in Electra:EIP7251]\n    pending_partial_withdrawals: List[PendingPartialWithdrawal, PENDING_PARTIAL_WITHDRAWALS_LIMIT]\n    # [New in Electra:EIP7251]\n    pending_consolidations: List[PendingConsolidation, PENDING_CONSOLIDATIONS_LIMIT]\n</code></pre>"},{"location":"specs/electra/beacon-chain/#helper-functions","title":"Helper functions","text":""},{"location":"specs/electra/beacon-chain/#predicates","title":"Predicates","text":""},{"location":"specs/electra/beacon-chain/#modified-compute_proposer_index","title":"Modified <code>compute_proposer_index</code>","text":"<p>Note: The function <code>compute_proposer_index</code> is modified to use <code>MAX_EFFECTIVE_BALANCE_ELECTRA</code> and to use a 16-bit random value instead of an 8-bit random byte in the effective balance filter.</p> <pre><code>def compute_proposer_index(\n    state: BeaconState, indices: Sequence[ValidatorIndex], seed: Bytes32\n) -&gt; ValidatorIndex:\n    \"\"\"\n    Return from ``indices`` a random index sampled by effective balance.\n    \"\"\"\n    assert len(indices) &gt; 0\n    # [Modified in Electra]\n    MAX_RANDOM_VALUE = 2**16 - 1\n    i = uint64(0)\n    total = uint64(len(indices))\n    while True:\n        candidate_index = indices[compute_shuffled_index(i % total, total, seed)]\n        # [Modified in Electra]\n        random_bytes = hash(seed + uint_to_bytes(i // 16))\n        offset = i % 16 * 2\n        random_value = bytes_to_uint64(random_bytes[offset : offset + 2])\n        effective_balance = state.validators[candidate_index].effective_balance\n        # [Modified in Electra:EIP7251]\n        if effective_balance * MAX_RANDOM_VALUE &gt;= MAX_EFFECTIVE_BALANCE_ELECTRA * random_value:\n            return candidate_index\n        i += 1\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-is_eligible_for_activation_queue","title":"Modified <code>is_eligible_for_activation_queue</code>","text":"<p>Note: The function <code>is_eligible_for_activation_queue</code> is modified to use <code>MIN_ACTIVATION_BALANCE</code> instead of <code>MAX_EFFECTIVE_BALANCE</code>.</p> <pre><code>def is_eligible_for_activation_queue(validator: Validator) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` is eligible to be placed into the activation queue.\n    \"\"\"\n    return (\n        validator.activation_eligibility_epoch == FAR_FUTURE_EPOCH\n        # [Modified in Electra:EIP7251]\n        and validator.effective_balance &gt;= MIN_ACTIVATION_BALANCE\n    )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-is_compounding_withdrawal_credential","title":"New <code>is_compounding_withdrawal_credential</code>","text":"<pre><code>def is_compounding_withdrawal_credential(withdrawal_credentials: Bytes32) -&gt; bool:\n    return withdrawal_credentials[:1] == COMPOUNDING_WITHDRAWAL_PREFIX\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-has_compounding_withdrawal_credential","title":"New <code>has_compounding_withdrawal_credential</code>","text":"<pre><code>def has_compounding_withdrawal_credential(validator: Validator) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` has an 0x02 prefixed \"compounding\" withdrawal credential.\n    \"\"\"\n    return is_compounding_withdrawal_credential(validator.withdrawal_credentials)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-has_execution_withdrawal_credential","title":"New <code>has_execution_withdrawal_credential</code>","text":"<pre><code>def has_execution_withdrawal_credential(validator: Validator) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` has a 0x01 or 0x02 prefixed withdrawal credential.\n    \"\"\"\n    return (\n        has_eth1_withdrawal_credential(validator)  # 0x01\n        or has_compounding_withdrawal_credential(validator)  # 0x02\n    )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-is_fully_withdrawable_validator","title":"Modified <code>is_fully_withdrawable_validator</code>","text":"<p>Note: The function <code>is_fully_withdrawable_validator</code> is modified to use <code>has_execution_withdrawal_credential</code> instead of <code>has_eth1_withdrawal_credential</code>.</p> <pre><code>def is_fully_withdrawable_validator(validator: Validator, balance: Gwei, epoch: Epoch) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` is fully withdrawable.\n    \"\"\"\n    return (\n        # [Modified in Electra:EIP7251]\n        has_execution_withdrawal_credential(validator)\n        and validator.withdrawable_epoch &lt;= epoch\n        and balance &gt; 0\n    )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-is_partially_withdrawable_validator","title":"Modified <code>is_partially_withdrawable_validator</code>","text":"<p>Note: The function <code>is_partially_withdrawable_validator</code> is modified to use <code>get_max_effective_balance</code> instead of <code>MAX_EFFECTIVE_BALANCE</code> and <code>has_execution_withdrawal_credential</code> instead of <code>has_eth1_withdrawal_credential</code>.</p> <pre><code>def is_partially_withdrawable_validator(validator: Validator, balance: Gwei) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` is partially withdrawable.\n    \"\"\"\n    max_effective_balance = get_max_effective_balance(validator)\n    # [Modified in Electra:EIP7251]\n    has_max_effective_balance = validator.effective_balance == max_effective_balance\n    # [Modified in Electra:EIP7251]\n    has_excess_balance = balance &gt; max_effective_balance\n    return (\n        # [Modified in Electra:EIP7251]\n        has_execution_withdrawal_credential(validator)\n        and has_max_effective_balance\n        and has_excess_balance\n    )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#misc_1","title":"Misc","text":""},{"location":"specs/electra/beacon-chain/#new-get_committee_indices","title":"New <code>get_committee_indices</code>","text":"<pre><code>def get_committee_indices(committee_bits: Bitvector) -&gt; Sequence[CommitteeIndex]:\n    return [CommitteeIndex(index) for index, bit in enumerate(committee_bits) if bit]\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-get_max_effective_balance","title":"New <code>get_max_effective_balance</code>","text":"<pre><code>def get_max_effective_balance(validator: Validator) -&gt; Gwei:\n    \"\"\"\n    Get max effective balance for ``validator``.\n    \"\"\"\n    if has_compounding_withdrawal_credential(validator):\n        return MAX_EFFECTIVE_BALANCE_ELECTRA\n    else:\n        return MIN_ACTIVATION_BALANCE\n</code></pre>"},{"location":"specs/electra/beacon-chain/#beacon-state-accessors","title":"Beacon state accessors","text":""},{"location":"specs/electra/beacon-chain/#new-get_balance_churn_limit","title":"New <code>get_balance_churn_limit</code>","text":"<pre><code>def get_balance_churn_limit(state: BeaconState) -&gt; Gwei:\n    \"\"\"\n    Return the churn limit for the current epoch.\n    \"\"\"\n    churn = max(\n        MIN_PER_EPOCH_CHURN_LIMIT_ELECTRA, get_total_active_balance(state) // CHURN_LIMIT_QUOTIENT\n    )\n    return churn - churn % EFFECTIVE_BALANCE_INCREMENT\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-get_activation_exit_churn_limit","title":"New <code>get_activation_exit_churn_limit</code>","text":"<pre><code>def get_activation_exit_churn_limit(state: BeaconState) -&gt; Gwei:\n    \"\"\"\n    Return the churn limit for the current epoch dedicated to activations and exits.\n    \"\"\"\n    return min(MAX_PER_EPOCH_ACTIVATION_EXIT_CHURN_LIMIT, get_balance_churn_limit(state))\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-get_consolidation_churn_limit","title":"New <code>get_consolidation_churn_limit</code>","text":"<pre><code>def get_consolidation_churn_limit(state: BeaconState) -&gt; Gwei:\n    return get_balance_churn_limit(state) - get_activation_exit_churn_limit(state)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-get_pending_balance_to_withdraw","title":"New <code>get_pending_balance_to_withdraw</code>","text":"<pre><code>def get_pending_balance_to_withdraw(state: BeaconState, validator_index: ValidatorIndex) -&gt; Gwei:\n    return sum(\n        withdrawal.amount\n        for withdrawal in state.pending_partial_withdrawals\n        if withdrawal.validator_index == validator_index\n    )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-get_attesting_indices","title":"Modified <code>get_attesting_indices</code>","text":"<p>Note: The function <code>get_attesting_indices</code> is modified to support EIP7549.</p> <pre><code>def get_attesting_indices(state: BeaconState, attestation: Attestation) -&gt; Set[ValidatorIndex]:\n    \"\"\"\n    Return the set of attesting indices corresponding to ``aggregation_bits`` and ``committee_bits``.\n    \"\"\"\n    output: Set[ValidatorIndex] = set()\n    committee_indices = get_committee_indices(attestation.committee_bits)\n    committee_offset = 0\n    for committee_index in committee_indices:\n        committee = get_beacon_committee(state, attestation.data.slot, committee_index)\n        committee_attesters = set(\n            attester_index\n            for i, attester_index in enumerate(committee)\n            if attestation.aggregation_bits[committee_offset + i]\n        )\n        output = output.union(committee_attesters)\n\n        committee_offset += len(committee)\n\n    return output\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-get_next_sync_committee_indices","title":"Modified <code>get_next_sync_committee_indices</code>","text":"<p>Note: The function <code>get_next_sync_committee_indices</code> is modified to use <code>MAX_EFFECTIVE_BALANCE_ELECTRA</code> and to use a 16-bit random value instead of an 8-bit random byte in the effective balance filter.</p> <pre><code>def get_next_sync_committee_indices(state: BeaconState) -&gt; Sequence[ValidatorIndex]:\n    \"\"\"\n    Return the sync committee indices, with possible duplicates, for the next sync committee.\n    \"\"\"\n    epoch = Epoch(get_current_epoch(state) + 1)\n\n    # [Modified in Electra]\n    MAX_RANDOM_VALUE = 2**16 - 1\n    active_validator_indices = get_active_validator_indices(state, epoch)\n    active_validator_count = uint64(len(active_validator_indices))\n    seed = get_seed(state, epoch, DOMAIN_SYNC_COMMITTEE)\n    i = uint64(0)\n    sync_committee_indices: List[ValidatorIndex] = []\n    while len(sync_committee_indices) &lt; SYNC_COMMITTEE_SIZE:\n        shuffled_index = compute_shuffled_index(\n            uint64(i % active_validator_count), active_validator_count, seed\n        )\n        candidate_index = active_validator_indices[shuffled_index]\n        # [Modified in Electra]\n        random_bytes = hash(seed + uint_to_bytes(i // 16))\n        offset = i % 16 * 2\n        random_value = bytes_to_uint64(random_bytes[offset : offset + 2])\n        effective_balance = state.validators[candidate_index].effective_balance\n        # [Modified in Electra:EIP7251]\n        if effective_balance * MAX_RANDOM_VALUE &gt;= MAX_EFFECTIVE_BALANCE_ELECTRA * random_value:\n            sync_committee_indices.append(candidate_index)\n        i += 1\n    return sync_committee_indices\n</code></pre>"},{"location":"specs/electra/beacon-chain/#beacon-state-mutators","title":"Beacon state mutators","text":""},{"location":"specs/electra/beacon-chain/#modified-initiate_validator_exit","title":"Modified <code>initiate_validator_exit</code>","text":"<p>Note: The function <code>initiate_validator_exit</code> is modified to use the new <code>compute_exit_epoch_and_update_churn</code> function.</p> <pre><code>def initiate_validator_exit(state: BeaconState, index: ValidatorIndex) -&gt; None:\n    \"\"\"\n    Initiate the exit of the validator with index ``index``.\n    \"\"\"\n    # Return if validator already initiated exit\n    validator = state.validators[index]\n    if validator.exit_epoch != FAR_FUTURE_EPOCH:\n        return\n\n    # Compute exit queue epoch [Modified in Electra:EIP7251]\n    exit_queue_epoch = compute_exit_epoch_and_update_churn(state, validator.effective_balance)\n\n    # Set validator exit epoch and withdrawable epoch\n    validator.exit_epoch = exit_queue_epoch\n    validator.withdrawable_epoch = Epoch(validator.exit_epoch + MIN_VALIDATOR_WITHDRAWABILITY_DELAY)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-switch_to_compounding_validator","title":"New <code>switch_to_compounding_validator</code>","text":"<pre><code>def switch_to_compounding_validator(state: BeaconState, index: ValidatorIndex) -&gt; None:\n    validator = state.validators[index]\n    validator.withdrawal_credentials = (\n        COMPOUNDING_WITHDRAWAL_PREFIX + validator.withdrawal_credentials[1:]\n    )\n    queue_excess_active_balance(state, index)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-queue_excess_active_balance","title":"New <code>queue_excess_active_balance</code>","text":"<pre><code>def queue_excess_active_balance(state: BeaconState, index: ValidatorIndex) -&gt; None:\n    balance = state.balances[index]\n    if balance &gt; MIN_ACTIVATION_BALANCE:\n        excess_balance = balance - MIN_ACTIVATION_BALANCE\n        state.balances[index] = MIN_ACTIVATION_BALANCE\n        validator = state.validators[index]\n        # Use bls.G2_POINT_AT_INFINITY as a signature field placeholder\n        # and GENESIS_SLOT to distinguish from a pending deposit request\n        state.pending_deposits.append(\n            PendingDeposit(\n                pubkey=validator.pubkey,\n                withdrawal_credentials=validator.withdrawal_credentials,\n                amount=excess_balance,\n                signature=bls.G2_POINT_AT_INFINITY,\n                slot=GENESIS_SLOT,\n            )\n        )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-compute_exit_epoch_and_update_churn","title":"New <code>compute_exit_epoch_and_update_churn</code>","text":"<pre><code>def compute_exit_epoch_and_update_churn(state: BeaconState, exit_balance: Gwei) -&gt; Epoch:\n    earliest_exit_epoch = max(\n        state.earliest_exit_epoch, compute_activation_exit_epoch(get_current_epoch(state))\n    )\n    per_epoch_churn = get_activation_exit_churn_limit(state)\n    # New epoch for exits.\n    if state.earliest_exit_epoch &lt; earliest_exit_epoch:\n        exit_balance_to_consume = per_epoch_churn\n    else:\n        exit_balance_to_consume = state.exit_balance_to_consume\n\n    # Exit doesn't fit in the current earliest epoch.\n    if exit_balance &gt; exit_balance_to_consume:\n        balance_to_process = exit_balance - exit_balance_to_consume\n        additional_epochs = (balance_to_process - 1) // per_epoch_churn + 1\n        earliest_exit_epoch += additional_epochs\n        exit_balance_to_consume += additional_epochs * per_epoch_churn\n\n    # Consume the balance and update state variables.\n    state.exit_balance_to_consume = exit_balance_to_consume - exit_balance\n    state.earliest_exit_epoch = earliest_exit_epoch\n\n    return state.earliest_exit_epoch\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-compute_consolidation_epoch_and_update_churn","title":"New <code>compute_consolidation_epoch_and_update_churn</code>","text":"<pre><code>def compute_consolidation_epoch_and_update_churn(\n    state: BeaconState, consolidation_balance: Gwei\n) -&gt; Epoch:\n    earliest_consolidation_epoch = max(\n        state.earliest_consolidation_epoch, compute_activation_exit_epoch(get_current_epoch(state))\n    )\n    per_epoch_consolidation_churn = get_consolidation_churn_limit(state)\n    # New epoch for consolidations.\n    if state.earliest_consolidation_epoch &lt; earliest_consolidation_epoch:\n        consolidation_balance_to_consume = per_epoch_consolidation_churn\n    else:\n        consolidation_balance_to_consume = state.consolidation_balance_to_consume\n\n    # Consolidation doesn't fit in the current earliest epoch.\n    if consolidation_balance &gt; consolidation_balance_to_consume:\n        balance_to_process = consolidation_balance - consolidation_balance_to_consume\n        additional_epochs = (balance_to_process - 1) // per_epoch_consolidation_churn + 1\n        earliest_consolidation_epoch += additional_epochs\n        consolidation_balance_to_consume += additional_epochs * per_epoch_consolidation_churn\n\n    # Consume the balance and update state variables.\n    state.consolidation_balance_to_consume = (\n        consolidation_balance_to_consume - consolidation_balance\n    )\n    state.earliest_consolidation_epoch = earliest_consolidation_epoch\n\n    return state.earliest_consolidation_epoch\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-slash_validator","title":"Modified <code>slash_validator</code>","text":"<p>Note: The function <code>slash_validator</code> is modified to change how the slashing penalty and proposer/whistleblower rewards are calculated in accordance with EIP7251.</p> <pre><code>def slash_validator(\n    state: BeaconState, slashed_index: ValidatorIndex, whistleblower_index: ValidatorIndex = None\n) -&gt; None:\n    \"\"\"\n    Slash the validator with index ``slashed_index``.\n    \"\"\"\n    epoch = get_current_epoch(state)\n    initiate_validator_exit(state, slashed_index)\n    validator = state.validators[slashed_index]\n    validator.slashed = True\n    validator.withdrawable_epoch = max(\n        validator.withdrawable_epoch, Epoch(epoch + EPOCHS_PER_SLASHINGS_VECTOR)\n    )\n    state.slashings[epoch % EPOCHS_PER_SLASHINGS_VECTOR] += validator.effective_balance\n    # [Modified in Electra:EIP7251]\n    slashing_penalty = validator.effective_balance // MIN_SLASHING_PENALTY_QUOTIENT_ELECTRA\n    decrease_balance(state, slashed_index, slashing_penalty)\n\n    # Apply proposer and whistleblower rewards\n    proposer_index = get_beacon_proposer_index(state)\n    if whistleblower_index is None:\n        whistleblower_index = proposer_index\n    # [Modified in Electra:EIP7251]\n    whistleblower_reward = Gwei(\n        validator.effective_balance // WHISTLEBLOWER_REWARD_QUOTIENT_ELECTRA\n    )\n    proposer_reward = Gwei(whistleblower_reward * PROPOSER_WEIGHT // WEIGHT_DENOMINATOR)\n    increase_balance(state, proposer_index, proposer_reward)\n    increase_balance(state, whistleblower_index, Gwei(whistleblower_reward - proposer_reward))\n</code></pre>"},{"location":"specs/electra/beacon-chain/#beacon-chain-state-transition-function","title":"Beacon chain state transition function","text":""},{"location":"specs/electra/beacon-chain/#epoch-processing","title":"Epoch processing","text":""},{"location":"specs/electra/beacon-chain/#modified-process_epoch","title":"Modified <code>process_epoch</code>","text":"<p>Note: The function <code>process_epoch</code> is modified to call updated functions and to process pending balance deposits and pending consolidations which are new in Electra.</p> <pre><code>def process_epoch(state: BeaconState) -&gt; None:\n    process_justification_and_finalization(state)\n    process_inactivity_updates(state)\n    process_rewards_and_penalties(state)\n    # [Modified in Electra:EIP7251]\n    process_registry_updates(state)\n    # [Modified in Electra:EIP7251]\n    process_slashings(state)\n    process_eth1_data_reset(state)\n    # [New in Electra:EIP7251]\n    process_pending_deposits(state)\n    # [New in Electra:EIP7251]\n    process_pending_consolidations(state)\n    # [Modified in Electra:EIP7251]\n    process_effective_balance_updates(state)\n    process_slashings_reset(state)\n    process_randao_mixes_reset(state)\n    process_historical_summaries_update(state)\n    process_participation_flag_updates(state)\n    process_sync_committee_updates(state)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-process_registry_updates","title":"Modified <code>process_registry_updates</code>","text":"<p>Note: The function <code>process_registry_updates</code> is modified to use the updated definitions of <code>initiate_validator_exit</code> and <code>is_eligible_for_activation_queue</code>, changes how the activation epochs are computed for eligible validators, and processes activations in the same loop as activation eligibility updates and ejections.</p> <pre><code>def process_registry_updates(state: BeaconState) -&gt; None:\n    current_epoch = get_current_epoch(state)\n    activation_epoch = compute_activation_exit_epoch(current_epoch)\n\n    # Process activation eligibility, ejections, and activations\n    for index, validator in enumerate(state.validators):\n        # [Modified in Electra:EIP7251]\n        if is_eligible_for_activation_queue(validator):\n            validator.activation_eligibility_epoch = current_epoch + 1\n        elif (\n            is_active_validator(validator, current_epoch)\n            and validator.effective_balance &lt;= EJECTION_BALANCE\n        ):\n            # [Modified in Electra:EIP7251]\n            initiate_validator_exit(state, ValidatorIndex(index))\n        elif is_eligible_for_activation(state, validator):\n            validator.activation_epoch = activation_epoch\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-process_slashings","title":"Modified <code>process_slashings</code>","text":"<p>Note: The function <code>process_slashings</code> is modified to use a new algorithm to compute correlation penalty.</p> <pre><code>def process_slashings(state: BeaconState) -&gt; None:\n    epoch = get_current_epoch(state)\n    total_balance = get_total_active_balance(state)\n    adjusted_total_slashing_balance = min(\n        sum(state.slashings) * PROPORTIONAL_SLASHING_MULTIPLIER_BELLATRIX, total_balance\n    )\n    increment = (\n        EFFECTIVE_BALANCE_INCREMENT  # Factored out from total balance to avoid uint64 overflow\n    )\n    penalty_per_effective_balance_increment = adjusted_total_slashing_balance // (\n        total_balance // increment\n    )\n    for index, validator in enumerate(state.validators):\n        if (\n            validator.slashed\n            and epoch + EPOCHS_PER_SLASHINGS_VECTOR // 2 == validator.withdrawable_epoch\n        ):\n            effective_balance_increments = validator.effective_balance // increment\n            # [Modified in Electra:EIP7251]\n            penalty = penalty_per_effective_balance_increment * effective_balance_increments\n            decrease_balance(state, ValidatorIndex(index), penalty)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-apply_pending_deposit","title":"New <code>apply_pending_deposit</code>","text":"<pre><code>def apply_pending_deposit(state: BeaconState, deposit: PendingDeposit) -&gt; None:\n    \"\"\"\n    Applies ``deposit`` to the ``state``.\n    \"\"\"\n    validator_pubkeys = [v.pubkey for v in state.validators]\n    if deposit.pubkey not in validator_pubkeys:\n        # Verify the deposit signature (proof of possession) which is not checked by the deposit contract\n        if is_valid_deposit_signature(\n            deposit.pubkey, deposit.withdrawal_credentials, deposit.amount, deposit.signature\n        ):\n            add_validator_to_registry(\n                state, deposit.pubkey, deposit.withdrawal_credentials, deposit.amount\n            )\n    else:\n        validator_index = ValidatorIndex(validator_pubkeys.index(deposit.pubkey))\n        increase_balance(state, validator_index, deposit.amount)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-process_pending_deposits","title":"New <code>process_pending_deposits</code>","text":"<p>Iterating over <code>pending_deposits</code> queue this function runs the following checks before applying pending deposit:</p> <ol> <li>All Eth1 bridge deposits are processed before the first deposit request gets    processed.</li> <li>Deposit position in the queue is finalized.</li> <li>Deposit does not exceed the <code>MAX_PENDING_DEPOSITS_PER_EPOCH</code> limit.</li> <li>Deposit does not exceed the activation churn limit.</li> </ol> <pre><code>def process_pending_deposits(state: BeaconState) -&gt; None:\n    next_epoch = Epoch(get_current_epoch(state) + 1)\n    available_for_processing = state.deposit_balance_to_consume + get_activation_exit_churn_limit(\n        state\n    )\n    processed_amount = 0\n    next_deposit_index = 0\n    deposits_to_postpone = []\n    is_churn_limit_reached = False\n    finalized_slot = compute_start_slot_at_epoch(state.finalized_checkpoint.epoch)\n\n    for deposit in state.pending_deposits:\n        # Do not process deposit requests if Eth1 bridge deposits are not yet applied.\n        if (\n            # Is deposit request\n            deposit.slot &gt; GENESIS_SLOT\n            and\n            # There are pending Eth1 bridge deposits\n            state.eth1_deposit_index &lt; state.deposit_requests_start_index\n        ):\n            break\n\n        # Check if deposit has been finalized, otherwise, stop processing.\n        if deposit.slot &gt; finalized_slot:\n            break\n\n        # Check if number of processed deposits has not reached the limit, otherwise, stop processing.\n        if next_deposit_index &gt;= MAX_PENDING_DEPOSITS_PER_EPOCH:\n            break\n\n        # Read validator state\n        is_validator_exited = False\n        is_validator_withdrawn = False\n        validator_pubkeys = [v.pubkey for v in state.validators]\n        if deposit.pubkey in validator_pubkeys:\n            validator = state.validators[ValidatorIndex(validator_pubkeys.index(deposit.pubkey))]\n            is_validator_exited = validator.exit_epoch &lt; FAR_FUTURE_EPOCH\n            is_validator_withdrawn = validator.withdrawable_epoch &lt; next_epoch\n\n        if is_validator_withdrawn:\n            # Deposited balance will never become active. Increase balance but do not consume churn\n            apply_pending_deposit(state, deposit)\n        elif is_validator_exited:\n            # Validator is exiting, postpone the deposit until after withdrawable epoch\n            deposits_to_postpone.append(deposit)\n        else:\n            # Check if deposit fits in the churn, otherwise, do no more deposit processing in this epoch.\n            is_churn_limit_reached = processed_amount + deposit.amount &gt; available_for_processing\n            if is_churn_limit_reached:\n                break\n\n            # Consume churn and apply deposit.\n            processed_amount += deposit.amount\n            apply_pending_deposit(state, deposit)\n\n        # Regardless of how the deposit was handled, we move on in the queue.\n        next_deposit_index += 1\n\n    state.pending_deposits = state.pending_deposits[next_deposit_index:] + deposits_to_postpone\n\n    # Accumulate churn only if the churn limit has been hit.\n    if is_churn_limit_reached:\n        state.deposit_balance_to_consume = available_for_processing - processed_amount\n    else:\n        state.deposit_balance_to_consume = Gwei(0)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-process_pending_consolidations","title":"New <code>process_pending_consolidations</code>","text":"<pre><code>def process_pending_consolidations(state: BeaconState) -&gt; None:\n    next_epoch = Epoch(get_current_epoch(state) + 1)\n    next_pending_consolidation = 0\n    for pending_consolidation in state.pending_consolidations:\n        source_validator = state.validators[pending_consolidation.source_index]\n        if source_validator.slashed:\n            next_pending_consolidation += 1\n            continue\n        if source_validator.withdrawable_epoch &gt; next_epoch:\n            break\n\n        # Calculate the consolidated balance\n        source_effective_balance = min(\n            state.balances[pending_consolidation.source_index], source_validator.effective_balance\n        )\n\n        # Move active balance to target. Excess balance is withdrawable.\n        decrease_balance(state, pending_consolidation.source_index, source_effective_balance)\n        increase_balance(state, pending_consolidation.target_index, source_effective_balance)\n        next_pending_consolidation += 1\n\n    state.pending_consolidations = state.pending_consolidations[next_pending_consolidation:]\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-process_effective_balance_updates","title":"Modified <code>process_effective_balance_updates</code>","text":"<p>Note: The function <code>process_effective_balance_updates</code> is modified to use the new limit for the maximum effective balance.</p> <pre><code>def process_effective_balance_updates(state: BeaconState) -&gt; None:\n    # Update effective balances with hysteresis\n    for index, validator in enumerate(state.validators):\n        balance = state.balances[index]\n        HYSTERESIS_INCREMENT = uint64(EFFECTIVE_BALANCE_INCREMENT // HYSTERESIS_QUOTIENT)\n        DOWNWARD_THRESHOLD = HYSTERESIS_INCREMENT * HYSTERESIS_DOWNWARD_MULTIPLIER\n        UPWARD_THRESHOLD = HYSTERESIS_INCREMENT * HYSTERESIS_UPWARD_MULTIPLIER\n        # [Modified in Electra:EIP7251]\n        max_effective_balance = get_max_effective_balance(validator)\n\n        if (\n            balance + DOWNWARD_THRESHOLD &lt; validator.effective_balance\n            or validator.effective_balance + UPWARD_THRESHOLD &lt; balance\n        ):\n            validator.effective_balance = min(\n                balance - balance % EFFECTIVE_BALANCE_INCREMENT, max_effective_balance\n            )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#execution-engine","title":"Execution engine","text":""},{"location":"specs/electra/beacon-chain/#request-data","title":"Request data","text":""},{"location":"specs/electra/beacon-chain/#modified-newpayloadrequest","title":"Modified <code>NewPayloadRequest</code>","text":"<pre><code>@dataclass\nclass NewPayloadRequest(object):\n    execution_payload: ExecutionPayload\n    versioned_hashes: Sequence[VersionedHash]\n    parent_beacon_block_root: Root\n    # [New in Electra]\n    execution_requests: ExecutionRequests\n</code></pre>"},{"location":"specs/electra/beacon-chain/#engine-apis","title":"Engine APIs","text":""},{"location":"specs/electra/beacon-chain/#modified-is_valid_block_hash","title":"Modified <code>is_valid_block_hash</code>","text":"<p>Note: The function <code>is_valid_block_hash</code> is modified to include the additional <code>execution_requests_list</code>.</p> <pre><code>def is_valid_block_hash(\n    self: ExecutionEngine,\n    execution_payload: ExecutionPayload,\n    parent_beacon_block_root: Root,\n    execution_requests_list: Sequence[bytes],\n) -&gt; bool:\n    \"\"\"\n    Return ``True`` if and only if ``execution_payload.block_hash`` is computed correctly.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-notify_new_payload","title":"Modified <code>notify_new_payload</code>","text":"<p>Note: The function <code>notify_new_payload</code> is modified to include the additional <code>execution_requests_list</code>.</p> <pre><code>def notify_new_payload(\n    self: ExecutionEngine,\n    execution_payload: ExecutionPayload,\n    parent_beacon_block_root: Root,\n    execution_requests_list: Sequence[bytes],\n) -&gt; bool:\n    \"\"\"\n    Return ``True`` if and only if ``execution_payload`` and ``execution_requests_list``\n    are valid with respect to ``self.execution_state``.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-verify_and_notify_new_payload","title":"Modified <code>verify_and_notify_new_payload</code>","text":"<p>Note: The function <code>verify_and_notify_new_payload</code> is modified to pass the additional parameter <code>execution_requests_list</code> when calling <code>is_valid_block_hash</code> and <code>notify_new_payload</code> in Electra.</p> <pre><code>def verify_and_notify_new_payload(\n    self: ExecutionEngine, new_payload_request: NewPayloadRequest\n) -&gt; bool:\n    \"\"\"\n    Return ``True`` if and only if ``new_payload_request`` is valid with respect to ``self.execution_state``.\n    \"\"\"\n    execution_payload = new_payload_request.execution_payload\n    parent_beacon_block_root = new_payload_request.parent_beacon_block_root\n    # [New in Electra]\n    execution_requests_list = get_execution_requests_list(new_payload_request.execution_requests)\n\n    if b\"\" in execution_payload.transactions:\n        return False\n\n    # [Modified in Electra]\n    if not self.is_valid_block_hash(\n        execution_payload, parent_beacon_block_root, execution_requests_list\n    ):\n        return False\n\n    if not self.is_valid_versioned_hashes(new_payload_request):\n        return False\n\n    # [Modified in Electra]\n    if not self.notify_new_payload(\n        execution_payload, parent_beacon_block_root, execution_requests_list\n    ):\n        return False\n\n    return True\n</code></pre>"},{"location":"specs/electra/beacon-chain/#block-processing","title":"Block processing","text":"<pre><code>def process_block(state: BeaconState, block: BeaconBlock) -&gt; None:\n    process_block_header(state, block)\n    # [Modified in Electra:EIP7251]\n    process_withdrawals(state, block.body.execution_payload)\n    # [Modified in Electra:EIP6110]\n    process_execution_payload(state, block.body, EXECUTION_ENGINE)\n    process_randao(state, block.body)\n    process_eth1_data(state, block.body)\n    # [Modified in Electra:EIP6110:EIP7002:EIP7549:EIP7251]\n    process_operations(state, block.body)\n    process_sync_aggregate(state, block.body.sync_aggregate)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#withdrawals","title":"Withdrawals","text":""},{"location":"specs/electra/beacon-chain/#modified-get_expected_withdrawals","title":"Modified <code>get_expected_withdrawals</code>","text":"<p>Note: The function <code>get_expected_withdrawals</code> is modified to support EIP7251.</p> <pre><code>def get_expected_withdrawals(state: BeaconState) -&gt; Tuple[Sequence[Withdrawal], uint64]:\n    epoch = get_current_epoch(state)\n    withdrawal_index = state.next_withdrawal_index\n    validator_index = state.next_withdrawal_validator_index\n    withdrawals: List[Withdrawal] = []\n    processed_partial_withdrawals_count = 0\n\n    # [New in Electra:EIP7251]\n    # Consume pending partial withdrawals\n    for withdrawal in state.pending_partial_withdrawals:\n        if (\n            withdrawal.withdrawable_epoch &gt; epoch\n            or len(withdrawals) == MAX_PENDING_PARTIALS_PER_WITHDRAWALS_SWEEP\n        ):\n            break\n\n        validator = state.validators[withdrawal.validator_index]\n        has_sufficient_effective_balance = validator.effective_balance &gt;= MIN_ACTIVATION_BALANCE\n        total_withdrawn = sum(\n            w.amount for w in withdrawals if w.validator_index == withdrawal.validator_index\n        )\n        balance = state.balances[withdrawal.validator_index] - total_withdrawn\n        has_excess_balance = balance &gt; MIN_ACTIVATION_BALANCE\n        if (\n            validator.exit_epoch == FAR_FUTURE_EPOCH\n            and has_sufficient_effective_balance\n            and has_excess_balance\n        ):\n            withdrawable_balance = min(balance - MIN_ACTIVATION_BALANCE, withdrawal.amount)\n            withdrawals.append(\n                Withdrawal(\n                    index=withdrawal_index,\n                    validator_index=withdrawal.validator_index,\n                    address=ExecutionAddress(validator.withdrawal_credentials[12:]),\n                    amount=withdrawable_balance,\n                )\n            )\n            withdrawal_index += WithdrawalIndex(1)\n\n        processed_partial_withdrawals_count += 1\n\n    # Sweep for remaining.\n    bound = min(len(state.validators), MAX_VALIDATORS_PER_WITHDRAWALS_SWEEP)\n    for _ in range(bound):\n        validator = state.validators[validator_index]\n        # [Modified in Electra:EIP7251]\n        total_withdrawn = sum(w.amount for w in withdrawals if w.validator_index == validator_index)\n        balance = state.balances[validator_index] - total_withdrawn\n        if is_fully_withdrawable_validator(validator, balance, epoch):\n            withdrawals.append(\n                Withdrawal(\n                    index=withdrawal_index,\n                    validator_index=validator_index,\n                    address=ExecutionAddress(validator.withdrawal_credentials[12:]),\n                    amount=balance,\n                )\n            )\n            withdrawal_index += WithdrawalIndex(1)\n        elif is_partially_withdrawable_validator(validator, balance):\n            withdrawals.append(\n                Withdrawal(\n                    index=withdrawal_index,\n                    validator_index=validator_index,\n                    address=ExecutionAddress(validator.withdrawal_credentials[12:]),\n                    # [Modified in Electra:EIP7251]\n                    amount=balance - get_max_effective_balance(validator),\n                )\n            )\n            withdrawal_index += WithdrawalIndex(1)\n        if len(withdrawals) == MAX_WITHDRAWALS_PER_PAYLOAD:\n            break\n        validator_index = ValidatorIndex((validator_index + 1) % len(state.validators))\n    return withdrawals, processed_partial_withdrawals_count\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-process_withdrawals","title":"Modified <code>process_withdrawals</code>","text":"<p>Note: The function <code>process_withdrawals</code> is modified to support EIP7251.</p> <pre><code>def process_withdrawals(state: BeaconState, payload: ExecutionPayload) -&gt; None:\n    # [Modified in Electra:EIP7251]\n    expected_withdrawals, processed_partial_withdrawals_count = get_expected_withdrawals(state)\n\n    assert payload.withdrawals == expected_withdrawals\n\n    for withdrawal in expected_withdrawals:\n        decrease_balance(state, withdrawal.validator_index, withdrawal.amount)\n\n    # [New in Electra:EIP7251] Update pending partial withdrawals\n    state.pending_partial_withdrawals = state.pending_partial_withdrawals[\n        processed_partial_withdrawals_count:\n    ]\n\n    # Update the next withdrawal index if this block contained withdrawals\n    if len(expected_withdrawals) != 0:\n        latest_withdrawal = expected_withdrawals[-1]\n        state.next_withdrawal_index = WithdrawalIndex(latest_withdrawal.index + 1)\n\n    # Update the next validator index to start the next withdrawal sweep\n    if len(expected_withdrawals) == MAX_WITHDRAWALS_PER_PAYLOAD:\n        # Next sweep starts after the latest withdrawal's validator index\n        next_validator_index = ValidatorIndex(\n            (expected_withdrawals[-1].validator_index + 1) % len(state.validators)\n        )\n        state.next_withdrawal_validator_index = next_validator_index\n    else:\n        # Advance sweep by the max length of the sweep if there was not a full set of withdrawals\n        next_index = state.next_withdrawal_validator_index + MAX_VALIDATORS_PER_WITHDRAWALS_SWEEP\n        next_validator_index = ValidatorIndex(next_index % len(state.validators))\n        state.next_withdrawal_validator_index = next_validator_index\n</code></pre>"},{"location":"specs/electra/beacon-chain/#execution-payload","title":"Execution payload","text":""},{"location":"specs/electra/beacon-chain/#new-get_execution_requests_list","title":"New <code>get_execution_requests_list</code>","text":"<p>Note: Encodes execution requests as defined by EIP-7685.</p> <pre><code>def get_execution_requests_list(execution_requests: ExecutionRequests) -&gt; Sequence[bytes]:\n    requests = [\n        (DEPOSIT_REQUEST_TYPE, execution_requests.deposits),\n        (WITHDRAWAL_REQUEST_TYPE, execution_requests.withdrawals),\n        (CONSOLIDATION_REQUEST_TYPE, execution_requests.consolidations),\n    ]\n\n    return [\n        request_type + ssz_serialize(request_data)\n        for request_type, request_data in requests\n        if len(request_data) != 0\n    ]\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-process_execution_payload","title":"Modified <code>process_execution_payload</code>","text":"<p>Note: The function <code>process_execution_payload</code> is modified to pass <code>execution_requests</code> into <code>execution_engine.verify_and_notify_new_payload</code> (via the updated <code>NewPayloadRequest</code>).</p> <pre><code>def process_execution_payload(\n    state: BeaconState, body: BeaconBlockBody, execution_engine: ExecutionEngine\n) -&gt; None:\n    payload = body.execution_payload\n\n    # Verify consistency of the parent hash with respect to the previous execution payload header\n    assert payload.parent_hash == state.latest_execution_payload_header.block_hash\n    # Verify prev_randao\n    assert payload.prev_randao == get_randao_mix(state, get_current_epoch(state))\n    # Verify timestamp\n    assert payload.timestamp == compute_time_at_slot(state, state.slot)\n    # [Modified in Electra:EIP7691] Verify commitments are under limit\n    assert len(body.blob_kzg_commitments) &lt;= MAX_BLOBS_PER_BLOCK_ELECTRA\n    # Verify the execution payload is valid\n    versioned_hashes = [\n        kzg_commitment_to_versioned_hash(commitment) for commitment in body.blob_kzg_commitments\n    ]\n    assert execution_engine.verify_and_notify_new_payload(\n        NewPayloadRequest(\n            execution_payload=payload,\n            versioned_hashes=versioned_hashes,\n            parent_beacon_block_root=state.latest_block_header.parent_root,\n            # [New in Electra]\n            execution_requests=body.execution_requests,\n        )\n    )\n    # Cache execution payload header\n    state.latest_execution_payload_header = ExecutionPayloadHeader(\n        parent_hash=payload.parent_hash,\n        fee_recipient=payload.fee_recipient,\n        state_root=payload.state_root,\n        receipts_root=payload.receipts_root,\n        logs_bloom=payload.logs_bloom,\n        prev_randao=payload.prev_randao,\n        block_number=payload.block_number,\n        gas_limit=payload.gas_limit,\n        gas_used=payload.gas_used,\n        timestamp=payload.timestamp,\n        extra_data=payload.extra_data,\n        base_fee_per_gas=payload.base_fee_per_gas,\n        block_hash=payload.block_hash,\n        transactions_root=hash_tree_root(payload.transactions),\n        withdrawals_root=hash_tree_root(payload.withdrawals),\n        blob_gas_used=payload.blob_gas_used,\n        excess_blob_gas=payload.excess_blob_gas,\n    )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#operations","title":"Operations","text":""},{"location":"specs/electra/beacon-chain/#modified-process_operations","title":"Modified <code>process_operations</code>","text":"<p>Note: The function <code>process_operations</code> is modified to support all of the new functionality in Electra.</p> <pre><code>def process_operations(state: BeaconState, body: BeaconBlockBody) -&gt; None:\n    # [Modified in Electra:EIP6110]\n    # Disable former deposit mechanism once all prior deposits are processed\n    eth1_deposit_index_limit = min(\n        state.eth1_data.deposit_count, state.deposit_requests_start_index\n    )\n    if state.eth1_deposit_index &lt; eth1_deposit_index_limit:\n        assert len(body.deposits) == min(\n            MAX_DEPOSITS, eth1_deposit_index_limit - state.eth1_deposit_index\n        )\n    else:\n        assert len(body.deposits) == 0\n\n    def for_ops(operations: Sequence[Any], fn: Callable[[BeaconState, Any], None]) -&gt; None:\n        for operation in operations:\n            fn(state, operation)\n\n    for_ops(body.proposer_slashings, process_proposer_slashing)\n    for_ops(body.attester_slashings, process_attester_slashing)\n    # [Modified in Electra:EIP7549]\n    for_ops(body.attestations, process_attestation)\n    for_ops(body.deposits, process_deposit)\n    # [Modified in Electra:EIP7251]\n    for_ops(body.voluntary_exits, process_voluntary_exit)\n    for_ops(body.bls_to_execution_changes, process_bls_to_execution_change)\n    # [New in Electra:EIP6110]\n    for_ops(body.execution_requests.deposits, process_deposit_request)\n    # [New in Electra:EIP7002:EIP7251]\n    for_ops(body.execution_requests.withdrawals, process_withdrawal_request)\n    # [New in Electra:EIP7251]\n    for_ops(body.execution_requests.consolidations, process_consolidation_request)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#attestations","title":"Attestations","text":""},{"location":"specs/electra/beacon-chain/#modified-process_attestation","title":"Modified <code>process_attestation</code>","text":"<p>Note: The function is modified to support EIP7549.</p> <pre><code>def process_attestation(state: BeaconState, attestation: Attestation) -&gt; None:\n    data = attestation.data\n    assert data.target.epoch in (get_previous_epoch(state), get_current_epoch(state))\n    assert data.target.epoch == compute_epoch_at_slot(data.slot)\n    assert data.slot + MIN_ATTESTATION_INCLUSION_DELAY &lt;= state.slot\n\n    # [Modified in Electra:EIP7549]\n    assert data.index == 0\n    committee_indices = get_committee_indices(attestation.committee_bits)\n    committee_offset = 0\n    for committee_index in committee_indices:\n        assert committee_index &lt; get_committee_count_per_slot(state, data.target.epoch)\n        committee = get_beacon_committee(state, data.slot, committee_index)\n        committee_attesters = set(\n            attester_index\n            for i, attester_index in enumerate(committee)\n            if attestation.aggregation_bits[committee_offset + i]\n        )\n        assert len(committee_attesters) &gt; 0\n        committee_offset += len(committee)\n\n    # Bitfield length matches total number of participants\n    assert len(attestation.aggregation_bits) == committee_offset\n\n    # Participation flag indices\n    participation_flag_indices = get_attestation_participation_flag_indices(\n        state, data, state.slot - data.slot\n    )\n\n    # Verify signature\n    assert is_valid_indexed_attestation(state, get_indexed_attestation(state, attestation))\n\n    # Update epoch participation flags\n    if data.target.epoch == get_current_epoch(state):\n        epoch_participation = state.current_epoch_participation\n    else:\n        epoch_participation = state.previous_epoch_participation\n\n    proposer_reward_numerator = 0\n    for index in get_attesting_indices(state, attestation):\n        for flag_index, weight in enumerate(PARTICIPATION_FLAG_WEIGHTS):\n            if flag_index in participation_flag_indices and not has_flag(\n                epoch_participation[index], flag_index\n            ):\n                epoch_participation[index] = add_flag(epoch_participation[index], flag_index)\n                proposer_reward_numerator += get_base_reward(state, index) * weight\n\n    # Reward proposer\n    proposer_reward_denominator = (\n        (WEIGHT_DENOMINATOR - PROPOSER_WEIGHT) * WEIGHT_DENOMINATOR // PROPOSER_WEIGHT\n    )\n    proposer_reward = Gwei(proposer_reward_numerator // proposer_reward_denominator)\n    increase_balance(state, get_beacon_proposer_index(state), proposer_reward)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#deposits","title":"Deposits","text":""},{"location":"specs/electra/beacon-chain/#modified-get_validator_from_deposit","title":"Modified <code>get_validator_from_deposit</code>","text":"<p>Note: The function is modified to use <code>MAX_EFFECTIVE_BALANCE_ELECTRA</code> for compounding withdrawal credential.</p> <pre><code>def get_validator_from_deposit(\n    pubkey: BLSPubkey, withdrawal_credentials: Bytes32, amount: uint64\n) -&gt; Validator:\n    validator = Validator(\n        pubkey=pubkey,\n        withdrawal_credentials=withdrawal_credentials,\n        effective_balance=Gwei(0),\n        slashed=False,\n        activation_eligibility_epoch=FAR_FUTURE_EPOCH,\n        activation_epoch=FAR_FUTURE_EPOCH,\n        exit_epoch=FAR_FUTURE_EPOCH,\n        withdrawable_epoch=FAR_FUTURE_EPOCH,\n    )\n\n    # [Modified in Electra:EIP7251]\n    max_effective_balance = get_max_effective_balance(validator)\n    validator.effective_balance = min(\n        amount - amount % EFFECTIVE_BALANCE_INCREMENT, max_effective_balance\n    )\n\n    return validator\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-add_validator_to_registry","title":"Modified <code>add_validator_to_registry</code>","text":"<p>Note: The function <code>add_validator_to_registry</code> is modified to use the modified <code>get_validator_from_deposit</code>.</p> <pre><code>def add_validator_to_registry(\n    state: BeaconState, pubkey: BLSPubkey, withdrawal_credentials: Bytes32, amount: uint64\n) -&gt; None:\n    index = get_index_for_new_validator(state)\n    # [Modified in Electra:EIP7251]\n    validator = get_validator_from_deposit(pubkey, withdrawal_credentials, amount)\n    set_or_append_list(state.validators, index, validator)\n    set_or_append_list(state.balances, index, amount)\n    set_or_append_list(state.previous_epoch_participation, index, ParticipationFlags(0b0000_0000))\n    set_or_append_list(state.current_epoch_participation, index, ParticipationFlags(0b0000_0000))\n    set_or_append_list(state.inactivity_scores, index, uint64(0))\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-apply_deposit","title":"Modified <code>apply_deposit</code>","text":"<p>Note: The function <code>apply_deposit</code> is modified to support EIP7251.</p> <pre><code>def apply_deposit(\n    state: BeaconState,\n    pubkey: BLSPubkey,\n    withdrawal_credentials: Bytes32,\n    amount: uint64,\n    signature: BLSSignature,\n) -&gt; None:\n    validator_pubkeys = [v.pubkey for v in state.validators]\n    if pubkey not in validator_pubkeys:\n        # Verify the deposit signature (proof of possession) which is not checked by the deposit contract\n        if is_valid_deposit_signature(pubkey, withdrawal_credentials, amount, signature):\n            # [Modified in Electra:EIP7251]\n            add_validator_to_registry(state, pubkey, withdrawal_credentials, Gwei(0))\n        else:\n            return\n\n    # [Modified in Electra:EIP7251]\n    # Increase balance by deposit amount\n    state.pending_deposits.append(\n        PendingDeposit(\n            pubkey=pubkey,\n            withdrawal_credentials=withdrawal_credentials,\n            amount=amount,\n            signature=signature,\n            slot=GENESIS_SLOT,  # Use GENESIS_SLOT to distinguish from a pending deposit request\n        )\n    )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-is_valid_deposit_signature","title":"New <code>is_valid_deposit_signature</code>","text":"<pre><code>def is_valid_deposit_signature(\n    pubkey: BLSPubkey, withdrawal_credentials: Bytes32, amount: uint64, signature: BLSSignature\n) -&gt; bool:\n    deposit_message = DepositMessage(\n        pubkey=pubkey,\n        withdrawal_credentials=withdrawal_credentials,\n        amount=amount,\n    )\n    # Fork-agnostic domain since deposits are valid across forks\n    domain = compute_domain(DOMAIN_DEPOSIT)\n    signing_root = compute_signing_root(deposit_message, domain)\n    return bls.Verify(pubkey, signing_root, signature)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#modified-process_deposit","title":"Modified <code>process_deposit</code>","text":"<p>Note: The function <code>process_deposit</code> is modified to use the modified <code>apply_deposit</code>.</p> <pre><code>def process_deposit(state: BeaconState, deposit: Deposit) -&gt; None:\n    # Verify the Merkle branch\n    assert is_valid_merkle_branch(\n        leaf=hash_tree_root(deposit.data),\n        branch=deposit.proof,\n        # Add 1 for the List length mix-in\n        depth=DEPOSIT_CONTRACT_TREE_DEPTH + 1,\n        index=state.eth1_deposit_index,\n        root=state.eth1_data.deposit_root,\n    )\n\n    # Deposits must be processed in order\n    state.eth1_deposit_index += 1\n\n    # [Modified in Electra:EIP7251]\n    apply_deposit(\n        state=state,\n        pubkey=deposit.data.pubkey,\n        withdrawal_credentials=deposit.data.withdrawal_credentials,\n        amount=deposit.data.amount,\n        signature=deposit.data.signature,\n    )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#voluntary-exits","title":"Voluntary exits","text":""},{"location":"specs/electra/beacon-chain/#modified-process_voluntary_exit","title":"Modified <code>process_voluntary_exit</code>","text":"<p>Note: The function <code>process_voluntary_exit</code> is modified to ensure the validator has no pending withdrawals in the queue.</p> <pre><code>def process_voluntary_exit(state: BeaconState, signed_voluntary_exit: SignedVoluntaryExit) -&gt; None:\n    voluntary_exit = signed_voluntary_exit.message\n    validator = state.validators[voluntary_exit.validator_index]\n    # Verify the validator is active\n    assert is_active_validator(validator, get_current_epoch(state))\n    # Verify exit has not been initiated\n    assert validator.exit_epoch == FAR_FUTURE_EPOCH\n    # Exits must specify an epoch when they become valid; they are not valid before then\n    assert get_current_epoch(state) &gt;= voluntary_exit.epoch\n    # Verify the validator has been active long enough\n    assert get_current_epoch(state) &gt;= validator.activation_epoch + SHARD_COMMITTEE_PERIOD\n    # [New in Electra:EIP7251]\n    # Only exit validator if it has no pending withdrawals in the queue\n    assert get_pending_balance_to_withdraw(state, voluntary_exit.validator_index) == 0\n    # Verify signature\n    domain = compute_domain(\n        DOMAIN_VOLUNTARY_EXIT, CAPELLA_FORK_VERSION, state.genesis_validators_root\n    )\n    signing_root = compute_signing_root(voluntary_exit, domain)\n    assert bls.Verify(validator.pubkey, signing_root, signed_voluntary_exit.signature)\n    # Initiate exit\n    initiate_validator_exit(state, voluntary_exit.validator_index)\n</code></pre>"},{"location":"specs/electra/beacon-chain/#execution-layer-withdrawal-requests","title":"Execution layer withdrawal requests","text":""},{"location":"specs/electra/beacon-chain/#new-process_withdrawal_request","title":"New <code>process_withdrawal_request</code>","text":"<pre><code>def process_withdrawal_request(state: BeaconState, withdrawal_request: WithdrawalRequest) -&gt; None:\n    amount = withdrawal_request.amount\n    is_full_exit_request = amount == FULL_EXIT_REQUEST_AMOUNT\n\n    # If partial withdrawal queue is full, only full exits are processed\n    if (\n        len(state.pending_partial_withdrawals) == PENDING_PARTIAL_WITHDRAWALS_LIMIT\n        and not is_full_exit_request\n    ):\n        return\n\n    validator_pubkeys = [v.pubkey for v in state.validators]\n    # Verify pubkey exists\n    request_pubkey = withdrawal_request.validator_pubkey\n    if request_pubkey not in validator_pubkeys:\n        return\n    index = ValidatorIndex(validator_pubkeys.index(request_pubkey))\n    validator = state.validators[index]\n\n    # Verify withdrawal credentials\n    has_correct_credential = has_execution_withdrawal_credential(validator)\n    is_correct_source_address = (\n        validator.withdrawal_credentials[12:] == withdrawal_request.source_address\n    )\n    if not (has_correct_credential and is_correct_source_address):\n        return\n    # Verify the validator is active\n    if not is_active_validator(validator, get_current_epoch(state)):\n        return\n    # Verify exit has not been initiated\n    if validator.exit_epoch != FAR_FUTURE_EPOCH:\n        return\n    # Verify the validator has been active long enough\n    if get_current_epoch(state) &lt; validator.activation_epoch + SHARD_COMMITTEE_PERIOD:\n        return\n\n    pending_balance_to_withdraw = get_pending_balance_to_withdraw(state, index)\n\n    if is_full_exit_request:\n        # Only exit validator if it has no pending withdrawals in the queue\n        if pending_balance_to_withdraw == 0:\n            initiate_validator_exit(state, index)\n        return\n\n    has_sufficient_effective_balance = validator.effective_balance &gt;= MIN_ACTIVATION_BALANCE\n    has_excess_balance = (\n        state.balances[index] &gt; MIN_ACTIVATION_BALANCE + pending_balance_to_withdraw\n    )\n\n    # Only allow partial withdrawals with compounding withdrawal credentials\n    if (\n        has_compounding_withdrawal_credential(validator)\n        and has_sufficient_effective_balance\n        and has_excess_balance\n    ):\n        to_withdraw = min(\n            state.balances[index] - MIN_ACTIVATION_BALANCE - pending_balance_to_withdraw, amount\n        )\n        exit_queue_epoch = compute_exit_epoch_and_update_churn(state, to_withdraw)\n        withdrawable_epoch = Epoch(exit_queue_epoch + MIN_VALIDATOR_WITHDRAWABILITY_DELAY)\n        state.pending_partial_withdrawals.append(\n            PendingPartialWithdrawal(\n                validator_index=index,\n                amount=to_withdraw,\n                withdrawable_epoch=withdrawable_epoch,\n            )\n        )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#deposit-requests","title":"Deposit requests","text":""},{"location":"specs/electra/beacon-chain/#new-process_deposit_request","title":"New <code>process_deposit_request</code>","text":"<pre><code>def process_deposit_request(state: BeaconState, deposit_request: DepositRequest) -&gt; None:\n    # Set deposit request start index\n    if state.deposit_requests_start_index == UNSET_DEPOSIT_REQUESTS_START_INDEX:\n        state.deposit_requests_start_index = deposit_request.index\n\n    # Create pending deposit\n    state.pending_deposits.append(\n        PendingDeposit(\n            pubkey=deposit_request.pubkey,\n            withdrawal_credentials=deposit_request.withdrawal_credentials,\n            amount=deposit_request.amount,\n            signature=deposit_request.signature,\n            slot=state.slot,\n        )\n    )\n</code></pre>"},{"location":"specs/electra/beacon-chain/#execution-layer-consolidation-requests","title":"Execution layer consolidation requests","text":""},{"location":"specs/electra/beacon-chain/#new-is_valid_switch_to_compounding_request","title":"New <code>is_valid_switch_to_compounding_request</code>","text":"<pre><code>def is_valid_switch_to_compounding_request(\n    state: BeaconState, consolidation_request: ConsolidationRequest\n) -&gt; bool:\n    # Switch to compounding requires source and target be equal\n    if consolidation_request.source_pubkey != consolidation_request.target_pubkey:\n        return False\n\n    # Verify pubkey exists\n    source_pubkey = consolidation_request.source_pubkey\n    validator_pubkeys = [v.pubkey for v in state.validators]\n    if source_pubkey not in validator_pubkeys:\n        return False\n\n    source_validator = state.validators[ValidatorIndex(validator_pubkeys.index(source_pubkey))]\n\n    # Verify request has been authorized\n    if source_validator.withdrawal_credentials[12:] != consolidation_request.source_address:\n        return False\n\n    # Verify source withdrawal credentials\n    if not has_eth1_withdrawal_credential(source_validator):\n        return False\n\n    # Verify the source is active\n    current_epoch = get_current_epoch(state)\n    if not is_active_validator(source_validator, current_epoch):\n        return False\n\n    # Verify exit for source has not been initiated\n    if source_validator.exit_epoch != FAR_FUTURE_EPOCH:\n        return False\n\n    return True\n</code></pre>"},{"location":"specs/electra/beacon-chain/#new-process_consolidation_request","title":"New <code>process_consolidation_request</code>","text":"<pre><code>def process_consolidation_request(\n    state: BeaconState, consolidation_request: ConsolidationRequest\n) -&gt; None:\n    if is_valid_switch_to_compounding_request(state, consolidation_request):\n        validator_pubkeys = [v.pubkey for v in state.validators]\n        request_source_pubkey = consolidation_request.source_pubkey\n        source_index = ValidatorIndex(validator_pubkeys.index(request_source_pubkey))\n        switch_to_compounding_validator(state, source_index)\n        return\n\n    # Verify that source != target, so a consolidation cannot be used as an exit\n    if consolidation_request.source_pubkey == consolidation_request.target_pubkey:\n        return\n    # If the pending consolidations queue is full, consolidation requests are ignored\n    if len(state.pending_consolidations) == PENDING_CONSOLIDATIONS_LIMIT:\n        return\n    # If there is too little available consolidation churn limit, consolidation requests are ignored\n    if get_consolidation_churn_limit(state) &lt;= MIN_ACTIVATION_BALANCE:\n        return\n\n    validator_pubkeys = [v.pubkey for v in state.validators]\n    # Verify pubkeys exists\n    request_source_pubkey = consolidation_request.source_pubkey\n    request_target_pubkey = consolidation_request.target_pubkey\n    if request_source_pubkey not in validator_pubkeys:\n        return\n    if request_target_pubkey not in validator_pubkeys:\n        return\n    source_index = ValidatorIndex(validator_pubkeys.index(request_source_pubkey))\n    target_index = ValidatorIndex(validator_pubkeys.index(request_target_pubkey))\n    source_validator = state.validators[source_index]\n    target_validator = state.validators[target_index]\n\n    # Verify source withdrawal credentials\n    has_correct_credential = has_execution_withdrawal_credential(source_validator)\n    is_correct_source_address = (\n        source_validator.withdrawal_credentials[12:] == consolidation_request.source_address\n    )\n    if not (has_correct_credential and is_correct_source_address):\n        return\n\n    # Verify that target has compounding withdrawal credentials\n    if not has_compounding_withdrawal_credential(target_validator):\n        return\n\n    # Verify the source and the target are active\n    current_epoch = get_current_epoch(state)\n    if not is_active_validator(source_validator, current_epoch):\n        return\n    if not is_active_validator(target_validator, current_epoch):\n        return\n    # Verify exits for source and target have not been initiated\n    if source_validator.exit_epoch != FAR_FUTURE_EPOCH:\n        return\n    if target_validator.exit_epoch != FAR_FUTURE_EPOCH:\n        return\n    # Verify the source has been active long enough\n    if current_epoch &lt; source_validator.activation_epoch + SHARD_COMMITTEE_PERIOD:\n        return\n    # Verify the source has no pending withdrawals in the queue\n    if get_pending_balance_to_withdraw(state, source_index) &gt; 0:\n        return\n\n    # Initiate source validator exit and append pending consolidation\n    source_validator.exit_epoch = compute_consolidation_epoch_and_update_churn(\n        state, source_validator.effective_balance\n    )\n    source_validator.withdrawable_epoch = Epoch(\n        source_validator.exit_epoch + MIN_VALIDATOR_WITHDRAWABILITY_DELAY\n    )\n    state.pending_consolidations.append(\n        PendingConsolidation(source_index=source_index, target_index=target_index)\n    )\n</code></pre>"},{"location":"specs/electra/fork/","title":"Electra -- Fork Logic","text":"<ul> <li>Introduction</li> <li>Configuration</li> <li>Fork to Electra</li> <li>Fork trigger</li> <li>Upgrading the state</li> </ul>"},{"location":"specs/electra/fork/#introduction","title":"Introduction","text":"<p>This document describes the process of the Electra upgrade.</p>"},{"location":"specs/electra/fork/#configuration","title":"Configuration","text":"<p>Warning: this configuration is not definitive.</p> Name Value <code>ELECTRA_FORK_VERSION</code> <code>Version('0x05000000')</code> <code>ELECTRA_FORK_EPOCH</code> <code>Epoch(364032)</code> (May 7, 2025, 10:05:11am UTC)"},{"location":"specs/electra/fork/#fork-to-electra","title":"Fork to Electra","text":""},{"location":"specs/electra/fork/#fork-trigger","title":"Fork trigger","text":"<p>The fork is triggered at epoch <code>ELECTRA_FORK_EPOCH</code>.</p> <p>Note that for the pure Electra networks, we don't apply <code>upgrade_to_electra</code> since it starts with Electra version logic.</p>"},{"location":"specs/electra/fork/#upgrading-the-state","title":"Upgrading the state","text":"<p>If <code>state.slot % SLOTS_PER_EPOCH == 0</code> and <code>compute_epoch_at_slot(state.slot) == ELECTRA_FORK_EPOCH</code>, an irregular state change is made to upgrade to Electra.</p> <pre><code>def upgrade_to_electra(pre: deneb.BeaconState) -&gt; BeaconState:\n    epoch = deneb.get_current_epoch(pre)\n\n    earliest_exit_epoch = compute_activation_exit_epoch(get_current_epoch(pre))\n    for validator in pre.validators:\n        if validator.exit_epoch != FAR_FUTURE_EPOCH:\n            if validator.exit_epoch &gt; earliest_exit_epoch:\n                earliest_exit_epoch = validator.exit_epoch\n    earliest_exit_epoch += Epoch(1)\n\n    post = BeaconState(\n        genesis_time=pre.genesis_time,\n        genesis_validators_root=pre.genesis_validators_root,\n        slot=pre.slot,\n        fork=Fork(\n            previous_version=pre.fork.current_version,\n            # [Modified in Electra]\n            current_version=ELECTRA_FORK_VERSION,\n            epoch=epoch,\n        ),\n        latest_block_header=pre.latest_block_header,\n        block_roots=pre.block_roots,\n        state_roots=pre.state_roots,\n        historical_roots=pre.historical_roots,\n        eth1_data=pre.eth1_data,\n        eth1_data_votes=pre.eth1_data_votes,\n        eth1_deposit_index=pre.eth1_deposit_index,\n        validators=pre.validators,\n        balances=pre.balances,\n        randao_mixes=pre.randao_mixes,\n        slashings=pre.slashings,\n        previous_epoch_participation=pre.previous_epoch_participation,\n        current_epoch_participation=pre.current_epoch_participation,\n        justification_bits=pre.justification_bits,\n        previous_justified_checkpoint=pre.previous_justified_checkpoint,\n        current_justified_checkpoint=pre.current_justified_checkpoint,\n        finalized_checkpoint=pre.finalized_checkpoint,\n        inactivity_scores=pre.inactivity_scores,\n        current_sync_committee=pre.current_sync_committee,\n        next_sync_committee=pre.next_sync_committee,\n        latest_execution_payload_header=pre.latest_execution_payload_header,\n        next_withdrawal_index=pre.next_withdrawal_index,\n        next_withdrawal_validator_index=pre.next_withdrawal_validator_index,\n        historical_summaries=pre.historical_summaries,\n        # [New in Electra:EIP6110]\n        deposit_requests_start_index=UNSET_DEPOSIT_REQUESTS_START_INDEX,\n        # [New in Electra:EIP7251]\n        deposit_balance_to_consume=0,\n        # [New in Electra:EIP7251]\n        exit_balance_to_consume=0,\n        # [New in Electra:EIP7251]\n        earliest_exit_epoch=earliest_exit_epoch,\n        # [New in Electra:EIP7251]\n        consolidation_balance_to_consume=0,\n        # [New in Electra:EIP7251]\n        earliest_consolidation_epoch=compute_activation_exit_epoch(get_current_epoch(pre)),\n        # [New in Electra:EIP7251]\n        pending_deposits=[],\n        # [New in Electra:EIP7251]\n        pending_partial_withdrawals=[],\n        # [New in Electra:EIP7251]\n        pending_consolidations=[],\n    )\n\n    post.exit_balance_to_consume = get_activation_exit_churn_limit(post)\n    post.consolidation_balance_to_consume = get_consolidation_churn_limit(post)\n\n    # [New in Electra:EIP7251]\n    # add validators that are not yet active to pending balance deposits\n    pre_activation = sorted(\n        [\n            index\n            for index, validator in enumerate(post.validators)\n            if validator.activation_epoch == FAR_FUTURE_EPOCH\n        ],\n        key=lambda index: (post.validators[index].activation_eligibility_epoch, index),\n    )\n\n    for index in pre_activation:\n        balance = post.balances[index]\n        post.balances[index] = 0\n        validator = post.validators[index]\n        validator.effective_balance = 0\n        validator.activation_eligibility_epoch = FAR_FUTURE_EPOCH\n        # Use bls.G2_POINT_AT_INFINITY as a signature field placeholder\n        # and GENESIS_SLOT to distinguish from a pending deposit request\n        post.pending_deposits.append(\n            PendingDeposit(\n                pubkey=validator.pubkey,\n                withdrawal_credentials=validator.withdrawal_credentials,\n                amount=balance,\n                signature=bls.G2_POINT_AT_INFINITY,\n                slot=GENESIS_SLOT,\n            )\n        )\n\n    # Ensure early adopters of compounding credentials go through the activation churn\n    for index, validator in enumerate(post.validators):\n        if has_compounding_withdrawal_credential(validator):\n            queue_excess_active_balance(post, ValidatorIndex(index))\n\n    return post\n</code></pre>"},{"location":"specs/electra/p2p-interface/","title":"Electra -- Networking","text":"<ul> <li>Introduction</li> <li>Modifications in Electra</li> <li>Helper functions<ul> <li>Modified <code>compute_fork_version</code></li> </ul> </li> <li>Configuration</li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>beacon_block</code></li> <li><code>beacon_aggregate_and_proof</code></li> <li><code>blob_sidecar_{subnet_id}</code></li> </ul> </li> <li>Attestation subnets<ul> <li><code>beacon_attestation_{subnet_id}</code></li> </ul> </li> </ul> </li> <li>The Req/Resp domain<ul> <li>Messages</li> <li>BeaconBlocksByRange v2</li> <li>BeaconBlocksByRoot v2</li> <li>BlobSidecarsByRange v1</li> <li>BlobSidecarsByRoot v1</li> </ul> </li> </ul>"},{"location":"specs/electra/p2p-interface/#introduction","title":"Introduction","text":"<p>This document contains the consensus-layer networking specification for Electra.</p> <p>The specification of these changes continues in the same format as the network specifications of previous upgrades, and assumes them as pre-requisite.</p>"},{"location":"specs/electra/p2p-interface/#modifications-in-electra","title":"Modifications in Electra","text":""},{"location":"specs/electra/p2p-interface/#helper-functions","title":"Helper functions","text":""},{"location":"specs/electra/p2p-interface/#modified-compute_fork_version","title":"Modified <code>compute_fork_version</code>","text":"<pre><code>def compute_fork_version(epoch: Epoch) -&gt; Version:\n    \"\"\"\n    Return the fork version at the given ``epoch``.\n    \"\"\"\n    if epoch &gt;= ELECTRA_FORK_EPOCH:\n        return ELECTRA_FORK_VERSION\n    if epoch &gt;= DENEB_FORK_EPOCH:\n        return DENEB_FORK_VERSION\n    if epoch &gt;= CAPELLA_FORK_EPOCH:\n        return CAPELLA_FORK_VERSION\n    if epoch &gt;= BELLATRIX_FORK_EPOCH:\n        return BELLATRIX_FORK_VERSION\n    if epoch &gt;= ALTAIR_FORK_EPOCH:\n        return ALTAIR_FORK_VERSION\n    return GENESIS_FORK_VERSION\n</code></pre>"},{"location":"specs/electra/p2p-interface/#configuration","title":"Configuration","text":"<p>[New in Electra:EIP7691]</p> Name Value Description <code>MAX_REQUEST_BLOB_SIDECARS_ELECTRA</code> <code>MAX_REQUEST_BLOCKS_DENEB * MAX_BLOBS_PER_BLOCK_ELECTRA</code> Maximum number of blob sidecars in a single request <code>BLOB_SIDECAR_SUBNET_COUNT_ELECTRA</code> <code>9</code> The number of blob sidecar subnets used in the gossipsub protocol"},{"location":"specs/electra/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":"<p>Some gossip meshes are upgraded in the fork of Electra to support upgraded types.</p>"},{"location":"specs/electra/p2p-interface/#topics-and-messages","title":"Topics and messages","text":"<p>Topics follow the same specification as in prior upgrades.</p> <p>The <code>beacon_block</code> topic is modified to also support Electra blocks.</p> <p>The <code>beacon_aggregate_and_proof</code> and <code>beacon_attestation_{subnet_id}</code> topics are modified to support the gossip of the new attestation type.</p> <p>The <code>attester_slashing</code> topic is modified to support the gossip of the new <code>AttesterSlashing</code> type.</p> <p>The specification around the creation, validation, and dissemination of messages has not changed from the Capella document unless explicitly noted here.</p> <p>The derivation of the <code>message-id</code> remains stable.</p>"},{"location":"specs/electra/p2p-interface/#global-topics","title":"Global topics","text":""},{"location":"specs/electra/p2p-interface/#beacon_block","title":"<code>beacon_block</code>","text":"<p>Updated validation</p> <ul> <li>[REJECT] The length of KZG commitments is less than or equal to the   limitation defined in Consensus Layer -- i.e. validate that   <code>len(signed_beacon_block.message.body.blob_kzg_commitments) &lt;= MAX_BLOBS_PER_BLOCK_ELECTRA</code></li> </ul>"},{"location":"specs/electra/p2p-interface/#beacon_aggregate_and_proof","title":"<code>beacon_aggregate_and_proof</code>","text":"<p>The following convenience variables are re-defined</p> <ul> <li><code>index = get_committee_indices(aggregate.committee_bits)[0]</code></li> </ul> <p>The following validations are added:</p> <ul> <li>[REJECT] <code>len(committee_indices) == 1</code>, where   <code>committee_indices = get_committee_indices(aggregate)</code>.</li> <li>[REJECT] <code>aggregate.data.index == 0</code></li> </ul>"},{"location":"specs/electra/p2p-interface/#blob_sidecar_subnet_id","title":"<code>blob_sidecar_{subnet_id}</code>","text":"<p>[Modified in Electra:EIP7691]</p> <p>The existing validations all apply as given from previous forks, with the following exceptions:</p> <ul> <li>Uses of <code>MAX_BLOBS_PER_BLOCK</code> in existing validations are replaced with   <code>MAX_BLOBS_PER_BLOCK_ELECTRA</code>.</li> </ul>"},{"location":"specs/electra/p2p-interface/#attestation-subnets","title":"Attestation subnets","text":""},{"location":"specs/electra/p2p-interface/#beacon_attestation_subnet_id","title":"<code>beacon_attestation_{subnet_id}</code>","text":"<p>The topic is updated to propagate <code>SingleAttestation</code> objects.</p> <p>The following convenience variables are re-defined:</p> <ul> <li><code>index = attestation.committee_index</code></li> </ul> <p>The following validations are added:</p> <ul> <li>[REJECT] <code>attestation.data.index == 0</code></li> <li>[REJECT] The attester is a member of the committee -- i.e.   <code>attestation.attester_index in get_beacon_committee(state, attestation.data.slot, index)</code>.</li> </ul> <p>The following validations are removed:</p> <ul> <li>[REJECT] The attestation is unaggregated -- that is, it has exactly one   participating validator (<code>len([bit for bit in aggregation_bits if bit]) == 1</code>,   i.e. exactly 1 bit is set).</li> <li>[REJECT] The number of aggregation bits matches the committee size -- i.e.   <code>len(aggregation_bits) == len(get_beacon_committee(state, attestation.data.slot, index))</code>.</li> </ul>"},{"location":"specs/electra/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/electra/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/electra/p2p-interface/#beaconblocksbyrange-v2","title":"BeaconBlocksByRange v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_range/2/</code></p> <p>The Electra fork-digest is introduced to the <code>context</code> enum to specify Electra beacon block type.</p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code> <code>BELLATRIX_FORK_VERSION</code> <code>bellatrix.SignedBeaconBlock</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.SignedBeaconBlock</code> <code>DENEB_FORK_VERSION</code> <code>deneb.SignedBeaconBlock</code> <code>ELECTRA_FORK_VERSION</code> <code>electra.SignedBeaconBlock</code>"},{"location":"specs/electra/p2p-interface/#beaconblocksbyroot-v2","title":"BeaconBlocksByRoot v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_root/2/</code></p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code> <code>BELLATRIX_FORK_VERSION</code> <code>bellatrix.SignedBeaconBlock</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.SignedBeaconBlock</code> <code>DENEB_FORK_VERSION</code> <code>deneb.SignedBeaconBlock</code> <code>ELECTRA_FORK_VERSION</code> <code>electra.SignedBeaconBlock</code>"},{"location":"specs/electra/p2p-interface/#blobsidecarsbyrange-v1","title":"BlobSidecarsByRange v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/blob_sidecars_by_range/1/</code></p> <p>[Modified in Electra:EIP7691]</p> <p>Request Content:</p> <pre><code>(\n  start_slot: Slot\n  count: uint64\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[BlobSidecar, MAX_REQUEST_BLOB_SIDECARS_ELECTRA]\n)\n</code></pre> <p>Updated validation</p> <p>Clients MUST respond with at least the blob sidecars of the first blob-carrying block that exists in the range, if they have it, and no more than <code>MAX_REQUEST_BLOB_SIDECARS_ELECTRA</code> sidecars.</p>"},{"location":"specs/electra/p2p-interface/#blobsidecarsbyroot-v1","title":"BlobSidecarsByRoot v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/blob_sidecars_by_root/1/</code></p> <p>[Modified in Electra:EIP7691]</p> <p>Request Content:</p> <pre><code>(\n  List[BlobIdentifier, MAX_REQUEST_BLOB_SIDECARS_ELECTRA]\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[BlobSidecar, MAX_REQUEST_BLOB_SIDECARS_ELECTRA]\n)\n</code></pre> <p>Updated validation</p> <p>No more than <code>MAX_REQUEST_BLOB_SIDECARS_ELECTRA</code> may be requested at a time.</p>"},{"location":"specs/electra/validator/","title":"Electra -- Honest Validator","text":"<ul> <li>Introduction</li> <li>Prerequisites</li> <li>Helpers</li> <li>Modified <code>GetPayloadResponse</code></li> <li>Containers</li> <li>Modified containers<ul> <li><code>AggregateAndProof</code></li> <li><code>SignedAggregateAndProof</code></li> </ul> </li> <li>Protocols</li> <li><code>ExecutionEngine</code><ul> <li>Modified <code>get_payload</code></li> </ul> </li> <li>Block proposal</li> <li>Constructing the <code>BeaconBlockBody</code><ul> <li>Attester slashings</li> <li>Attestations</li> <li>Deposits</li> <li>Execution payload</li> <li>Execution Requests</li> </ul> </li> <li>Constructing the <code>BlobSidecar</code>s<ul> <li>Sidecar</li> </ul> </li> <li>Attesting</li> <li>Construct attestation</li> <li>Attestation aggregation</li> <li>Construct aggregate</li> </ul>"},{"location":"specs/electra/validator/#introduction","title":"Introduction","text":"<p>This document represents the changes to be made in the code of an \"honest validator\" to implement Electra.</p>"},{"location":"specs/electra/validator/#prerequisites","title":"Prerequisites","text":"<p>This document is an extension of the Deneb -- Honest Validator guide. All behaviors and definitions defined in this document, and documents it extends, carry over unless explicitly noted or overridden.</p> <p>All terminology, constants, functions, and protocol mechanics defined in the updated Beacon Chain doc of Electra are requisite for this document and used throughout. Please see related Beacon Chain doc before continuing and use them as a reference throughout.</p>"},{"location":"specs/electra/validator/#helpers","title":"Helpers","text":""},{"location":"specs/electra/validator/#modified-getpayloadresponse","title":"Modified <code>GetPayloadResponse</code>","text":"<pre><code>@dataclass\nclass GetPayloadResponse(object):\n    execution_payload: ExecutionPayload\n    block_value: uint256\n    blobs_bundle: BlobsBundle\n    # [New in Electra]\n    execution_requests: Sequence[bytes]\n</code></pre>"},{"location":"specs/electra/validator/#containers","title":"Containers","text":""},{"location":"specs/electra/validator/#modified-containers","title":"Modified containers","text":""},{"location":"specs/electra/validator/#aggregateandproof","title":"<code>AggregateAndProof</code>","text":"<pre><code>class AggregateAndProof(Container):\n    aggregator_index: ValidatorIndex\n    # [Modified in Electra:EIP7549]\n    aggregate: Attestation\n    selection_proof: BLSSignature\n</code></pre>"},{"location":"specs/electra/validator/#signedaggregateandproof","title":"<code>SignedAggregateAndProof</code>","text":"<pre><code>class SignedAggregateAndProof(Container):\n    # [Modified in Electra:EIP7549]\n    message: AggregateAndProof\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/electra/validator/#protocols","title":"Protocols","text":""},{"location":"specs/electra/validator/#executionengine","title":"<code>ExecutionEngine</code>","text":""},{"location":"specs/electra/validator/#modified-get_payload","title":"Modified <code>get_payload</code>","text":"<p>Given the <code>payload_id</code>, <code>get_payload</code> returns the most recent version of the execution payload that has been built since the corresponding call to <code>notify_forkchoice_updated</code> method.</p> <pre><code>def get_payload(self: ExecutionEngine, payload_id: PayloadId) -&gt; GetPayloadResponse:\n    \"\"\"\n    Return ExecutionPayload, uint256, BlobsBundle and execution requests (as Sequence[bytes]) objects.\n    \"\"\"\n    # pylint: disable=unused-argument\n    ...\n</code></pre>"},{"location":"specs/electra/validator/#block-proposal","title":"Block proposal","text":""},{"location":"specs/electra/validator/#constructing-the-beaconblockbody","title":"Constructing the <code>BeaconBlockBody</code>","text":""},{"location":"specs/electra/validator/#attester-slashings","title":"Attester slashings","text":"<p>Changed the max attester slashings size to <code>MAX_ATTESTER_SLASHINGS_ELECTRA</code>.</p>"},{"location":"specs/electra/validator/#attestations","title":"Attestations","text":"<p>Changed the max attestations size to <code>MAX_ATTESTATIONS_ELECTRA</code>.</p> <p>The network attestation aggregates contain only the assigned committee attestations. Attestation aggregates received by the block proposer from the committee aggregators with disjoint <code>committee_bits</code> sets and equal <code>AttestationData</code> SHOULD be consolidated into a single <code>Attestation</code> object. The proposer should run the following function to construct an on chain final aggregate from a list of network aggregates with equal <code>AttestationData</code>:</p> <pre><code>def compute_on_chain_aggregate(network_aggregates: Sequence[Attestation]) -&gt; Attestation:\n    aggregates = sorted(\n        network_aggregates, key=lambda a: get_committee_indices(a.committee_bits)[0]\n    )\n\n    data = aggregates[0].data\n    aggregation_bits = Bitlist[MAX_VALIDATORS_PER_COMMITTEE * MAX_COMMITTEES_PER_SLOT]()\n    for a in aggregates:\n        for b in a.aggregation_bits:\n            aggregation_bits.append(b)\n\n    signature = bls.Aggregate([a.signature for a in aggregates])\n\n    committee_indices = [get_committee_indices(a.committee_bits)[0] for a in aggregates]\n    committee_flags = [(index in committee_indices) for index in range(0, MAX_COMMITTEES_PER_SLOT)]\n    committee_bits = Bitvector[MAX_COMMITTEES_PER_SLOT](committee_flags)\n\n    return Attestation(\n        aggregation_bits=aggregation_bits,\n        data=data,\n        committee_bits=committee_bits,\n        signature=signature,\n    )\n</code></pre>"},{"location":"specs/electra/validator/#deposits","title":"Deposits","text":"<p>[New in Electra:EIP6110] The expected number of deposits MUST be changed from <code>min(MAX_DEPOSITS, eth1_data.deposit_count - state.eth1_deposit_index)</code> to the result of the following function:</p> <pre><code>def get_eth1_pending_deposit_count(state: BeaconState) -&gt; uint64:\n    eth1_deposit_index_limit = min(\n        state.eth1_data.deposit_count, state.deposit_requests_start_index\n    )\n    if state.eth1_deposit_index &lt; eth1_deposit_index_limit:\n        return min(MAX_DEPOSITS, eth1_deposit_index_limit - state.eth1_deposit_index)\n    else:\n        return uint64(0)\n</code></pre> <p>Note: Clients will be able to remove the <code>Eth1Data</code> polling mechanism in an uncoordinated fashion once the transition period is finished. The transition period is considered finished when a network reaches the point where <code>state.eth1_deposit_index == state.deposit_requests_start_index</code>.</p> <pre><code>def get_eth1_vote(state: BeaconState, eth1_chain: Sequence[Eth1Block]) -&gt; Eth1Data:\n    # [New in Electra:EIP6110]\n    if state.eth1_deposit_index == state.deposit_requests_start_index:\n        return state.eth1_data\n\n    period_start = voting_period_start_time(state)\n    # `eth1_chain` abstractly represents all blocks in the eth1 chain sorted by ascending block height\n    votes_to_consider = [\n        get_eth1_data(block)\n        for block in eth1_chain\n        if (\n            is_candidate_block(block, period_start)\n            # Ensure cannot move back to earlier deposit contract states\n            and get_eth1_data(block).deposit_count &gt;= state.eth1_data.deposit_count\n        )\n    ]\n\n    # Valid votes already cast during this period\n    valid_votes = [vote for vote in state.eth1_data_votes if vote in votes_to_consider]\n\n    # Default vote on latest eth1 block data in the period range unless eth1 chain is not live\n    # Non-substantive casting for linter\n    state_eth1_data: Eth1Data = state.eth1_data\n    default_vote = (\n        votes_to_consider[len(votes_to_consider) - 1] if any(votes_to_consider) else state_eth1_data\n    )\n\n    return max(\n        valid_votes,\n        # Tiebreak by smallest distance\n        key=lambda v: (\n            valid_votes.count(v),\n            -valid_votes.index(v),\n        ),\n        default=default_vote,\n    )\n</code></pre>"},{"location":"specs/electra/validator/#execution-payload","title":"Execution payload","text":"<p><code>prepare_execution_payload</code> is updated from the Deneb specs.</p> <p>Note: In this section, <code>state</code> is the state of the slot for the block proposal without the block yet applied. That is, <code>state</code> is the <code>previous_state</code> processed through any empty slots up to the assigned slot using <code>process_slots(previous_state, slot)</code>.</p> <p>Note: The only change to <code>prepare_execution_payload</code> is the new definition of <code>get_expected_withdrawals</code>.</p> <pre><code>def prepare_execution_payload(\n    state: BeaconState,\n    safe_block_hash: Hash32,\n    finalized_block_hash: Hash32,\n    suggested_fee_recipient: ExecutionAddress,\n    execution_engine: ExecutionEngine,\n) -&gt; Optional[PayloadId]:\n    # Verify consistency of the parent hash with respect to the previous execution payload header\n    parent_hash = state.latest_execution_payload_header.block_hash\n\n    # [Modified in EIP7251]\n    # Set the forkchoice head and initiate the payload build process\n    withdrawals, _ = get_expected_withdrawals(state)\n\n    payload_attributes = PayloadAttributes(\n        timestamp=compute_time_at_slot(state, state.slot),\n        prev_randao=get_randao_mix(state, get_current_epoch(state)),\n        suggested_fee_recipient=suggested_fee_recipient,\n        withdrawals=withdrawals,\n        parent_beacon_block_root=hash_tree_root(state.latest_block_header),\n    )\n    return execution_engine.notify_forkchoice_updated(\n        head_block_hash=parent_hash,\n        safe_block_hash=safe_block_hash,\n        finalized_block_hash=finalized_block_hash,\n        payload_attributes=payload_attributes,\n    )\n</code></pre>"},{"location":"specs/electra/validator/#execution-requests","title":"Execution Requests","text":"<p>[New in Electra]</p> <ol> <li>The execution payload is obtained from the execution engine as defined above    using <code>payload_id</code>. The response also includes a <code>execution_requests</code> entry    containing a list of bytes. Each element on the list corresponds to one SSZ    list of requests as defined in    EIP-7685. The first byte of each    request is used to determine the request type. Requests must be ordered by    request type in ascending order. As a result, there can only be at most one    instance of each request type.</li> <li>Set    <code>block.body.execution_requests = get_execution_requests(execution_requests)</code>,    where:</li> </ol> <pre><code>def get_execution_requests(execution_requests_list: Sequence[bytes]) -&gt; ExecutionRequests:\n    deposits = []\n    withdrawals = []\n    consolidations = []\n\n    request_types = [\n        DEPOSIT_REQUEST_TYPE,\n        WITHDRAWAL_REQUEST_TYPE,\n        CONSOLIDATION_REQUEST_TYPE,\n    ]\n\n    prev_request_type = None\n    for request in execution_requests_list:\n        request_type, request_data = request[0:1], request[1:]\n\n        # Check that the request type is valid\n        assert request_type in request_types\n        # Check that the request data is not empty\n        assert len(request_data) != 0\n        # Check that requests are in strictly ascending order\n        # Each successive type must be greater than the last with no duplicates\n        assert prev_request_type is None or prev_request_type &lt; request_type\n        prev_request_type = request_type\n\n        if request_type == DEPOSIT_REQUEST_TYPE:\n            deposits = ssz_deserialize(\n                List[DepositRequest, MAX_DEPOSIT_REQUESTS_PER_PAYLOAD], request_data\n            )\n        elif request_type == WITHDRAWAL_REQUEST_TYPE:\n            withdrawals = ssz_deserialize(\n                List[WithdrawalRequest, MAX_WITHDRAWAL_REQUESTS_PER_PAYLOAD], request_data\n            )\n        elif request_type == CONSOLIDATION_REQUEST_TYPE:\n            consolidations = ssz_deserialize(\n                List[ConsolidationRequest, MAX_CONSOLIDATION_REQUESTS_PER_PAYLOAD], request_data\n            )\n\n    return ExecutionRequests(\n        deposits=deposits,\n        withdrawals=withdrawals,\n        consolidations=consolidations,\n    )\n</code></pre>"},{"location":"specs/electra/validator/#constructing-the-blobsidecars","title":"Constructing the <code>BlobSidecar</code>s","text":""},{"location":"specs/electra/validator/#sidecar","title":"Sidecar","text":"<p>[Modified in Electra:EIP7691]</p> <pre><code>def compute_subnet_for_blob_sidecar(blob_index: BlobIndex) -&gt; SubnetID:\n    return SubnetID(blob_index % BLOB_SIDECAR_SUBNET_COUNT_ELECTRA)\n</code></pre>"},{"location":"specs/electra/validator/#attesting","title":"Attesting","text":""},{"location":"specs/electra/validator/#construct-attestation","title":"Construct attestation","text":"<p>The validator creates <code>attestation</code> as a <code>SingleAttestation</code> container with updated field assignments:</p> <ul> <li>Set <code>attestation_data.index = 0</code>.</li> <li>Set <code>attestation.committee_index</code> to the index associated with the validator's   committee.</li> <li>Set <code>attestation.attester_index</code> to the index of the validator.</li> </ul>"},{"location":"specs/electra/validator/#attestation-aggregation","title":"Attestation aggregation","text":""},{"location":"specs/electra/validator/#construct-aggregate","title":"Construct aggregate","text":"<ul> <li>Set <code>attestation_data.index = 0</code>.</li> <li>Let <code>aggregation_bits</code> be a   <code>Bitlist[MAX_VALIDATORS_PER_COMMITTEE * MAX_COMMITTEES_PER_SLOT]</code> of length   <code>len(committee)</code>, where each bit set from each individual attestation is set   to <code>0b1</code>.</li> <li>Set <code>attestation.committee_bits = committee_bits</code>, where <code>committee_bits</code> has   the bit set corresponding to <code>committee_index</code> in each individual attestation.</li> </ul>"},{"location":"specs/electra/weak-subjectivity/","title":"Electra -- Weak Subjectivity Guide","text":"<ul> <li>Introduction</li> <li>Weak Subjectivity Period</li> <li>Calculating the Weak Subjectivity Period<ul> <li>Modified <code>compute_weak_subjectivity_period</code></li> <li>Modified <code>is_within_weak_subjectivity_period</code></li> </ul> </li> </ul>"},{"location":"specs/electra/weak-subjectivity/#introduction","title":"Introduction","text":"<p>This document is an extension of the Phase 0 -- Weak Subjectivity Guide. All behaviors and definitions defined in this document, and documents it extends, carry over unless explicitly noted or overridden.</p> <p>This document is a guide for implementing Weak Subjectivity protections in Electra. The Weak Subjectivity Period (WSP) calculations have changed in Electra due to EIP-7251, which increases the maximum effective balance for validators and allows validators to consolidate.</p>"},{"location":"specs/electra/weak-subjectivity/#weak-subjectivity-period","title":"Weak Subjectivity Period","text":""},{"location":"specs/electra/weak-subjectivity/#calculating-the-weak-subjectivity-period","title":"Calculating the Weak Subjectivity Period","text":""},{"location":"specs/electra/weak-subjectivity/#modified-compute_weak_subjectivity_period","title":"Modified <code>compute_weak_subjectivity_period</code>","text":"<pre><code>def compute_weak_subjectivity_period(state: BeaconState) -&gt; uint64:\n    \"\"\"\n    Returns the weak subjectivity period for the current ``state``.\n    This computation takes into account the effect of:\n        - validator set churn (bounded by ``get_balance_churn_limit()`` per epoch)\n    A detailed calculation can be found at:\n    https://notes.ethereum.org/@CarlBeek/electra_weak_subjectivity\n    \"\"\"\n    t = get_total_active_balance(state)\n    delta = get_balance_churn_limit(state)\n    epochs_for_validator_set_churn = SAFETY_DECAY * t // (2 * delta * 100)\n    return MIN_VALIDATOR_WITHDRAWABILITY_DELAY + epochs_for_validator_set_churn\n</code></pre> <p>A brief reference for what these values look like in practice (reference script):</p> Safety Decay Total Active Balance (ETH) Weak Sub. Period (Epochs) 10 1,048,576 665 10 2,097,152 1,075 10 4,194,304 1,894 10 8,388,608 3,532 10 16,777,216 3,532 10 33,554,432 3,532"},{"location":"specs/electra/weak-subjectivity/#modified-is_within_weak_subjectivity_period","title":"Modified <code>is_within_weak_subjectivity_period</code>","text":"<pre><code>def is_within_weak_subjectivity_period(\n    store: Store, ws_state: BeaconState, ws_checkpoint: Checkpoint\n) -&gt; bool:\n    # Clients may choose to validate the input state against the input Weak Subjectivity Checkpoint\n    assert ws_state.latest_block_header.state_root == ws_checkpoint.root\n    assert compute_epoch_at_slot(ws_state.slot) == ws_checkpoint.epoch\n\n    # [Modified in Electra]\n    ws_period = compute_weak_subjectivity_period(ws_state)\n    ws_state_epoch = compute_epoch_at_slot(ws_state.slot)\n    current_epoch = compute_epoch_at_slot(get_current_slot(store))\n    return current_epoch &lt;= ws_state_epoch + ws_period\n</code></pre>"},{"location":"specs/electra/light-client/fork/","title":"Electra Light Client -- Fork Logic","text":"<ul> <li>Introduction</li> <li>Helper functions</li> <li><code>normalize_merkle_branch</code></li> <li>Upgrading light client data</li> <li>Upgrading the store</li> </ul>"},{"location":"specs/electra/light-client/fork/#introduction","title":"Introduction","text":"<p>This document describes how to upgrade existing light client objects based on the Deneb specification to Electra. This is necessary when processing pre-Electra data with a post-Electra <code>LightClientStore</code>. Note that the data being exchanged over the network protocols uses the original format.</p>"},{"location":"specs/electra/light-client/fork/#helper-functions","title":"Helper functions","text":""},{"location":"specs/electra/light-client/fork/#normalize_merkle_branch","title":"<code>normalize_merkle_branch</code>","text":"<pre><code>def normalize_merkle_branch(\n    branch: Sequence[Bytes32], gindex: GeneralizedIndex\n) -&gt; Sequence[Bytes32]:\n    depth = floorlog2(gindex)\n    num_extra = depth - len(branch)\n    return [Bytes32()] * num_extra + [*branch]\n</code></pre>"},{"location":"specs/electra/light-client/fork/#upgrading-light-client-data","title":"Upgrading light client data","text":"<p>An Electra <code>LightClientStore</code> can still process earlier light client data. In order to do so, that pre-Electra data needs to be locally upgraded to Electra before processing.</p> <pre><code>def upgrade_lc_header_to_electra(pre: deneb.LightClientHeader) -&gt; LightClientHeader:\n    return LightClientHeader(\n        beacon=pre.beacon,\n        execution=pre.execution,\n        execution_branch=pre.execution_branch,\n    )\n</code></pre> <pre><code>def upgrade_lc_bootstrap_to_electra(pre: deneb.LightClientBootstrap) -&gt; LightClientBootstrap:\n    return LightClientBootstrap(\n        header=upgrade_lc_header_to_electra(pre.header),\n        current_sync_committee=pre.current_sync_committee,\n        current_sync_committee_branch=normalize_merkle_branch(\n            pre.current_sync_committee_branch, CURRENT_SYNC_COMMITTEE_GINDEX_ELECTRA\n        ),\n    )\n</code></pre> <pre><code>def upgrade_lc_update_to_electra(pre: deneb.LightClientUpdate) -&gt; LightClientUpdate:\n    return LightClientUpdate(\n        attested_header=upgrade_lc_header_to_electra(pre.attested_header),\n        next_sync_committee=pre.next_sync_committee,\n        next_sync_committee_branch=normalize_merkle_branch(\n            pre.next_sync_committee_branch, NEXT_SYNC_COMMITTEE_GINDEX_ELECTRA\n        ),\n        finalized_header=upgrade_lc_header_to_electra(pre.finalized_header),\n        finality_branch=normalize_merkle_branch(pre.finality_branch, FINALIZED_ROOT_GINDEX_ELECTRA),\n        sync_aggregate=pre.sync_aggregate,\n        signature_slot=pre.signature_slot,\n    )\n</code></pre> <pre><code>def upgrade_lc_finality_update_to_electra(\n    pre: deneb.LightClientFinalityUpdate,\n) -&gt; LightClientFinalityUpdate:\n    return LightClientFinalityUpdate(\n        attested_header=upgrade_lc_header_to_electra(pre.attested_header),\n        finalized_header=upgrade_lc_header_to_electra(pre.finalized_header),\n        finality_branch=normalize_merkle_branch(pre.finality_branch, FINALIZED_ROOT_GINDEX_ELECTRA),\n        sync_aggregate=pre.sync_aggregate,\n        signature_slot=pre.signature_slot,\n    )\n</code></pre> <pre><code>def upgrade_lc_optimistic_update_to_electra(\n    pre: deneb.LightClientOptimisticUpdate,\n) -&gt; LightClientOptimisticUpdate:\n    return LightClientOptimisticUpdate(\n        attested_header=upgrade_lc_header_to_electra(pre.attested_header),\n        sync_aggregate=pre.sync_aggregate,\n        signature_slot=pre.signature_slot,\n    )\n</code></pre>"},{"location":"specs/electra/light-client/fork/#upgrading-the-store","title":"Upgrading the store","text":"<p>Existing <code>LightClientStore</code> objects based on Deneb MUST be upgraded to Electra before Electra based light client data can be processed. The <code>LightClientStore</code> upgrade MAY be performed before <code>ELECTRA_FORK_EPOCH</code>.</p> <pre><code>def upgrade_lc_store_to_electra(pre: deneb.LightClientStore) -&gt; LightClientStore:\n    if pre.best_valid_update is None:\n        best_valid_update = None\n    else:\n        best_valid_update = upgrade_lc_update_to_electra(pre.best_valid_update)\n    return LightClientStore(\n        finalized_header=upgrade_lc_header_to_electra(pre.finalized_header),\n        current_sync_committee=pre.current_sync_committee,\n        next_sync_committee=pre.next_sync_committee,\n        best_valid_update=best_valid_update,\n        optimistic_header=upgrade_lc_header_to_electra(pre.optimistic_header),\n        previous_max_active_participants=pre.previous_max_active_participants,\n        current_max_active_participants=pre.current_max_active_participants,\n    )\n</code></pre>"},{"location":"specs/electra/light-client/p2p-interface/","title":"Electra Light Client -- Networking","text":"<ul> <li>Networking</li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>light_client_finality_update</code></li> <li><code>light_client_optimistic_update</code></li> </ul> </li> </ul> </li> <li>The Req/Resp domain<ul> <li>Messages</li> <li>GetLightClientBootstrap</li> <li>LightClientUpdatesByRange</li> <li>GetLightClientFinalityUpdate</li> <li>GetLightClientOptimisticUpdate</li> </ul> </li> </ul>"},{"location":"specs/electra/light-client/p2p-interface/#networking","title":"Networking","text":"<p>The Deneb light client networking specification is extended to exchange Electra light client data.</p>"},{"location":"specs/electra/light-client/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":""},{"location":"specs/electra/light-client/p2p-interface/#topics-and-messages","title":"Topics and messages","text":""},{"location":"specs/electra/light-client/p2p-interface/#global-topics","title":"Global topics","text":""},{"location":"specs/electra/light-client/p2p-interface/#light_client_finality_update","title":"<code>light_client_finality_update</code>","text":"<code>fork_version</code> Message SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientFinalityUpdate</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientFinalityUpdate</code> <code>DENEB_FORK_VERSION</code> <code>deneb.LightClientFinalityUpdate</code> <code>ELECTRA_FORK_VERSION</code> and later <code>electra.LightClientFinalityUpdate</code>"},{"location":"specs/electra/light-client/p2p-interface/#light_client_optimistic_update","title":"<code>light_client_optimistic_update</code>","text":"<code>fork_version</code> Message SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientOptimisticUpdate</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientOptimisticUpdate</code> <code>DENEB_FORK_VERSION</code> <code>deneb.LightClientOptimisticUpdate</code> <code>ELECTRA_FORK_VERSION</code> and later <code>electra.LightClientOptimisticUpdate</code>"},{"location":"specs/electra/light-client/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/electra/light-client/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/electra/light-client/p2p-interface/#getlightclientbootstrap","title":"GetLightClientBootstrap","text":"<code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientBootstrap</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientBootstrap</code> <code>DENEB_FORK_VERSION</code> <code>deneb.LightClientBootstrap</code> <code>ELECTRA_FORK_VERSION</code> and later <code>electra.LightClientBootstrap</code>"},{"location":"specs/electra/light-client/p2p-interface/#lightclientupdatesbyrange","title":"LightClientUpdatesByRange","text":"<code>fork_version</code> Response chunk SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientUpdate</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientUpdate</code> <code>DENEB_FORK_VERSION</code> <code>deneb.LightClientUpdate</code> <code>ELECTRA_FORK_VERSION</code> and later <code>electra.LightClientUpdate</code>"},{"location":"specs/electra/light-client/p2p-interface/#getlightclientfinalityupdate","title":"GetLightClientFinalityUpdate","text":"<code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientFinalityUpdate</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientFinalityUpdate</code> <code>DENEB_FORK_VERSION</code> <code>deneb.LightClientFinalityUpdate</code> <code>ELECTRA_FORK_VERSION</code> and later <code>electra.LightClientFinalityUpdate</code>"},{"location":"specs/electra/light-client/p2p-interface/#getlightclientoptimisticupdate","title":"GetLightClientOptimisticUpdate","text":"<code>fork_version</code> Response SSZ type <code>GENESIS_FORK_VERSION</code> n/a <code>ALTAIR_FORK_VERSION</code> through <code>BELLATRIX_FORK_VERSION</code> <code>altair.LightClientOptimisticUpdate</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.LightClientOptimisticUpdate</code> <code>DENEB_FORK_VERSION</code> <code>deneb.LightClientOptimisticUpdate</code> <code>ELECTRA_FORK_VERSION</code> and later <code>electra.LightClientOptimisticUpdate</code>"},{"location":"specs/electra/light-client/sync-protocol/","title":"Electra Light Client -- Sync Protocol","text":"<ul> <li>Introduction</li> <li>Custom types</li> <li>Constants</li> <li>Frozen constants</li> <li>New constants</li> <li>Helper functions</li> <li>Modified <code>finalized_root_gindex_at_slot</code></li> <li>Modified <code>current_sync_committee_gindex_at_slot</code></li> <li>Modified <code>next_sync_committee_gindex_at_slot</code></li> <li>Modified <code>get_lc_execution_root</code></li> </ul>"},{"location":"specs/electra/light-client/sync-protocol/#introduction","title":"Introduction","text":"<p>This upgrade updates light client data to include the Electra changes to the <code>ExecutionPayload</code> structure and to the generalized indices of surrounding containers. It extends the Deneb Light Client specifications. The fork document explains how to upgrade existing Deneb based deployments to Electra.</p> <p>Additional documents describes the impact of the upgrade on certain roles:</p> <ul> <li>Networking</li> </ul>"},{"location":"specs/electra/light-client/sync-protocol/#custom-types","title":"Custom types","text":"Name SSZ equivalent Description <code>FinalityBranch</code> <code>Vector[Bytes32, floorlog2(FINALIZED_ROOT_GINDEX_ELECTRA)]</code> Merkle branch of <code>finalized_checkpoint.root</code> within <code>BeaconState</code> <code>CurrentSyncCommitteeBranch</code> <code>Vector[Bytes32, floorlog2(CURRENT_SYNC_COMMITTEE_GINDEX_ELECTRA)]</code> Merkle branch of <code>current_sync_committee</code> within <code>BeaconState</code> <code>NextSyncCommitteeBranch</code> <code>Vector[Bytes32, floorlog2(NEXT_SYNC_COMMITTEE_GINDEX_ELECTRA)]</code> Merkle branch of <code>next_sync_committee</code> within <code>BeaconState</code>"},{"location":"specs/electra/light-client/sync-protocol/#constants","title":"Constants","text":""},{"location":"specs/electra/light-client/sync-protocol/#frozen-constants","title":"Frozen constants","text":"<p>Existing <code>GeneralizedIndex</code> constants are frozen at their Altair values.</p> Name Value <code>FINALIZED_ROOT_GINDEX</code> <code>get_generalized_index(altair.BeaconState, 'finalized_checkpoint', 'root')</code> (= 105) <code>CURRENT_SYNC_COMMITTEE_GINDEX</code> <code>get_generalized_index(altair.BeaconState, 'current_sync_committee')</code> (= 54) <code>NEXT_SYNC_COMMITTEE_GINDEX</code> <code>get_generalized_index(altair.BeaconState, 'next_sync_committee')</code> (= 55)"},{"location":"specs/electra/light-client/sync-protocol/#new-constants","title":"New constants","text":"Name Value <code>FINALIZED_ROOT_GINDEX_ELECTRA</code> <code>get_generalized_index(BeaconState, 'finalized_checkpoint', 'root')</code> (= 169) <code>CURRENT_SYNC_COMMITTEE_GINDEX_ELECTRA</code> <code>get_generalized_index(BeaconState, 'current_sync_committee')</code> (= 86) <code>NEXT_SYNC_COMMITTEE_GINDEX_ELECTRA</code> <code>get_generalized_index(BeaconState, 'next_sync_committee')</code> (= 87)"},{"location":"specs/electra/light-client/sync-protocol/#helper-functions","title":"Helper functions","text":""},{"location":"specs/electra/light-client/sync-protocol/#modified-finalized_root_gindex_at_slot","title":"Modified <code>finalized_root_gindex_at_slot</code>","text":"<pre><code>def finalized_root_gindex_at_slot(slot: Slot) -&gt; GeneralizedIndex:\n    epoch = compute_epoch_at_slot(slot)\n\n    # [Modified in Electra]\n    if epoch &gt;= ELECTRA_FORK_EPOCH:\n        return FINALIZED_ROOT_GINDEX_ELECTRA\n    return FINALIZED_ROOT_GINDEX\n</code></pre>"},{"location":"specs/electra/light-client/sync-protocol/#modified-current_sync_committee_gindex_at_slot","title":"Modified <code>current_sync_committee_gindex_at_slot</code>","text":"<pre><code>def current_sync_committee_gindex_at_slot(slot: Slot) -&gt; GeneralizedIndex:\n    epoch = compute_epoch_at_slot(slot)\n\n    # [Modified in Electra]\n    if epoch &gt;= ELECTRA_FORK_EPOCH:\n        return CURRENT_SYNC_COMMITTEE_GINDEX_ELECTRA\n    return CURRENT_SYNC_COMMITTEE_GINDEX\n</code></pre>"},{"location":"specs/electra/light-client/sync-protocol/#modified-next_sync_committee_gindex_at_slot","title":"Modified <code>next_sync_committee_gindex_at_slot</code>","text":"<pre><code>def next_sync_committee_gindex_at_slot(slot: Slot) -&gt; GeneralizedIndex:\n    epoch = compute_epoch_at_slot(slot)\n\n    # [Modified in Electra]\n    if epoch &gt;= ELECTRA_FORK_EPOCH:\n        return NEXT_SYNC_COMMITTEE_GINDEX_ELECTRA\n    return NEXT_SYNC_COMMITTEE_GINDEX\n</code></pre>"},{"location":"specs/electra/light-client/sync-protocol/#modified-get_lc_execution_root","title":"Modified <code>get_lc_execution_root</code>","text":"<pre><code>def get_lc_execution_root(header: LightClientHeader) -&gt; Root:\n    epoch = compute_epoch_at_slot(header.beacon.slot)\n\n    # [New in Electra]\n    if epoch &gt;= ELECTRA_FORK_EPOCH:\n        return hash_tree_root(header.execution)\n\n    # [Modified in Electra]\n    if epoch &gt;= DENEB_FORK_EPOCH:\n        execution_header = deneb.ExecutionPayloadHeader(\n            parent_hash=header.execution.parent_hash,\n            fee_recipient=header.execution.fee_recipient,\n            state_root=header.execution.state_root,\n            receipts_root=header.execution.receipts_root,\n            logs_bloom=header.execution.logs_bloom,\n            prev_randao=header.execution.prev_randao,\n            block_number=header.execution.block_number,\n            gas_limit=header.execution.gas_limit,\n            gas_used=header.execution.gas_used,\n            timestamp=header.execution.timestamp,\n            extra_data=header.execution.extra_data,\n            base_fee_per_gas=header.execution.base_fee_per_gas,\n            block_hash=header.execution.block_hash,\n            transactions_root=header.execution.transactions_root,\n            withdrawals_root=header.execution.withdrawals_root,\n            blob_gas_used=header.execution.blob_gas_used,\n            excess_blob_gas=header.execution.excess_blob_gas,\n        )\n        return hash_tree_root(execution_header)\n\n    if epoch &gt;= CAPELLA_FORK_EPOCH:\n        execution_header = capella.ExecutionPayloadHeader(\n            parent_hash=header.execution.parent_hash,\n            fee_recipient=header.execution.fee_recipient,\n            state_root=header.execution.state_root,\n            receipts_root=header.execution.receipts_root,\n            logs_bloom=header.execution.logs_bloom,\n            prev_randao=header.execution.prev_randao,\n            block_number=header.execution.block_number,\n            gas_limit=header.execution.gas_limit,\n            gas_used=header.execution.gas_used,\n            timestamp=header.execution.timestamp,\n            extra_data=header.execution.extra_data,\n            base_fee_per_gas=header.execution.base_fee_per_gas,\n            block_hash=header.execution.block_hash,\n            transactions_root=header.execution.transactions_root,\n            withdrawals_root=header.execution.withdrawals_root,\n        )\n        return hash_tree_root(execution_header)\n\n    return Root()\n</code></pre>"},{"location":"specs/fulu/","title":"Index","text":""},{"location":"specs/fulu/#core","title":"Core","text":"<ul> <li>Beacon Chain</li> <li>DAS Core</li> <li>Fork Choice</li> <li>Fork</li> <li>P2P Interface</li> <li>Polynomial Commitments Sampling</li> <li>Validator</li> </ul>"},{"location":"specs/fulu/beacon-chain/","title":"Fulu -- The Beacon Chain","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Configuration</li> <li>Blob schedule</li> <li>Beacon chain state transition function</li> <li>Block processing<ul> <li>Execution payload</li> <li>Modified <code>process_execution_payload</code></li> </ul> </li> <li>Containers</li> <li>Extended Containers<ul> <li><code>BeaconState</code></li> </ul> </li> <li>Helper functions</li> <li>Misc<ul> <li>New <code>BlobParameters</code></li> <li>New <code>get_blob_parameters</code></li> <li>Modified <code>compute_fork_digest</code></li> <li>New <code>compute_proposer_indices</code></li> </ul> </li> <li>Beacon state accessors<ul> <li>Modified <code>get_beacon_proposer_index</code></li> <li>New <code>get_beacon_proposer_indices</code></li> </ul> </li> <li>Epoch processing<ul> <li>Modified <code>process_epoch</code></li> <li>New <code>process_proposer_lookahead</code></li> </ul> </li> </ul>"},{"location":"specs/fulu/beacon-chain/#introduction","title":"Introduction","text":"<p>Note: This specification is built upon Electra and is under active development.</p>"},{"location":"specs/fulu/beacon-chain/#configuration","title":"Configuration","text":""},{"location":"specs/fulu/beacon-chain/#blob-schedule","title":"Blob schedule","text":"<p>[New in Fulu:EIP7892] This schedule defines the maximum blobs per block limit for a given epoch.</p> <p>There MUST NOT exist multiple blob schedule entries with the same epoch value. The epoch value in each entry MUST be greater than or equal to <code>FULU_FORK_EPOCH</code>. The maximum blobs per block limit in each entry MUST be less than or equal to <code>MAX_BLOB_COMMITMENTS_PER_BLOCK</code>. The blob schedule entries SHOULD be sorted by epoch in ascending order. The blob schedule MAY be empty.</p> <p>Note: The blob schedule is to be determined.</p> Epoch Max Blobs Per Block Description"},{"location":"specs/fulu/beacon-chain/#beacon-chain-state-transition-function","title":"Beacon chain state transition function","text":""},{"location":"specs/fulu/beacon-chain/#block-processing","title":"Block processing","text":""},{"location":"specs/fulu/beacon-chain/#execution-payload","title":"Execution payload","text":""},{"location":"specs/fulu/beacon-chain/#modified-process_execution_payload","title":"Modified <code>process_execution_payload</code>","text":"<pre><code>def process_execution_payload(\n    state: BeaconState, body: BeaconBlockBody, execution_engine: ExecutionEngine\n) -&gt; None:\n    payload = body.execution_payload\n\n    # Verify consistency of the parent hash with respect to the previous execution payload header\n    assert payload.parent_hash == state.latest_execution_payload_header.block_hash\n    # Verify prev_randao\n    assert payload.prev_randao == get_randao_mix(state, get_current_epoch(state))\n    # Verify timestamp\n    assert payload.timestamp == compute_time_at_slot(state, state.slot)\n    # [Modified in Fulu:EIP7892]\n    # Verify commitments are under limit\n    assert (\n        len(body.blob_kzg_commitments)\n        &lt;= get_blob_parameters(get_current_epoch(state)).max_blobs_per_block\n    )\n    # Verify the execution payload is valid\n    versioned_hashes = [\n        kzg_commitment_to_versioned_hash(commitment) for commitment in body.blob_kzg_commitments\n    ]\n    assert execution_engine.verify_and_notify_new_payload(\n        NewPayloadRequest(\n            execution_payload=payload,\n            versioned_hashes=versioned_hashes,\n            parent_beacon_block_root=state.latest_block_header.parent_root,\n            execution_requests=body.execution_requests,\n        )\n    )\n    # Cache execution payload header\n    state.latest_execution_payload_header = ExecutionPayloadHeader(\n        parent_hash=payload.parent_hash,\n        fee_recipient=payload.fee_recipient,\n        state_root=payload.state_root,\n        receipts_root=payload.receipts_root,\n        logs_bloom=payload.logs_bloom,\n        prev_randao=payload.prev_randao,\n        block_number=payload.block_number,\n        gas_limit=payload.gas_limit,\n        gas_used=payload.gas_used,\n        timestamp=payload.timestamp,\n        extra_data=payload.extra_data,\n        base_fee_per_gas=payload.base_fee_per_gas,\n        block_hash=payload.block_hash,\n        transactions_root=hash_tree_root(payload.transactions),\n        withdrawals_root=hash_tree_root(payload.withdrawals),\n        blob_gas_used=payload.blob_gas_used,\n        excess_blob_gas=payload.excess_blob_gas,\n    )\n</code></pre>"},{"location":"specs/fulu/beacon-chain/#containers","title":"Containers","text":""},{"location":"specs/fulu/beacon-chain/#extended-containers","title":"Extended Containers","text":""},{"location":"specs/fulu/beacon-chain/#beaconstate","title":"<code>BeaconState</code>","text":"<p>Note: The <code>BeaconState</code> container is extended with the <code>proposer_lookahead</code> field, which is a list of validator indices covering the full lookahead period, starting from the beginning of the current epoch. For example, <code>proposer_lookahead[0]</code> is the validator index for the first proposer in the current epoch, <code>proposer_lookahead[1]</code> is the validator index for the next proposer in the current epoch, and so forth. The length of the <code>proposer_lookahead</code> list is <code>(MIN_SEED_LOOKAHEAD + 1) * SLOTS_PER_EPOCH</code>, reflecting how far ahead proposer indices are computed based on the <code>MIN_SEED_LOOKAHEAD</code> parameter.</p> <pre><code>class BeaconState(Container):\n    genesis_time: uint64\n    genesis_validators_root: Root\n    slot: Slot\n    fork: Fork\n    latest_block_header: BeaconBlockHeader\n    block_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    state_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    historical_roots: List[Root, HISTORICAL_ROOTS_LIMIT]\n    eth1_data: Eth1Data\n    eth1_data_votes: List[Eth1Data, EPOCHS_PER_ETH1_VOTING_PERIOD * SLOTS_PER_EPOCH]\n    eth1_deposit_index: uint64\n    validators: List[Validator, VALIDATOR_REGISTRY_LIMIT]\n    balances: List[Gwei, VALIDATOR_REGISTRY_LIMIT]\n    randao_mixes: Vector[Bytes32, EPOCHS_PER_HISTORICAL_VECTOR]\n    slashings: Vector[Gwei, EPOCHS_PER_SLASHINGS_VECTOR]\n    previous_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    current_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    justification_bits: Bitvector[JUSTIFICATION_BITS_LENGTH]\n    previous_justified_checkpoint: Checkpoint\n    current_justified_checkpoint: Checkpoint\n    finalized_checkpoint: Checkpoint\n    inactivity_scores: List[uint64, VALIDATOR_REGISTRY_LIMIT]\n    current_sync_committee: SyncCommittee\n    next_sync_committee: SyncCommittee\n    latest_execution_payload_header: ExecutionPayloadHeader\n    next_withdrawal_index: WithdrawalIndex\n    next_withdrawal_validator_index: ValidatorIndex\n    historical_summaries: List[HistoricalSummary, HISTORICAL_ROOTS_LIMIT]\n    deposit_requests_start_index: uint64\n    deposit_balance_to_consume: Gwei\n    exit_balance_to_consume: Gwei\n    earliest_exit_epoch: Epoch\n    consolidation_balance_to_consume: Gwei\n    earliest_consolidation_epoch: Epoch\n    pending_deposits: List[PendingDeposit, PENDING_DEPOSITS_LIMIT]\n    pending_partial_withdrawals: List[PendingPartialWithdrawal, PENDING_PARTIAL_WITHDRAWALS_LIMIT]\n    pending_consolidations: List[PendingConsolidation, PENDING_CONSOLIDATIONS_LIMIT]\n    # [New in Fulu:EIP7917]\n    proposer_lookahead: Vector[ValidatorIndex, (MIN_SEED_LOOKAHEAD + 1) * SLOTS_PER_EPOCH]\n</code></pre>"},{"location":"specs/fulu/beacon-chain/#helper-functions","title":"Helper functions","text":""},{"location":"specs/fulu/beacon-chain/#misc","title":"Misc","text":""},{"location":"specs/fulu/beacon-chain/#new-blobparameters","title":"New <code>BlobParameters</code>","text":"<pre><code>@dataclass\nclass BlobParameters:\n    epoch: Epoch\n    max_blobs_per_block: uint64\n</code></pre>"},{"location":"specs/fulu/beacon-chain/#new-get_blob_parameters","title":"New <code>get_blob_parameters</code>","text":"<pre><code>def get_blob_parameters(epoch: Epoch) -&gt; BlobParameters:\n    \"\"\"\n    Return the blob parameters at a given epoch.\n    \"\"\"\n    for entry in sorted(BLOB_SCHEDULE, key=lambda e: e[\"EPOCH\"], reverse=True):\n        if epoch &gt;= entry[\"EPOCH\"]:\n            return BlobParameters(entry[\"EPOCH\"], entry[\"MAX_BLOBS_PER_BLOCK\"])\n    return BlobParameters(ELECTRA_FORK_EPOCH, MAX_BLOBS_PER_BLOCK_ELECTRA)\n</code></pre>"},{"location":"specs/fulu/beacon-chain/#modified-compute_fork_digest","title":"Modified <code>compute_fork_digest</code>","text":"<p>Note: The <code>compute_fork_digest</code> helper is updated to account for Blob-Parameters-Only forks.</p> <pre><code>def compute_fork_digest(\n    genesis_validators_root: Root,\n    epoch: Epoch,\n) -&gt; ForkDigest:\n    \"\"\"\n    Return the 4-byte fork digest for the ``genesis_validators_root`` at a given ``epoch``.\n\n    This is a digest primarily used for domain separation on the p2p layer.\n    4-bytes suffices for practical separation of forks/chains.\n    \"\"\"\n    fork_version = compute_fork_version(epoch)\n    base_digest = compute_fork_data_root(fork_version, genesis_validators_root)\n\n    # [Modified in Fulu:EIP7892]\n    # Bitmask digest with hash of blob parameters\n    blob_parameters = get_blob_parameters(epoch)\n    return ForkDigest(\n        bytes(\n            xor(\n                base_digest,\n                hash(\n                    uint_to_bytes(uint64(blob_parameters.epoch))\n                    + uint_to_bytes(uint64(blob_parameters.max_blobs_per_block))\n                ),\n            )\n        )[:4]\n    )\n</code></pre>"},{"location":"specs/fulu/beacon-chain/#new-compute_proposer_indices","title":"New <code>compute_proposer_indices</code>","text":"<pre><code>def compute_proposer_indices(\n    state: BeaconState, epoch: Epoch, seed: Bytes32, indices: Sequence[ValidatorIndex]\n) -&gt; Vector[ValidatorIndex, SLOTS_PER_EPOCH]:\n    \"\"\"\n    Return the proposer indices for the given ``epoch``.\n    \"\"\"\n    start_slot = compute_start_slot_at_epoch(epoch)\n    seeds = [hash(seed + uint_to_bytes(Slot(start_slot + i))) for i in range(SLOTS_PER_EPOCH)]\n    return [compute_proposer_index(state, indices, seed) for seed in seeds]\n</code></pre>"},{"location":"specs/fulu/beacon-chain/#beacon-state-accessors","title":"Beacon state accessors","text":""},{"location":"specs/fulu/beacon-chain/#modified-get_beacon_proposer_index","title":"Modified <code>get_beacon_proposer_index</code>","text":"<p>Note: The function <code>get_beacon_proposer_index</code> is modified to use the pre-calculated <code>current_proposer_lookahead</code> instead of calculating it on-demand.</p> <pre><code>def get_beacon_proposer_index(state: BeaconState) -&gt; ValidatorIndex:\n    \"\"\"\n    Return the beacon proposer index at the current slot.\n    \"\"\"\n    return state.proposer_lookahead[state.slot % SLOTS_PER_EPOCH]\n</code></pre>"},{"location":"specs/fulu/beacon-chain/#new-get_beacon_proposer_indices","title":"New <code>get_beacon_proposer_indices</code>","text":"<pre><code>def get_beacon_proposer_indices(\n    state: BeaconState, epoch: Epoch\n) -&gt; Vector[ValidatorIndex, SLOTS_PER_EPOCH]:\n    \"\"\"\n    Return the proposer indices for the given ``epoch``.\n    \"\"\"\n    indices = get_active_validator_indices(state, epoch)\n    seed = get_seed(state, epoch, DOMAIN_BEACON_PROPOSER)\n    return compute_proposer_indices(state, epoch, seed, indices)\n</code></pre>"},{"location":"specs/fulu/beacon-chain/#epoch-processing","title":"Epoch processing","text":""},{"location":"specs/fulu/beacon-chain/#modified-process_epoch","title":"Modified <code>process_epoch</code>","text":"<p>Note: The function <code>process_epoch</code> is modified in Fulu to call <code>process_proposer_lookahead</code> to update the <code>proposer_lookahead</code> in the beacon state.</p> <pre><code>def process_epoch(state: BeaconState) -&gt; None:\n    process_justification_and_finalization(state)\n    process_inactivity_updates(state)\n    process_rewards_and_penalties(state)\n    process_registry_updates(state)\n    process_slashings(state)\n    process_eth1_data_reset(state)\n    process_pending_deposits(state)\n    process_pending_consolidations(state)\n    process_effective_balance_updates(state)\n    process_slashings_reset(state)\n    process_randao_mixes_reset(state)\n    process_historical_summaries_update(state)\n    process_participation_flag_updates(state)\n    process_sync_committee_updates(state)\n    # [New in Fulu:EIP7917]\n    process_proposer_lookahead(state)\n</code></pre>"},{"location":"specs/fulu/beacon-chain/#new-process_proposer_lookahead","title":"New <code>process_proposer_lookahead</code>","text":"<p>Note: This function updates the <code>proposer_lookahead</code> field in the beacon state by shifting out proposer indices from the earliest epoch and appending new proposer indices for the latest epoch. With <code>MIN_SEED_LOOKAHEAD</code> set to <code>1</code>, this means that at the start of epoch <code>N</code>, the proposer lookahead for epoch <code>N+1</code> will be computed and included in the beacon state's lookahead.</p> <pre><code>def process_proposer_lookahead(state: BeaconState) -&gt; None:\n    last_epoch_start = len(state.proposer_lookahead) - SLOTS_PER_EPOCH\n    # Shift out proposers in the first epoch\n    state.proposer_lookahead[:last_epoch_start] = state.proposer_lookahead[SLOTS_PER_EPOCH:]\n    # Fill in the last epoch with new proposer indices\n    last_epoch_proposers = get_beacon_proposer_indices(\n        state, Epoch(get_current_epoch(state) + MIN_SEED_LOOKAHEAD + 1)\n    )\n    state.proposer_lookahead[last_epoch_start:] = last_epoch_proposers\n</code></pre>"},{"location":"specs/fulu/das-core/","title":"Fulu -- Data Availability Sampling Core","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Constants</li> <li>Misc</li> <li>Custom types</li> <li>Configuration</li> <li>Custody setting</li> <li>Preset</li> <li>Size parameters</li> <li>Containers<ul> <li><code>DataColumnSidecar</code></li> <li><code>MatrixEntry</code></li> </ul> </li> <li>Helper functions</li> <li><code>get_custody_groups</code></li> <li><code>compute_columns_for_custody_group</code></li> <li><code>compute_matrix</code></li> <li><code>recover_matrix</code></li> <li>Custody</li> <li>Custody requirement</li> <li>Public, deterministic selection</li> <li>Custody sampling</li> <li>Extended data</li> <li>Column gossip</li> <li>Parameters</li> <li>Reconstruction and cross-seeding</li> <li>FAQs</li> <li>Why don't nodes custody rows?</li> <li>Why don't we rotate custody over time?</li> <li>Does having a lot of column subnets make the network unstable?</li> </ul>"},{"location":"specs/fulu/das-core/#constants","title":"Constants","text":"<p>The following values are (non-configurable) constants used throughout the specification.</p>"},{"location":"specs/fulu/das-core/#misc","title":"Misc","text":"Name Value <code>UINT256_MAX</code> <code>uint256(2**256 - 1)</code>"},{"location":"specs/fulu/das-core/#custom-types","title":"Custom types","text":"Name SSZ equivalent Description <code>RowIndex</code> <code>uint64</code> Row identifier in the matrix of cells <code>ColumnIndex</code> <code>uint64</code> Column identifier in the matrix of cells <code>CustodyIndex</code> <code>uint64</code> Custody group identifier in the set of custody groups"},{"location":"specs/fulu/das-core/#configuration","title":"Configuration","text":""},{"location":"specs/fulu/das-core/#custody-setting","title":"Custody setting","text":"Name Value Description <code>SAMPLES_PER_SLOT</code> <code>8</code> Minimum number of samples for an honest node <code>NUMBER_OF_CUSTODY_GROUPS</code> <code>128</code> Number of custody groups available for nodes to custody <code>CUSTODY_REQUIREMENT</code> <code>4</code> Minimum number of custody groups an honest node custodies and serves samples from"},{"location":"specs/fulu/das-core/#preset","title":"Preset","text":""},{"location":"specs/fulu/das-core/#size-parameters","title":"Size parameters","text":"Name Value Description <code>NUMBER_OF_COLUMNS</code> <code>uint64(CELLS_PER_EXT_BLOB)</code> (= 128) Number of columns in the extended data matrix"},{"location":"specs/fulu/das-core/#containers","title":"Containers","text":""},{"location":"specs/fulu/das-core/#datacolumnsidecar","title":"<code>DataColumnSidecar</code>","text":"<pre><code>class DataColumnSidecar(Container):\n    index: ColumnIndex\n    column: List[Cell, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    kzg_commitments: List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    kzg_proofs: List[KZGProof, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    signed_block_header: SignedBeaconBlockHeader\n    kzg_commitments_inclusion_proof: Vector[Bytes32, KZG_COMMITMENTS_INCLUSION_PROOF_DEPTH]\n</code></pre>"},{"location":"specs/fulu/das-core/#matrixentry","title":"<code>MatrixEntry</code>","text":"<pre><code>class MatrixEntry(Container):\n    cell: Cell\n    kzg_proof: KZGProof\n    column_index: ColumnIndex\n    row_index: RowIndex\n</code></pre>"},{"location":"specs/fulu/das-core/#helper-functions","title":"Helper functions","text":""},{"location":"specs/fulu/das-core/#get_custody_groups","title":"<code>get_custody_groups</code>","text":"<pre><code>def get_custody_groups(node_id: NodeID, custody_group_count: uint64) -&gt; Sequence[CustodyIndex]:\n    assert custody_group_count &lt;= NUMBER_OF_CUSTODY_GROUPS\n\n    # Skip computation if all groups are custodied\n    if custody_group_count == NUMBER_OF_CUSTODY_GROUPS:\n        return [CustodyIndex(i) for i in range(NUMBER_OF_CUSTODY_GROUPS)]\n\n    current_id = uint256(node_id)\n    custody_groups: List[CustodyIndex] = []\n    while len(custody_groups) &lt; custody_group_count:\n        custody_group = CustodyIndex(\n            bytes_to_uint64(hash(uint_to_bytes(current_id))[0:8]) % NUMBER_OF_CUSTODY_GROUPS\n        )\n        if custody_group not in custody_groups:\n            custody_groups.append(custody_group)\n        if current_id == UINT256_MAX:\n            # Overflow prevention\n            current_id = uint256(0)\n        else:\n            current_id += 1\n\n    assert len(custody_groups) == len(set(custody_groups))\n    return sorted(custody_groups)\n</code></pre>"},{"location":"specs/fulu/das-core/#compute_columns_for_custody_group","title":"<code>compute_columns_for_custody_group</code>","text":"<pre><code>def compute_columns_for_custody_group(custody_group: CustodyIndex) -&gt; Sequence[ColumnIndex]:\n    assert custody_group &lt; NUMBER_OF_CUSTODY_GROUPS\n    columns_per_group = NUMBER_OF_COLUMNS // NUMBER_OF_CUSTODY_GROUPS\n    return [\n        ColumnIndex(NUMBER_OF_CUSTODY_GROUPS * i + custody_group) for i in range(columns_per_group)\n    ]\n</code></pre>"},{"location":"specs/fulu/das-core/#compute_matrix","title":"<code>compute_matrix</code>","text":"<pre><code>def compute_matrix(blobs: Sequence[Blob]) -&gt; Sequence[MatrixEntry]:\n    \"\"\"\n    Return the full, flattened sequence of matrix entries.\n\n    This helper demonstrates the relationship between blobs and the matrix of cells/proofs.\n    The data structure for storing cells/proofs is implementation-dependent.\n    \"\"\"\n    matrix = []\n    for blob_index, blob in enumerate(blobs):\n        cells, proofs = compute_cells_and_kzg_proofs(blob)\n        for cell_index, (cell, proof) in enumerate(zip(cells, proofs)):\n            matrix.append(\n                MatrixEntry(\n                    cell=cell,\n                    kzg_proof=proof,\n                    row_index=blob_index,\n                    column_index=cell_index,\n                )\n            )\n    return matrix\n</code></pre>"},{"location":"specs/fulu/das-core/#recover_matrix","title":"<code>recover_matrix</code>","text":"<pre><code>def recover_matrix(\n    partial_matrix: Sequence[MatrixEntry], blob_count: uint64\n) -&gt; Sequence[MatrixEntry]:\n    \"\"\"\n    Recover the full, flattened sequence of matrix entries.\n\n    This helper demonstrates how to apply ``recover_cells_and_kzg_proofs``.\n    The data structure for storing cells/proofs is implementation-dependent.\n    \"\"\"\n    matrix = []\n    for blob_index in range(blob_count):\n        cell_indices = [e.column_index for e in partial_matrix if e.row_index == blob_index]\n        cells = [e.cell for e in partial_matrix if e.row_index == blob_index]\n        recovered_cells, recovered_proofs = recover_cells_and_kzg_proofs(cell_indices, cells)\n        for cell_index, (cell, proof) in enumerate(zip(recovered_cells, recovered_proofs)):\n            matrix.append(\n                MatrixEntry(\n                    cell=cell,\n                    kzg_proof=proof,\n                    row_index=blob_index,\n                    column_index=cell_index,\n                )\n            )\n    return matrix\n</code></pre>"},{"location":"specs/fulu/das-core/#custody","title":"Custody","text":""},{"location":"specs/fulu/das-core/#custody-requirement","title":"Custody requirement","text":"<p>Columns are grouped into custody groups. Nodes custodying a custody group MUST custody all the columns in that group. When syncing, a node MUST backfill columns from all of its custody groups.</p> <p>A node may choose to custody and serve more than the minimum honesty requirement. Such a node explicitly advertises a number greater than <code>CUSTODY_REQUIREMENT</code> through the peer discovery mechanism, specifically by setting a higher value in the <code>custody_group_count</code> field within its ENR. This value can be increased up to <code>NUMBER_OF_CUSTODY_GROUPS</code>, indicating a super-full node.</p> <p>A node stores the custodied columns for the duration of the pruning period and responds to peer requests for samples on those columns.</p>"},{"location":"specs/fulu/das-core/#public-deterministic-selection","title":"Public, deterministic selection","text":"<p>The particular columns/groups that a node custodies are selected pseudo-randomly as a function (<code>get_custody_groups</code>) of the node-id and custody size -- importantly this function can be run by any party as the inputs are all public.</p> <p>Note: increasing the <code>custody_size</code> parameter for a given <code>node_id</code> extends the returned list (rather than being an entirely new shuffle) such that if <code>custody_size</code> is unknown, the default <code>CUSTODY_REQUIREMENT</code> will be correct for a subset of the node's custody.</p>"},{"location":"specs/fulu/das-core/#custody-sampling","title":"Custody sampling","text":"<p>At each slot, a node advertising <code>custody_group_count</code> downloads a minimum of <code>sampling_size = max(SAMPLES_PER_SLOT, custody_group_count)</code> custody groups, selected by <code>groups = get_custody_groups(node_id, sampling_size)</code>, to which correspond the columns <code>compute_columns_for_custody_group(group) for group in groups</code>. The custody groups to custody, selected by <code>get_custody_groups(node_id, custody_group_count)</code>, are then in particular a subset of those to sample. Sampling is considered successful if the node manages to retrieve all selected columns.</p>"},{"location":"specs/fulu/das-core/#extended-data","title":"Extended data","text":"<p>In this construction, we extend the blobs using a one-dimensional erasure coding extension. The matrix comprises maximum <code>MAX_BLOBS_PER_BLOCK</code> rows and fixed <code>NUMBER_OF_COLUMNS</code> columns, with each row containing a <code>Blob</code> and its corresponding extension. <code>compute_matrix</code> demonstrates the relationship between blobs and the matrix, a potential method of storing cells/proofs.</p>"},{"location":"specs/fulu/das-core/#column-gossip","title":"Column gossip","text":""},{"location":"specs/fulu/das-core/#parameters","title":"Parameters","text":"<p>Verifiable samples from their respective column are distributed on the assigned subnet. To custody columns in a particular custody group, a node joins the respective gossipsub subnets. If a node fails to get columns on the column subnets, a node can also utilize the Req/Resp protocol to query the missing columns from other peers.</p>"},{"location":"specs/fulu/das-core/#reconstruction-and-cross-seeding","title":"Reconstruction and cross-seeding","text":"<p>If the node obtains 50%+ of all the columns, it SHOULD reconstruct the full data matrix via the <code>recover_matrix</code> helper. Nodes MAY delay this reconstruction allowing time for other columns to arrive over the network. If delaying reconstruction, nodes may use a random delay in order to desynchronize reconstruction among nodes, thus reducing overall CPU load.</p> <p>Once the node obtains a column through reconstruction, the node MUST expose the new column as if it had received it over the network. If the node is subscribed to the subnet corresponding to the column, it MUST send the reconstructed <code>DataColumnSidecar</code> to its topic mesh neighbors. If instead the node is not subscribed to the corresponding subnet, it SHOULD still expose the availability of the <code>DataColumnSidecar</code> as part of the gossip emission process. After exposing the reconstructed <code>DataColumnSidecar</code> to the network, the node MAY delete the <code>DataColumnSidecar</code> if it is not part of the node's custody requirement.</p> <p>Note: A node always maintains a matrix view of the rows and columns they are following, able to cross-reference and cross-seed in either direction.</p> <p>Note: There are timing considerations to analyze -- at what point does a node consider samples missing and choose to reconstruct and cross-seed.</p> <p>Note: There may be anti-DoS and quality-of-service considerations around how to send samples and consider samples -- is each individual sample a message or are they sent in aggregate forms.</p>"},{"location":"specs/fulu/das-core/#faqs","title":"FAQs","text":""},{"location":"specs/fulu/das-core/#why-dont-nodes-custody-rows","title":"Why don't nodes custody rows?","text":"<p>In the one-dimensional construction, a node samples the peers by requesting the whole <code>DataColumnSidecar</code>. In reconstruction, a node can reconstruct all the blobs by 50% of the columns. Note that nodes can still download the row via <code>blob_sidecar_{subnet_id}</code> subnets.</p> <p>The potential benefits of having row custody could include:</p> <ol> <li>Allow for more \"natural\" distribution of data to consumers -- e.g., roll-ups    -- but realistically, they won't know a priori which row their blob is going    to be included in the block, so they would either need to listen to all rows    or download a particular row after seeing the block. The former looks just    like listening to column [0, N) and the latter is req/resp instead of    gossiping.</li> <li>Help with some sort of distributed reconstruction. Those with full rows can    compute extensions and seed missing samples to the network. This would either    need to be able to send individual points on the gossip or would need some    sort of req/resp faculty, potentially similar to an <code>IHAVEPOINTBITFIELD</code> and    <code>IWANTSAMPLE</code>.</li> </ol> <p>However, for simplicity, we don't assign row custody assignments to nodes in the current design.</p>"},{"location":"specs/fulu/das-core/#why-dont-we-rotate-custody-over-time","title":"Why don't we rotate custody over time?","text":"<p>To start with a simple, stable backbone, for now, we don't shuffle the custody assignments via the deterministic custody selection helper <code>get_custody_groups</code>. However, staggered rotation likely needs to happen on the order of the pruning period to ensure subnets can be utilized for recovery. For example, introducing an <code>epoch</code> argument allows the function to maintain stability over many epochs.</p>"},{"location":"specs/fulu/das-core/#does-having-a-lot-of-column-subnets-make-the-network-unstable","title":"Does having a lot of column subnets make the network unstable?","text":"<p>No, the number of subnets doesn't really matter. What matters to the network stability is the number of nodes and the churn rate in the network. If the number of the nodes is too low, it's likely to have a network partition when some nodes are down. For the churn rate, if the churn rate is high, we even need to have a higher number of nodes, since nodes are likely to be turned off more often.</p>"},{"location":"specs/fulu/fork-choice/","title":"Fulu -- Fork Choice","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Helpers</li> <li>Modified <code>is_data_available</code></li> <li>Updated fork-choice handlers</li> <li>Modified <code>on_block</code></li> </ul>"},{"location":"specs/fulu/fork-choice/#introduction","title":"Introduction","text":"<p>This is the modification of the fork choice accompanying Fulu.</p>"},{"location":"specs/fulu/fork-choice/#helpers","title":"Helpers","text":""},{"location":"specs/fulu/fork-choice/#modified-is_data_available","title":"Modified <code>is_data_available</code>","text":"<pre><code>def is_data_available(beacon_block_root: Root) -&gt; bool:\n    # `retrieve_column_sidecars` is implementation and context dependent, replacing\n    # `retrieve_blobs_and_proofs`. For the given block root, it returns all column\n    # sidecars to sample, or raises an exception if they are not available.\n    # The p2p network does not guarantee sidecar retrieval outside of\n    # `MIN_EPOCHS_FOR_DATA_COLUMN_SIDECARS_REQUESTS` epochs.\n    column_sidecars = retrieve_column_sidecars(beacon_block_root)\n    return all(\n        verify_data_column_sidecar(column_sidecar)\n        and verify_data_column_sidecar_kzg_proofs(column_sidecar)\n        for column_sidecar in column_sidecars\n    )\n</code></pre>"},{"location":"specs/fulu/fork-choice/#updated-fork-choice-handlers","title":"Updated fork-choice handlers","text":""},{"location":"specs/fulu/fork-choice/#modified-on_block","title":"Modified <code>on_block</code>","text":"<p>Note: The only modification is that <code>is_data_available</code> does not take <code>blob_kzg_commitments</code> as input.</p> <pre><code>def on_block(store: Store, signed_block: SignedBeaconBlock) -&gt; None:\n    \"\"\"\n    Run ``on_block`` upon receiving a new block.\n    \"\"\"\n    block = signed_block.message\n    # Parent block must be known\n    assert block.parent_root in store.block_states\n    # Make a copy of the state to avoid mutability issues\n    state = copy(store.block_states[block.parent_root])\n    # Blocks cannot be in the future. If they are, their consideration must be delayed until they are in the past.\n    assert get_current_slot(store) &gt;= block.slot\n\n    # Check that block is later than the finalized epoch slot (optimization to reduce calls to get_ancestor)\n    finalized_slot = compute_start_slot_at_epoch(store.finalized_checkpoint.epoch)\n    assert block.slot &gt; finalized_slot\n    # Check block is a descendant of the finalized block at the checkpoint finalized slot\n    finalized_checkpoint_block = get_checkpoint_block(\n        store,\n        block.parent_root,\n        store.finalized_checkpoint.epoch,\n    )\n    assert store.finalized_checkpoint.root == finalized_checkpoint_block\n\n    # [Modified in Fulu:EIP7594]\n    # Check if blob data is available\n    # If not, this payload MAY be queued and subsequently considered when blob data becomes available\n    assert is_data_available(hash_tree_root(block))\n\n    # Check the block is valid and compute the post-state\n    block_root = hash_tree_root(block)\n    state_transition(state, signed_block, True)\n\n    # Add new block to the store\n    store.blocks[block_root] = block\n    # Add new state for this block to the store\n    store.block_states[block_root] = state\n\n    # Add block timeliness to the store\n    seconds_since_genesis = store.time - store.genesis_time\n    time_into_slot_ms = seconds_to_milliseconds(seconds_since_genesis) % SLOT_DURATION_MS\n    attestation_threshold_ms = get_slot_component_duration_ms(ATTESTATION_DUE_BPS)\n    is_before_attesting_interval = time_into_slot_ms &lt; attestation_threshold_ms\n    is_timely = get_current_slot(store) == block.slot and is_before_attesting_interval\n    store.block_timeliness[hash_tree_root(block)] = is_timely\n\n    # Add proposer score boost if the block is timely and not conflicting with an existing block\n    is_first_block = store.proposer_boost_root == Root()\n    if is_timely and is_first_block:\n        store.proposer_boost_root = hash_tree_root(block)\n\n    # Update checkpoints in store if necessary\n    update_checkpoints(store, state.current_justified_checkpoint, state.finalized_checkpoint)\n\n    # Eagerly compute unrealized justification and finality.\n    compute_pulled_up_tip(store, block_root)\n</code></pre>"},{"location":"specs/fulu/fork/","title":"Fulu -- Fork Logic","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Configuration</li> <li>New <code>initialize_proposer_lookahead</code></li> <li>Fork to Fulu</li> <li>Fork trigger</li> <li>Upgrading the state</li> </ul>"},{"location":"specs/fulu/fork/#introduction","title":"Introduction","text":"<p>This document describes the process of the Fulu upgrade.</p>"},{"location":"specs/fulu/fork/#configuration","title":"Configuration","text":"<p>Warning: this configuration is not definitive.</p> Name Value <code>FULU_FORK_VERSION</code> <code>Version('0x06000000')</code> <code>FULU_FORK_EPOCH</code> <code>Epoch(18446744073709551615)</code> TBD"},{"location":"specs/fulu/fork/#new-initialize_proposer_lookahead","title":"New <code>initialize_proposer_lookahead</code>","text":"<pre><code>def initialize_proposer_lookahead(\n    state: electra.BeaconState,\n) -&gt; Vector[ValidatorIndex, (MIN_SEED_LOOKAHEAD + 1) * SLOTS_PER_EPOCH]:\n    \"\"\"\n    Return the proposer indices for the full available lookahead starting from current epoch.\n    Used to initialize the ``proposer_lookahead`` field in the beacon state at genesis and after forks.\n    \"\"\"\n    current_epoch = get_current_epoch(state)\n    lookahead = []\n    for i in range(MIN_SEED_LOOKAHEAD + 1):\n        lookahead.extend(get_beacon_proposer_indices(state, Epoch(current_epoch + i)))\n    return lookahead\n</code></pre>"},{"location":"specs/fulu/fork/#fork-to-fulu","title":"Fork to Fulu","text":""},{"location":"specs/fulu/fork/#fork-trigger","title":"Fork trigger","text":"<p>The fork is triggered at epoch <code>FULU_FORK_EPOCH</code>.</p> <p>Note that for the pure Fulu networks, we don't apply <code>upgrade_to_fulu</code> since it starts with Fulu version logic.</p>"},{"location":"specs/fulu/fork/#upgrading-the-state","title":"Upgrading the state","text":"<p>If <code>state.slot % SLOTS_PER_EPOCH == 0</code> and <code>compute_epoch_at_slot(state.slot) == FULU_FORK_EPOCH</code>, an irregular state change is made to upgrade to Fulu.</p> <pre><code>def upgrade_to_fulu(pre: electra.BeaconState) -&gt; BeaconState:\n    epoch = electra.get_current_epoch(pre)\n    post = BeaconState(\n        genesis_time=pre.genesis_time,\n        genesis_validators_root=pre.genesis_validators_root,\n        slot=pre.slot,\n        fork=Fork(\n            previous_version=pre.fork.current_version,\n            # [Modified in Fulu]\n            current_version=FULU_FORK_VERSION,\n            epoch=epoch,\n        ),\n        latest_block_header=pre.latest_block_header,\n        block_roots=pre.block_roots,\n        state_roots=pre.state_roots,\n        historical_roots=pre.historical_roots,\n        eth1_data=pre.eth1_data,\n        eth1_data_votes=pre.eth1_data_votes,\n        eth1_deposit_index=pre.eth1_deposit_index,\n        validators=pre.validators,\n        balances=pre.balances,\n        randao_mixes=pre.randao_mixes,\n        slashings=pre.slashings,\n        previous_epoch_participation=pre.previous_epoch_participation,\n        current_epoch_participation=pre.current_epoch_participation,\n        justification_bits=pre.justification_bits,\n        previous_justified_checkpoint=pre.previous_justified_checkpoint,\n        current_justified_checkpoint=pre.current_justified_checkpoint,\n        finalized_checkpoint=pre.finalized_checkpoint,\n        inactivity_scores=pre.inactivity_scores,\n        current_sync_committee=pre.current_sync_committee,\n        next_sync_committee=pre.next_sync_committee,\n        latest_execution_payload_header=pre.latest_execution_payload_header,\n        next_withdrawal_index=pre.next_withdrawal_index,\n        next_withdrawal_validator_index=pre.next_withdrawal_validator_index,\n        historical_summaries=pre.historical_summaries,\n        deposit_requests_start_index=pre.deposit_requests_start_index,\n        deposit_balance_to_consume=pre.deposit_balance_to_consume,\n        exit_balance_to_consume=pre.exit_balance_to_consume,\n        earliest_exit_epoch=pre.earliest_exit_epoch,\n        consolidation_balance_to_consume=pre.consolidation_balance_to_consume,\n        earliest_consolidation_epoch=pre.earliest_consolidation_epoch,\n        pending_deposits=pre.pending_deposits,\n        pending_partial_withdrawals=pre.pending_partial_withdrawals,\n        pending_consolidations=pre.pending_consolidations,\n        # [New in Fulu:EIP7917]\n        proposer_lookahead=initialize_proposer_lookahead(pre),\n    )\n\n    return post\n</code></pre>"},{"location":"specs/fulu/p2p-interface/","title":"Fulu -- Networking","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Modifications in Fulu</li> <li>Helper functions<ul> <li>Modified <code>compute_fork_version</code></li> </ul> </li> <li>Preset</li> <li>Configuration</li> <li>Containers<ul> <li><code>DataColumnsByRootIdentifier</code></li> </ul> </li> <li>Helpers<ul> <li><code>verify_data_column_sidecar</code></li> <li><code>verify_data_column_sidecar_kzg_proofs</code></li> <li><code>verify_data_column_sidecar_inclusion_proof</code></li> <li><code>compute_subnet_for_data_column_sidecar</code></li> </ul> </li> <li>MetaData</li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>beacon_block</code></li> </ul> </li> <li>Blob subnets<ul> <li>Deprecated <code>blob_sidecar_{subnet_id}</code></li> <li><code>data_column_sidecar_{subnet_id}</code></li> <li>Distributed Blob Publishing using blobs retrieved from local execution layer client</li> </ul> </li> </ul> </li> <li>The Req/Resp domain<ul> <li>Messages</li> <li>Status v2</li> <li>BlobSidecarsByRange v1</li> <li>BlobSidecarsByRoot v1</li> <li>DataColumnSidecarsByRange v1</li> <li>DataColumnSidecarsByRoot v1</li> <li>GetMetaData v3</li> </ul> </li> <li>The discovery domain: discv5<ul> <li>ENR structure</li> <li><code>eth2</code> field</li> <li>Custody group count</li> <li>Next fork digest</li> </ul> </li> <li>Peer Scoring</li> <li>Supernodes</li> </ul>"},{"location":"specs/fulu/p2p-interface/#introduction","title":"Introduction","text":"<p>This document contains the consensus-layer networking specification for Fulu.</p> <p>The specification of these changes continues in the same format as the network specifications of previous upgrades, and assumes them as pre-requisite.</p>"},{"location":"specs/fulu/p2p-interface/#modifications-in-fulu","title":"Modifications in Fulu","text":""},{"location":"specs/fulu/p2p-interface/#helper-functions","title":"Helper functions","text":""},{"location":"specs/fulu/p2p-interface/#modified-compute_fork_version","title":"Modified <code>compute_fork_version</code>","text":"<pre><code>def compute_fork_version(epoch: Epoch) -&gt; Version:\n    \"\"\"\n    Return the fork version at the given ``epoch``.\n    \"\"\"\n    if epoch &gt;= FULU_FORK_EPOCH:\n        return FULU_FORK_VERSION\n    if epoch &gt;= ELECTRA_FORK_EPOCH:\n        return ELECTRA_FORK_VERSION\n    if epoch &gt;= DENEB_FORK_EPOCH:\n        return DENEB_FORK_VERSION\n    if epoch &gt;= CAPELLA_FORK_EPOCH:\n        return CAPELLA_FORK_VERSION\n    if epoch &gt;= BELLATRIX_FORK_EPOCH:\n        return BELLATRIX_FORK_VERSION\n    if epoch &gt;= ALTAIR_FORK_EPOCH:\n        return ALTAIR_FORK_VERSION\n    return GENESIS_FORK_VERSION\n</code></pre>"},{"location":"specs/fulu/p2p-interface/#preset","title":"Preset","text":"Name Value Description <code>KZG_COMMITMENTS_INCLUSION_PROOF_DEPTH</code> <code>uint64(floorlog2(get_generalized_index(BeaconBlockBody, 'blob_kzg_commitments')))</code> (= 4)  Merkle proof index for <code>blob_kzg_commitments</code>"},{"location":"specs/fulu/p2p-interface/#configuration","title":"Configuration","text":"<p>[New in Fulu:EIP7594]</p> Name Value Description <code>DATA_COLUMN_SIDECAR_SUBNET_COUNT</code> <code>128</code> The number of data column sidecar subnets used in the gossipsub protocol <code>MAX_REQUEST_DATA_COLUMN_SIDECARS</code> <code>MAX_REQUEST_BLOCKS_DENEB * NUMBER_OF_COLUMNS</code> Maximum number of data column sidecars in a single request <code>MIN_EPOCHS_FOR_DATA_COLUMN_SIDECARS_REQUESTS</code> <code>2**12</code> (= 4096 epochs, ~18 days) The minimum epoch range over which a node must serve data column sidecars"},{"location":"specs/fulu/p2p-interface/#containers","title":"Containers","text":""},{"location":"specs/fulu/p2p-interface/#datacolumnsbyrootidentifier","title":"<code>DataColumnsByRootIdentifier</code>","text":"<pre><code>class DataColumnsByRootIdentifier(Container):\n    block_root: Root\n    columns: List[ColumnIndex, NUMBER_OF_COLUMNS]\n</code></pre>"},{"location":"specs/fulu/p2p-interface/#helpers","title":"Helpers","text":""},{"location":"specs/fulu/p2p-interface/#verify_data_column_sidecar","title":"<code>verify_data_column_sidecar</code>","text":"<pre><code>def verify_data_column_sidecar(sidecar: DataColumnSidecar) -&gt; bool:\n    \"\"\"\n    Verify if the data column sidecar is valid.\n    \"\"\"\n    # The sidecar index must be within the valid range\n    if sidecar.index &gt;= NUMBER_OF_COLUMNS:\n        return False\n\n    # A sidecar for zero blobs is invalid\n    if len(sidecar.kzg_commitments) == 0:\n        return False\n\n    # The column length must be equal to the number of commitments/proofs\n    if len(sidecar.column) != len(sidecar.kzg_commitments) or len(sidecar.column) != len(\n        sidecar.kzg_proofs\n    ):\n        return False\n\n    return True\n</code></pre>"},{"location":"specs/fulu/p2p-interface/#verify_data_column_sidecar_kzg_proofs","title":"<code>verify_data_column_sidecar_kzg_proofs</code>","text":"<pre><code>def verify_data_column_sidecar_kzg_proofs(sidecar: DataColumnSidecar) -&gt; bool:\n    \"\"\"\n    Verify if the KZG proofs are correct.\n    \"\"\"\n    # The column index also represents the cell index\n    cell_indices = [CellIndex(sidecar.index)] * len(sidecar.column)\n\n    # Batch verify that the cells match the corresponding commitments and proofs\n    return verify_cell_kzg_proof_batch(\n        commitments_bytes=sidecar.kzg_commitments,\n        cell_indices=cell_indices,\n        cells=sidecar.column,\n        proofs_bytes=sidecar.kzg_proofs,\n    )\n</code></pre>"},{"location":"specs/fulu/p2p-interface/#verify_data_column_sidecar_inclusion_proof","title":"<code>verify_data_column_sidecar_inclusion_proof</code>","text":"<pre><code>def verify_data_column_sidecar_inclusion_proof(sidecar: DataColumnSidecar) -&gt; bool:\n    \"\"\"\n    Verify if the given KZG commitments included in the given beacon block.\n    \"\"\"\n    return is_valid_merkle_branch(\n        leaf=hash_tree_root(sidecar.kzg_commitments),\n        branch=sidecar.kzg_commitments_inclusion_proof,\n        depth=KZG_COMMITMENTS_INCLUSION_PROOF_DEPTH,\n        index=get_subtree_index(get_generalized_index(BeaconBlockBody, \"blob_kzg_commitments\")),\n        root=sidecar.signed_block_header.message.body_root,\n    )\n</code></pre>"},{"location":"specs/fulu/p2p-interface/#compute_subnet_for_data_column_sidecar","title":"<code>compute_subnet_for_data_column_sidecar</code>","text":"<pre><code>def compute_subnet_for_data_column_sidecar(column_index: ColumnIndex) -&gt; SubnetID:\n    return SubnetID(column_index % DATA_COLUMN_SIDECAR_SUBNET_COUNT)\n</code></pre>"},{"location":"specs/fulu/p2p-interface/#metadata","title":"MetaData","text":"<p>The <code>MetaData</code> stored locally by clients is updated with an additional field to communicate the custody group count.</p> <pre><code>(\n  seq_number: uint64\n  attnets: Bitvector[ATTESTATION_SUBNET_COUNT]\n  syncnets: Bitvector[SYNC_COMMITTEE_SUBNET_COUNT]\n  custody_group_count: uint64 # cgc\n)\n</code></pre> <p>Where</p> <ul> <li><code>seq_number</code>, <code>attnets</code>, and <code>syncnets</code> have the same meaning defined in the   Altair document.</li> <li><code>custody_group_count</code> represents the node's custody group count. Clients MAY   reject peers with a value less than <code>CUSTODY_REQUIREMENT</code>.</li> </ul>"},{"location":"specs/fulu/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":"<p>Some gossip meshes are upgraded in the Fulu fork to support upgraded types.</p>"},{"location":"specs/fulu/p2p-interface/#topics-and-messages","title":"Topics and messages","text":""},{"location":"specs/fulu/p2p-interface/#global-topics","title":"Global topics","text":""},{"location":"specs/fulu/p2p-interface/#beacon_block","title":"<code>beacon_block</code>","text":"<p>Updated validation</p> <ul> <li>[REJECT] The length of KZG commitments is less than or equal to the   limitation defined in Consensus Layer -- i.e. validate that   <code>len(signed_beacon_block.message.body.blob_kzg_commitments) &lt;= get_blob_parameters(get_current_epoch(state)).max_blobs_per_block</code></li> </ul>"},{"location":"specs/fulu/p2p-interface/#blob-subnets","title":"Blob subnets","text":""},{"location":"specs/fulu/p2p-interface/#deprecated-blob_sidecar_subnet_id","title":"Deprecated <code>blob_sidecar_{subnet_id}</code>","text":"<p><code>blob_sidecar_{subnet_id}</code> is deprecated.</p>"},{"location":"specs/fulu/p2p-interface/#data_column_sidecar_subnet_id","title":"<code>data_column_sidecar_{subnet_id}</code>","text":"<p>This topic is used to propagate column sidecars, where each column maps to some <code>subnet_id</code>.</p> <p>The type of the payload of this topic is <code>DataColumnSidecar</code>.</p> <p>The following validations MUST pass before forwarding the <code>sidecar: DataColumnSidecar</code> on the network, assuming the alias <code>block_header = sidecar.signed_block_header.message</code>:</p> <ul> <li>[REJECT] The sidecar is valid as verified by   <code>verify_data_column_sidecar(sidecar)</code>.</li> <li>[REJECT] The sidecar is for the correct subnet -- i.e.   <code>compute_subnet_for_data_column_sidecar(sidecar.index) == subnet_id</code>.</li> <li>[IGNORE] The sidecar is not from a future slot (with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e. validate that   <code>block_header.slot &lt;= current_slot</code> (a client MAY queue future sidecars for   processing at the appropriate slot).</li> <li>[IGNORE] The sidecar is from a slot greater than the latest finalized slot   -- i.e. validate that   <code>block_header.slot &gt; compute_start_slot_at_epoch(state.finalized_checkpoint.epoch)</code></li> <li>[REJECT] The proposer signature of <code>sidecar.signed_block_header</code>, is valid   with respect to the <code>block_header.proposer_index</code> pubkey.</li> <li>[IGNORE] The sidecar's block's parent (defined by   <code>block_header.parent_root</code>) has been seen (via gossip or non-gossip sources)   (a client MAY queue sidecars for processing once the parent block is   retrieved).</li> <li>[REJECT] The sidecar's block's parent (defined by   <code>block_header.parent_root</code>) passes validation.</li> <li>[REJECT] The sidecar is from a higher slot than the sidecar's block's parent   (defined by <code>block_header.parent_root</code>).</li> <li>[REJECT] The current finalized_checkpoint is an ancestor of the sidecar's   block -- i.e.   <code>get_checkpoint_block(store, block_header.parent_root, store.finalized_checkpoint.epoch) == store.finalized_checkpoint.root</code>.</li> <li>[REJECT] The sidecar's <code>kzg_commitments</code> field inclusion proof is valid as   verified by <code>verify_data_column_sidecar_inclusion_proof(sidecar)</code>.</li> <li>[REJECT] The sidecar's column data is valid as verified by   <code>verify_data_column_sidecar_kzg_proofs(sidecar)</code>.</li> <li>[IGNORE] The sidecar is the first sidecar for the tuple   <code>(block_header.slot, block_header.proposer_index, sidecar.index)</code> with valid   header signature, sidecar inclusion proof, and kzg proof.</li> <li>[REJECT] The sidecar is proposed by the expected <code>proposer_index</code> for the   block's slot in the context of the current shuffling (defined by   <code>block_header.parent_root</code>/<code>block_header.slot</code>). If the <code>proposer_index</code>   cannot immediately be verified against the expected shuffling, the sidecar MAY   be queued for later processing while proposers for the block's branch are   calculated -- in such a case do not <code>REJECT</code>, instead <code>IGNORE</code> this message.</li> </ul> <p>Note: In the <code>verify_data_column_sidecar_inclusion_proof(sidecar)</code> check, for all the sidecars of the same block, it verifies against the same set of <code>kzg_commitments</code> of the given beacon block. Client can choose to cache the result of the arguments tuple <code>(sidecar.kzg_commitments, sidecar.kzg_commitments_inclusion_proof, sidecar.signed_block_header)</code>.</p>"},{"location":"specs/fulu/p2p-interface/#distributed-blob-publishing-using-blobs-retrieved-from-local-execution-layer-client","title":"Distributed Blob Publishing using blobs retrieved from local execution layer client","text":"<p>Honest nodes SHOULD query <code>engine_getBlobsV2</code> as soon as they receive a valid <code>beacon_block</code> or <code>data_column_sidecar</code> from gossip. If ALL blobs matching <code>kzg_commitments</code> are retrieved, they should convert the response to data columns, and import the result.</p> <p>Implementers are encouraged to leverage this method to increase the likelihood of incorporating and attesting to the last block when its proposer is not able to publish data columns on time.</p> <p>When clients use the local execution layer to retrieve blobs, they SHOULD skip verification of those blobs. When subsequently importing the blobs as data columns, they MUST behave as if the <code>data_column_sidecar</code> had been received via gossip. In particular, clients MUST:</p> <ul> <li>Publish the corresponding <code>data_column_sidecar</code> on the   <code>data_column_sidecar_{subnet_id}</code> topic if and only if they are   subscribed to it, either due to custody requirements or additional   sampling.</li> <li>Update gossip rule related data structures (i.e. update the anti-equivocation   cache).</li> </ul>"},{"location":"specs/fulu/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/fulu/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/fulu/p2p-interface/#status-v2","title":"Status v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/status/2/</code></p> <p>Request, Response Content:</p> <pre><code>(\n  fork_digest: ForkDigest\n  finalized_root: Root\n  finalized_epoch: Epoch\n  head_root: Root\n  head_slot: Slot\n  # [New in Fulu:EIP7594]\n  earliest_available_slot: Slot\n)\n</code></pre> <p>As seen by the client at the time of sending the message:</p> <ul> <li><code>earliest_available_slot</code>: The slot of earliest available block   (<code>SignedBeaconBlock</code>).</li> </ul>"},{"location":"specs/fulu/p2p-interface/#blobsidecarsbyrange-v1","title":"BlobSidecarsByRange v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/blob_sidecars_by_range/1/</code></p> <p>Deprecated as of <code>FULU_FORK_EPOCH + MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS</code>.</p> <p>During the deprecation transition period:</p> <ul> <li>Clients MUST respond with a list of blob sidecars from the range   <code>[min(current_epoch - MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS, FULU_FORK_EPOCH), FULU_FORK_EPOCH)</code>   if the requested range includes any epochs in this interval.</li> <li>Clients MAY respond with an empty list if the requested range lies entirely at   or after <code>FULU_FORK_EPOCH</code>.</li> <li>Clients SHOULD NOT penalize peers for requesting blob sidecars from   <code>FULU_FORK_EPOCH</code>.</li> </ul>"},{"location":"specs/fulu/p2p-interface/#blobsidecarsbyroot-v1","title":"BlobSidecarsByRoot v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/blob_sidecars_by_root/1/</code></p> <p>Deprecated as of <code>FULU_FORK_EPOCH + MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS</code>.</p> <p>During the deprecation transition period:</p> <ul> <li>Clients MUST respond with blob sidecars corresponding to block roots from the   range   <code>[min(current_epoch - MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS, FULU_FORK_EPOCH), FULU_FORK_EPOCH)</code>   if any of the requested roots correspond to blocks in this interval.</li> <li>Clients MAY respond with an empty list if all requested roots correspond to   blocks at or after <code>FULU_FORK_EPOCH</code>.</li> <li>Clients SHOULD NOT penalize peers for requesting blob sidecars from   <code>FULU_FORK_EPOCH</code>.</li> </ul>"},{"location":"specs/fulu/p2p-interface/#datacolumnsidecarsbyrange-v1","title":"DataColumnSidecarsByRange v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/data_column_sidecars_by_range/1/</code></p> <p>Request Content:</p> <pre><code>(\n  start_slot: Slot\n  count: uint64\n  columns: List[ColumnIndex, NUMBER_OF_COLUMNS]\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[DataColumnSidecar, MAX_REQUEST_DATA_COLUMN_SIDECARS]\n)\n</code></pre> <p>Requests data column sidecars in the slot range <code>[start_slot, start_slot + count)</code> of the given <code>columns</code>, leading up to the current head block as selected by fork choice.</p> <p>Before consuming the next response chunk, the response reader SHOULD verify the data column sidecar is well-formatted through <code>verify_data_column_sidecar</code>, has valid inclusion proof through <code>verify_data_column_sidecar_inclusion_proof</code>, and is correct w.r.t. the expected KZG commitments through <code>verify_data_column_sidecar_kzg_proofs</code>.</p> <p><code>DataColumnSidecarsByRange</code> is primarily used to sync data columns that may have been missed on gossip and to sync within the <code>MIN_EPOCHS_FOR_DATA_COLUMN_SIDECARS_REQUESTS</code> window.</p> <p>The request MUST be encoded as an SSZ-container.</p> <p>The response MUST consist of zero or more <code>response_chunk</code>. Each successful <code>response_chunk</code> MUST contain a single <code>DataColumnSidecar</code> payload.</p> <p>Let <code>data_column_serve_range</code> be <code>[max(current_epoch - MIN_EPOCHS_FOR_DATA_COLUMN_SIDECARS_REQUESTS, FULU_FORK_EPOCH), current_epoch]</code>. Clients MUST keep a record of data column sidecars seen on the epoch range <code>data_column_serve_range</code> where <code>current_epoch</code> is defined by the current wall-clock time, and clients MUST support serving requests of data columns on this range.</p> <p>Peers that are unable to reply to data column sidecar requests within the range <code>data_column_serve_range</code> SHOULD respond with error code <code>3: ResourceUnavailable</code>. Such peers that are unable to successfully reply to this range of requests MAY get descored or disconnected at any time.</p> <p>Note: The above requirement implies that nodes that start from a recent weak subjectivity checkpoint MUST backfill the local data columns database to at least the range <code>data_column_serve_range</code> to be fully compliant with <code>DataColumnSidecarsByRange</code> requests.</p> <p>Note: Although clients that bootstrap from a weak subjectivity checkpoint can begin participating in the networking immediately, other peers MAY disconnect and/or temporarily ban such an un-synced or semi-synced client.</p> <p>Clients MUST respond with at least the data column sidecars of the first blob-carrying block that exists in the range, if they have it, and no more than <code>MAX_REQUEST_DATA_COLUMN_SIDECARS</code> sidecars.</p> <p>Clients MUST include all data column sidecars of each block from which they include data column sidecars.</p> <p>The following data column sidecars, where they exist, MUST be sent in <code>(slot, column_index)</code> order.</p> <p>Slots that do not contain known data columns MUST be skipped, mimicking the behaviour of the <code>BlocksByRange</code> request. Only response chunks with known data columns should therefore be sent.</p> <p>Clients MAY limit the number of data column sidecars in the response.</p> <p>The response MUST contain no more than <code>count * NUMBER_OF_COLUMNS</code> data column sidecars.</p> <p>Clients MUST respond with data columns sidecars from their view of the current fork choice -- that is, data column sidecars as included by blocks from the single chain defined by the current head. Of note, blocks from slots before the finalization MUST lead to the finalized block reported in the <code>Status</code> handshake.</p> <p>Clients MUST respond with data column sidecars that are consistent from a single chain within the context of the request.</p> <p>After the initial data column sidecar, clients MAY stop in the process of responding if their fork choice changes the view of the chain in the context of the request.</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(data_column_sidecar.signed_block_header.message.slot)</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>epoch</code> Chunk SSZ type <code>FULU_FORK_EPOCH</code> and later <code>fulu.DataColumnSidecar</code>"},{"location":"specs/fulu/p2p-interface/#datacolumnsidecarsbyroot-v1","title":"DataColumnSidecarsByRoot v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/data_column_sidecars_by_root/1/</code></p> <p>[New in Fulu:EIP7594]</p> <p>Request Content:</p> <pre><code>(\n  List[DataColumnsByRootIdentifier, MAX_REQUEST_BLOCKS_DENEB]\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[DataColumnSidecar, MAX_REQUEST_DATA_COLUMN_SIDECARS]\n)\n</code></pre> <p>Requests data column sidecars by block root and column indices. The response is a list of <code>DataColumnSidecar</code> whose length is less than or equal to <code>requested_columns_count</code>, where <code>requested_columns_count = sum(len(r.columns) for r in request)</code>. It may be less in the case that the responding peer is missing blocks or sidecars.</p> <p>Before consuming the next response chunk, the response reader SHOULD verify the data column sidecar is well-formatted through <code>verify_data_column_sidecar</code>, has valid inclusion proof through <code>verify_data_column_sidecar_inclusion_proof</code>, and is correct w.r.t. the expected KZG commitments through <code>verify_data_column_sidecar_kzg_proofs</code>.</p> <p>No more than <code>MAX_REQUEST_DATA_COLUMN_SIDECARS</code> may be requested at a time.</p> <p>The response MUST consist of zero or more <code>response_chunk</code>. Each successful <code>response_chunk</code> MUST contain a single <code>DataColumnSidecar</code> payload.</p> <p>Clients MUST support requesting sidecars since <code>minimum_request_epoch</code>, where <code>minimum_request_epoch = max(current_epoch - MIN_EPOCHS_FOR_DATA_COLUMN_SIDECARS_REQUESTS, FULU_FORK_EPOCH)</code>. If any root in the request content references a block earlier than <code>minimum_request_epoch</code>, peers MAY respond with error code <code>3: ResourceUnavailable</code> or not include the data column sidecar in the response.</p> <p>Clients MUST respond with at least one sidecar, if they have it. Clients MAY limit the number of blocks and sidecars in the response.</p> <p>Clients SHOULD include a sidecar in the response as soon as it passes the gossip validation rules. Clients SHOULD NOT respond with sidecars related to blocks that fail gossip validation rules. Clients SHOULD NOT respond with sidecars related to blocks that fail the beacon chain state transition</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(data_column_sidecar.signed_block_header.message.slot)</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>epoch</code> Chunk SSZ type <code>FULU_FORK_EPOCH</code> and later <code>fulu.DataColumnSidecar</code>"},{"location":"specs/fulu/p2p-interface/#getmetadata-v3","title":"GetMetaData v3","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/metadata/3/</code></p> <p>No Request Content.</p> <p>Response Content:</p> <pre><code>(\n  MetaData\n)\n</code></pre> <p>Requests the MetaData of a peer, using the new <code>MetaData</code> definition given above that is extended from Altair. Other conditions for the <code>GetMetaData</code> protocol are unchanged from the Altair p2p networking document.</p>"},{"location":"specs/fulu/p2p-interface/#the-discovery-domain-discv5","title":"The discovery domain: discv5","text":""},{"location":"specs/fulu/p2p-interface/#enr-structure","title":"ENR structure","text":""},{"location":"specs/fulu/p2p-interface/#eth2-field","title":"<code>eth2</code> field","text":"<p>[Modified in Fulu:EIP7892]</p> <p>Note: The structure of <code>ENRForkID</code> has not changed but the field value computations have changed. Unless explicitly mentioned here, all specifications from phase0/p2p-interface.md#eth2-field carry over.</p> <p>ENRs MUST carry a generic <code>eth2</code> key with an 16-byte value of the node's current fork digest, next fork version, and next fork epoch to ensure connections are made with peers on the intended Ethereum network.</p> Key Value <code>eth2</code> SSZ <code>ENRForkID</code> <p>Specifically, the value of the <code>eth2</code> key MUST be the following SSZ encoded object (<code>ENRForkID</code>):</p> <pre><code>(\n  fork_digest: ForkDigest\n  next_fork_version: Version\n  next_fork_epoch: Epoch\n)\n</code></pre> <p>The fields of <code>ENRForkID</code> are defined as:</p> <ul> <li><code>fork_digest</code> is <code>compute_fork_digest(genesis_validators_root, epoch)</code> where:</li> <li><code>genesis_validators_root</code> is the static <code>Root</code> found in     <code>state.genesis_validators_root</code>.</li> <li><code>epoch</code> is the node's current epoch defined by the wall-clock time (not     necessarily the epoch to which the node is sync).</li> <li><code>next_fork_version</code> is the fork version corresponding to the next planned fork   at a future epoch. The fork version will only change for regular forks, not   BPO forks. Note that it is possible for the blob schedule to define a change   at the same epoch as a regular fork; this situation would be considered a   regular fork. If no future fork is planned, set   <code>next_fork_version = current_fork_version</code> to signal this fact.</li> <li><code>next_fork_epoch</code> is the epoch at which the next fork (whether a regular fork   or a BPO fork) is planned. If no future fork is planned, set   <code>next_fork_epoch = FAR_FUTURE_EPOCH</code> to signal this fact.</li> </ul>"},{"location":"specs/fulu/p2p-interface/#custody-group-count","title":"Custody group count","text":"<p>A new field is added to the ENR under the key <code>cgc</code> to facilitate custody data column discovery. This new field MUST be added once <code>FULU_FORK_EPOCH</code> is assigned any value other than <code>FAR_FUTURE_EPOCH</code>.</p> Key Value <code>cgc</code> Custody group count, <code>uint64</code> big endian integer with no leading zero bytes (<code>0</code> is encoded as empty byte string)"},{"location":"specs/fulu/p2p-interface/#next-fork-digest","title":"Next fork digest","text":"<p>A new entry is added to the ENR under the key <code>nfd</code>, short for next fork digest. This entry communicates the digest of the next scheduled fork, regardless of whether it is a regular or a Blob-Parameters-Only fork. This new entry MUST be added once <code>FULU_FORK_EPOCH</code> is assigned any value other than <code>FAR_FUTURE_EPOCH</code>. Adding this entry prior to the Fulu fork will not impact peering as nodes will ignore unknown ENR entries and <code>nfd</code> mismatches do not cause disconnects.</p> <p>If no next fork is scheduled, the <code>nfd</code> entry contains the default value for the type (i.e., the SSZ representation of a zero-filled array).</p> Key Value <code>nfd</code> SSZ Bytes4 <code>ForkDigest</code> <p>When discovering and interfacing with peers, nodes MUST evaluate <code>nfd</code> alongside their existing consideration of the <code>ENRForkID::next_*</code> fields under the <code>eth2</code> key, to form a more accurate view of the peer's intended next fork for the purposes of sustained peering. If there is a mismatch, the node MUST NOT disconnect before the fork boundary, but it MAY disconnect at/after the fork boundary.</p> <p>Nodes unprepared to follow the Fulu fork will be unaware of <code>nfd</code> entries. However, their existing comparison of <code>eth2</code> entries (concretely <code>next_fork_epoch</code>) is sufficient to detect upcoming divergence.</p>"},{"location":"specs/fulu/p2p-interface/#peer-scoring","title":"Peer Scoring","text":"<p>Due to the deterministic custody functions, a node knows exactly what a peer should be able to respond to. In the event that a peer does not respond to samples of their custodied rows/columns, a node may downscore or disconnect from a peer.</p>"},{"location":"specs/fulu/p2p-interface/#supernodes","title":"Supernodes","text":"<p>A supernode is a node which subscribes to all data column sidecar subnets, custodies all data column sidecars, and performs reconstruction and cross-seeding. Being a supernode requires considerably higher bandwidth, storage, and computation resources. In order to reconstruct missing data, there must be at least one supernode on the network. Due to validator custody requirements, a node which is connected to validator(s) with a combined balance greater than or equal to 4096 ETH must be a supernode. Moreover, any node with the necessary resources may altruistically be a supernode. Therefore, there are expected to be many (hundreds) of supernodes on mainnet and it is likely (though not necessary) for a node to be connected to several of these by chance.</p>"},{"location":"specs/fulu/polynomial-commitments-sampling/","title":"Fulu -- Polynomial Commitments Sampling","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Public Methods</li> <li>Custom types</li> <li>Cryptographic types</li> <li>Preset</li> <li>Blob</li> <li>Helper functions</li> <li>BLS12-381 helpers<ul> <li><code>cell_to_coset_evals</code></li> <li><code>coset_evals_to_cell</code></li> </ul> </li> <li>FFTs<ul> <li><code>_fft_field</code></li> <li><code>fft_field</code></li> <li><code>coset_fft_field</code></li> <li><code>compute_verify_cell_kzg_proof_batch_challenge</code></li> </ul> </li> <li>Polynomials in coefficient form<ul> <li><code>polynomial_eval_to_coeff</code></li> <li><code>add_polynomialcoeff</code></li> <li><code>multiply_polynomialcoeff</code></li> <li><code>divide_polynomialcoeff</code></li> <li><code>interpolate_polynomialcoeff</code></li> <li><code>vanishing_polynomialcoeff</code></li> <li><code>evaluate_polynomialcoeff</code></li> </ul> </li> <li>KZG multiproofs<ul> <li><code>compute_kzg_proof_multi_impl</code></li> <li><code>verify_cell_kzg_proof_batch_impl</code></li> </ul> </li> <li>Cell cosets<ul> <li><code>coset_shift_for_cell</code></li> <li><code>coset_for_cell</code></li> </ul> </li> <li>Cells</li> <li>Cell computation<ul> <li><code>compute_cells</code></li> <li><code>compute_cells_and_kzg_proofs_polynomialcoeff</code></li> <li><code>compute_cells_and_kzg_proofs</code></li> </ul> </li> <li>Cell verification<ul> <li><code>verify_cell_kzg_proof_batch</code></li> </ul> </li> <li>Reconstruction</li> <li><code>construct_vanishing_polynomial</code></li> <li><code>recover_polynomialcoeff</code></li> <li><code>recover_cells_and_kzg_proofs</code></li> </ul>"},{"location":"specs/fulu/polynomial-commitments-sampling/#introduction","title":"Introduction","text":"<p>This document extends polynomial-commitments.md with the functions required for data availability sampling (DAS). It is not part of the core Deneb spec but an extension that can be optionally implemented to allow nodes to reduce their load using DAS.</p>"},{"location":"specs/fulu/polynomial-commitments-sampling/#public-methods","title":"Public Methods","text":"<p>For any KZG library extended to support DAS, functions flagged as \"Public method\" MUST be provided by the underlying KZG library as public functions. All other functions are private functions used internally by the KZG library.</p> <p>Public functions MUST accept raw bytes as input and perform the required cryptographic normalization before invoking any internal functions.</p> <p>The following is a list of the public methods:</p> <ul> <li><code>compute_cells_and_kzg_proofs</code></li> <li><code>verify_cell_kzg_proof_batch</code></li> <li><code>recover_cells_and_kzg_proofs</code></li> </ul>"},{"location":"specs/fulu/polynomial-commitments-sampling/#custom-types","title":"Custom types","text":"Name SSZ equivalent Description <code>Cell</code> <code>ByteVector[BYTES_PER_FIELD_ELEMENT * FIELD_ELEMENTS_PER_CELL]</code> The unit of blob data that can come with its own KZG proof <code>CellIndex</code> <code>uint64</code> Validation: <code>x &lt; CELLS_PER_EXT_BLOB</code> <code>CommitmentIndex</code> <code>uint64</code> The type which represents the index of an element in the list of commitments"},{"location":"specs/fulu/polynomial-commitments-sampling/#cryptographic-types","title":"Cryptographic types","text":"Name SSZ equivalent Description <code>PolynomialCoeff</code> <code>List[BLSFieldElement, FIELD_ELEMENTS_PER_EXT_BLOB]</code>  A polynomial in coefficient form <code>Coset</code> <code>Vector[BLSFieldElement, FIELD_ELEMENTS_PER_CELL]</code>  The evaluation domain of a cell <code>CosetEvals</code> <code>Vector[BLSFieldElement, FIELD_ELEMENTS_PER_CELL]</code>  A cell's evaluations over its coset"},{"location":"specs/fulu/polynomial-commitments-sampling/#preset","title":"Preset","text":""},{"location":"specs/fulu/polynomial-commitments-sampling/#blob","title":"Blob","text":"<p>Cells are the smallest unit of blob data that can come with their own KZG proofs. Samples can be constructed from one or several cells (e.g. an individual cell or line).</p> Name Value Description <code>FIELD_ELEMENTS_PER_EXT_BLOB</code> <code>2 * FIELD_ELEMENTS_PER_BLOB</code> Number of field elements in a Reed-Solomon extended blob <code>FIELD_ELEMENTS_PER_CELL</code> <code>uint64(64)</code> Number of field elements in a cell <code>BYTES_PER_CELL</code> <code>FIELD_ELEMENTS_PER_CELL * BYTES_PER_FIELD_ELEMENT</code> The number of bytes in a cell <code>CELLS_PER_EXT_BLOB</code> <code>FIELD_ELEMENTS_PER_EXT_BLOB // FIELD_ELEMENTS_PER_CELL</code> The number of cells in an extended blob <code>RANDOM_CHALLENGE_KZG_CELL_BATCH_DOMAIN</code> <code>b'RCKZGCBATCH__V1_'</code>"},{"location":"specs/fulu/polynomial-commitments-sampling/#helper-functions","title":"Helper functions","text":""},{"location":"specs/fulu/polynomial-commitments-sampling/#bls12-381-helpers","title":"BLS12-381 helpers","text":""},{"location":"specs/fulu/polynomial-commitments-sampling/#cell_to_coset_evals","title":"<code>cell_to_coset_evals</code>","text":"<pre><code>def cell_to_coset_evals(cell: Cell) -&gt; CosetEvals:\n    \"\"\"\n    Convert an untrusted ``Cell`` into a trusted ``CosetEvals``.\n    \"\"\"\n    evals = CosetEvals()\n    for i in range(FIELD_ELEMENTS_PER_CELL):\n        start = i * BYTES_PER_FIELD_ELEMENT\n        end = (i + 1) * BYTES_PER_FIELD_ELEMENT\n        evals[i] = bytes_to_bls_field(cell[start:end])\n    return evals\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#coset_evals_to_cell","title":"<code>coset_evals_to_cell</code>","text":"<pre><code>def coset_evals_to_cell(coset_evals: CosetEvals) -&gt; Cell:\n    \"\"\"\n    Convert a trusted ``CosetEval`` into an untrusted ``Cell``.\n    \"\"\"\n    cell = []\n    for i in range(FIELD_ELEMENTS_PER_CELL):\n        cell += bls_field_to_bytes(coset_evals[i])\n    return Cell(cell)\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#ffts","title":"FFTs","text":""},{"location":"specs/fulu/polynomial-commitments-sampling/#_fft_field","title":"<code>_fft_field</code>","text":"<pre><code>def _fft_field(\n    vals: Sequence[BLSFieldElement], roots_of_unity: Sequence[BLSFieldElement]\n) -&gt; Sequence[BLSFieldElement]:\n    if len(vals) == 1:\n        return vals\n    L = _fft_field(vals[::2], roots_of_unity[::2])\n    R = _fft_field(vals[1::2], roots_of_unity[::2])\n    o = [BLSFieldElement(0) for _ in vals]\n    for i, (x, y) in enumerate(zip(L, R)):\n        y_times_root = y * roots_of_unity[i]\n        o[i] = x + y_times_root\n        o[i + len(L)] = x - y_times_root\n    return o\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#fft_field","title":"<code>fft_field</code>","text":"<pre><code>def fft_field(\n    vals: Sequence[BLSFieldElement], roots_of_unity: Sequence[BLSFieldElement], inv: bool = False\n) -&gt; Sequence[BLSFieldElement]:\n    if inv:\n        # Inverse FFT\n        invlen = BLSFieldElement(len(vals)).pow(BLSFieldElement(BLS_MODULUS - 2))\n        return [\n            x * invlen\n            for x in _fft_field(vals, list(roots_of_unity[0:1]) + list(roots_of_unity[:0:-1]))\n        ]\n    else:\n        # Regular FFT\n        return _fft_field(vals, roots_of_unity)\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#coset_fft_field","title":"<code>coset_fft_field</code>","text":"<pre><code>def coset_fft_field(\n    vals: Sequence[BLSFieldElement], roots_of_unity: Sequence[BLSFieldElement], inv: bool = False\n) -&gt; Sequence[BLSFieldElement]:\n    \"\"\"\n    Computes an FFT/IFFT over a coset of the roots of unity.\n    This is useful for when one wants to divide by a polynomial which\n    vanishes on one or more elements in the domain.\n    \"\"\"\n    vals = [v for v in vals]  # copy\n\n    def shift_vals(\n        vals: Sequence[BLSFieldElement], factor: BLSFieldElement\n    ) -&gt; Sequence[BLSFieldElement]:\n        \"\"\"\n        Multiply each entry in `vals` by succeeding powers of `factor`\n        i.e., [vals[0] * factor^0, vals[1] * factor^1, ..., vals[n] * factor^n]\n        \"\"\"\n        updated_vals: List[BLSFieldElement] = []\n        shift = BLSFieldElement(1)\n        for i in range(len(vals)):\n            updated_vals.append(vals[i] * shift)\n            shift = shift * factor\n        return updated_vals\n\n    # This is the coset generator; it is used to compute a FFT/IFFT over a coset of\n    # the roots of unity.\n    shift_factor = BLSFieldElement(PRIMITIVE_ROOT_OF_UNITY)\n    if inv:\n        vals = fft_field(vals, roots_of_unity, inv)\n        return shift_vals(vals, shift_factor.inverse())\n    else:\n        vals = shift_vals(vals, shift_factor)\n        return fft_field(vals, roots_of_unity, inv)\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#compute_verify_cell_kzg_proof_batch_challenge","title":"<code>compute_verify_cell_kzg_proof_batch_challenge</code>","text":"<pre><code>def compute_verify_cell_kzg_proof_batch_challenge(\n    commitments: Sequence[KZGCommitment],\n    commitment_indices: Sequence[CommitmentIndex],\n    cell_indices: Sequence[CellIndex],\n    cosets_evals: Sequence[CosetEvals],\n    proofs: Sequence[KZGProof],\n) -&gt; BLSFieldElement:\n    \"\"\"\n    Compute a random challenge ``r`` used in the universal verification equation. To compute the\n    challenge, ``RANDOM_CHALLENGE_KZG_CELL_BATCH_DOMAIN`` and all data that can influence the\n    verification is hashed together to deterministically generate a \"random\" field element via\n    the Fiat-Shamir heuristic.\n    \"\"\"\n    hashinput = RANDOM_CHALLENGE_KZG_CELL_BATCH_DOMAIN\n    hashinput += int.to_bytes(FIELD_ELEMENTS_PER_BLOB, 8, KZG_ENDIANNESS)\n    hashinput += int.to_bytes(FIELD_ELEMENTS_PER_CELL, 8, KZG_ENDIANNESS)\n    hashinput += int.to_bytes(len(commitments), 8, KZG_ENDIANNESS)\n    hashinput += int.to_bytes(len(cell_indices), 8, KZG_ENDIANNESS)\n    for commitment in commitments:\n        hashinput += commitment\n    for k, coset_evals in enumerate(cosets_evals):\n        hashinput += int.to_bytes(commitment_indices[k], 8, KZG_ENDIANNESS)\n        hashinput += int.to_bytes(cell_indices[k], 8, KZG_ENDIANNESS)\n        for coset_eval in coset_evals:\n            hashinput += bls_field_to_bytes(coset_eval)\n        hashinput += proofs[k]\n    return hash_to_bls_field(hashinput)\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#polynomials-in-coefficient-form","title":"Polynomials in coefficient form","text":""},{"location":"specs/fulu/polynomial-commitments-sampling/#polynomial_eval_to_coeff","title":"<code>polynomial_eval_to_coeff</code>","text":"<pre><code>def polynomial_eval_to_coeff(polynomial: Polynomial) -&gt; PolynomialCoeff:\n    \"\"\"\n    Interpolates a polynomial (given in evaluation form) to a polynomial in coefficient form.\n    \"\"\"\n    roots_of_unity = compute_roots_of_unity(FIELD_ELEMENTS_PER_BLOB)\n    return PolynomialCoeff(\n        fft_field(bit_reversal_permutation(polynomial), roots_of_unity, inv=True)\n    )\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#add_polynomialcoeff","title":"<code>add_polynomialcoeff</code>","text":"<pre><code>def add_polynomialcoeff(a: PolynomialCoeff, b: PolynomialCoeff) -&gt; PolynomialCoeff:\n    \"\"\"\n    Sum the coefficient form polynomials ``a`` and ``b``.\n    \"\"\"\n    a, b = (a, b) if len(a) &gt;= len(b) else (b, a)\n    length_a, length_b = len(a), len(b)\n    return PolynomialCoeff(\n        [a[i] + (b[i] if i &lt; length_b else BLSFieldElement(0)) for i in range(length_a)]\n    )\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#multiply_polynomialcoeff","title":"<code>multiply_polynomialcoeff</code>","text":"<pre><code>def multiply_polynomialcoeff(a: PolynomialCoeff, b: PolynomialCoeff) -&gt; PolynomialCoeff:\n    \"\"\"\n    Multiplies the coefficient form polynomials ``a`` and ``b``.\n    \"\"\"\n    assert len(a) + len(b) &lt;= FIELD_ELEMENTS_PER_EXT_BLOB\n\n    r = PolynomialCoeff([BLSFieldElement(0)])\n    for power, coef in enumerate(a):\n        summand = PolynomialCoeff([BLSFieldElement(0)] * power + [coef * x for x in b])\n        r = add_polynomialcoeff(r, summand)\n    return r\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#divide_polynomialcoeff","title":"<code>divide_polynomialcoeff</code>","text":"<pre><code>def divide_polynomialcoeff(a: PolynomialCoeff, b: PolynomialCoeff) -&gt; PolynomialCoeff:\n    \"\"\"\n    Long polynomial division for two coefficient form polynomials ``a`` and ``b``.\n    \"\"\"\n    a = PolynomialCoeff(a[:])  # copy\n    o = PolynomialCoeff([])\n    apos = len(a) - 1\n    bpos = len(b) - 1\n    diff = apos - bpos\n    while diff &gt;= 0:\n        quot = a[apos] / b[bpos]\n        o.insert(0, quot)\n        for i in range(bpos, -1, -1):\n            a[diff + i] = a[diff + i] - b[i] * quot\n        apos -= 1\n        diff -= 1\n    return o\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#interpolate_polynomialcoeff","title":"<code>interpolate_polynomialcoeff</code>","text":"<pre><code>def interpolate_polynomialcoeff(\n    xs: Sequence[BLSFieldElement], ys: Sequence[BLSFieldElement]\n) -&gt; PolynomialCoeff:\n    \"\"\"\n    Lagrange interpolation: Finds the lowest degree polynomial that takes the value ``ys[i]`` at ``x[i]`` for all i.\n    Outputs a coefficient form polynomial. Leading coefficients may be zero.\n    \"\"\"\n    assert len(xs) == len(ys)\n\n    r = PolynomialCoeff([BLSFieldElement(0)])\n    for i in range(len(xs)):\n        summand = PolynomialCoeff([ys[i]])\n        for j in range(len(ys)):\n            if j != i:\n                weight_adjustment = (xs[i] - xs[j]).inverse()\n                summand = multiply_polynomialcoeff(\n                    summand, PolynomialCoeff([-weight_adjustment * xs[j], weight_adjustment])\n                )\n        r = add_polynomialcoeff(r, summand)\n    return r\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#vanishing_polynomialcoeff","title":"<code>vanishing_polynomialcoeff</code>","text":"<pre><code>def vanishing_polynomialcoeff(xs: Sequence[BLSFieldElement]) -&gt; PolynomialCoeff:\n    \"\"\"\n    Compute the vanishing polynomial on ``xs`` (in coefficient form).\n    \"\"\"\n    p = PolynomialCoeff([BLSFieldElement(1)])\n    for x in xs:\n        p = multiply_polynomialcoeff(p, PolynomialCoeff([-x, BLSFieldElement(1)]))\n    return p\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#evaluate_polynomialcoeff","title":"<code>evaluate_polynomialcoeff</code>","text":"<pre><code>def evaluate_polynomialcoeff(\n    polynomial_coeff: PolynomialCoeff, z: BLSFieldElement\n) -&gt; BLSFieldElement:\n    \"\"\"\n    Evaluate a coefficient form polynomial at ``z`` using Horner's schema.\n    \"\"\"\n    y = BLSFieldElement(0)\n    for coef in polynomial_coeff[::-1]:\n        y = y * z + coef\n    return y\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#kzg-multiproofs","title":"KZG multiproofs","text":"<p>Extended KZG functions for multiproofs</p>"},{"location":"specs/fulu/polynomial-commitments-sampling/#compute_kzg_proof_multi_impl","title":"<code>compute_kzg_proof_multi_impl</code>","text":"<pre><code>def compute_kzg_proof_multi_impl(\n    polynomial_coeff: PolynomialCoeff, zs: Coset\n) -&gt; Tuple[KZGProof, CosetEvals]:\n    \"\"\"\n    Compute a KZG multi-evaluation proof for a set of `k` points.\n\n    This is done by committing to the following quotient polynomial:\n        Q(X) = f(X) - I(X) / Z(X)\n    Where:\n        - I(X) is the degree `k-1` polynomial that agrees with f(x) at all `k` points\n        - Z(X) is the degree `k` polynomial that evaluates to zero on all `k` points\n\n    We further note that since the degree of I(X) is less than the degree of Z(X),\n    the computation can be simplified in monomial form to Q(X) = f(X) / Z(X).\n    \"\"\"\n\n    # For all points, compute the evaluation of those points\n    ys = CosetEvals([evaluate_polynomialcoeff(polynomial_coeff, z) for z in zs])\n\n    # Compute Z(X)\n    denominator_poly = vanishing_polynomialcoeff(zs)\n\n    # Compute the quotient polynomial directly in monomial form\n    quotient_polynomial = divide_polynomialcoeff(polynomial_coeff, denominator_poly)\n\n    return KZGProof(\n        g1_lincomb(KZG_SETUP_G1_MONOMIAL[: len(quotient_polynomial)], quotient_polynomial)\n    ), ys\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#verify_cell_kzg_proof_batch_impl","title":"<code>verify_cell_kzg_proof_batch_impl</code>","text":"<pre><code>def verify_cell_kzg_proof_batch_impl(\n    commitments: Sequence[KZGCommitment],\n    commitment_indices: Sequence[CommitmentIndex],\n    cell_indices: Sequence[CellIndex],\n    cosets_evals: Sequence[CosetEvals],\n    proofs: Sequence[KZGProof],\n) -&gt; bool:\n    \"\"\"\n    Helper: Verify that a set of cells belong to their corresponding commitment.\n\n    Given a list of ``commitments`` (which contains no duplicates) and four lists representing\n    tuples of (``commitment_index``, ``cell_index``, ``evals``, ``proof``), the function\n    verifies ``proof`` which shows that ``evals`` are the evaluations of the polynomial associated\n    with ``commitments[commitment_index]``, evaluated over the domain specified by ``cell_index``.\n\n    This function is the internal implementation of ``verify_cell_kzg_proof_batch``.\n    \"\"\"\n    assert len(commitment_indices) == len(cell_indices) == len(cosets_evals) == len(proofs)\n    assert len(commitments) == len(set(commitments))\n    for commitment_index in commitment_indices:\n        assert commitment_index &lt; len(commitments)\n\n    # The verification equation that we will check is pairing (LL, LR) = pairing (RL, [1]), where\n    # LL = sum_k r^k proofs[k],\n    # LR = [s^n]\n    # RL = RLC - RLI + RLP, where\n    #   RLC = sum_i weights[i] commitments[i]\n    #   RLI = [sum_k r^k interpolation_poly_k(s)]\n    #   RLP = sum_k (r^k * h_k^n) proofs[k]\n    #\n    # Here, the variables have the following meaning:\n    # - k &lt; len(cell_indices) is an index iterating over all cells in the input\n    # - r is a random coefficient, derived from hashing all data provided by the prover\n    # - s is the secret embedded in the KZG setup\n    # - n = FIELD_ELEMENTS_PER_CELL is the size of the evaluation domain\n    # - i ranges over all provided commitments\n    # - weights[i] is a weight computed for commitment i\n    #   - It depends on r and on which cells are associated with commitment i\n    # - interpolation_poly_k is the interpolation polynomial for the kth cell\n    # - h_k is the coset shift specifying the evaluation domain of the kth cell\n\n    # Preparation\n    num_cells = len(cell_indices)\n    n = FIELD_ELEMENTS_PER_CELL\n    num_commitments = len(commitments)\n\n    # Step 1: Compute a challenge r and its powers r^0, ..., r^{num_cells-1}\n    r = compute_verify_cell_kzg_proof_batch_challenge(\n        commitments, commitment_indices, cell_indices, cosets_evals, proofs\n    )\n    r_powers = compute_powers(r, num_cells)\n\n    # Step 2: Compute LL = sum_k r^k proofs[k]\n    ll = bls.bytes48_to_G1(g1_lincomb(proofs, r_powers))\n\n    # Step 3: Compute LR = [s^n]\n    lr = bls.bytes96_to_G2(KZG_SETUP_G2_MONOMIAL[n])\n\n    # Step 4: Compute RL = RLC - RLI + RLP\n    # Step 4.1: Compute RLC = sum_i weights[i] commitments[i]\n    # Step 4.1a: Compute weights[i]: the sum of all r^k for which cell k is associated with commitment i.\n    # Note: we do that by iterating over all k and updating the correct weights[i] accordingly\n    weights = [BLSFieldElement(0)] * num_commitments\n    for k in range(num_cells):\n        i = commitment_indices[k]\n        weights[i] += r_powers[k]\n    # Step 4.1b: Linearly combine the weights with the commitments to get RLC\n    rlc = bls.bytes48_to_G1(g1_lincomb(commitments, weights))\n\n    # Step 4.2: Compute RLI = [sum_k r^k interpolation_poly_k(s)]\n    # Note: an efficient implementation would use the IDFT based method explained in the blog post\n    sum_interp_polys_coeff = PolynomialCoeff([BLSFieldElement(0)] * n)\n    for k in range(num_cells):\n        interp_poly_coeff = interpolate_polynomialcoeff(\n            coset_for_cell(cell_indices[k]), cosets_evals[k]\n        )\n        interp_poly_scaled_coeff = multiply_polynomialcoeff(\n            PolynomialCoeff([r_powers[k]]), interp_poly_coeff\n        )\n        sum_interp_polys_coeff = add_polynomialcoeff(\n            sum_interp_polys_coeff, interp_poly_scaled_coeff\n        )\n    rli = bls.bytes48_to_G1(g1_lincomb(KZG_SETUP_G1_MONOMIAL[:n], sum_interp_polys_coeff))\n\n    # Step 4.3: Compute RLP = sum_k (r^k * h_k^n) proofs[k]\n    weighted_r_powers = []\n    for k in range(num_cells):\n        h_k = coset_shift_for_cell(cell_indices[k])\n        h_k_pow = h_k.pow(BLSFieldElement(n))\n        wrp = r_powers[k] * h_k_pow\n        weighted_r_powers.append(wrp)\n    rlp = bls.bytes48_to_G1(g1_lincomb(proofs, weighted_r_powers))\n\n    # Step 4.4: Compute RL = RLC - RLI + RLP\n    rl = bls.add(rlc, bls.neg(rli))\n    rl = bls.add(rl, rlp)\n\n    # Step 5: Check pairing (LL, LR) = pairing (RL, [1])\n    return bls.pairing_check(\n        [\n            [ll, lr],\n            [rl, bls.neg(bls.bytes96_to_G2(KZG_SETUP_G2_MONOMIAL[0]))],\n        ]\n    )\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#cell-cosets","title":"Cell cosets","text":""},{"location":"specs/fulu/polynomial-commitments-sampling/#coset_shift_for_cell","title":"<code>coset_shift_for_cell</code>","text":"<pre><code>def coset_shift_for_cell(cell_index: CellIndex) -&gt; BLSFieldElement:\n    \"\"\"\n    Get the shift that determines the coset for a given ``cell_index``.\n    Precisely, consider the group of roots of unity of order FIELD_ELEMENTS_PER_CELL * CELLS_PER_EXT_BLOB.\n    Let G = {1, g, g^2, ...} denote its subgroup of order FIELD_ELEMENTS_PER_CELL.\n    Then, the coset is defined as h * G = {h, hg, hg^2, ...} for an element h.\n    This function returns h.\n    \"\"\"\n    assert cell_index &lt; CELLS_PER_EXT_BLOB\n    roots_of_unity_brp = bit_reversal_permutation(\n        compute_roots_of_unity(FIELD_ELEMENTS_PER_EXT_BLOB)\n    )\n    return roots_of_unity_brp[FIELD_ELEMENTS_PER_CELL * cell_index]\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#coset_for_cell","title":"<code>coset_for_cell</code>","text":"<pre><code>def coset_for_cell(cell_index: CellIndex) -&gt; Coset:\n    \"\"\"\n    Get the coset for a given ``cell_index``.\n    Precisely, consider the group of roots of unity of order FIELD_ELEMENTS_PER_CELL * CELLS_PER_EXT_BLOB.\n    Let G = {1, g, g^2, ...} denote its subgroup of order FIELD_ELEMENTS_PER_CELL.\n    Then, the coset is defined as h * G = {h, hg, hg^2, ...}.\n    This function, returns the coset.\n    \"\"\"\n    assert cell_index &lt; CELLS_PER_EXT_BLOB\n    roots_of_unity_brp = bit_reversal_permutation(\n        compute_roots_of_unity(FIELD_ELEMENTS_PER_EXT_BLOB)\n    )\n    return Coset(\n        roots_of_unity_brp[\n            FIELD_ELEMENTS_PER_CELL * cell_index : FIELD_ELEMENTS_PER_CELL * (cell_index + 1)\n        ]\n    )\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#cells","title":"Cells","text":""},{"location":"specs/fulu/polynomial-commitments-sampling/#cell-computation","title":"Cell computation","text":""},{"location":"specs/fulu/polynomial-commitments-sampling/#compute_cells","title":"<code>compute_cells</code>","text":"<pre><code>def compute_cells(blob: Blob) -&gt; Vector[Cell, CELLS_PER_EXT_BLOB]:\n    \"\"\"\n    Given a blob, extend it and return all the cells of the extended blob.\n\n    Public method.\n    \"\"\"\n    assert len(blob) == BYTES_PER_BLOB\n\n    polynomial = blob_to_polynomial(blob)\n    polynomial_coeff = polynomial_eval_to_coeff(polynomial)\n\n    cells = []\n    for i in range(CELLS_PER_EXT_BLOB):\n        coset = coset_for_cell(CellIndex(i))\n        ys = CosetEvals([evaluate_polynomialcoeff(polynomial_coeff, z) for z in coset])\n        cells.append(coset_evals_to_cell(CosetEvals(ys)))\n    return cells\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#compute_cells_and_kzg_proofs_polynomialcoeff","title":"<code>compute_cells_and_kzg_proofs_polynomialcoeff</code>","text":"<pre><code>def compute_cells_and_kzg_proofs_polynomialcoeff(\n    polynomial_coeff: PolynomialCoeff,\n) -&gt; Tuple[Vector[Cell, CELLS_PER_EXT_BLOB], Vector[KZGProof, CELLS_PER_EXT_BLOB]]:\n    \"\"\"\n    Helper function which computes cells/proofs for a polynomial in coefficient form.\n    \"\"\"\n    cells, proofs = [], []\n    for i in range(CELLS_PER_EXT_BLOB):\n        coset = coset_for_cell(CellIndex(i))\n        proof, ys = compute_kzg_proof_multi_impl(polynomial_coeff, coset)\n        cells.append(coset_evals_to_cell(CosetEvals(ys)))\n        proofs.append(proof)\n    return cells, proofs\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#compute_cells_and_kzg_proofs","title":"<code>compute_cells_and_kzg_proofs</code>","text":"<pre><code>def compute_cells_and_kzg_proofs(\n    blob: Blob,\n) -&gt; Tuple[Vector[Cell, CELLS_PER_EXT_BLOB], Vector[KZGProof, CELLS_PER_EXT_BLOB]]:\n    \"\"\"\n    Compute all the cell proofs for an extended blob. This is an inefficient O(n^2) algorithm,\n    for performant implementation the FK20 algorithm that runs in O(n log n) should be\n    used instead.\n\n    Public method.\n    \"\"\"\n    assert len(blob) == BYTES_PER_BLOB\n\n    polynomial = blob_to_polynomial(blob)\n    polynomial_coeff = polynomial_eval_to_coeff(polynomial)\n    return compute_cells_and_kzg_proofs_polynomialcoeff(polynomial_coeff)\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#cell-verification","title":"Cell verification","text":""},{"location":"specs/fulu/polynomial-commitments-sampling/#verify_cell_kzg_proof_batch","title":"<code>verify_cell_kzg_proof_batch</code>","text":"<pre><code>def verify_cell_kzg_proof_batch(\n    commitments_bytes: Sequence[Bytes48],\n    cell_indices: Sequence[CellIndex],\n    cells: Sequence[Cell],\n    proofs_bytes: Sequence[Bytes48],\n) -&gt; bool:\n    \"\"\"\n    Verify that a set of cells belong to their corresponding commitments.\n\n    Given four lists representing tuples of (``commitment``, ``cell_index``, ``cell``, ``proof``),\n    the function verifies ``proof`` which shows that ``cell`` are the evaluations of the polynomial\n    associated with ``commitment``, evaluated over the domain specified by ``cell_index``.\n\n    This function implements the universal verification equation that has been introduced here:\n    https://ethresear.ch/t/a-universal-verification-equation-for-data-availability-sampling/13240\n\n    Public method.\n    \"\"\"\n\n    assert len(commitments_bytes) == len(cells) == len(proofs_bytes) == len(cell_indices)\n    for commitment_bytes in commitments_bytes:\n        assert len(commitment_bytes) == BYTES_PER_COMMITMENT\n    for cell_index in cell_indices:\n        assert cell_index &lt; CELLS_PER_EXT_BLOB\n    for cell in cells:\n        assert len(cell) == BYTES_PER_CELL\n    for proof_bytes in proofs_bytes:\n        assert len(proof_bytes) == BYTES_PER_PROOF\n\n    # Create the list of deduplicated commitments we are dealing with\n    deduplicated_commitments = [\n        bytes_to_kzg_commitment(commitment_bytes)\n        for index, commitment_bytes in enumerate(commitments_bytes)\n        if commitments_bytes.index(commitment_bytes) == index\n    ]\n    # Create indices list mapping initial commitments (that may contain duplicates) to the deduplicated commitments\n    commitment_indices = [\n        CommitmentIndex(deduplicated_commitments.index(commitment_bytes))\n        for commitment_bytes in commitments_bytes\n    ]\n\n    cosets_evals = [cell_to_coset_evals(cell) for cell in cells]\n    proofs = [bytes_to_kzg_proof(proof_bytes) for proof_bytes in proofs_bytes]\n\n    # Do the actual verification\n    return verify_cell_kzg_proof_batch_impl(\n        deduplicated_commitments, commitment_indices, cell_indices, cosets_evals, proofs\n    )\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#reconstruction","title":"Reconstruction","text":""},{"location":"specs/fulu/polynomial-commitments-sampling/#construct_vanishing_polynomial","title":"<code>construct_vanishing_polynomial</code>","text":"<pre><code>def construct_vanishing_polynomial(\n    missing_cell_indices: Sequence[CellIndex],\n) -&gt; Sequence[BLSFieldElement]:\n    \"\"\"\n    Given the cells indices that are missing from the data, compute the polynomial that vanishes at every point that\n    corresponds to a missing field element.\n\n    This method assumes that all of the cells cannot be missing. In this case the vanishing polynomial\n    could be computed as Z(x) = x^n - 1, where `n` is FIELD_ELEMENTS_PER_EXT_BLOB.\n\n    We never encounter this case however because this method is used solely for recovery and recovery only\n    works if at least half of the cells are available.\n    \"\"\"\n    # Get the small domain\n    roots_of_unity_reduced = compute_roots_of_unity(CELLS_PER_EXT_BLOB)\n\n    # Compute polynomial that vanishes at all the missing cells (over the small domain)\n    short_zero_poly = vanishing_polynomialcoeff(\n        [\n            roots_of_unity_reduced[reverse_bits(missing_cell_index, CELLS_PER_EXT_BLOB)]\n            for missing_cell_index in missing_cell_indices\n        ]\n    )\n\n    # Extend vanishing polynomial to full domain using the closed form of the vanishing polynomial over a coset\n    zero_poly_coeff = [BLSFieldElement(0)] * FIELD_ELEMENTS_PER_EXT_BLOB\n    for i, coeff in enumerate(short_zero_poly):\n        zero_poly_coeff[i * FIELD_ELEMENTS_PER_CELL] = coeff\n\n    return zero_poly_coeff\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#recover_polynomialcoeff","title":"<code>recover_polynomialcoeff</code>","text":"<pre><code>def recover_polynomialcoeff(\n    cell_indices: Sequence[CellIndex], cosets_evals: Sequence[CosetEvals]\n) -&gt; PolynomialCoeff:\n    \"\"\"\n    Recover the polynomial in coefficient form that when evaluated at the roots of unity will give the extended blob.\n    \"\"\"\n    # Get the extended domain. This will be referred to as the FFT domain.\n    roots_of_unity_extended = compute_roots_of_unity(FIELD_ELEMENTS_PER_EXT_BLOB)\n\n    # Flatten the cosets evaluations.\n    # If a cell is missing, then its evaluation is zero.\n    # We let E(x) be a polynomial of degree FIELD_ELEMENTS_PER_EXT_BLOB - 1\n    # that interpolates the evaluations including the zeros for missing ones.\n    extended_evaluation_rbo = [BLSFieldElement(0)] * FIELD_ELEMENTS_PER_EXT_BLOB\n    for cell_index, cell in zip(cell_indices, cosets_evals):\n        start = cell_index * FIELD_ELEMENTS_PER_CELL\n        end = (cell_index + 1) * FIELD_ELEMENTS_PER_CELL\n        extended_evaluation_rbo[start:end] = cell\n    extended_evaluation = bit_reversal_permutation(extended_evaluation_rbo)\n\n    # Compute the vanishing polynomial Z(x) in coefficient form.\n    # Z(x) is the polynomial which vanishes on all of the evaluations which are missing.\n    missing_cell_indices = [\n        CellIndex(cell_index)\n        for cell_index in range(CELLS_PER_EXT_BLOB)\n        if cell_index not in cell_indices\n    ]\n    zero_poly_coeff = construct_vanishing_polynomial(missing_cell_indices)\n\n    # Convert Z(x) to evaluation form over the FFT domain\n    zero_poly_eval = fft_field(zero_poly_coeff, roots_of_unity_extended)\n\n    # Compute (E*Z)(x) = E(x) * Z(x) in evaluation form over the FFT domain\n    # Note: over the FFT domain, the polynomials (E*Z)(x) and (P*Z)(x) agree, where\n    # P(x) is the polynomial we want to reconstruct (degree FIELD_ELEMENTS_PER_BLOB - 1).\n    extended_evaluation_times_zero = [a * b for a, b in zip(zero_poly_eval, extended_evaluation)]\n\n    # We know that (E*Z)(x) and (P*Z)(x) agree over the FFT domain,\n    # and we know that (P*Z)(x) has degree at most FIELD_ELEMENTS_PER_EXT_BLOB - 1.\n    # Thus, an inverse FFT of the evaluations of (E*Z)(x) (= evaluations of (P*Z)(x))\n    # yields the coefficient form of (P*Z)(x).\n    extended_evaluation_times_zero_coeffs = fft_field(\n        extended_evaluation_times_zero, roots_of_unity_extended, inv=True\n    )\n\n    # Next step is to divide the polynomial (P*Z)(x) by polynomial Z(x) to get P(x).\n    # We do this in evaluation form over a coset of the FFT domain to avoid division by 0.\n\n    # Convert (P*Z)(x) to evaluation form over a coset of the FFT domain\n    extended_evaluations_over_coset = coset_fft_field(\n        extended_evaluation_times_zero_coeffs, roots_of_unity_extended\n    )\n\n    # Convert Z(x) to evaluation form over a coset of the FFT domain\n    zero_poly_over_coset = coset_fft_field(zero_poly_coeff, roots_of_unity_extended)\n\n    # Compute P(x) = (P*Z)(x) / Z(x) in evaluation form over a coset of the FFT domain\n    reconstructed_poly_over_coset = [\n        a / b for a, b in zip(extended_evaluations_over_coset, zero_poly_over_coset)\n    ]\n\n    # Convert P(x) to coefficient form\n    reconstructed_poly_coeff = coset_fft_field(\n        reconstructed_poly_over_coset, roots_of_unity_extended, inv=True\n    )\n\n    return PolynomialCoeff(reconstructed_poly_coeff[:FIELD_ELEMENTS_PER_BLOB])\n</code></pre>"},{"location":"specs/fulu/polynomial-commitments-sampling/#recover_cells_and_kzg_proofs","title":"<code>recover_cells_and_kzg_proofs</code>","text":"<pre><code>def recover_cells_and_kzg_proofs(\n    cell_indices: Sequence[CellIndex], cells: Sequence[Cell]\n) -&gt; Tuple[Vector[Cell, CELLS_PER_EXT_BLOB], Vector[KZGProof, CELLS_PER_EXT_BLOB]]:\n    \"\"\"\n    Given at least 50% of cells for a blob, recover all the cells/proofs.\n    This algorithm uses FFTs to recover cells faster than using Lagrange\n    implementation, as can be seen here:\n    https://ethresear.ch/t/reed-solomon-erasure-code-recovery-in-n-log-2-n-time-with-ffts/3039\n\n    A faster version thanks to Qi Zhou can be found here:\n    https://github.com/ethereum/research/blob/51b530a53bd4147d123ab3e390a9d08605c2cdb8/polynomial_reconstruction/polynomial_reconstruction_danksharding.py\n\n    Public method.\n    \"\"\"\n    # Check we have the same number of cells and indices\n    assert len(cell_indices) == len(cells)\n    # Check we have enough cells to be able to perform the reconstruction\n    assert CELLS_PER_EXT_BLOB // 2 &lt;= len(cell_indices) &lt;= CELLS_PER_EXT_BLOB\n    # Check for duplicates\n    assert len(cell_indices) == len(set(cell_indices))\n    # Check that indices are in ascending order\n    assert cell_indices == sorted(cell_indices)\n    # Check that the cell indices are within bounds\n    for cell_index in cell_indices:\n        assert cell_index &lt; CELLS_PER_EXT_BLOB\n    # Check that each cell is the correct length\n    for cell in cells:\n        assert len(cell) == BYTES_PER_CELL\n\n    # Convert cells to coset evaluations\n    cosets_evals = [cell_to_coset_evals(cell) for cell in cells]\n\n    # Given the coset evaluations, recover the polynomial in coefficient form\n    polynomial_coeff = recover_polynomialcoeff(cell_indices, cosets_evals)\n\n    # Recompute all cells/proofs\n    return compute_cells_and_kzg_proofs_polynomialcoeff(polynomial_coeff)\n</code></pre>"},{"location":"specs/fulu/validator/","title":"Fulu -- Honest Validator","text":"<ul> <li>Introduction</li> <li>Prerequisites</li> <li>Configuration</li> <li>Custody setting</li> <li>Helpers</li> <li><code>BlobsBundle</code></li> <li>Modified <code>GetPayloadResponse</code></li> <li>Protocols</li> <li><code>ExecutionEngine</code><ul> <li>Modified <code>get_payload</code></li> </ul> </li> <li>Beacon chain responsibilities</li> <li>Validator custody</li> <li>Block and sidecar proposal<ul> <li>Constructing the sidecars</li> <li><code>get_data_column_sidecars</code></li> <li><code>get_data_column_sidecars_from_block</code></li> <li><code>get_data_column_sidecars_from_column_sidecar</code></li> <li>Sidecar publishing</li> <li>Sidecar retention</li> </ul> </li> </ul>"},{"location":"specs/fulu/validator/#introduction","title":"Introduction","text":"<p>This document represents the changes to be made in the code of an \"honest validator\" to implement Fulu.</p>"},{"location":"specs/fulu/validator/#prerequisites","title":"Prerequisites","text":"<p>This document is an extension of the Electra -- Honest Validator guide. All behaviors and definitions defined in this document, and documents it extends, carry over unless explicitly noted or overridden.</p> <p>All terminology, constants, functions, and protocol mechanics defined in Fulu -- Beacon Chain and Fulu -- Data Availability Sampling Core are requisite for this document and used throughout.</p>"},{"location":"specs/fulu/validator/#configuration","title":"Configuration","text":""},{"location":"specs/fulu/validator/#custody-setting","title":"Custody setting","text":"Name Value Description <code>VALIDATOR_CUSTODY_REQUIREMENT</code> <code>8</code> Minimum number of custody groups an honest node with validators attached custodies and serves samples from <code>BALANCE_PER_ADDITIONAL_CUSTODY_GROUP</code> <code>Gwei(32 * 10**9)</code> Effective balance increment corresponding to one additional group to custody"},{"location":"specs/fulu/validator/#helpers","title":"Helpers","text":""},{"location":"specs/fulu/validator/#blobsbundle","title":"<code>BlobsBundle</code>","text":"<p>[Modified in Fulu:EIP7594]</p> <p>The <code>BlobsBundle</code> object is modified to include cell KZG proofs instead of blob KZG proofs.</p> <pre><code>@dataclass\nclass BlobsBundle(object):\n    commitments: List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    # [Modified in Fulu:EIP7594]\n    proofs: List[KZGProof, FIELD_ELEMENTS_PER_EXT_BLOB * MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    blobs: List[Blob, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n</code></pre>"},{"location":"specs/fulu/validator/#modified-getpayloadresponse","title":"Modified <code>GetPayloadResponse</code>","text":"<p>[Modified in Fulu:EIP7594]</p> <p>The <code>GetPayloadResponse</code> object is modified to use the updated <code>BlobsBundle</code> object.</p> <pre><code>@dataclass\nclass GetPayloadResponse(object):\n    execution_payload: ExecutionPayload\n    block_value: uint256\n    # [Modified in Fulu:EIP7594]\n    blobs_bundle: BlobsBundle\n    execution_requests: Sequence[bytes]\n</code></pre>"},{"location":"specs/fulu/validator/#protocols","title":"Protocols","text":""},{"location":"specs/fulu/validator/#executionengine","title":"<code>ExecutionEngine</code>","text":""},{"location":"specs/fulu/validator/#modified-get_payload","title":"Modified <code>get_payload</code>","text":"<p>The <code>get_payload</code> method is modified to return the updated <code>GetPayloadResponse</code> object.</p> <pre><code>def get_payload(self: ExecutionEngine, payload_id: PayloadId) -&gt; GetPayloadResponse:\n    \"\"\"\n    Return ExecutionPayload, uint256, BlobsBundle objects.\n    \"\"\"\n    # pylint: disable=unused-argument\n    ...\n</code></pre>"},{"location":"specs/fulu/validator/#beacon-chain-responsibilities","title":"Beacon chain responsibilities","text":""},{"location":"specs/fulu/validator/#validator-custody","title":"Validator custody","text":"<p>[New in Fulu:EIP7594]</p> <p>A node with validators attached downloads and custodies a higher minimum of custody groups per slot, determined by <code>get_validators_custody_requirement(state, validator_indices)</code>. Here, <code>state</code> is the latest finalized <code>BeaconState</code> and <code>validator_indices</code> is the list of indices corresponding to validators attached to the node. Any node with at least one validator attached, and with the sum of the effective balances of all attached validators being <code>total_node_balance</code>, downloads and custodies <code>total_node_balance // BALANCE_PER_ADDITIONAL_CUSTODY_GROUP</code> custody groups per slot, with a minimum of <code>VALIDATOR_CUSTODY_REQUIREMENT</code> and of course a maximum of <code>NUMBER_OF_CUSTODY_GROUPS</code>.</p> <pre><code>def get_validators_custody_requirement(\n    state: BeaconState, validator_indices: Sequence[ValidatorIndex]\n) -&gt; uint64:\n    total_node_balance = sum(\n        state.validators[index].effective_balance for index in validator_indices\n    )\n    count = total_node_balance // BALANCE_PER_ADDITIONAL_CUSTODY_GROUP\n    return min(max(count, VALIDATOR_CUSTODY_REQUIREMENT), NUMBER_OF_CUSTODY_GROUPS)\n</code></pre> <p>This higher custody is advertised in the node's Metadata by setting a higher <code>custody_group_count</code> and in the node's ENR by setting a higher <code>custody_group_count</code>. As with the regular custody requirement, a node with validators MAY still choose to custody, advertise and serve more than this minimum. As with the regular custody requirement, a node MUST backfill columns when syncing.</p> <p>A node SHOULD dynamically adjust its custody groups (without any input from the user) following any changes to the total effective balances of attached validators.</p> <p>If the node's custody requirements are increased, it SHOULD immediately advertise the updated <code>custody_group_count</code>. It MAY backfill custody groups as a result of this change.</p> <p>If a node's custody requirements decrease, it SHOULD NOT update the <code>custody_group_count</code> to reflect this reduction. The node SHOULD continue to custody and advertise the previous (highest) <code>custody_group_count</code>. The node SHOULD continue to respond to any <code>DataColumnSidecar</code> request corresponding to the previous (highest) <code>custody_group_count</code>. The previous (highest) <code>custody_group_count</code> SHOULD persist across node restarts.</p> <p>Nodes SHOULD be capable of handling multiple changes to custody requirements within the same retention period (e.g., an increase in one epoch followed by a decrease in the next).</p> <p>When a value for <code>custody_group_count</code> is set, the <code>earliest_available_slot</code> field in the status RPC message SHOULD reflect the slot at which the <code>custody_group_count</code> was updated.</p> <p>If the node decides to backfill due to the <code>custody_group_count</code> change, the <code>earliest_available_slot</code> field in the status RPC message MAY be updated with progressively lower values as the backfill process advances.</p>"},{"location":"specs/fulu/validator/#block-and-sidecar-proposal","title":"Block and sidecar proposal","text":""},{"location":"specs/fulu/validator/#constructing-the-sidecars","title":"Constructing the sidecars","text":"<p>[New in Fulu:EIP7594]</p> <p>For a block proposal, blobs associated with a block are packaged into many <code>DataColumnSidecar</code> objects for distribution to the associated sidecar topic, the <code>data_column_sidecar_{subnet_id}</code> pubsub topic. A <code>DataColumnSidecar</code> can be viewed as vertical slice of all blobs stacked on top of each other, with extra fields for the necessary context.</p>"},{"location":"specs/fulu/validator/#get_data_column_sidecars","title":"<code>get_data_column_sidecars</code>","text":"<p>The sidecars associated with a block can be created by calling <code>engine_getPayloadV5</code>, then constructing the list of cells and proofs for each blob (as defined in the example below) using the blobs bundle in the response, and finally by calling <code>get_data_column_sidecars_from_block(signed_block, cells_and_kzg_proofs)</code>.</p> <pre><code>cells_and_kzg_proofs = []\nfor i, blob in enumerate(blobs_bundle.blobs):\n    start = i * CELLS_PER_EXT_BLOB\n    end = (i + 1) * CELLS_PER_EXT_BLOB\n    cell_proofs = zip(compute_cells(blob), blobs_bundle.proofs[start:end])\n    cells_and_kzg_proofs.extend(cell_proofs)\n</code></pre> <p>Moreover, the full sequence of sidecars can also be computed from <code>cells_and_kzg_proofs</code> and any single <code>sidecar</code> by calling <code>get_data_column_sidecars_from_column_sidecar(sidecar, cells_and_kzg_proofs)</code>. This can be used in distributed blob publishing, to reconstruct all sidecars from any sidecar received on the wire, assuming all cells and kzg proofs could be retrieved from the local execution layer client.</p> <pre><code>def get_data_column_sidecars(\n    signed_block_header: SignedBeaconBlockHeader,\n    kzg_commitments: List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK],\n    kzg_commitments_inclusion_proof: Vector[Bytes32, KZG_COMMITMENTS_INCLUSION_PROOF_DEPTH],\n    cells_and_kzg_proofs: Sequence[\n        Tuple[Vector[Cell, CELLS_PER_EXT_BLOB], Vector[KZGProof, CELLS_PER_EXT_BLOB]]\n    ],\n) -&gt; Sequence[DataColumnSidecar]:\n    \"\"\"\n    Given a signed block header and the commitments, inclusion proof, cells/proofs associated with\n    each blob in the block, assemble the sidecars which can be distributed to peers.\n    \"\"\"\n    assert len(cells_and_kzg_proofs) == len(kzg_commitments)\n\n    sidecars = []\n    for column_index in range(NUMBER_OF_COLUMNS):\n        column_cells, column_proofs = [], []\n        for cells, proofs in cells_and_kzg_proofs:\n            column_cells.append(cells[column_index])\n            column_proofs.append(proofs[column_index])\n        sidecars.append(\n            DataColumnSidecar(\n                index=column_index,\n                column=column_cells,\n                kzg_commitments=kzg_commitments,\n                kzg_proofs=column_proofs,\n                signed_block_header=signed_block_header,\n                kzg_commitments_inclusion_proof=kzg_commitments_inclusion_proof,\n            )\n        )\n    return sidecars\n</code></pre>"},{"location":"specs/fulu/validator/#get_data_column_sidecars_from_block","title":"<code>get_data_column_sidecars_from_block</code>","text":"<pre><code>def get_data_column_sidecars_from_block(\n    signed_block: SignedBeaconBlock,\n    cells_and_kzg_proofs: Sequence[\n        Tuple[Vector[Cell, CELLS_PER_EXT_BLOB], Vector[KZGProof, CELLS_PER_EXT_BLOB]]\n    ],\n) -&gt; Sequence[DataColumnSidecar]:\n    \"\"\"\n    Given a signed block and the cells/proofs associated with each blob in the\n    block, assemble the sidecars which can be distributed to peers.\n    \"\"\"\n    blob_kzg_commitments = signed_block.message.body.blob_kzg_commitments\n    signed_block_header = compute_signed_block_header(signed_block)\n    kzg_commitments_inclusion_proof = compute_merkle_proof(\n        signed_block.message.body,\n        get_generalized_index(BeaconBlockBody, \"blob_kzg_commitments\"),\n    )\n    return get_data_column_sidecars(\n        signed_block_header,\n        blob_kzg_commitments,\n        kzg_commitments_inclusion_proof,\n        cells_and_kzg_proofs,\n    )\n</code></pre>"},{"location":"specs/fulu/validator/#get_data_column_sidecars_from_column_sidecar","title":"<code>get_data_column_sidecars_from_column_sidecar</code>","text":"<pre><code>def get_data_column_sidecars_from_column_sidecar(\n    sidecar: DataColumnSidecar,\n    cells_and_kzg_proofs: Sequence[\n        Tuple[Vector[Cell, CELLS_PER_EXT_BLOB], Vector[KZGProof, CELLS_PER_EXT_BLOB]]\n    ],\n) -&gt; Sequence[DataColumnSidecar]:\n    \"\"\"\n    Given a DataColumnSidecar and the cells/proofs associated with each blob corresponding\n    to the commitments it contains, assemble all sidecars for distribution to peers.\n    \"\"\"\n    assert len(cells_and_kzg_proofs) == len(sidecar.kzg_commitments)\n\n    return get_data_column_sidecars(\n        sidecar.signed_block_header,\n        sidecar.kzg_commitments,\n        sidecar.kzg_commitments_inclusion_proof,\n        cells_and_kzg_proofs,\n    )\n</code></pre>"},{"location":"specs/fulu/validator/#sidecar-publishing","title":"Sidecar publishing","text":"<p>The <code>subnet_id</code> for the <code>data_column_sidecar</code> is calculated with:</p> <ul> <li>Let <code>column_index = data_column_sidecar.index</code>.</li> <li>Let <code>subnet_id = compute_subnet_for_data_column_sidecar(column_index)</code>.</li> </ul> <p>After publishing all columns to their respective subnets, peers on the network may request the sidecar through sync-requests, or a local user may be interested.</p>"},{"location":"specs/fulu/validator/#sidecar-retention","title":"Sidecar retention","text":"<p>The validator MUST hold on to sidecars for <code>MIN_EPOCHS_FOR_DATA_COLUMN_SIDECARS_REQUESTS</code> epochs and serve when capable, to ensure the data-availability of these blobs throughout the network.</p> <p>After <code>MIN_EPOCHS_FOR_DATA_COLUMN_SIDECARS_REQUESTS</code> nodes MAY prune the sidecars and/or stop serving them.</p>"},{"location":"specs/gloas/","title":"Index","text":""},{"location":"specs/gloas/#core","title":"Core","text":"<ul> <li>Beacon Chain</li> <li>Builder</li> <li>Fork Choice</li> <li>Fork</li> <li>P2P Interface</li> <li>Validator</li> </ul>"},{"location":"specs/gloas/beacon-chain/","title":"Gloas -- The Beacon Chain","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Constants</li> <li>Domain types</li> <li>Misc</li> <li>Preset</li> <li>Misc</li> <li>Max operations per block</li> <li>State list lengths</li> <li>Withdrawal prefixes</li> <li>Containers</li> <li>New containers<ul> <li><code>BuilderPendingPayment</code></li> <li><code>BuilderPendingWithdrawal</code></li> <li><code>PayloadAttestationData</code></li> <li><code>PayloadAttestation</code></li> <li><code>PayloadAttestationMessage</code></li> <li><code>IndexedPayloadAttestation</code></li> <li><code>ExecutionPayloadBid</code></li> <li><code>SignedExecutionPayloadBid</code></li> <li><code>ExecutionPayloadEnvelope</code></li> <li><code>SignedExecutionPayloadEnvelope</code></li> </ul> </li> <li>Modified containers<ul> <li><code>BeaconBlockBody</code></li> <li><code>BeaconState</code></li> </ul> </li> <li>Helper functions</li> <li>Predicates<ul> <li>New <code>has_builder_withdrawal_credential</code></li> <li>Modified <code>has_compounding_withdrawal_credential</code></li> <li>New <code>is_attestation_same_slot</code></li> <li>New <code>is_builder_withdrawal_credential</code></li> <li>New <code>is_valid_indexed_payload_attestation</code></li> <li>New <code>is_parent_block_full</code></li> </ul> </li> <li>Misc<ul> <li>Modified <code>get_pending_balance_to_withdraw</code></li> <li>New <code>remove_flag</code></li> <li>New <code>compute_balance_weighted_selection</code></li> <li>New <code>compute_balance_weighted_acceptance</code></li> <li>Modified <code>compute_proposer_indices</code></li> </ul> </li> <li>Beacon State accessors<ul> <li>Modified <code>get_next_sync_committee_indices</code></li> <li>New <code>get_attestation_participation_flag_indices</code></li> <li>New <code>get_ptc</code></li> <li>New <code>get_indexed_payload_attestation</code></li> <li>New <code>get_builder_payment_quorum_threshold</code></li> </ul> </li> <li>Beacon chain state transition function</li> <li>Modified <code>process_slot</code></li> <li>Epoch processing<ul> <li>Modified <code>process_epoch</code></li> <li>New <code>process_builder_pending_payments</code></li> </ul> </li> <li>Block processing<ul> <li>Withdrawals</li> <li>New <code>is_builder_payment_withdrawable</code></li> <li>Modified <code>get_expected_withdrawals</code></li> <li>Modified <code>process_withdrawals</code></li> <li>Execution payload bid</li> <li>New <code>verify_execution_payload_bid_signature</code></li> <li>New <code>process_execution_payload_bid</code></li> <li>Operations</li> <li>Modified <code>process_operations</code></li> <li>Attestations<ul> <li>Modified <code>process_attestation</code></li> </ul> </li> <li>Payload Attestations<ul> <li>New <code>process_payload_attestation</code></li> </ul> </li> <li>Proposer Slashing<ul> <li>Modified <code>process_proposer_slashing</code></li> </ul> </li> <li>Modified <code>is_merge_transition_complete</code></li> <li>Modified <code>validate_merge_block</code></li> </ul> </li> <li>Execution payload processing<ul> <li>New <code>verify_execution_payload_envelope_signature</code></li> <li>New <code>process_execution_payload</code></li> </ul> </li> </ul>"},{"location":"specs/gloas/beacon-chain/#introduction","title":"Introduction","text":"<p>This is the beacon chain specification of the enshrined proposer builder separation feature.</p> <p>Note: This specification is built upon Fulu and is under active development.</p> <p>This feature adds new staked consensus participants called Builders and new honest validators duties called payload timeliness attestations. The slot is divided in four intervals. Honest validators gather signed bids (a <code>SignedExecutionPayloadBid</code>) from builders and submit their consensus blocks (a <code>SignedBeaconBlock</code>) including accepted bids at the beginning of the slot. At the start of the second interval, honest validators submit attestations just as they do previous to this feature). At the start of the third interval, aggregators aggregate these attestations and the builder broadcasts either a full payload or a message indicating that they are withholding the payload (a <code>SignedExecutionPayloadEnvelope</code>). At the start of the fourth interval, some validators selected to be members of the new Payload Timeliness Committee (PTC) attest to the presence and timeliness of the builder's payload.</p> <p>At any given slot, the status of the blockchain's head may be either</p> <ul> <li>A block from a previous slot (e.g. the current slot's proposer did not submit   its block).</li> <li>An empty block from the current slot (e.g. the proposer submitted a timely   block, but the builder did not reveal the payload on time).</li> <li>A full block for the current slot (both the proposer and the builder revealed   on time).</li> </ul>"},{"location":"specs/gloas/beacon-chain/#constants","title":"Constants","text":""},{"location":"specs/gloas/beacon-chain/#domain-types","title":"Domain types","text":"Name Value <code>DOMAIN_BEACON_BUILDER</code> <code>DomainType('0x1B000000')</code> <code>DOMAIN_PTC_ATTESTER</code> <code>DomainType('0x0C000000')</code>"},{"location":"specs/gloas/beacon-chain/#misc","title":"Misc","text":"Name Value <code>BUILDER_PAYMENT_THRESHOLD_NUMERATOR</code> <code>uint64(6)</code> <code>BUILDER_PAYMENT_THRESHOLD_DENOMINATOR</code> <code>uint64(10)</code>"},{"location":"specs/gloas/beacon-chain/#preset","title":"Preset","text":""},{"location":"specs/gloas/beacon-chain/#misc_1","title":"Misc","text":"Name Value <code>PTC_SIZE</code> <code>uint64(2**9)</code> (=512)"},{"location":"specs/gloas/beacon-chain/#max-operations-per-block","title":"Max operations per block","text":"Name Value <code>MAX_PAYLOAD_ATTESTATIONS</code> <code>4</code>"},{"location":"specs/gloas/beacon-chain/#state-list-lengths","title":"State list lengths","text":"Name Value Unit <code>BUILDER_PENDING_WITHDRAWALS_LIMIT</code> <code>uint64(2**20)</code> (= 1,048,576) Builder pending withdrawals"},{"location":"specs/gloas/beacon-chain/#withdrawal-prefixes","title":"Withdrawal prefixes","text":"Name Value Description <code>BUILDER_WITHDRAWAL_PREFIX</code> <code>Bytes1('0x03')</code> Withdrawal credential prefix for a builder"},{"location":"specs/gloas/beacon-chain/#containers","title":"Containers","text":""},{"location":"specs/gloas/beacon-chain/#new-containers","title":"New containers","text":""},{"location":"specs/gloas/beacon-chain/#builderpendingpayment","title":"<code>BuilderPendingPayment</code>","text":"<pre><code>class BuilderPendingPayment(Container):\n    weight: Gwei\n    withdrawal: BuilderPendingWithdrawal\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#builderpendingwithdrawal","title":"<code>BuilderPendingWithdrawal</code>","text":"<pre><code>class BuilderPendingWithdrawal(Container):\n    fee_recipient: ExecutionAddress\n    amount: Gwei\n    builder_index: ValidatorIndex\n    withdrawable_epoch: Epoch\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#payloadattestationdata","title":"<code>PayloadAttestationData</code>","text":"<pre><code>class PayloadAttestationData(Container):\n    beacon_block_root: Root\n    slot: Slot\n    payload_present: boolean\n    blob_data_available: boolean\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#payloadattestation","title":"<code>PayloadAttestation</code>","text":"<pre><code>class PayloadAttestation(Container):\n    aggregation_bits: Bitvector[PTC_SIZE]\n    data: PayloadAttestationData\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#payloadattestationmessage","title":"<code>PayloadAttestationMessage</code>","text":"<pre><code>class PayloadAttestationMessage(Container):\n    validator_index: ValidatorIndex\n    data: PayloadAttestationData\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#indexedpayloadattestation","title":"<code>IndexedPayloadAttestation</code>","text":"<pre><code>class IndexedPayloadAttestation(Container):\n    attesting_indices: List[ValidatorIndex, PTC_SIZE]\n    data: PayloadAttestationData\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#executionpayloadbid","title":"<code>ExecutionPayloadBid</code>","text":"<pre><code>class ExecutionPayloadBid(Container):\n    parent_block_hash: Hash32\n    parent_block_root: Root\n    block_hash: Hash32\n    fee_recipient: ExecutionAddress\n    gas_limit: uint64\n    builder_index: ValidatorIndex\n    slot: Slot\n    value: Gwei\n    blob_kzg_commitments_root: Root\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#signedexecutionpayloadbid","title":"<code>SignedExecutionPayloadBid</code>","text":"<pre><code>class SignedExecutionPayloadBid(Container):\n    message: ExecutionPayloadBid\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#executionpayloadenvelope","title":"<code>ExecutionPayloadEnvelope</code>","text":"<pre><code>class ExecutionPayloadEnvelope(Container):\n    payload: ExecutionPayload\n    execution_requests: ExecutionRequests\n    builder_index: ValidatorIndex\n    beacon_block_root: Root\n    slot: Slot\n    blob_kzg_commitments: List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    state_root: Root\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#signedexecutionpayloadenvelope","title":"<code>SignedExecutionPayloadEnvelope</code>","text":"<pre><code>class SignedExecutionPayloadEnvelope(Container):\n    message: ExecutionPayloadEnvelope\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#modified-containers","title":"Modified containers","text":""},{"location":"specs/gloas/beacon-chain/#beaconblockbody","title":"<code>BeaconBlockBody</code>","text":"<p>Note: The <code>BeaconBlockBody</code> container is modified to contain a <code>SignedExecutionPayloadBid</code>. The containers <code>BeaconBlock</code> and <code>SignedBeaconBlock</code> are modified indirectly. The field <code>execution_requests</code> is removed from the beacon block body and moved into the signed execution payload envelope.</p> <pre><code>class BeaconBlockBody(Container):\n    randao_reveal: BLSSignature\n    eth1_data: Eth1Data\n    graffiti: Bytes32\n    proposer_slashings: List[ProposerSlashing, MAX_PROPOSER_SLASHINGS]\n    attester_slashings: List[AttesterSlashing, MAX_ATTESTER_SLASHINGS_ELECTRA]\n    attestations: List[Attestation, MAX_ATTESTATIONS_ELECTRA]\n    deposits: List[Deposit, MAX_DEPOSITS]\n    voluntary_exits: List[SignedVoluntaryExit, MAX_VOLUNTARY_EXITS]\n    sync_aggregate: SyncAggregate\n    # [Modified in Gloas:EIP7732]\n    # Removed `execution_payload`\n    bls_to_execution_changes: List[SignedBLSToExecutionChange, MAX_BLS_TO_EXECUTION_CHANGES]\n    # [Modified in Gloas:EIP7732]\n    # Removed `blob_kzg_commitments`\n    # [Modified in Gloas:EIP7732]\n    # Removed `execution_requests`\n    # [New in Gloas:EIP7732]\n    signed_execution_payload_bid: SignedExecutionPayloadBid\n    # [New in Gloas:EIP7732]\n    payload_attestations: List[PayloadAttestation, MAX_PAYLOAD_ATTESTATIONS]\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#beaconstate","title":"<code>BeaconState</code>","text":"<p>Note: The <code>BeaconState</code> is modified to track the last withdrawals honored in the CL. A new field <code>latest_execution_payload_bid</code> is added to track the state's slot builder's bid. The <code>latest_execution_payload_header</code> remains unchanged from previous specs. Another addition is to track the last committed block hash and the last slot that was full, that is in which there were both consensus and execution blocks included.</p> <pre><code>class BeaconState(Container):\n    genesis_time: uint64\n    genesis_validators_root: Root\n    slot: Slot\n    fork: Fork\n    latest_block_header: BeaconBlockHeader\n    block_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    state_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    historical_roots: List[Root, HISTORICAL_ROOTS_LIMIT]\n    eth1_data: Eth1Data\n    eth1_data_votes: List[Eth1Data, EPOCHS_PER_ETH1_VOTING_PERIOD * SLOTS_PER_EPOCH]\n    eth1_deposit_index: uint64\n    validators: List[Validator, VALIDATOR_REGISTRY_LIMIT]\n    balances: List[Gwei, VALIDATOR_REGISTRY_LIMIT]\n    randao_mixes: Vector[Bytes32, EPOCHS_PER_HISTORICAL_VECTOR]\n    slashings: Vector[Gwei, EPOCHS_PER_SLASHINGS_VECTOR]\n    previous_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    current_epoch_participation: List[ParticipationFlags, VALIDATOR_REGISTRY_LIMIT]\n    justification_bits: Bitvector[JUSTIFICATION_BITS_LENGTH]\n    previous_justified_checkpoint: Checkpoint\n    current_justified_checkpoint: Checkpoint\n    finalized_checkpoint: Checkpoint\n    inactivity_scores: List[uint64, VALIDATOR_REGISTRY_LIMIT]\n    current_sync_committee: SyncCommittee\n    next_sync_committee: SyncCommittee\n    latest_execution_payload_header: ExecutionPayloadHeader\n    next_withdrawal_index: WithdrawalIndex\n    next_withdrawal_validator_index: ValidatorIndex\n    historical_summaries: List[HistoricalSummary, HISTORICAL_ROOTS_LIMIT]\n    deposit_requests_start_index: uint64\n    deposit_balance_to_consume: Gwei\n    exit_balance_to_consume: Gwei\n    earliest_exit_epoch: Epoch\n    consolidation_balance_to_consume: Gwei\n    earliest_consolidation_epoch: Epoch\n    pending_deposits: List[PendingDeposit, PENDING_DEPOSITS_LIMIT]\n    pending_partial_withdrawals: List[PendingPartialWithdrawal, PENDING_PARTIAL_WITHDRAWALS_LIMIT]\n    pending_consolidations: List[PendingConsolidation, PENDING_CONSOLIDATIONS_LIMIT]\n    proposer_lookahead: Vector[ValidatorIndex, (MIN_SEED_LOOKAHEAD + 1) * SLOTS_PER_EPOCH]\n    # [New in Gloas:EIP7732]\n    latest_execution_payload_bid: ExecutionPayloadBid\n    # [New in Gloas:EIP7732]\n    execution_payload_availability: Bitvector[SLOTS_PER_HISTORICAL_ROOT]\n    # [New in Gloas:EIP7732]\n    builder_pending_payments: Vector[BuilderPendingPayment, 2 * SLOTS_PER_EPOCH]\n    # [New in Gloas:EIP7732]\n    builder_pending_withdrawals: List[BuilderPendingWithdrawal, BUILDER_PENDING_WITHDRAWALS_LIMIT]\n    # [New in Gloas:EIP7732]\n    latest_block_hash: Hash32\n    # [New in Gloas:EIP7732]\n    latest_withdrawals_root: Root\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#helper-functions","title":"Helper functions","text":""},{"location":"specs/gloas/beacon-chain/#predicates","title":"Predicates","text":""},{"location":"specs/gloas/beacon-chain/#new-has_builder_withdrawal_credential","title":"New <code>has_builder_withdrawal_credential</code>","text":"<pre><code>def has_builder_withdrawal_credential(validator: Validator) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` has an 0x03 prefixed \"builder\" withdrawal credential.\n    \"\"\"\n    return is_builder_withdrawal_credential(validator.withdrawal_credentials)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#modified-has_compounding_withdrawal_credential","title":"Modified <code>has_compounding_withdrawal_credential</code>","text":"<p>Note: the function <code>has_compounding_withdrawal_credential</code> is modified to return true for builders.</p> <pre><code>def has_compounding_withdrawal_credential(validator: Validator) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` has an 0x02 or 0x03 prefixed withdrawal credential.\n    \"\"\"\n    return is_compounding_withdrawal_credential(\n        validator.withdrawal_credentials\n    ) or is_builder_withdrawal_credential(validator.withdrawal_credentials)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-is_attestation_same_slot","title":"New <code>is_attestation_same_slot</code>","text":"<pre><code>def is_attestation_same_slot(state: BeaconState, data: AttestationData) -&gt; bool:\n    \"\"\"\n    Checks if the attestation was for the block proposed at the attestation slot\n    \"\"\"\n    if data.slot == 0:\n        return True\n    is_matching_blockroot = data.beacon_block_root == get_block_root_at_slot(state, Slot(data.slot))\n    is_current_blockroot = data.beacon_block_root != get_block_root_at_slot(\n        state, Slot(data.slot - 1)\n    )\n    return is_matching_blockroot and is_current_blockroot\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-is_builder_withdrawal_credential","title":"New <code>is_builder_withdrawal_credential</code>","text":"<pre><code>def is_builder_withdrawal_credential(withdrawal_credentials: Bytes32) -&gt; bool:\n    return withdrawal_credentials[:1] == BUILDER_WITHDRAWAL_PREFIX\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-is_valid_indexed_payload_attestation","title":"New <code>is_valid_indexed_payload_attestation</code>","text":"<pre><code>def is_valid_indexed_payload_attestation(\n    state: BeaconState, indexed_payload_attestation: IndexedPayloadAttestation\n) -&gt; bool:\n    \"\"\"\n    Check if ``indexed_payload_attestation`` is not empty, has sorted and unique indices and has\n    a valid aggregate signature.\n    \"\"\"\n    # Verify indices are non-empty and sorted\n    indices = indexed_payload_attestation.attesting_indices\n    if len(indices) == 0 or not indices == sorted(indices):\n        return False\n\n    # Verify aggregate signature\n    pubkeys = [state.validators[i].pubkey for i in indices]\n    domain = get_domain(state, DOMAIN_PTC_ATTESTER, None)\n    signing_root = compute_signing_root(indexed_payload_attestation.data, domain)\n    return bls.FastAggregateVerify(pubkeys, signing_root, indexed_payload_attestation.signature)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-is_parent_block_full","title":"New <code>is_parent_block_full</code>","text":"<p>This function returns true if the last committed payload bid was fulfilled with a payload, this can only happen when both beacon block and payload were present. This function must be called on a beacon state before processing the execution payload bid in the block.</p> <pre><code>def is_parent_block_full(state: BeaconState) -&gt; bool:\n    return state.latest_execution_payload_bid.block_hash == state.latest_block_hash\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#misc_2","title":"Misc","text":""},{"location":"specs/gloas/beacon-chain/#modified-get_pending_balance_to_withdraw","title":"Modified <code>get_pending_balance_to_withdraw</code>","text":"<p>Note: <code>get_pending_balance_to_withdraw</code> is modified to account for pending builder payments.</p> <pre><code>def get_pending_balance_to_withdraw(state: BeaconState, validator_index: ValidatorIndex) -&gt; Gwei:\n    return (\n        sum(\n            withdrawal.amount\n            for withdrawal in state.pending_partial_withdrawals\n            if withdrawal.validator_index == validator_index\n        )\n        + sum(\n            withdrawal.amount\n            for withdrawal in state.builder_pending_withdrawals\n            if withdrawal.builder_index == validator_index\n        )\n        + sum(\n            payment.withdrawal.amount\n            for payment in state.builder_pending_payments\n            if payment.withdrawal.builder_index == validator_index\n        )\n    )\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-remove_flag","title":"New <code>remove_flag</code>","text":"<pre><code>def remove_flag(flags: ParticipationFlags, flag_index: int) -&gt; ParticipationFlags:\n    flag = ParticipationFlags(2**flag_index)\n    return flags &amp; ~flag\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-compute_balance_weighted_selection","title":"New <code>compute_balance_weighted_selection</code>","text":"<pre><code>def compute_balance_weighted_selection(\n    state: BeaconState,\n    indices: Sequence[ValidatorIndex],\n    seed: Bytes32,\n    size: uint64,\n    shuffle_indices: bool,\n) -&gt; Sequence[ValidatorIndex]:\n    \"\"\"\n    Return ``size`` indices sampled by effective balance, using ``indices``\n    as candidates. If ``shuffle_indices`` is ``True``, candidate indices\n    are themselves sampled from ``indices`` by shuffling it, otherwise\n    ``indices`` is traversed in order.\n    \"\"\"\n    total = uint64(len(indices))\n    assert total &gt; 0\n    selected: List[ValidatorIndex] = []\n    i = uint64(0)\n    while len(selected) &lt; size:\n        next_index = i % total\n        if shuffle_indices:\n            next_index = compute_shuffled_index(next_index, total, seed)\n        candidate_index = indices[next_index]\n        if compute_balance_weighted_acceptance(state, candidate_index, seed, i):\n            selected.append(candidate_index)\n        i += 1\n    return selected\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-compute_balance_weighted_acceptance","title":"New <code>compute_balance_weighted_acceptance</code>","text":"<pre><code>def compute_balance_weighted_acceptance(\n    state: BeaconState, index: ValidatorIndex, seed: Bytes32, i: uint64\n) -&gt; bool:\n    \"\"\"\n    Return whether to accept the selection of the validator ``index``, with probability\n    proportional to its ``effective_balance``, and randomness given by ``seed`` and ``i``.\n    \"\"\"\n    MAX_RANDOM_VALUE = 2**16 - 1\n    random_bytes = hash(seed + uint_to_bytes(i // 16))\n    offset = i % 16 * 2\n    random_value = bytes_to_uint64(random_bytes[offset : offset + 2])\n    effective_balance = state.validators[index].effective_balance\n    return effective_balance * MAX_RANDOM_VALUE &gt;= MAX_EFFECTIVE_BALANCE_ELECTRA * random_value\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#modified-compute_proposer_indices","title":"Modified <code>compute_proposer_indices</code>","text":"<p>Note: <code>compute_proposer_indices</code> is refactored to use <code>compute_balance_weighted_selection</code> as a helper for the balance-weighted sampling process.</p> <pre><code>def compute_proposer_indices(\n    state: BeaconState, epoch: Epoch, seed: Bytes32, indices: Sequence[ValidatorIndex]\n) -&gt; Vector[ValidatorIndex, SLOTS_PER_EPOCH]:\n    \"\"\"\n    Return the proposer indices for the given ``epoch``.\n    \"\"\"\n    start_slot = compute_start_slot_at_epoch(epoch)\n    seeds = [hash(seed + uint_to_bytes(Slot(start_slot + i))) for i in range(SLOTS_PER_EPOCH)]\n    return [\n        compute_balance_weighted_selection(state, indices, seed, size=1, shuffle_indices=True)[0]\n        for seed in seeds\n    ]\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#beacon-state-accessors","title":"Beacon State accessors","text":""},{"location":"specs/gloas/beacon-chain/#modified-get_next_sync_committee_indices","title":"Modified <code>get_next_sync_committee_indices</code>","text":"<p>Note: <code>get_next_sync_committee_indices</code> is refactored to use <code>compute_balance_weighted_selection</code> as a helper for the balance-weighted sampling process.</p> <pre><code>def get_next_sync_committee_indices(state: BeaconState) -&gt; Sequence[ValidatorIndex]:\n    \"\"\"\n    Return the sync committee indices, with possible duplicates, for the next sync committee.\n    \"\"\"\n    epoch = Epoch(get_current_epoch(state) + 1)\n    seed = get_seed(state, epoch, DOMAIN_SYNC_COMMITTEE)\n    indices = get_active_validator_indices(state, epoch)\n    return compute_balance_weighted_selection(\n        state, indices, seed, size=SYNC_COMMITTEE_SIZE, shuffle_indices=True\n    )\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-get_attestation_participation_flag_indices","title":"New <code>get_attestation_participation_flag_indices</code>","text":"<pre><code>def get_attestation_participation_flag_indices(\n    state: BeaconState, data: AttestationData, inclusion_delay: uint64\n) -&gt; Sequence[int]:\n    \"\"\"\n    Return the flag indices that are satisfied by an attestation.\n    \"\"\"\n    if data.target.epoch == get_current_epoch(state):\n        justified_checkpoint = state.current_justified_checkpoint\n    else:\n        justified_checkpoint = state.previous_justified_checkpoint\n\n    # Matching roots\n    is_matching_source = data.source == justified_checkpoint\n    is_matching_target = is_matching_source and data.target.root == get_block_root(\n        state, data.target.epoch\n    )\n    is_matching_blockroot = is_matching_target and data.beacon_block_root == get_block_root_at_slot(\n        state, Slot(data.slot)\n    )\n    is_matching_payload = False\n    if is_attestation_same_slot(state, data):\n        assert data.index == 0\n        is_matching_payload = True\n    else:\n        is_matching_payload = (\n            data.index\n            == state.execution_payload_availability[data.slot % SLOTS_PER_HISTORICAL_ROOT]\n        )\n    is_matching_head = is_matching_blockroot and is_matching_payload\n\n    assert is_matching_source\n\n    participation_flag_indices = []\n    if is_matching_source and inclusion_delay &lt;= integer_squareroot(SLOTS_PER_EPOCH):\n        participation_flag_indices.append(TIMELY_SOURCE_FLAG_INDEX)\n    if is_matching_target and inclusion_delay &lt;= SLOTS_PER_EPOCH:\n        participation_flag_indices.append(TIMELY_TARGET_FLAG_INDEX)\n    if is_matching_head and inclusion_delay == MIN_ATTESTATION_INCLUSION_DELAY:\n        participation_flag_indices.append(TIMELY_HEAD_FLAG_INDEX)\n\n    return participation_flag_indices\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-get_ptc","title":"New <code>get_ptc</code>","text":"<pre><code>def get_ptc(state: BeaconState, slot: Slot) -&gt; Vector[ValidatorIndex, PTC_SIZE]:\n    \"\"\"\n    Get the payload timeliness committee for the given ``slot``\n    \"\"\"\n    epoch = compute_epoch_at_slot(slot)\n    seed = hash(get_seed(state, epoch, DOMAIN_PTC_ATTESTER) + uint_to_bytes(slot))\n    indices: List[ValidatorIndex] = []\n    # Concatenate all committees for this slot in order\n    committees_per_slot = get_committee_count_per_slot(state, epoch)\n    for i in range(committees_per_slot):\n        committee = get_beacon_committee(state, slot, CommitteeIndex(i))\n        indices.extend(committee)\n    return compute_balance_weighted_selection(\n        state, indices, seed, size=PTC_SIZE, shuffle_indices=False\n    )\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-get_indexed_payload_attestation","title":"New <code>get_indexed_payload_attestation</code>","text":"<pre><code>def get_indexed_payload_attestation(\n    state: BeaconState, slot: Slot, payload_attestation: PayloadAttestation\n) -&gt; IndexedPayloadAttestation:\n    \"\"\"\n    Return the indexed payload attestation corresponding to ``payload_attestation``.\n    \"\"\"\n    ptc = get_ptc(state, slot)\n    attesting_indices = [\n        index for i, index in enumerate(ptc) if payload_attestation.aggregation_bits[i]\n    ]\n\n    return IndexedPayloadAttestation(\n        attesting_indices=sorted(attesting_indices),\n        data=payload_attestation.data,\n        signature=payload_attestation.signature,\n    )\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-get_builder_payment_quorum_threshold","title":"New <code>get_builder_payment_quorum_threshold</code>","text":"<pre><code>def get_builder_payment_quorum_threshold(state: BeaconState) -&gt; uint64:\n    \"\"\"\n    Calculate the quorum threshold for builder payments.\n    \"\"\"\n    quorum = (\n        get_total_active_balance(state) // SLOTS_PER_EPOCH * BUILDER_PAYMENT_THRESHOLD_NUMERATOR\n    )\n    return uint64(quorum // BUILDER_PAYMENT_THRESHOLD_DENOMINATOR)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#beacon-chain-state-transition-function","title":"Beacon chain state transition function","text":"<p>Note: state transition is fundamentally modified in Gloas. The full state transition is broken in two parts, first importing a signed block and then importing an execution payload.</p> <p>The post-state corresponding to a pre-state <code>state</code> and a signed beacon block <code>signed_block</code> is defined as <code>state_transition(state, signed_block)</code>. State transitions that trigger an unhandled exception (e.g. a failed <code>assert</code> or an out-of-range list access) are considered invalid. State transitions that cause a <code>uint64</code> overflow or underflow are also considered invalid.</p> <p>The post-state corresponding to a pre-state <code>state</code> and a signed execution payload envelope <code>signed_envelope</code> is defined as <code>process_execution_payload(state, signed_envelope)</code>. State transitions that trigger an unhandled exception (e.g. a failed <code>assert</code> or an out-of-range list access) are considered invalid. State transitions that cause an <code>uint64</code> overflow or underflow are also considered invalid.</p>"},{"location":"specs/gloas/beacon-chain/#modified-process_slot","title":"Modified <code>process_slot</code>","text":"<p>Note: <code>process_slot</code> is modified to unset the payload availability bit.</p> <pre><code>def process_slot(state: BeaconState) -&gt; None:\n    # Cache state root\n    previous_state_root = hash_tree_root(state)\n    state.state_roots[state.slot % SLOTS_PER_HISTORICAL_ROOT] = previous_state_root\n    # Cache latest block header state root\n    if state.latest_block_header.state_root == Bytes32():\n        state.latest_block_header.state_root = previous_state_root\n    # Cache block root\n    previous_block_root = hash_tree_root(state.latest_block_header)\n    state.block_roots[state.slot % SLOTS_PER_HISTORICAL_ROOT] = previous_block_root\n    # [New in Gloas:EIP7732]\n    # Unset the next payload availability\n    state.execution_payload_availability[(state.slot + 1) % SLOTS_PER_HISTORICAL_ROOT] = 0b0\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#epoch-processing","title":"Epoch processing","text":""},{"location":"specs/gloas/beacon-chain/#modified-process_epoch","title":"Modified <code>process_epoch</code>","text":"<p>Note: The function <code>process_epoch</code> is modified to process the builder payments.</p> <pre><code>def process_epoch(state: BeaconState) -&gt; None:\n    process_justification_and_finalization(state)\n    process_inactivity_updates(state)\n    process_rewards_and_penalties(state)\n    process_registry_updates(state)\n    process_slashings(state)\n    process_eth1_data_reset(state)\n    process_pending_deposits(state)\n    process_pending_consolidations(state)\n    process_effective_balance_updates(state)\n    process_slashings_reset(state)\n    process_randao_mixes_reset(state)\n    process_historical_summaries_update(state)\n    process_participation_flag_updates(state)\n    process_sync_committee_updates(state)\n    process_proposer_lookahead(state)\n    # [New in Gloas:EIP7732]\n    process_builder_pending_payments(state)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-process_builder_pending_payments","title":"New <code>process_builder_pending_payments</code>","text":"<pre><code>def process_builder_pending_payments(state: BeaconState) -&gt; None:\n    \"\"\"\n    Processes the builder pending payments from the previous epoch.\n    \"\"\"\n    quorum = get_builder_payment_quorum_threshold(state)\n    for payment in state.builder_pending_payments[:SLOTS_PER_EPOCH]:\n        if payment.weight &gt; quorum:\n            exit_queue_epoch = compute_exit_epoch_and_update_churn(state, payment.withdrawal.amount)\n            payment.withdrawal.withdrawable_epoch = Epoch(\n                exit_queue_epoch + MIN_VALIDATOR_WITHDRAWABILITY_DELAY\n            )\n            state.builder_pending_withdrawals.append(payment.withdrawal)\n    state.builder_pending_payments = state.builder_pending_payments[SLOTS_PER_EPOCH:] + [\n        BuilderPendingPayment() for _ in range(SLOTS_PER_EPOCH)\n    ]\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#block-processing","title":"Block processing","text":"<p>Note: The function <code>process_block</code> is modified to call the new and updated functions and removes the call to <code>process_execution_payload</code>.</p> <pre><code>def process_block(state: BeaconState, block: BeaconBlock) -&gt; None:\n    process_block_header(state, block)\n    # [Modified in Gloas:EIP7732]\n    process_withdrawals(state)\n    # [Modified in Gloas:EIP7732]\n    # Removed `process_execution_payload`\n    # [New in Gloas:EIP7732]\n    process_execution_payload_bid(state, block)\n    process_randao(state, block.body)\n    process_eth1_data(state, block.body)\n    # [Modified in Gloas:EIP7732]\n    process_operations(state, block.body)\n    process_sync_aggregate(state, block.body.sync_aggregate)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#withdrawals","title":"Withdrawals","text":""},{"location":"specs/gloas/beacon-chain/#new-is_builder_payment_withdrawable","title":"New <code>is_builder_payment_withdrawable</code>","text":"<pre><code>def is_builder_payment_withdrawable(\n    state: BeaconState, withdrawal: BuilderPendingWithdrawal\n) -&gt; bool:\n    \"\"\"\n    Check if the builder is slashed and not yet withdrawable.\n    \"\"\"\n    builder = state.validators[withdrawal.builder_index]\n    current_epoch = compute_epoch_at_slot(state.slot)\n    return builder.withdrawable_epoch &gt;= current_epoch or not builder.slashed\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#modified-get_expected_withdrawals","title":"Modified <code>get_expected_withdrawals</code>","text":"<p>Note: The function <code>get_expected_withdrawals</code> is modified to include builder payments.</p> <pre><code>def get_expected_withdrawals(state: BeaconState) -&gt; Tuple[Sequence[Withdrawal], uint64, uint64]:\n    epoch = get_current_epoch(state)\n    withdrawal_index = state.next_withdrawal_index\n    validator_index = state.next_withdrawal_validator_index\n    withdrawals: List[Withdrawal] = []\n    processed_partial_withdrawals_count = 0\n    processed_builder_withdrawals_count = 0\n\n    # [New in Gloas:EIP7732]\n    # Sweep for builder payments\n    for withdrawal in state.builder_pending_withdrawals:\n        if (\n            withdrawal.withdrawable_epoch &gt; epoch\n            or len(withdrawals) + 1 == MAX_WITHDRAWALS_PER_PAYLOAD\n        ):\n            break\n        if is_builder_payment_withdrawable(state, withdrawal):\n            total_withdrawn = sum(\n                w.amount for w in withdrawals if w.validator_index == withdrawal.builder_index\n            )\n            balance = state.balances[withdrawal.builder_index] - total_withdrawn\n            builder = state.validators[withdrawal.builder_index]\n            if builder.slashed:\n                withdrawable_balance = min(balance, withdrawal.amount)\n            elif balance &gt; MIN_ACTIVATION_BALANCE:\n                withdrawable_balance = min(balance - MIN_ACTIVATION_BALANCE, withdrawal.amount)\n            else:\n                withdrawable_balance = 0\n\n            withdrawals.append(\n                Withdrawal(\n                    index=withdrawal_index,\n                    validator_index=withdrawal.builder_index,\n                    address=withdrawal.fee_recipient,\n                    amount=withdrawable_balance,\n                )\n            )\n            withdrawal_index += WithdrawalIndex(1)\n        processed_builder_withdrawals_count += 1\n\n    # Sweep for pending partial withdrawals\n    bound = min(\n        len(withdrawals) + MAX_PENDING_PARTIALS_PER_WITHDRAWALS_SWEEP,\n        MAX_WITHDRAWALS_PER_PAYLOAD - 1,\n    )\n    for withdrawal in state.pending_partial_withdrawals:\n        if withdrawal.withdrawable_epoch &gt; epoch or len(withdrawals) == bound:\n            break\n\n        validator = state.validators[withdrawal.validator_index]\n        has_sufficient_effective_balance = validator.effective_balance &gt;= MIN_ACTIVATION_BALANCE\n        total_withdrawn = sum(\n            w.amount for w in withdrawals if w.validator_index == withdrawal.validator_index\n        )\n        balance = state.balances[withdrawal.validator_index] - total_withdrawn\n        has_excess_balance = balance &gt; MIN_ACTIVATION_BALANCE\n        if (\n            validator.exit_epoch == FAR_FUTURE_EPOCH\n            and has_sufficient_effective_balance\n            and has_excess_balance\n        ):\n            withdrawable_balance = min(balance - MIN_ACTIVATION_BALANCE, withdrawal.amount)\n            withdrawals.append(\n                Withdrawal(\n                    index=withdrawal_index,\n                    validator_index=withdrawal.validator_index,\n                    address=ExecutionAddress(validator.withdrawal_credentials[12:]),\n                    amount=withdrawable_balance,\n                )\n            )\n            withdrawal_index += WithdrawalIndex(1)\n\n        processed_partial_withdrawals_count += 1\n\n    # Sweep for remaining.\n    bound = min(len(state.validators), MAX_VALIDATORS_PER_WITHDRAWALS_SWEEP)\n    for _ in range(bound):\n        validator = state.validators[validator_index]\n        total_withdrawn = sum(w.amount for w in withdrawals if w.validator_index == validator_index)\n        balance = state.balances[validator_index] - total_withdrawn\n        if is_fully_withdrawable_validator(validator, balance, epoch):\n            withdrawals.append(\n                Withdrawal(\n                    index=withdrawal_index,\n                    validator_index=validator_index,\n                    address=ExecutionAddress(validator.withdrawal_credentials[12:]),\n                    amount=balance,\n                )\n            )\n            withdrawal_index += WithdrawalIndex(1)\n        elif is_partially_withdrawable_validator(validator, balance):\n            withdrawals.append(\n                Withdrawal(\n                    index=withdrawal_index,\n                    validator_index=validator_index,\n                    address=ExecutionAddress(validator.withdrawal_credentials[12:]),\n                    amount=balance - get_max_effective_balance(validator),\n                )\n            )\n            withdrawal_index += WithdrawalIndex(1)\n        if len(withdrawals) == MAX_WITHDRAWALS_PER_PAYLOAD:\n            break\n        validator_index = ValidatorIndex((validator_index + 1) % len(state.validators))\n    return (\n        withdrawals,\n        processed_builder_withdrawals_count,\n        processed_partial_withdrawals_count,\n    )\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#modified-process_withdrawals","title":"Modified <code>process_withdrawals</code>","text":"<p>Note: This is modified to take only the <code>state</code> as parameter. Withdrawals are deterministic given the beacon state, any execution payload that has the corresponding block as parent beacon block is required to honor these withdrawals in the execution layer. This function must be called before <code>process_execution_payload_bid</code> as this latter function affects validator balances.</p> <pre><code>def process_withdrawals(state: BeaconState) -&gt; None:\n    # return early if the parent block was empty\n    if not is_parent_block_full(state):\n        return\n\n    withdrawals, processed_builder_withdrawals_count, processed_partial_withdrawals_count = (\n        get_expected_withdrawals(state)\n    )\n    withdrawals_list = List[Withdrawal, MAX_WITHDRAWALS_PER_PAYLOAD](withdrawals)\n    state.latest_withdrawals_root = hash_tree_root(withdrawals_list)\n    for withdrawal in withdrawals:\n        decrease_balance(state, withdrawal.validator_index, withdrawal.amount)\n\n    # Update the pending builder withdrawals\n    state.builder_pending_withdrawals = [\n        w\n        for w in state.builder_pending_withdrawals[:processed_builder_withdrawals_count]\n        if not is_builder_payment_withdrawable(state, w)\n    ] + state.builder_pending_withdrawals[processed_builder_withdrawals_count:]\n\n    # Update pending partial withdrawals\n    state.pending_partial_withdrawals = state.pending_partial_withdrawals[\n        processed_partial_withdrawals_count:\n    ]\n\n    # Update the next withdrawal index if this block contained withdrawals\n    if len(withdrawals) != 0:\n        latest_withdrawal = withdrawals[-1]\n        state.next_withdrawal_index = WithdrawalIndex(latest_withdrawal.index + 1)\n\n    # Update the next validator index to start the next withdrawal sweep\n    if len(withdrawals) == MAX_WITHDRAWALS_PER_PAYLOAD:\n        # Next sweep starts after the latest withdrawal's validator index\n        next_validator_index = ValidatorIndex(\n            (withdrawals[-1].validator_index + 1) % len(state.validators)\n        )\n        state.next_withdrawal_validator_index = next_validator_index\n    else:\n        # Advance sweep by the max length of the sweep if there was not a full set of withdrawals\n        next_index = state.next_withdrawal_validator_index + MAX_VALIDATORS_PER_WITHDRAWALS_SWEEP\n        next_validator_index = ValidatorIndex(next_index % len(state.validators))\n        state.next_withdrawal_validator_index = next_validator_index\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#execution-payload-bid","title":"Execution payload bid","text":""},{"location":"specs/gloas/beacon-chain/#new-verify_execution_payload_bid_signature","title":"New <code>verify_execution_payload_bid_signature</code>","text":"<pre><code>def verify_execution_payload_bid_signature(\n    state: BeaconState, signed_bid: SignedExecutionPayloadBid\n) -&gt; bool:\n    # Check the signature\n    builder = state.validators[signed_bid.message.builder_index]\n    signing_root = compute_signing_root(\n        signed_bid.message, get_domain(state, DOMAIN_BEACON_BUILDER)\n    )\n    return bls.Verify(builder.pubkey, signing_root, signed_bid.signature)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-process_execution_payload_bid","title":"New <code>process_execution_payload_bid</code>","text":"<pre><code>def process_execution_payload_bid(state: BeaconState, block: BeaconBlock) -&gt; None:\n    signed_bid = block.body.signed_execution_payload_bid\n    bid = signed_bid.message\n    builder_index = bid.builder_index\n    builder = state.validators[builder_index]\n\n    amount = bid.value\n    # For self-builds, amount must be zero regardless of withdrawal credential prefix\n    if builder_index == block.proposer_index:\n        assert amount == 0\n        assert signed_bid.signature == bls.G2_POINT_AT_INFINITY\n    else:\n        # Non-self builds require builder withdrawal credential\n        assert has_builder_withdrawal_credential(builder)\n        assert verify_execution_payload_bid_signature(state, signed_bid)\n\n    assert is_active_validator(builder, get_current_epoch(state))\n    assert not builder.slashed\n\n    # Check that the builder is active, non-slashed, and has funds to cover the bid\n    pending_payments = sum(\n        payment.withdrawal.amount\n        for payment in state.builder_pending_payments\n        if payment.withdrawal.builder_index == builder_index\n    )\n    pending_withdrawals = sum(\n        withdrawal.amount\n        for withdrawal in state.builder_pending_withdrawals\n        if withdrawal.builder_index == builder_index\n    )\n    assert (\n        amount == 0\n        or state.balances[builder_index]\n        &gt;= amount + pending_payments + pending_withdrawals + MIN_ACTIVATION_BALANCE\n    )\n\n    # Verify that the bid is for the current slot\n    assert bid.slot == block.slot\n    # Verify that the bid is for the right parent block\n    assert bid.parent_block_hash == state.latest_block_hash\n    assert bid.parent_block_root == block.parent_root\n\n    # Record the pending payment\n    pending_payment = BuilderPendingPayment(\n        weight=0,\n        withdrawal=BuilderPendingWithdrawal(\n            fee_recipient=bid.fee_recipient,\n            amount=amount,\n            builder_index=builder_index,\n        ),\n    )\n    state.builder_pending_payments[SLOTS_PER_EPOCH + bid.slot % SLOTS_PER_EPOCH] = pending_payment\n\n    # Cache the signed execution payload bid\n    state.latest_execution_payload_bid = bid\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#operations","title":"Operations","text":""},{"location":"specs/gloas/beacon-chain/#modified-process_operations","title":"Modified <code>process_operations</code>","text":"<p>Note: <code>process_operations</code> is modified to process PTC attestations and removes calls to <code>process_deposit_request</code>, <code>process_withdrawal_request</code>, and <code>process_consolidation_request</code>.</p> <pre><code>def process_operations(state: BeaconState, body: BeaconBlockBody) -&gt; None:\n    # Verify that outstanding deposits are processed up to the maximum number of deposits\n    assert len(body.deposits) == min(\n        MAX_DEPOSITS, state.eth1_data.deposit_count - state.eth1_deposit_index\n    )\n\n    def for_ops(operations: Sequence[Any], fn: Callable[[BeaconState, Any], None]) -&gt; None:\n        for operation in operations:\n            fn(state, operation)\n\n    # [Modified in Gloas:EIP7732]\n    for_ops(body.proposer_slashings, process_proposer_slashing)\n    for_ops(body.attester_slashings, process_attester_slashing)\n    # [Modified in Gloas:EIP7732]\n    for_ops(body.attestations, process_attestation)\n    for_ops(body.deposits, process_deposit)\n    for_ops(body.voluntary_exits, process_voluntary_exit)\n    for_ops(body.bls_to_execution_changes, process_bls_to_execution_change)\n    # [Modified in Gloas:EIP7732]\n    # Removed `process_deposit_request`\n    # [Modified in Gloas:EIP7732]\n    # Removed `process_withdrawal_request`\n    # [Modified in Gloas:EIP7732]\n    # Removed `process_consolidation_request`\n    # [New in Gloas:EIP7732]\n    for_ops(body.payload_attestations, process_payload_attestation)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#attestations","title":"Attestations","text":""},{"location":"specs/gloas/beacon-chain/#modified-process_attestation","title":"Modified <code>process_attestation</code>","text":"<p>Note: The function is modified to track the weight for pending builder payments and to use the <code>index</code> field in the <code>AttestationData</code> to signal the payload availability.</p> <pre><code>def process_attestation(state: BeaconState, attestation: Attestation) -&gt; None:\n    data = attestation.data\n    assert data.target.epoch in (get_previous_epoch(state), get_current_epoch(state))\n    assert data.target.epoch == compute_epoch_at_slot(data.slot)\n    assert data.slot + MIN_ATTESTATION_INCLUSION_DELAY &lt;= state.slot\n\n    # [Modified in Gloas:EIP7732]\n    assert data.index &lt; 2\n    committee_indices = get_committee_indices(attestation.committee_bits)\n    committee_offset = 0\n    for committee_index in committee_indices:\n        assert committee_index &lt; get_committee_count_per_slot(state, data.target.epoch)\n        committee = get_beacon_committee(state, data.slot, committee_index)\n        committee_attesters = set(\n            attester_index\n            for i, attester_index in enumerate(committee)\n            if attestation.aggregation_bits[committee_offset + i]\n        )\n        assert len(committee_attesters) &gt; 0\n        committee_offset += len(committee)\n\n    # Bitfield length matches total number of participants\n    assert len(attestation.aggregation_bits) == committee_offset\n\n    # Participation flag indices\n    participation_flag_indices = get_attestation_participation_flag_indices(\n        state, data, state.slot - data.slot\n    )\n\n    # Verify signature\n    assert is_valid_indexed_attestation(state, get_indexed_attestation(state, attestation))\n\n    # Update epoch participation flags\n    current_epoch_target = True\n    if data.target.epoch == get_current_epoch(state):\n        epoch_participation = state.current_epoch_participation\n        payment = state.builder_pending_payments[SLOTS_PER_EPOCH + data.slot % SLOTS_PER_EPOCH]\n    else:\n        epoch_participation = state.previous_epoch_participation\n        payment = state.builder_pending_payments[data.slot % SLOTS_PER_EPOCH]\n        current_epoch_target = False\n\n    proposer_reward_numerator = 0\n    for index in get_attesting_indices(state, attestation):\n        # [New in Gloas:EIP7732]\n        # For same-slot attestations, check if we're setting any new flags\n        # If we are, this validator hasn't contributed to this slot's quorum yet\n        will_set_new_flag = False\n\n        for flag_index, weight in enumerate(PARTICIPATION_FLAG_WEIGHTS):\n            if flag_index in participation_flag_indices and not has_flag(\n                epoch_participation[index], flag_index\n            ):\n                epoch_participation[index] = add_flag(epoch_participation[index], flag_index)\n                proposer_reward_numerator += get_base_reward(state, index) * weight\n                will_set_new_flag = True\n\n        # [New in Gloas:EIP7732]\n        # Add weight for same-slot attestations when any new flag is set\n        # This ensures each validator contributes exactly once per slot\n        if will_set_new_flag and is_attestation_same_slot(state, data):\n            payment.weight += state.validators[index].effective_balance\n\n    # Reward proposer\n    proposer_reward_denominator = (\n        (WEIGHT_DENOMINATOR - PROPOSER_WEIGHT) * WEIGHT_DENOMINATOR // PROPOSER_WEIGHT\n    )\n    proposer_reward = Gwei(proposer_reward_numerator // proposer_reward_denominator)\n    increase_balance(state, get_beacon_proposer_index(state), proposer_reward)\n    # Update builder payment weight\n\n    if current_epoch_target:\n        state.builder_pending_payments[SLOTS_PER_EPOCH + data.slot % SLOTS_PER_EPOCH] = payment\n    else:\n        state.builder_pending_payments[data.slot % SLOTS_PER_EPOCH] = payment\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#payload-attestations","title":"Payload Attestations","text":""},{"location":"specs/gloas/beacon-chain/#new-process_payload_attestation","title":"New <code>process_payload_attestation</code>","text":"<pre><code>def process_payload_attestation(\n    state: BeaconState, payload_attestation: PayloadAttestation\n) -&gt; None:\n    # Check that the attestation is for the parent beacon block\n    data = payload_attestation.data\n    assert data.beacon_block_root == state.latest_block_header.parent_root\n    # Check that the attestation is for the previous slot\n    assert data.slot + 1 == state.slot\n\n    # Verify signature\n    indexed_payload_attestation = get_indexed_payload_attestation(\n        state, data.slot, payload_attestation\n    )\n    assert is_valid_indexed_payload_attestation(state, indexed_payload_attestation)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#proposer-slashing","title":"Proposer Slashing","text":""},{"location":"specs/gloas/beacon-chain/#modified-process_proposer_slashing","title":"Modified <code>process_proposer_slashing</code>","text":"<pre><code>def process_proposer_slashing(state: BeaconState, proposer_slashing: ProposerSlashing) -&gt; None:\n    header_1 = proposer_slashing.signed_header_1.message\n    header_2 = proposer_slashing.signed_header_2.message\n\n    # Verify header slots match\n    assert header_1.slot == header_2.slot\n    # Verify header proposer indices match\n    assert header_1.proposer_index == header_2.proposer_index\n    # Verify the headers are different\n    assert header_1 != header_2\n    # Verify the proposer is slashable\n    proposer = state.validators[header_1.proposer_index]\n    assert is_slashable_validator(proposer, get_current_epoch(state))\n    # Verify signatures\n    for signed_header in (proposer_slashing.signed_header_1, proposer_slashing.signed_header_2):\n        domain = get_domain(\n            state, DOMAIN_BEACON_PROPOSER, compute_epoch_at_slot(signed_header.message.slot)\n        )\n        signing_root = compute_signing_root(signed_header.message, domain)\n        assert bls.Verify(proposer.pubkey, signing_root, signed_header.signature)\n\n    # [New in Gloas:EIP7732]\n    # Remove the BuilderPendingPayment corresponding to\n    # this proposal if it is still in the 2-epoch window.\n    slot = header_1.slot\n    proposal_epoch = compute_epoch_at_slot(slot)\n    if proposal_epoch == get_current_epoch(state):\n        payment_index = SLOTS_PER_EPOCH + slot % SLOTS_PER_EPOCH\n        state.builder_pending_payments[payment_index] = BuilderPendingPayment()\n    elif proposal_epoch == get_previous_epoch(state):\n        payment_index = slot % SLOTS_PER_EPOCH\n        state.builder_pending_payments[payment_index] = BuilderPendingPayment()\n\n    slash_validator(state, header_1.proposer_index)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#modified-is_merge_transition_complete","title":"Modified <code>is_merge_transition_complete</code>","text":"<p><code>is_merge_transition_complete</code> is modified only for testing purposes to add the blob kzg commitments root for an empty list</p> <pre><code>def is_merge_transition_complete(state: BeaconState) -&gt; bool:\n    bid = ExecutionPayloadBid()\n    kzgs = List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK]()\n    bid.blob_kzg_commitments_root = kzgs.hash_tree_root()\n\n    return state.latest_execution_payload_bid != bid\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#modified-validate_merge_block","title":"Modified <code>validate_merge_block</code>","text":"<p><code>validate_merge_block</code> is modified to use the new <code>signed_execution_payload_bid</code> message in the Beacon Block Body</p> <pre><code>def validate_merge_block(block: BeaconBlock) -&gt; None:\n    \"\"\"\n    Check the parent PoW block of execution payload is a valid terminal PoW block.\n\n    Note: Unavailable PoW block(s) may later become available,\n    and a client software MAY delay a call to ``validate_merge_block``\n    until the PoW block(s) become available.\n    \"\"\"\n    if TERMINAL_BLOCK_HASH != Hash32():\n        # If `TERMINAL_BLOCK_HASH` is used as an override, the activation epoch must be reached.\n        assert compute_epoch_at_slot(block.slot) &gt;= TERMINAL_BLOCK_HASH_ACTIVATION_EPOCH\n        assert (\n            block.body.signed_execution_payload_bid.message.parent_block_hash == TERMINAL_BLOCK_HASH\n        )\n        return\n\n    # [Modified in Gloas:EIP7732]\n    pow_block = get_pow_block(block.body.signed_execution_payload_bid.message.parent_block_hash)\n    # Check if `pow_block` is available\n    assert pow_block is not None\n    pow_parent = get_pow_block(pow_block.parent_hash)\n    # Check if `pow_parent` is available\n    assert pow_parent is not None\n    # Check if `pow_block` is a valid terminal PoW block\n    assert is_valid_terminal_pow_block(pow_block, pow_parent)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#execution-payload-processing","title":"Execution payload processing","text":""},{"location":"specs/gloas/beacon-chain/#new-verify_execution_payload_envelope_signature","title":"New <code>verify_execution_payload_envelope_signature</code>","text":"<pre><code>def verify_execution_payload_envelope_signature(\n    state: BeaconState, signed_envelope: SignedExecutionPayloadEnvelope\n) -&gt; bool:\n    builder = state.validators[signed_envelope.message.builder_index]\n    signing_root = compute_signing_root(\n        signed_envelope.message, get_domain(state, DOMAIN_BEACON_BUILDER)\n    )\n    return bls.Verify(builder.pubkey, signing_root, signed_envelope.signature)\n</code></pre>"},{"location":"specs/gloas/beacon-chain/#new-process_execution_payload","title":"New <code>process_execution_payload</code>","text":"<p>Note: <code>process_execution_payload</code> is now an independent check in state transition. It is called when importing a signed execution payload proposed by the builder of the current slot.</p> <pre><code>def process_execution_payload(\n    state: BeaconState,\n    signed_envelope: SignedExecutionPayloadEnvelope,\n    execution_engine: ExecutionEngine,\n    verify: bool = True,\n) -&gt; None:\n    # Verify signature\n    if verify:\n        assert verify_execution_payload_envelope_signature(state, signed_envelope)\n    envelope = signed_envelope.message\n    payload = envelope.payload\n    # Cache latest block header state root\n    previous_state_root = hash_tree_root(state)\n    if state.latest_block_header.state_root == Root():\n        state.latest_block_header.state_root = previous_state_root\n\n    # Verify consistency with the beacon block\n    assert envelope.beacon_block_root == hash_tree_root(state.latest_block_header)\n    assert envelope.slot == state.slot\n\n    # Verify consistency with the committed bid\n    committed_bid = state.latest_execution_payload_bid\n    assert envelope.builder_index == committed_bid.builder_index\n    assert committed_bid.blob_kzg_commitments_root == hash_tree_root(envelope.blob_kzg_commitments)\n\n    # Verify the withdrawals root\n    assert hash_tree_root(payload.withdrawals) == state.latest_withdrawals_root\n\n    # Verify the gas_limit\n    assert committed_bid.gas_limit == payload.gas_limit\n    # Verify the block hash\n    assert committed_bid.block_hash == payload.block_hash\n    # Verify consistency of the parent hash with respect to the previous execution payload\n    assert payload.parent_hash == state.latest_block_hash\n    # Verify prev_randao\n    assert payload.prev_randao == get_randao_mix(state, get_current_epoch(state))\n    # Verify timestamp\n    assert payload.timestamp == compute_time_at_slot(state, state.slot)\n    # Verify commitments are under limit\n    assert (\n        len(envelope.blob_kzg_commitments)\n        &lt;= get_blob_parameters(get_current_epoch(state)).max_blobs_per_block\n    )\n    # Verify the execution payload is valid\n    versioned_hashes = [\n        kzg_commitment_to_versioned_hash(commitment) for commitment in envelope.blob_kzg_commitments\n    ]\n    requests = envelope.execution_requests\n    assert execution_engine.verify_and_notify_new_payload(\n        NewPayloadRequest(\n            execution_payload=payload,\n            versioned_hashes=versioned_hashes,\n            parent_beacon_block_root=state.latest_block_header.parent_root,\n            execution_requests=requests,\n        )\n    )\n\n    def for_ops(operations: Sequence[Any], fn: Callable[[BeaconState, Any], None]) -&gt; None:\n        for operation in operations:\n            fn(state, operation)\n\n    for_ops(requests.deposits, process_deposit_request)\n    for_ops(requests.withdrawals, process_withdrawal_request)\n    for_ops(requests.consolidations, process_consolidation_request)\n\n    # Queue the builder payment\n    payment = state.builder_pending_payments[SLOTS_PER_EPOCH + state.slot % SLOTS_PER_EPOCH]\n    amount = payment.withdrawal.amount\n    if amount &gt; 0:\n        exit_queue_epoch = compute_exit_epoch_and_update_churn(state, amount)\n        payment.withdrawal.withdrawable_epoch = Epoch(\n            exit_queue_epoch + MIN_VALIDATOR_WITHDRAWABILITY_DELAY\n        )\n        state.builder_pending_withdrawals.append(payment.withdrawal)\n    state.builder_pending_payments[SLOTS_PER_EPOCH + state.slot % SLOTS_PER_EPOCH] = (\n        BuilderPendingPayment()\n    )\n\n    # Cache the execution payload hash\n    state.execution_payload_availability[state.slot % SLOTS_PER_HISTORICAL_ROOT] = 0b1\n    state.latest_block_hash = payload.block_hash\n\n    # Verify the state root\n    if verify:\n        assert envelope.state_root == hash_tree_root(state)\n</code></pre>"},{"location":"specs/gloas/builder/","title":"Gloas -- Honest Builder","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Becoming a builder</li> <li>Builder withdrawal credentials</li> <li>Submit deposit</li> <li>Process deposit</li> <li>Builder index</li> <li>Activation</li> <li>Builders attributions</li> <li>Constructing the payload bid</li> <li>Constructing the <code>DataColumnSidecar</code>s<ul> <li>Modified <code>get_data_column_sidecars</code></li> <li>Modified <code>get_data_column_sidecars_from_block</code></li> </ul> </li> <li>Constructing the execution payload envelope</li> <li>Honest payload withheld messages</li> </ul>"},{"location":"specs/gloas/builder/#introduction","title":"Introduction","text":"<p>This is an accompanying document which describes the expected actions of a \"builder\" participating in the Ethereum proof-of-stake protocol.</p> <p>With the Gloas fork, the protocol includes new staked participants of the protocol called Builders. While Builders are a subset of the validator set, they have extra attributions that are optional. Validators may opt to not be builders and as such we collect the set of guidelines for those validators that want to act as builders in this document.</p>"},{"location":"specs/gloas/builder/#becoming-a-builder","title":"Becoming a builder","text":""},{"location":"specs/gloas/builder/#builder-withdrawal-credentials","title":"Builder withdrawal credentials","text":"<p>The <code>withdrawal_credentials</code> field for builders has a specific format that identifies them as registered builders in the network. Builders must use the <code>BUILDER_WITHDRAWAL_PREFIX</code> to participate in the Gloas mechanism.</p> <p>The <code>withdrawal_credentials</code> field must be such that:</p> <ul> <li><code>withdrawal_credentials[:1] == BUILDER_WITHDRAWAL_PREFIX</code> (i.e., <code>0x03</code>)</li> <li><code>withdrawal_credentials[1:12] == b'\\x00' * 11</code></li> <li><code>withdrawal_credentials[12:] == builder_execution_address</code></li> </ul> <p>Where <code>builder_execution_address</code> is a 20-byte execution layer address that will receive:</p> <ul> <li>Withdrawal rewards (similar to <code>ETH1_ADDRESS_WITHDRAWAL_PREFIX</code>)</li> <li>Compounding rewards (builders inherit compounding functionality)</li> </ul>"},{"location":"specs/gloas/builder/#submit-deposit","title":"Submit deposit","text":"<p>Builders follow the same deposit process as regular validators, but with the builder-specific withdrawal credentials. The deposit must include:</p> <ul> <li><code>pubkey</code>: The builder's BLS public key</li> <li><code>withdrawal_credentials</code>: Set with <code>BUILDER_WITHDRAWAL_PREFIX</code> (<code>0x03</code>)</li> <li><code>amount</code>: At least <code>MIN_DEPOSIT_AMOUNT</code></li> <li><code>signature</code>: BLS signature over the deposit data</li> </ul>"},{"location":"specs/gloas/builder/#process-deposit","title":"Process deposit","text":"<p>The beacon chain processes builder deposits identically to validator deposits, with the withdrawal credentials using <code>BUILDER_WITHDRAWAL_PREFIX</code>.</p>"},{"location":"specs/gloas/builder/#builder-index","title":"Builder index","text":"<p>Once the deposit is processed, the builder is assigned a unique <code>validator_index</code> within the validator registry. This index is used to identify the builder in execution payload bids and envelopes.</p>"},{"location":"specs/gloas/builder/#activation","title":"Activation","text":"<p>Builder activation follows the same process as validator activation.</p>"},{"location":"specs/gloas/builder/#builders-attributions","title":"Builders attributions","text":"<p>Builders can submit bids to produce execution payloads. They can broadcast these bids in the form of <code>SignedExecutionPayloadBid</code> objects, these objects encode a commitment to reveal an execution payload in exchange for a payment. When their bids are chosen by the corresponding proposer, builders are expected to broadcast an accompanying <code>SignedExecutionPayloadEnvelope</code> object honoring the commitment.</p> <p>Thus, builders tasks are divided in two, submitting bids, and submitting payloads.</p>"},{"location":"specs/gloas/builder/#constructing-the-payload-bid","title":"Constructing the payload bid","text":"<p>Builders can broadcast a payload bid for the current or the next slot's proposer to include. They produce a <code>SignedExecutionPayloadBid</code> as follows.</p> <ol> <li>Set <code>bid.parent_block_hash</code> to the current head of the execution chain (this     can be obtained from the beacon state as <code>state.latest_block_hash</code>).</li> <li>Set <code>bid.parent_block_root</code> to be the head of the consensus chain (this can     be obtained from the beacon state as     <code>hash_tree_root(state.latest_block_header)</code>. The <code>parent_block_root</code> and     <code>parent_block_hash</code> must be compatible, in the sense that they both should     come from the same <code>state</code> by the method described in this and the previous     point.</li> <li>Construct an execution payload. This can be performed with an external     execution engine with a call to <code>engine_getPayloadV4</code>.</li> <li>Set <code>bid.block_hash</code> to be the block hash of the constructed payload, that     is <code>payload.block_hash</code>.</li> <li>Set <code>bid.gas_limit</code> to be the gas limit of the constructed payload, that is     <code>payload.gas_limit</code>.</li> <li>Set <code>bid.builder_index</code> to be the validator index of the builder performing     these actions.</li> <li>Set <code>bid.slot</code> to be the slot for which this bid is aimed. This slot     MUST be either the current slot or the next slot.</li> <li>Set <code>bid.value</code> to be the value that the builder will pay the proposer if     the bid is accepted. The builder MUST have enough balance to fulfill     this bid and all pending payments.</li> <li>Set <code>bid.kzg_commitments_root</code> to be the <code>hash_tree_root</code> of the     <code>blobsbundle.commitments</code> field returned by <code>engine_getPayloadV4</code>.</li> <li>Set <code>bid.fee_recipient</code> to be an execution address to receive the payment.     This address can be obtained from the proposer directly via a request or can     be set from the withdrawal credentials of the proposer. The burn address can     be used as a fallback.</li> </ol> <p>After building the <code>bid</code>, the builder obtains a <code>signature</code> of the bid by using</p> <pre><code>def get_execution_payload_bid_signature(\n    state: BeaconState, bid: ExecutionPayloadBid, privkey: int\n) -&gt; BLSSignature:\n    domain = get_domain(state, DOMAIN_BEACON_BUILDER, compute_epoch_at_slot(bid.slot))\n    signing_root = compute_signing_root(bid, domain)\n    return bls.Sign(privkey, signing_root)\n</code></pre> <p>The builder assembles then <code>signed_execution_payload_bid = SignedExecutionPayloadBid(message=bid, signature=signature)</code> and broadcasts it on the <code>execution_payload_bid</code> global gossip topic.</p>"},{"location":"specs/gloas/builder/#constructing-the-datacolumnsidecars","title":"Constructing the <code>DataColumnSidecar</code>s","text":""},{"location":"specs/gloas/builder/#modified-get_data_column_sidecars","title":"Modified <code>get_data_column_sidecars</code>","text":"<p>Note: The function <code>get_data_column_sidecars</code> is modified to remove <code>signed_block_header</code> and <code>kzg_commitments_inclusion_proof</code> parameters as header and inclusion proof verifications are no longer required in ePBS.</p> <pre><code>def get_data_column_sidecars(\n    beacon_block_root: Root,\n    kzg_commitments: List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK],\n    cells_and_kzg_proofs: Sequence[\n        Tuple[Vector[Cell, CELLS_PER_EXT_BLOB], Vector[KZGProof, CELLS_PER_EXT_BLOB]]\n    ],\n) -&gt; Sequence[DataColumnSidecar]:\n    \"\"\"\n    Given a beacon block root and the commitments, cells/proofs associated with\n    each blob in the block, assemble the sidecars which can be distributed to peers.\n    \"\"\"\n    assert len(cells_and_kzg_proofs) == len(kzg_commitments)\n\n    sidecars = []\n    for column_index in range(NUMBER_OF_COLUMNS):\n        column_cells, column_proofs = [], []\n        for cells, proofs in cells_and_kzg_proofs:\n            column_cells.append(cells[column_index])\n            column_proofs.append(proofs[column_index])\n        sidecars.append(\n            DataColumnSidecar(\n                index=column_index,\n                column=column_cells,\n                kzg_commitments=kzg_commitments,\n                kzg_proofs=column_proofs,\n                beacon_block_root=beacon_block_root,\n            )\n        )\n    return sidecars\n</code></pre>"},{"location":"specs/gloas/builder/#modified-get_data_column_sidecars_from_block","title":"Modified <code>get_data_column_sidecars_from_block</code>","text":"<p>Note: The function <code>get_data_column_sidecars_from_block</code> is modified to include the list of blob KZG commitments and to use <code>beacon_block_root</code> instead of header and inclusion proof computations.</p> <pre><code>def get_data_column_sidecars_from_block(\n    signed_block: SignedBeaconBlock,\n    # [New in Gloas:EIP7732]\n    blob_kzg_commitments: List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK],\n    cells_and_kzg_proofs: Sequence[\n        Tuple[Vector[Cell, CELLS_PER_EXT_BLOB], Vector[KZGProof, CELLS_PER_EXT_BLOB]]\n    ],\n) -&gt; Sequence[DataColumnSidecar]:\n    \"\"\"\n    Given a signed block and the cells/proofs associated with each blob in the\n    block, assemble the sidecars which can be distributed to peers.\n    \"\"\"\n    beacon_block_root = hash_tree_root(signed_block.message)\n    return get_data_column_sidecars(\n        beacon_block_root,\n        blob_kzg_commitments,\n        cells_and_kzg_proofs,\n    )\n</code></pre>"},{"location":"specs/gloas/builder/#constructing-the-execution-payload-envelope","title":"Constructing the execution payload envelope","text":"<p>When the proposer publishes a valid <code>SignedBeaconBlock</code> containing a signed commitment by the builder, the builder is later expected to broadcast the corresponding <code>SignedExecutionPayloadEnvelope</code> that fulfills this commitment. See below for a special case of an honestly withheld payload.</p> <p>To construct the <code>execution_payload_envelope</code> the builder must perform the following steps. We alias <code>block</code> to be the corresponding beacon block and alias <code>bid</code> to be the committed <code>ExecutionPayloadBid</code> in <code>block.body.signed_execution_payload_bid.message</code>.</p> <ol> <li>Set the <code>payload</code> field to be the <code>ExecutionPayload</code> constructed when    creating the corresponding bid. This payload MUST have the same block    hash as <code>bid.block_hash</code>.</li> <li>Set the <code>execution_requests</code> field to be the <code>ExecutionRequests</code> associated    with <code>payload</code>.</li> <li>Set the <code>builder_index</code> field to be the validator index of the builder    performing these steps. This field MUST be <code>bid.builder_index</code>.</li> <li>Set <code>beacon_block_root</code> to be <code>hash_tree_root(block)</code>.</li> <li>Set <code>slot</code> to be <code>block.slot</code>.</li> <li>Set <code>blob_kzg_commitments</code> to be the <code>commitments</code> field of the blobs bundle    constructed when constructing the bid. This field MUST have a    <code>hash_tree_root</code> equal to <code>bid.blob_kzg_commitments_root</code>.</li> </ol> <p>After setting these parameters, the builder should run <code>process_execution_payload(state, signed_envelope, verify=False)</code> and this function should not trigger an exception.</p> <ol> <li>Set <code>state_root</code> to <code>hash_tree_root(state)</code>.</li> </ol> <p>After preparing the <code>envelope</code> the builder should sign the envelope using:</p> <pre><code>def get_execution_payload_envelope_signature(\n    state: BeaconState, envelope: ExecutionPayloadEnvelope, privkey: int\n) -&gt; BLSSignature:\n    domain = get_domain(state, DOMAIN_BEACON_BUILDER, compute_epoch_at_slot(state.slot))\n    signing_root = compute_signing_root(envelope, domain)\n    return bls.Sign(privkey, signing_root)\n</code></pre> <p>The builder assembles then <code>signed_execution_payload_envelope = SignedExecutionPayloadEnvelope(message=envelope, signature=signature)</code> and broadcasts it on the <code>execution_payload</code> global gossip topic.</p>"},{"location":"specs/gloas/builder/#honest-payload-withheld-messages","title":"Honest payload withheld messages","text":"<p>An honest builder that has seen a <code>SignedBeaconBlock</code> referencing his signed bid, but that block was not timely and thus it is not the head of the builder's chain, may choose to withhold their execution payload. For this the builder should act as if no block was produced and not broadcast the payload.</p>"},{"location":"specs/gloas/fork-choice/","title":"Gloas -- Fork Choice","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Custom types</li> <li>Constants</li> <li>Containers</li> <li>New <code>ForkChoiceNode</code></li> <li>Modified <code>LatestMessage</code></li> <li>Modified <code>update_latest_messages</code></li> <li>Modified <code>Store</code></li> <li>Modified <code>get_forkchoice_store</code></li> <li>New <code>notify_ptc_messages</code></li> <li>New <code>is_payload_timely</code></li> <li>New <code>get_parent_payload_status</code></li> <li>New <code>is_parent_node_full</code></li> <li>Modified <code>get_ancestor</code></li> <li>Modified <code>get_checkpoint_block</code></li> <li>New <code>is_supporting_vote</code></li> <li>New <code>should_extend_payload</code></li> <li>New <code>get_payload_status_tiebreaker</code></li> <li>Modified <code>get_weight</code></li> <li>New <code>get_node_children</code></li> <li>Modified <code>get_head</code></li> <li>Updated fork-choice handlers</li> <li>Modified <code>on_block</code></li> <li>New fork-choice handlers</li> <li>New <code>on_execution_payload</code></li> <li>New <code>on_payload_attestation_message</code></li> <li>Modified <code>validate_on_attestation</code></li> <li>Modified <code>validate_merge_block</code></li> </ul>"},{"location":"specs/gloas/fork-choice/#introduction","title":"Introduction","text":"<p>This is the modification of the fork-choice accompanying the Gloas upgrade.</p>"},{"location":"specs/gloas/fork-choice/#custom-types","title":"Custom types","text":"Name SSZ equivalent Description <code>PayloadStatus</code> <code>uint8</code> Possible status of a payload in the fork-choice"},{"location":"specs/gloas/fork-choice/#constants","title":"Constants","text":"Name Value <code>PAYLOAD_TIMELY_THRESHOLD</code> <code>PTC_SIZE // 2</code> (= 256) <code>PAYLOAD_STATUS_PENDING</code> <code>PayloadStatus(0)</code> <code>PAYLOAD_STATUS_EMPTY</code> <code>PayloadStatus(1)</code> <code>PAYLOAD_STATUS_FULL</code> <code>PayloadStatus(2)</code>"},{"location":"specs/gloas/fork-choice/#containers","title":"Containers","text":""},{"location":"specs/gloas/fork-choice/#new-forkchoicenode","title":"New <code>ForkChoiceNode</code>","text":"<pre><code>class ForkChoiceNode(Container):\n    root: Root\n    payload_status: PayloadStatus  # One of PAYLOAD_STATUS_* values\n</code></pre>"},{"location":"specs/gloas/fork-choice/#modified-latestmessage","title":"Modified <code>LatestMessage</code>","text":"<p>Note: The class is modified to keep track of the slot instead of the epoch.</p> <pre><code>@dataclass(eq=True, frozen=True)\nclass LatestMessage(object):\n    slot: Slot\n    root: Root\n    payload_present: boolean\n</code></pre>"},{"location":"specs/gloas/fork-choice/#modified-update_latest_messages","title":"Modified <code>update_latest_messages</code>","text":"<p>Note: the function <code>update_latest_messages</code> is updated to use the attestation slot instead of target. Notice that this function is only called on validated attestations and validators cannot attest twice in the same epoch without equivocating. Notice also that target epoch number and slot number are validated on <code>validate_on_attestation</code>.</p> <pre><code>def update_latest_messages(\n    store: Store, attesting_indices: Sequence[ValidatorIndex], attestation: Attestation\n) -&gt; None:\n    slot = attestation.data.slot\n    beacon_block_root = attestation.data.beacon_block_root\n    payload_present = attestation.data.index == 1\n    non_equivocating_attesting_indices = [\n        i for i in attesting_indices if i not in store.equivocating_indices\n    ]\n    for i in non_equivocating_attesting_indices:\n        if i not in store.latest_messages or slot &gt; store.latest_messages[i].slot:\n            store.latest_messages[i] = LatestMessage(\n                slot=slot, root=beacon_block_root, payload_present=payload_present\n            )\n</code></pre>"},{"location":"specs/gloas/fork-choice/#modified-store","title":"Modified <code>Store</code>","text":"<p>Note: <code>Store</code> is modified to track the intermediate states of \"empty\" consensus blocks, that is, those consensus blocks for which the corresponding execution payload has not been revealed or has not been included on chain.</p> <pre><code>@dataclass\nclass Store(object):\n    time: uint64\n    genesis_time: uint64\n    justified_checkpoint: Checkpoint\n    finalized_checkpoint: Checkpoint\n    unrealized_justified_checkpoint: Checkpoint\n    unrealized_finalized_checkpoint: Checkpoint\n    proposer_boost_root: Root\n    equivocating_indices: Set[ValidatorIndex]\n    blocks: Dict[Root, BeaconBlock] = field(default_factory=dict)\n    block_states: Dict[Root, BeaconState] = field(default_factory=dict)\n    block_timeliness: Dict[Root, boolean] = field(default_factory=dict)\n    checkpoint_states: Dict[Checkpoint, BeaconState] = field(default_factory=dict)\n    latest_messages: Dict[ValidatorIndex, LatestMessage] = field(default_factory=dict)\n    unrealized_justifications: Dict[Root, Checkpoint] = field(default_factory=dict)\n    # [New in Gloas:EIP7732]\n    execution_payload_states: Dict[Root, BeaconState] = field(default_factory=dict)\n    # [New in Gloas:EIP7732]\n    ptc_vote: Dict[Root, Vector[boolean, PTC_SIZE]] = field(default_factory=dict)\n</code></pre>"},{"location":"specs/gloas/fork-choice/#modified-get_forkchoice_store","title":"Modified <code>get_forkchoice_store</code>","text":"<pre><code>def get_forkchoice_store(anchor_state: BeaconState, anchor_block: BeaconBlock) -&gt; Store:\n    assert anchor_block.state_root == hash_tree_root(anchor_state)\n    anchor_root = hash_tree_root(anchor_block)\n    anchor_epoch = get_current_epoch(anchor_state)\n    justified_checkpoint = Checkpoint(epoch=anchor_epoch, root=anchor_root)\n    finalized_checkpoint = Checkpoint(epoch=anchor_epoch, root=anchor_root)\n    proposer_boost_root = Root()\n    return Store(\n        time=uint64(anchor_state.genesis_time + SECONDS_PER_SLOT * anchor_state.slot),\n        genesis_time=anchor_state.genesis_time,\n        justified_checkpoint=justified_checkpoint,\n        finalized_checkpoint=finalized_checkpoint,\n        unrealized_justified_checkpoint=justified_checkpoint,\n        unrealized_finalized_checkpoint=finalized_checkpoint,\n        proposer_boost_root=proposer_boost_root,\n        equivocating_indices=set(),\n        blocks={anchor_root: copy(anchor_block)},\n        block_states={anchor_root: copy(anchor_state)},\n        checkpoint_states={justified_checkpoint: copy(anchor_state)},\n        unrealized_justifications={anchor_root: justified_checkpoint},\n        # [New in Gloas:EIP7732]\n        execution_payload_states={anchor_root: copy(anchor_state)},\n        ptc_vote={anchor_root: Vector[boolean, PTC_SIZE]()},\n    )\n</code></pre>"},{"location":"specs/gloas/fork-choice/#new-notify_ptc_messages","title":"New <code>notify_ptc_messages</code>","text":"<pre><code>def notify_ptc_messages(\n    store: Store, state: BeaconState, payload_attestations: Sequence[PayloadAttestation]\n) -&gt; None:\n    \"\"\"\n    Extracts a list of ``PayloadAttestationMessage`` from ``payload_attestations`` and updates the store with them\n    These Payload attestations are assumed to be in the beacon block hence signature verification is not needed\n    \"\"\"\n    if state.slot == 0:\n        return\n    for payload_attestation in payload_attestations:\n        indexed_payload_attestation = get_indexed_payload_attestation(\n            state, Slot(state.slot - 1), payload_attestation\n        )\n        for idx in indexed_payload_attestation.attesting_indices:\n            on_payload_attestation_message(\n                store,\n                PayloadAttestationMessage(\n                    validator_index=idx,\n                    data=payload_attestation.data,\n                    signature=BLSSignature(),\n                ),\n                is_from_block=True,\n            )\n</code></pre>"},{"location":"specs/gloas/fork-choice/#new-is_payload_timely","title":"New <code>is_payload_timely</code>","text":"<pre><code>def is_payload_timely(store: Store, root: Root) -&gt; bool:\n    \"\"\"\n    Return whether the execution payload for the beacon block with root ``root``\n    was voted as present by the PTC, and was locally determined to be available.\n    \"\"\"\n    # The beacon block root must be known\n    assert root in store.ptc_vote\n\n    # If the payload is not locally available, the payload\n    # is not considered available regardless of the PTC vote\n    if root not in store.execution_payload_states:\n        return False\n\n    return sum(store.ptc_vote[root]) &gt; PAYLOAD_TIMELY_THRESHOLD\n</code></pre>"},{"location":"specs/gloas/fork-choice/#new-get_parent_payload_status","title":"New <code>get_parent_payload_status</code>","text":"<pre><code>def get_parent_payload_status(store: Store, block: BeaconBlock) -&gt; PayloadStatus:\n    parent = store.blocks[block.parent_root]\n    parent_block_hash = block.body.signed_execution_payload_bid.message.parent_block_hash\n    message_block_hash = parent.body.signed_execution_payload_bid.message.block_hash\n    return PAYLOAD_STATUS_FULL if parent_block_hash == message_block_hash else PAYLOAD_STATUS_EMPTY\n</code></pre>"},{"location":"specs/gloas/fork-choice/#new-is_parent_node_full","title":"New <code>is_parent_node_full</code>","text":"<pre><code>def is_parent_node_full(store: Store, block: BeaconBlock) -&gt; bool:\n    return get_parent_payload_status(store, block) == PAYLOAD_STATUS_FULL\n</code></pre>"},{"location":"specs/gloas/fork-choice/#modified-get_ancestor","title":"Modified <code>get_ancestor</code>","text":"<p>Note: <code>get_ancestor</code> is modified to return whether the chain is based on an empty or full block.</p> <pre><code>def get_ancestor(store: Store, root: Root, slot: Slot) -&gt; ForkChoiceNode:\n    \"\"\"\n    Returns the beacon block root and the payload status of the ancestor of the beacon block\n    with ``root`` at ``slot``. If the beacon block with ``root`` is already at ``slot`` or we are\n    requesting an ancestor \"in the future\", it returns ``PAYLOAD_STATUS_PENDING``.\n    \"\"\"\n    block = store.blocks[root]\n    if block.slot &lt;= slot:\n        return ForkChoiceNode(root=root, payload_status=PAYLOAD_STATUS_PENDING)\n\n    parent = store.blocks[block.parent_root]\n    if parent.slot &gt; slot:\n        return get_ancestor(store, block.parent_root, slot)\n    else:\n        return ForkChoiceNode(\n            root=block.parent_root,\n            payload_status=get_parent_payload_status(store, block),\n        )\n</code></pre>"},{"location":"specs/gloas/fork-choice/#modified-get_checkpoint_block","title":"Modified <code>get_checkpoint_block</code>","text":"<p>Note: <code>get_checkpoint_block</code> is modified to use the new <code>get_ancestor</code></p> <pre><code>def get_checkpoint_block(store: Store, root: Root, epoch: Epoch) -&gt; Root:\n    \"\"\"\n    Compute the checkpoint block for epoch ``epoch`` in the chain of block ``root``\n    \"\"\"\n    epoch_first_slot = compute_start_slot_at_epoch(epoch)\n    return get_ancestor(store, root, epoch_first_slot).root\n</code></pre>"},{"location":"specs/gloas/fork-choice/#new-is_supporting_vote","title":"New <code>is_supporting_vote</code>","text":"<pre><code>def is_supporting_vote(store: Store, node: ForkChoiceNode, message: LatestMessage) -&gt; bool:\n    \"\"\"\n    Returns whether a vote for ``message.root`` supports the chain containing the beacon block ``node.root`` with the\n    payload contents indicated by ``node.payload_status`` as head during slot ``node.slot``.\n    \"\"\"\n    block = store.blocks[node.root]\n    if node.root == message.root:\n        if node.payload_status == PAYLOAD_STATUS_PENDING:\n            return True\n        if message.slot &lt;= block.slot:\n            return False\n        if message.payload_present:\n            return node.payload_status == PAYLOAD_STATUS_FULL\n        else:\n            return node.payload_status == PAYLOAD_STATUS_EMPTY\n\n    else:\n        ancestor = get_ancestor(store, message.root, block.slot)\n        return node.root == ancestor.root and (\n            node.payload_status == PAYLOAD_STATUS_PENDING\n            or node.payload_status == ancestor.payload_status\n        )\n</code></pre>"},{"location":"specs/gloas/fork-choice/#new-should_extend_payload","title":"New <code>should_extend_payload</code>","text":"<p>Note: <code>should_extend_payload</code> decides whether to extend an available payload from the previous slot, corresponding to the beacon block <code>root</code>. We extend it if a majority of the PTC has voted for it. If not, we also extend it if the proposer boost root is not set, set to something conflicting with the given root, or to something extending the payload.</p> <pre><code>def should_extend_payload(store: Store, root: Root) -&gt; bool:\n    proposer_root = store.proposer_boost_root\n    return (\n        is_payload_timely(store, root)\n        or proposer_root == Root()\n        or store.blocks[proposer_root].parent_root != root\n        or is_parent_node_full(store, store.blocks[proposer_root])\n    )\n</code></pre>"},{"location":"specs/gloas/fork-choice/#new-get_payload_status_tiebreaker","title":"New <code>get_payload_status_tiebreaker</code>","text":"<pre><code>def get_payload_status_tiebreaker(store: Store, node: ForkChoiceNode) -&gt; uint8:\n    if node.payload_status == PAYLOAD_STATUS_PENDING or store.blocks[\n        node.root\n    ].slot + 1 != get_current_slot(store):\n        return node.payload_status\n    else:\n        # To decide on a payload from the previous slot, choose\n        # between FULL and EMPTY based on `should_extend_payload`\n        if node.payload_status == PAYLOAD_STATUS_EMPTY:\n            return 1\n        else:\n            return 2 if should_extend_payload(store, node.root) else 0\n</code></pre>"},{"location":"specs/gloas/fork-choice/#modified-get_weight","title":"Modified <code>get_weight</code>","text":"<pre><code>def get_weight(store: Store, node: ForkChoiceNode) -&gt; Gwei:\n    if node.payload_status == PAYLOAD_STATUS_PENDING or store.blocks[\n        node.root\n    ].slot + 1 != get_current_slot(store):\n        state = store.checkpoint_states[store.justified_checkpoint]\n        unslashed_and_active_indices = [\n            i\n            for i in get_active_validator_indices(state, get_current_epoch(state))\n            if not state.validators[i].slashed\n        ]\n        attestation_score = Gwei(\n            sum(\n                state.validators[i].effective_balance\n                for i in unslashed_and_active_indices\n                if (\n                    i in store.latest_messages\n                    and i not in store.equivocating_indices\n                    and is_supporting_vote(store, node, store.latest_messages[i])\n                )\n            )\n        )\n\n        if store.proposer_boost_root == Root():\n            # Return only attestation score if `proposer_boost_root` is not set\n            return attestation_score\n\n        # Calculate proposer score if `proposer_boost_root` is set\n        proposer_score = Gwei(0)\n\n        # `proposer_boost_root` is treated as a vote for the\n        # proposer's block in the current slot. Proposer boost\n        # is applied accordingly to all ancestors\n        message = LatestMessage(\n            slot=get_current_slot(store),\n            root=store.proposer_boost_root,\n            payload_present=False,\n        )\n        if is_supporting_vote(store, node, message):\n            proposer_score = get_proposer_score(store)\n\n        return attestation_score + proposer_score\n    else:\n        return Gwei(0)\n</code></pre>"},{"location":"specs/gloas/fork-choice/#new-get_node_children","title":"New <code>get_node_children</code>","text":"<pre><code>def get_node_children(\n    store: Store, blocks: Dict[Root, BeaconBlock], node: ForkChoiceNode\n) -&gt; Sequence[ForkChoiceNode]:\n    if node.payload_status == PAYLOAD_STATUS_PENDING:\n        children = [ForkChoiceNode(root=node.root, payload_status=PAYLOAD_STATUS_EMPTY)]\n        if node.root in store.execution_payload_states:\n            children.append(ForkChoiceNode(root=node.root, payload_status=PAYLOAD_STATUS_FULL))\n        return children\n    else:\n        return [\n            ForkChoiceNode(root=root, payload_status=PAYLOAD_STATUS_PENDING)\n            for root in blocks.keys()\n            if (\n                blocks[root].parent_root == node.root\n                and node.payload_status == get_parent_payload_status(store, blocks[root])\n            )\n        ]\n</code></pre>"},{"location":"specs/gloas/fork-choice/#modified-get_head","title":"Modified <code>get_head</code>","text":"<p>Note: <code>get_head</code> is a modified to use the new <code>get_weight</code> function. It returns the <code>ForkChoiceNode</code> object corresponding to the head block.</p> <pre><code>def get_head(store: Store) -&gt; ForkChoiceNode:\n    # Get filtered block tree that only includes viable branches\n    blocks = get_filtered_block_tree(store)\n    # Execute the LMD-GHOST fork-choice\n    head = ForkChoiceNode(\n        root=store.justified_checkpoint.root,\n        payload_status=PAYLOAD_STATUS_PENDING,\n    )\n\n    while True:\n        children = get_node_children(store, blocks, head)\n        if len(children) == 0:\n            return head\n        # Sort by latest attesting balance with ties broken lexicographically\n        head = max(\n            children,\n            key=lambda child: (\n                get_weight(store, child),\n                child.root,\n                get_payload_status_tiebreaker(store, child),\n            ),\n        )\n</code></pre>"},{"location":"specs/gloas/fork-choice/#updated-fork-choice-handlers","title":"Updated fork-choice handlers","text":""},{"location":"specs/gloas/fork-choice/#modified-on_block","title":"Modified <code>on_block</code>","text":"<p>Note: The handler <code>on_block</code> is modified to consider the pre <code>state</code> of the given consensus beacon block depending not only on the parent block root, but also on the parent blockhash. In addition we delay the checking of blob data availability until the processing of the execution payload.</p> <pre><code>def on_block(store: Store, signed_block: SignedBeaconBlock) -&gt; None:\n    \"\"\"\n    Run ``on_block`` upon receiving a new block.\n    \"\"\"\n    block = signed_block.message\n    # Parent block must be known\n    assert block.parent_root in store.block_states\n\n    # Check if this blocks builds on empty or full parent block\n    parent_block = store.blocks[block.parent_root]\n    bid = block.body.signed_execution_payload_bid.message\n    parent_bid = parent_block.body.signed_execution_payload_bid.message\n    # Make a copy of the state to avoid mutability issues\n    if is_parent_node_full(store, block):\n        assert block.parent_root in store.execution_payload_states\n        state = copy(store.execution_payload_states[block.parent_root])\n    else:\n        assert bid.parent_block_hash == parent_bid.parent_block_hash\n        state = copy(store.block_states[block.parent_root])\n\n    # Blocks cannot be in the future. If they are, their consideration must be delayed until they are in the past.\n    current_slot = get_current_slot(store)\n    assert current_slot &gt;= block.slot\n\n    # Check that block is later than the finalized epoch slot (optimization to reduce calls to get_ancestor)\n    finalized_slot = compute_start_slot_at_epoch(store.finalized_checkpoint.epoch)\n    assert block.slot &gt; finalized_slot\n    # Check block is a descendant of the finalized block at the checkpoint finalized slot\n    finalized_checkpoint_block = get_checkpoint_block(\n        store,\n        block.parent_root,\n        store.finalized_checkpoint.epoch,\n    )\n    assert store.finalized_checkpoint.root == finalized_checkpoint_block\n\n    # Check the block is valid and compute the post-state\n    block_root = hash_tree_root(block)\n    state_transition(state, signed_block, True)\n\n    # Add new block to the store\n    store.blocks[block_root] = block\n    # Add new state for this block to the store\n    store.block_states[block_root] = state\n    # Add a new PTC voting for this block to the store\n    store.ptc_vote[block_root] = [False] * PTC_SIZE\n\n    # Notify the store about the payload_attestations in the block\n    notify_ptc_messages(store, state, block.body.payload_attestations)\n    # Add proposer score boost if the block is timely\n    seconds_since_genesis = store.time - store.genesis_time\n    time_into_slot_ms = seconds_to_milliseconds(seconds_since_genesis) % SLOT_DURATION_MS\n    # [Modified in Gloas:EIP7732]\n    attestation_threshold_ms = get_slot_component_duration_ms(ATTESTATION_DUE_BPS_GLOAS)\n    is_before_attesting_interval = time_into_slot_ms &lt; attestation_threshold_ms\n    is_timely = get_current_slot(store) == block.slot and is_before_attesting_interval\n    store.block_timeliness[hash_tree_root(block)] = is_timely\n\n    # Add proposer score boost if the block is timely and not conflicting with an existing block\n    is_first_block = store.proposer_boost_root == Root()\n    if is_timely and is_first_block:\n        store.proposer_boost_root = hash_tree_root(block)\n\n    # Update checkpoints in store if necessary\n    update_checkpoints(store, state.current_justified_checkpoint, state.finalized_checkpoint)\n\n    # Eagerly compute unrealized justification and finality.\n    compute_pulled_up_tip(store, block_root)\n</code></pre>"},{"location":"specs/gloas/fork-choice/#new-fork-choice-handlers","title":"New fork-choice handlers","text":""},{"location":"specs/gloas/fork-choice/#new-on_execution_payload","title":"New <code>on_execution_payload</code>","text":"<p>The handler <code>on_execution_payload</code> is called when the node receives a <code>SignedExecutionPayloadEnvelope</code> to sync.</p> <pre><code>def on_execution_payload(store: Store, signed_envelope: SignedExecutionPayloadEnvelope) -&gt; None:\n    \"\"\"\n    Run ``on_execution_payload`` upon receiving a new execution payload.\n    \"\"\"\n    envelope = signed_envelope.message\n    # The corresponding beacon block root needs to be known\n    assert envelope.beacon_block_root in store.block_states\n\n    # Check if blob data is available\n    # If not, this payload MAY be queued and subsequently considered when blob data becomes available\n    assert is_data_available(envelope.beacon_block_root)\n\n    # Make a copy of the state to avoid mutability issues\n    state = copy(store.block_states[envelope.beacon_block_root])\n\n    # Process the execution payload\n    process_execution_payload(state, signed_envelope, EXECUTION_ENGINE)\n\n    # Add new state for this payload to the store\n    store.execution_payload_states[envelope.beacon_block_root] = state\n</code></pre>"},{"location":"specs/gloas/fork-choice/#new-on_payload_attestation_message","title":"New <code>on_payload_attestation_message</code>","text":"<pre><code>def on_payload_attestation_message(\n    store: Store, ptc_message: PayloadAttestationMessage, is_from_block: bool = False\n) -&gt; None:\n    \"\"\"\n    Run ``on_payload_attestation_message`` upon receiving a new ``ptc_message`` directly on the wire.\n    \"\"\"\n    # The beacon block root must be known\n    data = ptc_message.data\n    # PTC attestation must be for a known block. If block is unknown, delay consideration until the block is found\n    state = store.block_states[data.beacon_block_root]\n    ptc = get_ptc(state, data.slot)\n    # PTC votes can only change the vote for their assigned beacon block, return early otherwise\n    if data.slot != state.slot:\n        return\n    # Check that the attester is from the PTC\n    assert ptc_message.validator_index in ptc\n\n    # Verify the signature and check that its for the current slot if it is coming from the wire\n    if not is_from_block:\n        # Check that the attestation is for the current slot\n        assert data.slot == get_current_slot(store)\n        # Verify the signature\n        assert is_valid_indexed_payload_attestation(\n            state,\n            IndexedPayloadAttestation(\n                attesting_indices=[ptc_message.validator_index],\n                data=data,\n                signature=ptc_message.signature,\n            ),\n        )\n    # Update the ptc vote for the block\n    ptc_index = ptc.index(ptc_message.validator_index)\n    ptc_vote = store.ptc_vote[data.beacon_block_root]\n    ptc_vote[ptc_index] = data.payload_present\n</code></pre>"},{"location":"specs/gloas/fork-choice/#modified-validate_on_attestation","title":"Modified <code>validate_on_attestation</code>","text":"<pre><code>def validate_on_attestation(store: Store, attestation: Attestation, is_from_block: bool) -&gt; None:\n    target = attestation.data.target\n\n    # If the given attestation is not from a beacon block message,\n    # we have to check the target epoch scope.\n    if not is_from_block:\n        validate_target_epoch_against_current_time(store, attestation)\n\n    # Check that the epoch number and slot number are matching.\n    assert target.epoch == compute_epoch_at_slot(attestation.data.slot)\n\n    # Attestation target must be for a known block. If target block\n    # is unknown, delay consideration until block is found.\n    assert target.root in store.blocks\n\n    # Attestations must be for a known block. If block\n    # is unknown, delay consideration until the block is found.\n    assert attestation.data.beacon_block_root in store.blocks\n    # Attestations must not be for blocks in the future.\n    # If not, the attestation should not be considered.\n    block_slot = store.blocks[attestation.data.beacon_block_root].slot\n    assert block_slot &lt;= attestation.data.slot\n\n    # [New in Gloas:EIP7732]\n    assert attestation.data.index in [0, 1]\n    if block_slot == attestation.data.slot:\n        assert attestation.data.index == 0\n\n    # LMD vote must be consistent with FFG vote target\n    assert target.root == get_checkpoint_block(\n        store, attestation.data.beacon_block_root, target.epoch\n    )\n\n    # Attestations can only affect the fork-choice of subsequent slots.\n    # Delay consideration in the fork-choice until their slot is in the past.\n    assert get_current_slot(store) &gt;= attestation.data.slot + 1\n</code></pre>"},{"location":"specs/gloas/fork-choice/#modified-validate_merge_block","title":"Modified <code>validate_merge_block</code>","text":"<p>The function <code>validate_merge_block</code> is modified for test purposes</p> <pre><code>def validate_merge_block(block: BeaconBlock) -&gt; None:\n    \"\"\"\n    Check the parent PoW block of execution payload is a valid terminal PoW block.\n\n    Note: Unavailable PoW block(s) may later become available,\n    and a client software MAY delay a call to ``validate_merge_block``\n    until the PoW block(s) become available.\n    \"\"\"\n    if TERMINAL_BLOCK_HASH != Hash32():\n        # If `TERMINAL_BLOCK_HASH` is used as an override, the activation epoch must be reached.\n        assert compute_epoch_at_slot(block.slot) &gt;= TERMINAL_BLOCK_HASH_ACTIVATION_EPOCH\n        assert (\n            block.body.signed_execution_payload_bid.message.parent_block_hash == TERMINAL_BLOCK_HASH\n        )\n        return\n\n    pow_block = get_pow_block(block.body.signed_execution_payload_bid.message.parent_block_hash)\n    # Check if `pow_block` is available\n    assert pow_block is not None\n    pow_parent = get_pow_block(pow_block.parent_hash)\n    # Check if `pow_parent` is available\n    assert pow_parent is not None\n    # Check if `pow_block` is a valid terminal PoW block\n    assert is_valid_terminal_pow_block(pow_block, pow_parent)\n</code></pre>"},{"location":"specs/gloas/fork/","title":"Gloas -- Fork Logic","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Configuration</li> <li>Fork to Gloas</li> <li>Fork trigger</li> <li>Upgrading the state</li> </ul>"},{"location":"specs/gloas/fork/#introduction","title":"Introduction","text":"<p>This document describes the process of the Gloas upgrade.</p>"},{"location":"specs/gloas/fork/#configuration","title":"Configuration","text":"<p>Warning: this configuration is not definitive.</p> Name Value <code>GLOAS_FORK_VERSION</code> <code>Version('0x07000000')</code> <code>GLOAS_FORK_EPOCH</code> <code>Epoch(18446744073709551615)</code> TBD"},{"location":"specs/gloas/fork/#fork-to-gloas","title":"Fork to Gloas","text":""},{"location":"specs/gloas/fork/#fork-trigger","title":"Fork trigger","text":"<p>The fork is triggered at epoch <code>GLOAS_FORK_EPOCH</code>.</p>"},{"location":"specs/gloas/fork/#upgrading-the-state","title":"Upgrading the state","text":"<p>If <code>state.slot % SLOTS_PER_EPOCH == 0</code> and <code>compute_epoch_at_slot(state.slot) == GLOAS_FORK_EPOCH</code>, an irregular state change is made to upgrade to Gloas.</p> <pre><code>def upgrade_to_gloas(pre: fulu.BeaconState) -&gt; BeaconState:\n    epoch = fulu.get_current_epoch(pre)\n\n    post = BeaconState(\n        genesis_time=pre.genesis_time,\n        genesis_validators_root=pre.genesis_validators_root,\n        slot=pre.slot,\n        fork=Fork(\n            previous_version=pre.fork.current_version,\n            # [Modified in Gloas:EIP7732]\n            current_version=GLOAS_FORK_VERSION,\n            epoch=epoch,\n        ),\n        latest_block_header=pre.latest_block_header,\n        block_roots=pre.block_roots,\n        state_roots=pre.state_roots,\n        historical_roots=pre.historical_roots,\n        eth1_data=pre.eth1_data,\n        eth1_data_votes=pre.eth1_data_votes,\n        eth1_deposit_index=pre.eth1_deposit_index,\n        validators=pre.validators,\n        balances=pre.balances,\n        randao_mixes=pre.randao_mixes,\n        slashings=pre.slashings,\n        previous_epoch_participation=pre.previous_epoch_participation,\n        current_epoch_participation=pre.current_epoch_participation,\n        justification_bits=pre.justification_bits,\n        previous_justified_checkpoint=pre.previous_justified_checkpoint,\n        current_justified_checkpoint=pre.current_justified_checkpoint,\n        finalized_checkpoint=pre.finalized_checkpoint,\n        inactivity_scores=pre.inactivity_scores,\n        current_sync_committee=pre.current_sync_committee,\n        next_sync_committee=pre.next_sync_committee,\n        # [Modified in Gloas:EIP7732]\n        latest_execution_payload_header=ExecutionPayloadHeader(),\n        # [New in Gloas:EIP7732]\n        latest_execution_payload_bid=ExecutionPayloadBid(),\n        next_withdrawal_index=pre.next_withdrawal_index,\n        next_withdrawal_validator_index=pre.next_withdrawal_validator_index,\n        historical_summaries=pre.historical_summaries,\n        deposit_requests_start_index=pre.deposit_requests_start_index,\n        deposit_balance_to_consume=pre.deposit_balance_to_consume,\n        exit_balance_to_consume=pre.exit_balance_to_consume,\n        earliest_exit_epoch=pre.earliest_exit_epoch,\n        consolidation_balance_to_consume=pre.consolidation_balance_to_consume,\n        earliest_consolidation_epoch=pre.earliest_consolidation_epoch,\n        pending_deposits=pre.pending_deposits,\n        pending_partial_withdrawals=pre.pending_partial_withdrawals,\n        pending_consolidations=pre.pending_consolidations,\n        proposer_lookahead=pre.proposer_lookahead,\n        # [New in Gloas:EIP7732]\n        execution_payload_availability=[0b1 for _ in range(SLOTS_PER_HISTORICAL_ROOT)],\n        # [New in Gloas:EIP7732]\n        builder_pending_payments=[BuilderPendingPayment() for _ in range(2 * SLOTS_PER_EPOCH)],\n        # [New in Gloas:EIP7732]\n        builder_pending_withdrawals=[],\n        # [New in Gloas:EIP7732]\n        latest_block_hash=pre.latest_execution_payload_header.block_hash,\n        # [New in Gloas:EIP7732]\n        latest_withdrawals_root=Root(),\n    )\n\n    return post\n</code></pre>"},{"location":"specs/gloas/p2p-interface/","title":"Gloas -- Networking","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Modification in Gloas</li> <li>Helper functions<ul> <li>Modified <code>compute_fork_version</code></li> </ul> </li> <li>Configuration</li> <li>Containers<ul> <li>Modified <code>DataColumnSidecar</code></li> </ul> </li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>beacon_aggregate_and_proof</code></li> <li><code>beacon_block</code></li> <li><code>execution_payload</code></li> <li><code>payload_attestation_message</code></li> <li><code>execution_payload_bid</code></li> </ul> </li> <li>Blob subnets<ul> <li><code>data_column_sidecar_{subnet_id}</code></li> </ul> </li> <li>Attestation subnets<ul> <li><code>beacon_attestation_{subnet_id}</code></li> </ul> </li> </ul> </li> <li>The Req/Resp domain<ul> <li>Messages</li> <li>BeaconBlocksByRange v2</li> <li>BeaconBlocksByRoot v2</li> <li>ExecutionPayloadEnvelopesByRange v1</li> <li>ExecutionPayloadEnvelopesByRoot v1</li> </ul> </li> </ul>"},{"location":"specs/gloas/p2p-interface/#introduction","title":"Introduction","text":"<p>This document contains the consensus-layer networking specification for Gloas.</p> <p>The specification of these changes continues in the same format as the network specifications of previous upgrades, and assumes them as pre-requisite.</p>"},{"location":"specs/gloas/p2p-interface/#modification-in-gloas","title":"Modification in Gloas","text":""},{"location":"specs/gloas/p2p-interface/#helper-functions","title":"Helper functions","text":""},{"location":"specs/gloas/p2p-interface/#modified-compute_fork_version","title":"Modified <code>compute_fork_version</code>","text":"<pre><code>def compute_fork_version(epoch: Epoch) -&gt; Version:\n    \"\"\"\n    Return the fork version at the given ``epoch``.\n    \"\"\"\n    if epoch &gt;= GLOAS_FORK_EPOCH:\n        return GLOAS_FORK_VERSION\n    if epoch &gt;= FULU_FORK_EPOCH:\n        return FULU_FORK_VERSION\n    if epoch &gt;= ELECTRA_FORK_EPOCH:\n        return ELECTRA_FORK_VERSION\n    if epoch &gt;= DENEB_FORK_EPOCH:\n        return DENEB_FORK_VERSION\n    if epoch &gt;= CAPELLA_FORK_EPOCH:\n        return CAPELLA_FORK_VERSION\n    if epoch &gt;= BELLATRIX_FORK_EPOCH:\n        return BELLATRIX_FORK_VERSION\n    if epoch &gt;= ALTAIR_FORK_EPOCH:\n        return ALTAIR_FORK_VERSION\n    return GENESIS_FORK_VERSION\n</code></pre>"},{"location":"specs/gloas/p2p-interface/#configuration","title":"Configuration","text":"<p>[New in Gloas:EIP7732]</p> Name Value Description <code>MAX_REQUEST_PAYLOADS</code> <code>2**7</code> (= 128) Maximum number of execution payload envelopes in a single request"},{"location":"specs/gloas/p2p-interface/#containers","title":"Containers","text":""},{"location":"specs/gloas/p2p-interface/#modified-datacolumnsidecar","title":"Modified <code>DataColumnSidecar</code>","text":"<p>Note: The <code>signed_block_header</code> and <code>kzg_commitments_inclusion_proof</code> fields have been removed from <code>DataColumnSidecar</code> in Gloas as header and inclusion proof verifications are no longer required in ePBS. Instead, sidecars are validated by checking that the hash of <code>kzg_commitments</code> matches what's committed in the builder's bid for the corresponding <code>beacon_block_root</code>.</p> <pre><code>class DataColumnSidecar(Container):\n    index: ColumnIndex\n    column: List[Cell, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    kzg_commitments: List[KZGCommitment, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    kzg_proofs: List[KZGProof, MAX_BLOB_COMMITMENTS_PER_BLOCK]\n    beacon_block_root: Root\n</code></pre>"},{"location":"specs/gloas/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":"<p>Some gossip meshes are upgraded in the fork of Gloas to support upgraded types.</p>"},{"location":"specs/gloas/p2p-interface/#topics-and-messages","title":"Topics and messages","text":"<p>Topics follow the same specification as in prior upgrades.</p> <p>The <code>beacon_block</code> topic is updated to support the modified type</p> Name Message Type <code>beacon_block</code> <code>SignedBeaconBlock</code> <p>The new topics along with the type of the <code>data</code> field of a gossipsub message are given in this table:</p> Name Message Type <code>execution_payload_bid</code> <code>SignedExecutionPayloadBid</code> <code>execution_payload</code> <code>SignedExecutionPayloadEnvelope</code> <code>payload_attestation_message</code> <code>PayloadAttestationMessage</code>"},{"location":"specs/gloas/p2p-interface/#global-topics","title":"Global topics","text":"<p>Gloas introduces new global topics for execution bid, execution payload and payload attestation.</p>"},{"location":"specs/gloas/p2p-interface/#beacon_aggregate_and_proof","title":"<code>beacon_aggregate_and_proof</code>","text":"<p>Let <code>block</code> be the beacon block corresponding to <code>aggregate.data.beacon_block_root</code>.</p> <p>The following validations are added:</p> <ul> <li>[REJECT] <code>aggregate.data.index &lt; 2</code>.</li> <li>[REJECT] <code>aggregate.data.index == 0</code> if <code>block.slot == aggregate.data.slot</code>.</li> </ul> <p>The following validations are removed:</p> <ul> <li>[REJECT] <code>aggregate.data.index == 0</code>.</li> </ul>"},{"location":"specs/gloas/p2p-interface/#beacon_block","title":"<code>beacon_block</code>","text":"<p>[Modified in Gloas:EIP7732]</p> <p>The type of the payload of this topic changes to the (modified) <code>SignedBeaconBlock</code> found in the Beacon Chain changes.</p> <p>There are no new validations for this topic. However, all validations with regards to the <code>ExecutionPayload</code> are removed:</p> <ul> <li>[REJECT] The length of KZG commitments is less than or equal to the   limitation defined in Consensus Layer -- i.e. validate that   <code>len(signed_beacon_block.message.body.blob_kzg_commitments) &lt;= get_blob_parameters(get_current_epoch(state)).max_blobs_per_block</code></li> <li>[REJECT] The block's execution payload timestamp is correct with respect to   the slot -- i.e.   <code>execution_payload.timestamp == compute_time_at_slot(state, block.slot)</code>.</li> <li>If <code>execution_payload</code> verification of block's parent by an execution node is   not complete:</li> <li>[REJECT] The block's parent (defined by <code>block.parent_root</code>) passes all     validation (excluding execution node verification of the     <code>block.body.execution_payload</code>).</li> <li>otherwise:</li> <li>[IGNORE] The block's parent (defined by <code>block.parent_root</code>) passes all     validation (including execution node verification of the     <code>block.body.execution_payload</code>).</li> <li>[REJECT] The block's parent (defined by <code>block.parent_root</code>) passes   validation.</li> </ul> <p>And instead the following validations are set in place with the alias <code>bid = signed_execution_payload_bid.message</code>:</p> <ul> <li>If <code>execution_payload</code> verification of block's execution payload parent by an   execution node is complete:</li> <li>[REJECT] The block's execution payload parent (defined by     <code>bid.parent_block_hash</code>) passes all validation.</li> <li>[REJECT] The block's parent (defined by <code>block.parent_root</code>) passes   validation.</li> </ul>"},{"location":"specs/gloas/p2p-interface/#execution_payload","title":"<code>execution_payload</code>","text":"<p>This topic is used to propagate execution payload messages as <code>SignedExecutionPayloadEnvelope</code>.</p> <p>The following validations MUST pass before forwarding the <code>signed_execution_payload_envelope</code> on the network, assuming the alias <code>envelope = signed_execution_payload_envelope.message</code>, <code>payload = payload_envelope.payload</code>:</p> <ul> <li>[IGNORE] The envelope's block root <code>envelope.block_root</code> has been seen (via   gossip or non-gossip sources) (a client MAY queue payload for processing once   the block is retrieved).</li> <li>[IGNORE] The node has not seen another valid   <code>SignedExecutionPayloadEnvelope</code> for this block root from this builder.</li> </ul> <p>Let <code>block</code> be the block with <code>envelope.beacon_block_root</code>. Let <code>bid</code> alias <code>block.body.signed_execution_payload_bid.message</code> (notice that this can be obtained from the <code>state.latest_execution_payload_bid</code>)</p> <ul> <li>[REJECT] <code>block</code> passes validation.</li> <li>[REJECT] <code>block.slot</code> equals <code>envelope.slot</code>.</li> <li>[REJECT] <code>envelope.builder_index == bid.builder_index</code></li> <li>[REJECT] <code>payload.block_hash == bid.block_hash</code></li> <li>[REJECT] <code>signed_execution_payload_envelope.signature</code> is valid with respect   to the builder's public key.</li> </ul>"},{"location":"specs/gloas/p2p-interface/#payload_attestation_message","title":"<code>payload_attestation_message</code>","text":"<p>This topic is used to propagate signed payload attestation message.</p> <p>The following validations MUST pass before forwarding the <code>payload_attestation_message</code> on the network, assuming the alias <code>data = payload_attestation_message.data</code>:</p> <ul> <li>[IGNORE] The message's slot is for the current slot (with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance), i.e. <code>data.slot == current_slot</code>.</li> <li>[IGNORE] The <code>payload_attestation_message</code> is the first valid message   received from the validator with index   <code>payload_attestation_message.validate_index</code>.</li> <li>[IGNORE] The message's block <code>data.beacon_block_root</code> has been seen (via   gossip or non-gossip sources) (a client MAY queue attestation for processing   once the block is retrieved. Note a client might want to request payload   after).</li> <li>[REJECT] The message's block <code>data.beacon_block_root</code> passes validation.</li> <li>[REJECT] The message's validator index is within the payload committee in   <code>get_ptc(state, data.slot)</code>. The <code>state</code> is the head state corresponding to   processing the block up to the current slot as determined by the fork choice.</li> <li>[REJECT] <code>payload_attestation_message.signature</code> is valid with respect to   the validator's public key.</li> </ul>"},{"location":"specs/gloas/p2p-interface/#execution_payload_bid","title":"<code>execution_payload_bid</code>","text":"<p>This topic is used to propagate signed bids as <code>SignedExecutionPayloadBid</code>.</p> <p>The following validations MUST pass before forwarding the <code>signed_execution_payload_bid</code> on the network, assuming the alias <code>bid = signed_execution_payload_bid.message</code>:</p> <ul> <li>[REJECT] <code>bid.builder_index</code> is a valid, active, and non-slashed builder   index.</li> <li>[REJECT] the builder's withdrawal credentials' prefix is   <code>BUILDER_WITHDRAWAL_PREFIX</code> -- i.e.   <code>is_builder_withdrawal_credential(state.validators[bid.builder_index].withdrawal_credentials)</code>   returns <code>True</code>.</li> <li>[IGNORE] this is the first signed bid seen with a valid signature from the   given builder for this slot.</li> <li>[IGNORE] this bid is the highest value bid seen for the corresponding slot   and the given parent block hash.</li> <li>[IGNORE] <code>bid.value</code> is less or equal than the builder's excess balance --   i.e.   <code>MIN_ACTIVATION_BALANCE + bid.value &lt;= state.balances[bid.builder_index]</code>.</li> <li>[IGNORE] <code>bid.parent_block_hash</code> is the block hash of a known execution   payload in fork choice.</li> <li>[IGNORE] <code>bid.parent_block_root</code> is the hash tree root of a known beacon   block in fork choice.</li> <li>[IGNORE] <code>bid.slot</code> is the current slot or the next slot.</li> <li>[REJECT] <code>signed_execution_payload_bid.signature</code> is valid with respect to   the <code>bid.builder_index</code>.</li> </ul>"},{"location":"specs/gloas/p2p-interface/#blob-subnets","title":"Blob subnets","text":""},{"location":"specs/gloas/p2p-interface/#data_column_sidecar_subnet_id","title":"<code>data_column_sidecar_{subnet_id}</code>","text":"<p>[Modified in Gloas:EIP7732]</p> <p>This topic is used to propagate column sidecars, where each column maps to some <code>subnet_id</code>.</p> <p>The type of the payload of this topic is <code>DataColumnSidecar</code>.</p> <p>The following validations MUST pass before forwarding the <code>sidecar: DataColumnSidecar</code> on the network:</p> <p>Modified from Fulu:</p> <ul> <li>[IGNORE] The sidecar is the first sidecar for the tuple   <code>(sidecar.beacon_block_root, sidecar.index)</code> with valid kzg proof.</li> </ul> <p>Added in Gloas:</p> <ul> <li>[IGNORE] The sidecar's <code>beacon_block_root</code> has been seen via a valid signed   execution payload header (builder's bid).</li> <li>[REJECT] The hash of the sidecar's <code>kzg_commitments</code> matches the   <code>blob_kzg_commitments_root</code> in the corresponding builder's bid for   <code>sidecar.beacon_block_root</code>.</li> </ul> <p>Removed from Fulu:</p> <ul> <li>[IGNORE] The sidecar is not from a future slot (with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e. validate that   <code>block_header.slot &lt;= current_slot</code> (a client MAY queue future sidecars for   processing at the appropriate slot).</li> <li>[IGNORE] The sidecar is from a slot greater than the latest finalized slot   -- i.e. validate that   <code>block_header.slot &gt; compute_start_slot_at_epoch(state.finalized_checkpoint.epoch)</code></li> <li>[REJECT] The proposer signature of <code>sidecar.signed_block_header</code>, is valid   with respect to the <code>block_header.proposer_index</code> pubkey.</li> <li>[IGNORE] The sidecar's block's parent (defined by   <code>block_header.parent_root</code>) has been seen (via gossip or non-gossip sources)   (a client MAY queue sidecars for processing once the parent block is   retrieved).</li> <li>[REJECT] The sidecar's block's parent (defined by   <code>block_header.parent_root</code>) passes validation.</li> <li>[REJECT] The sidecar is from a higher slot than the sidecar's block's parent   (defined by <code>block_header.parent_root</code>).</li> <li>[REJECT] The current finalized_checkpoint is an ancestor of the sidecar's   block -- i.e.   <code>get_checkpoint_block(store, block_header.parent_root, store.finalized_checkpoint.epoch) == store.finalized_checkpoint.root</code>.</li> <li>[REJECT] The sidecar's <code>kzg_commitments</code> field inclusion proof is valid as   verified by <code>verify_data_column_sidecar_inclusion_proof(sidecar)</code>.</li> <li>[REJECT] The sidecar is proposed by the expected <code>proposer_index</code> for the   block's slot in the context of the current shuffling (defined by   <code>block_header.parent_root</code>/<code>block_header.slot</code>). If the <code>proposer_index</code>   cannot immediately be verified against the expected shuffling, the sidecar MAY   be queued for later processing while proposers for the block's branch are   calculated -- in such a case do not <code>REJECT</code>, instead <code>IGNORE</code> this message.</li> </ul>"},{"location":"specs/gloas/p2p-interface/#attestation-subnets","title":"Attestation subnets","text":""},{"location":"specs/gloas/p2p-interface/#beacon_attestation_subnet_id","title":"<code>beacon_attestation_{subnet_id}</code>","text":"<p>Let <code>block</code> be the beacon block corresponding to <code>attestation.data.beacon_block_root</code>.</p> <p>The following validations are added:</p> <ul> <li>[REJECT] <code>attestation.data.index &lt; 2</code>.</li> <li>[REJECT] <code>attestation.data.index == 0</code> if   <code>block.slot == attestation.data.slot</code>.</li> </ul> <p>The following validations are removed:</p> <ul> <li>[REJECT] <code>attestation.data.index == 0</code>.</li> </ul>"},{"location":"specs/gloas/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/gloas/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/gloas/p2p-interface/#beaconblocksbyrange-v2","title":"BeaconBlocksByRange v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_range/2/</code></p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code> <code>BELLATRIX_FORK_VERSION</code> <code>bellatrix.SignedBeaconBlock</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.SignedBeaconBlock</code> <code>DENEB_FORK_VERSION</code> <code>deneb.SignedBeaconBlock</code> <code>ELECTRA_FORK_VERSION</code> <code>electra.SignedBeaconBlock</code> <code>FULU_FORK_VERSION</code> <code>fulu.SignedBeaconBlock</code> <code>GLOAS_FORK_VERSION</code> <code>gloas.SignedBeaconBlock</code>"},{"location":"specs/gloas/p2p-interface/#beaconblocksbyroot-v2","title":"BeaconBlocksByRoot v2","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_root/2/</code></p> <code>fork_version</code> Chunk SSZ type <code>GENESIS_FORK_VERSION</code> <code>phase0.SignedBeaconBlock</code> <code>ALTAIR_FORK_VERSION</code> <code>altair.SignedBeaconBlock</code> <code>BELLATRIX_FORK_VERSION</code> <code>bellatrix.SignedBeaconBlock</code> <code>CAPELLA_FORK_VERSION</code> <code>capella.SignedBeaconBlock</code> <code>DENEB_FORK_VERSION</code> <code>deneb.SignedBeaconBlock</code> <code>ELECTRA_FORK_VERSION</code> <code>electra.SignedBeaconBlock</code> <code>FULU_FORK_VERSION</code> <code>fulu.SignedBeaconBlock</code> <code>GLOAS_FORK_VERSION</code> <code>gloas.SignedBeaconBlock</code>"},{"location":"specs/gloas/p2p-interface/#executionpayloadenvelopesbyrange-v1","title":"ExecutionPayloadEnvelopesByRange v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/execution_payload_envelopes_by_range/1/</code></p> <p>[New in Gloas:EIP7732]</p> <p>Request Content:</p> <pre><code>(\n  start_slot: Slot\n  count: uint64\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[SignedExecutionPayloadEnvelope, MAX_REQUEST_BLOCKS_DENEB]\n)\n</code></pre> <p>Specifications of req\\response methods are equivalent to BeaconBlocksByRange v2, with the only difference being the response content type.</p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(beacon_block.slot)</code> based on the <code>beacon_block</code> referred to by <code>signed_execution_payload_envelope.message.beacon_block_root</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Chunk SSZ type <code>GLOAS_FORK_VERSION</code> <code>gloas.SignedExecutionPayloadEnvelope</code>"},{"location":"specs/gloas/p2p-interface/#executionpayloadenvelopesbyroot-v1","title":"ExecutionPayloadEnvelopesByRoot v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/execution_payload_envelopes_by_root/1/</code></p> <p>For each successful <code>response_chunk</code>, the <code>ForkDigest</code> context epoch is determined by <code>compute_epoch_at_slot(beacon_block.slot)</code> based on the <code>beacon_block</code> referred to by <code>signed_execution_payload_envelope.message.beacon_block_root</code>.</p> <p>Per <code>fork_version = compute_fork_version(epoch)</code>:</p> <code>fork_version</code> Chunk SSZ type <code>GLOAS_FORK_VERSION</code> <code>gloas.SignedExecutionPayloadEnvelope</code> <p>Request Content:</p> <pre><code>(\n  List[Root, MAX_REQUEST_PAYLOADS]\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[SignedExecutionPayloadEnvelope, MAX_REQUEST_PAYLOADS]\n)\n</code></pre> <p>Requests execution payload envelopes by <code>signed_execution_payload_envelope.message.block_root</code>. The response is a list of <code>SignedExecutionPayloadEnvelope</code> whose length is less than or equal to the number of requested execution payload envelopes. It may be less in the case that the responding peer is missing payload envelopes.</p> <p>No more than <code>MAX_REQUEST_PAYLOADS</code> may be requested at a time.</p> <p>ExecutionPayloadEnvelopesByRoot is primarily used to recover recent execution payload envelopes (e.g. when receiving a payload attestation with revealed status as true but never received a payload).</p> <p>The request MUST be encoded as an SSZ-field.</p> <p>The response MUST consist of zero or more <code>response_chunk</code>. Each successful <code>response_chunk</code> MUST contain a single <code>SignedExecutionPayloadEnvelope</code> payload.</p> <p>Clients MUST support requesting payload envelopes since the latest finalized epoch.</p> <p>Clients MUST respond with at least one payload envelope, if they have it. Clients MAY limit the number of payload envelopes in the response.</p>"},{"location":"specs/gloas/validator/","title":"Gloas -- Honest Validator","text":"<p>Note: This document is a work-in-progress for researchers and implementers.</p> <ul> <li>Introduction</li> <li>Configuration</li> <li>Time parameters</li> <li>Validator assignment</li> <li>Lookahead</li> <li>Beacon chain responsibilities</li> <li>Attestation</li> <li>Sync Committee participations</li> <li>Block proposal<ul> <li>Constructing the new <code>signed_execution_payload_bid</code> field in <code>BeaconBlockBody</code></li> <li>Constructing the new <code>payload_attestations</code> field in <code>BeaconBlockBody</code></li> <li>Blob sidecars</li> </ul> </li> <li>Payload timeliness attestation<ul> <li>Constructing a payload attestation</li> </ul> </li> <li>Modified functions</li> <li>Modified <code>prepare_execution_payload</code></li> <li>Data column sidecars</li> <li>Modified <code>get_data_column_sidecars_from_column_sidecar</code></li> </ul>"},{"location":"specs/gloas/validator/#introduction","title":"Introduction","text":"<p>This document represents the changes and additions to the Honest validator guide included in Gloas.</p>"},{"location":"specs/gloas/validator/#configuration","title":"Configuration","text":""},{"location":"specs/gloas/validator/#time-parameters","title":"Time parameters","text":"Name Value Unit Duration <code>ATTESTATION_DUE_BPS_GLOAS</code> <code>uint64(2500)</code> basis points 25% of <code>SLOT_DURATION_MS</code> <code>AGGREGATE_DUE_BPS_GLOAS</code> <code>uint64(5000)</code> basis points 50% of <code>SLOT_DURATION_MS</code> <code>SYNC_MESSAGE_DUE_BPS_GLOAS</code> <code>uint64(2500)</code> basis points 25% of <code>SLOT_DURATION_MS</code> <code>CONTRIBUTION_DUE_BPS_GLOAS</code> <code>uint64(5000)</code> basis points 50% of <code>SLOT_DURATION_MS</code> <code>PAYLOAD_ATTESTATION_DUE_BPS</code> <code>uint64(7500)</code> basis points 75% of <code>SLOT_DURATION_MS</code>"},{"location":"specs/gloas/validator/#validator-assignment","title":"Validator assignment","text":"<p>A validator may be a member of the new Payload Timeliness Committee (PTC) for a given slot. To check for PTC assignments the validator uses the helper <code>get_ptc_assignment(state, epoch, validator_index)</code> where <code>epoch &lt;= next_epoch</code>.</p> <p>PTC committee selection is only stable within the context of the current and next epoch.</p> <pre><code>def get_ptc_assignment(\n    state: BeaconState, epoch: Epoch, validator_index: ValidatorIndex\n) -&gt; Optional[Slot]:\n    \"\"\"\n    Returns the slot during the requested epoch in which the validator with index `validator_index`\n    is a member of the PTC. Returns None if no assignment is found.\n    \"\"\"\n    next_epoch = Epoch(get_current_epoch(state) + 1)\n    assert epoch &lt;= next_epoch\n\n    start_slot = compute_start_slot_at_epoch(epoch)\n    for slot in range(start_slot, start_slot + SLOTS_PER_EPOCH):\n        if validator_index in get_ptc(state, Slot(slot)):\n            return Slot(slot)\n    return None\n</code></pre>"},{"location":"specs/gloas/validator/#lookahead","title":"Lookahead","text":"<p>[New in Gloas:EIP7732]</p> <p><code>get_ptc_assignment</code> should be called at the start of each epoch to get the assignment for the next epoch (<code>current_epoch + 1</code>). A validator should plan for future assignments by noting their assigned PTC slot.</p>"},{"location":"specs/gloas/validator/#beacon-chain-responsibilities","title":"Beacon chain responsibilities","text":"<p>All validator responsibilities remain unchanged other than the following:</p> <ul> <li>Proposers are no longer required to broadcast <code>BlobSidecar</code> objects, as this   becomes a builder's duty.</li> <li>Some validators are selected per slot to become PTC members, these validators   must broadcast <code>PayloadAttestationMessage</code> objects during the assigned slot   before the deadline of   <code>get_slot_component_duration_ms(PAYLOAD_ATTESTATION_DUE_BPS)</code> milliseconds   into the slot.</li> </ul>"},{"location":"specs/gloas/validator/#attestation","title":"Attestation","text":"<p>The attestation deadline is changed with <code>ATTESTATION_DUE_BPS_GLOAS</code>. Moreover, the <code>attestation.data.index</code> field is now used to signal the payload status of the block being attested to (<code>attestation.data.beacon_block_root</code>). With the alias <code>data = attestation.data</code>, the validator should set this field as follows:</p> <ul> <li>If <code>block.slot == current_slot</code> (i.e., <code>data.slot</code>), then always set   <code>data.index = 0</code>.</li> <li>Otherwise, set <code>data.index</code> based on the payload status in the validator's   fork-choice:</li> <li>Set <code>data.index = 0</code> to signal that the payload is not present in the     canonical chain (payload status is <code>EMPTY</code> in the fork-choice).</li> <li>Set <code>data.index = 1</code> to signal that the payload is present in the canonical     chain (payload status is <code>FULL</code> in the fork-choice).</li> </ul>"},{"location":"specs/gloas/validator/#sync-committee-participations","title":"Sync Committee participations","text":"<p>Sync committee duties are not changed for validators, however the submission deadline is changed with <code>SYNC_MESSAGE_DUE_BPS_GLOAS</code>.</p>"},{"location":"specs/gloas/validator/#block-proposal","title":"Block proposal","text":"<p>Validators are still expected to propose <code>SignedBeaconBlock</code> at the beginning of any slot during which <code>is_proposer(state, validator_index)</code> returns <code>true</code>. The mechanism to prepare this beacon block and related sidecars differs from previous forks as follows</p>"},{"location":"specs/gloas/validator/#constructing-the-new-signed_execution_payload_bid-field-in-beaconblockbody","title":"Constructing the new <code>signed_execution_payload_bid</code> field in <code>BeaconBlockBody</code>","text":"<p>To obtain <code>signed_execution_payload_bid</code>, a block proposer building a block on top of a <code>state</code> must take the following actions:</p> <ul> <li>Listen to the <code>execution_payload_bid</code> gossip global topic and save an accepted   <code>signed_execution_payload_bid</code> from a builder. Proposer MAY obtain these   signed messages by other off-protocol means.</li> <li>The <code>signed_execution_payload_bid</code> must satisfy the verification conditions   found in <code>process_execution_payload_bid</code>, that is:</li> <li>For external builders: The header signature must be valid</li> <li>For self-builds: The signature must be <code>bls.G2_POINT_AT_INFINITY</code> and the     bid amount must be zero</li> <li>The builder balance can cover the header value</li> <li>The header slot is for the proposal block slot</li> <li>The header parent block hash equals the state's <code>latest_block_hash</code>.</li> <li>The header parent block root equals the current block's <code>parent_root</code>.</li> <li>Select one bid and set   <code>body.signed_execution_payload_bid = signed_execution_payload_bid</code></li> </ul> <p>Note: The execution address encoded in the field <code>fee_recipient</code> in the <code>signed_execution_payload_bid.message</code> is the recipient of the builder payment.</p>"},{"location":"specs/gloas/validator/#constructing-the-new-payload_attestations-field-in-beaconblockbody","title":"Constructing the new <code>payload_attestations</code> field in <code>BeaconBlockBody</code>","text":"<p>Up to <code>MAX_PAYLOAD_ATTESTATIONS</code>, aggregate payload attestations can be included in the block. The validator will have to</p> <ul> <li>Listen to the <code>payload_attestation_message</code> gossip global topic</li> <li>The payload attestations added must satisfy the verification conditions found   in payload attestation gossip validation and payload attestation processing.   This means</li> <li>The <code>data.beacon_block_root</code> corresponds to <code>block.parent_root</code>.</li> <li>The slot of the parent block is exactly one slot before the proposing slot.</li> <li>The signature of the payload attestation data message verifies correctly.</li> <li>The proposer needs to aggregate all payload attestations with the same data   into a given <code>PayloadAttestation</code> object. For this it needs to fill the   <code>aggregation_bits</code> field by using the relative position of the validator   indices with respect to the PTC that is obtained from   <code>get_ptc(state, block_slot - 1)</code>.</li> </ul>"},{"location":"specs/gloas/validator/#blob-sidecars","title":"Blob sidecars","text":"<p>The blob sidecars are no longer broadcast by the validator, and thus their construction is not necessary. This deprecates the corresponding sections from the honest validator guide in the Fulu fork, moving them, albeit with some modifications, to the honest Builder guide</p>"},{"location":"specs/gloas/validator/#payload-timeliness-attestation","title":"Payload timeliness attestation","text":"<p>Some validators are selected to submit payload timeliness attestations. Validators should call <code>get_ptc_assignment</code> at the beginning of an epoch to be prepared to submit their PTC attestations during the next epoch.</p> <p>A validator should create and broadcast the <code>payload_attestation_message</code> to the global execution attestation subnet not after <code>get_slot_component_duration_ms(PAYLOAD_ATTESTATION_DUE_BPS)</code> milliseconds since the start of <code>slot</code>.</p>"},{"location":"specs/gloas/validator/#constructing-a-payload-attestation","title":"Constructing a payload attestation","text":"<p>If a validator is in the payload attestation committee for the current slot (as obtained from <code>get_ptc_assignment</code> above) then the validator should prepare a <code>PayloadAttestationMessage</code> for the current slot, according to the logic in <code>get_payload_attestation_message</code> below and broadcast it not after <code>get_slot_component_duration_ms(PAYLOAD_ATTESTATION_DUE_BPS)</code> milliseconds since the start of the slot, to the global <code>payload_attestation_message</code> pubsub topic.</p> <p>The validator creates <code>payload_attestation_message</code> as follows:</p> <ul> <li>If the validator has not seen any beacon block for the assigned slot, do not   submit a payload attestation. It will be ignored anyway.</li> <li>Set <code>data.beacon_block_root</code> be the HTR of the beacon block seen for the   assigned slot</li> <li>Set <code>data.slot</code> to be the assigned slot.</li> <li>If a <code>SignedExecutionPayloadEnvelope</code> has been seen referencing the block   <code>data.beacon_block_root</code> set <code>data.payload_present = True</code>. Otherwise set it   to <code>False</code>.</li> <li>Set <code>payload_attestation_message.validator_index = validator_index</code> where   <code>validator_index</code> is the validator chosen to submit. The private key mapping   to <code>state.validators[validator_index].pubkey</code> is used to sign the payload   timeliness attestation.</li> <li>Sign the <code>payload_attestation_message.data</code> using the helper   <code>get_payload_attestation_message_signature</code>.</li> </ul> <p>Notice that the attester only signs the <code>PayloadAttestationData</code> and not the <code>validator_index</code> field in the message. Proposers need to aggregate these attestations as described above.</p> <pre><code>def get_payload_attestation_message_signature(\n    state: BeaconState, attestation: PayloadAttestationMessage, privkey: int\n) -&gt; BLSSignature:\n    domain = get_domain(state, DOMAIN_PTC_ATTESTER, compute_epoch_at_slot(attestation.data.slot))\n    signing_root = compute_signing_root(attestation.data, domain)\n    return bls.Sign(privkey, signing_root)\n</code></pre> <p>Remark Validators do not need to check the full validity of the <code>ExecutionPayload</code> contained in within the envelope, but the checks in the P2P guide should pass for the <code>SignedExecutionPayloadEnvelope</code>.</p>"},{"location":"specs/gloas/validator/#modified-functions","title":"Modified functions","text":""},{"location":"specs/gloas/validator/#modified-prepare_execution_payload","title":"Modified <code>prepare_execution_payload</code>","text":"<p>Note: The function <code>prepare_execution_payload</code> is modified to handle the updated <code>get_expected_withdrawals</code> return signature.</p> <pre><code>def prepare_execution_payload(\n    state: BeaconState,\n    safe_block_hash: Hash32,\n    finalized_block_hash: Hash32,\n    suggested_fee_recipient: ExecutionAddress,\n    execution_engine: ExecutionEngine,\n) -&gt; Optional[PayloadId]:\n    # Verify consistency of the parent hash with respect to the previous execution payload bid\n    parent_hash = state.latest_execution_payload_bid.block_hash\n\n    # [Modified in Gloas:EIP7732]\n    # Set the forkchoice head and initiate the payload build process\n    withdrawals, _, _ = get_expected_withdrawals(state)\n\n    payload_attributes = PayloadAttributes(\n        timestamp=compute_time_at_slot(state, state.slot),\n        prev_randao=get_randao_mix(state, get_current_epoch(state)),\n        suggested_fee_recipient=suggested_fee_recipient,\n        withdrawals=withdrawals,\n        parent_beacon_block_root=hash_tree_root(state.latest_block_header),\n    )\n    return execution_engine.notify_forkchoice_updated(\n        head_block_hash=parent_hash,\n        safe_block_hash=safe_block_hash,\n        finalized_block_hash=finalized_block_hash,\n        payload_attributes=payload_attributes,\n    )\n</code></pre>"},{"location":"specs/gloas/validator/#data-column-sidecars","title":"Data column sidecars","text":"<p>[Modified in Gloas]</p>"},{"location":"specs/gloas/validator/#modified-get_data_column_sidecars_from_column_sidecar","title":"Modified <code>get_data_column_sidecars_from_column_sidecar</code>","text":"<pre><code>def get_data_column_sidecars_from_column_sidecar(\n    sidecar: DataColumnSidecar,\n    cells_and_kzg_proofs: Sequence[\n        Tuple[Vector[Cell, CELLS_PER_EXT_BLOB], Vector[KZGProof, CELLS_PER_EXT_BLOB]]\n    ],\n) -&gt; Sequence[DataColumnSidecar]:\n    \"\"\"\n    Given a DataColumnSidecar and the cells/proofs associated with each blob corresponding\n    to the commitments it contains, assemble all sidecars for distribution to peers.\n    \"\"\"\n    assert len(cells_and_kzg_proofs) == len(sidecar.kzg_commitments)\n\n    return get_data_column_sidecars(\n        sidecar.signed_block_header.message.body_root,\n        sidecar.kzg_commitments,\n        cells_and_kzg_proofs,\n    )\n</code></pre>"},{"location":"specs/phase0/","title":"Index","text":""},{"location":"specs/phase0/#core","title":"Core","text":"<ul> <li>Beacon Chain</li> <li>Deposit Contract</li> <li>Fork Choice</li> <li>P2P Interface</li> <li>Validator</li> <li>Weak Subjectivity</li> </ul>"},{"location":"specs/phase0/beacon-chain/","title":"Phase 0 -- The Beacon Chain","text":"<ul> <li>Introduction</li> <li>Notation</li> <li>Custom types</li> <li>Constants</li> <li>Misc</li> <li>Withdrawal prefixes</li> <li>Domain types</li> <li>Preset</li> <li>Misc</li> <li>Gwei values</li> <li>Time parameters</li> <li>State list lengths</li> <li>Rewards and penalties</li> <li>Max operations per block</li> <li>Configuration</li> <li>Genesis settings</li> <li>Time parameters</li> <li>Validator cycle</li> <li>Containers</li> <li>Misc dependencies<ul> <li><code>Fork</code></li> <li><code>ForkData</code></li> <li><code>Checkpoint</code></li> <li><code>Validator</code></li> <li><code>AttestationData</code></li> <li><code>IndexedAttestation</code></li> <li><code>PendingAttestation</code></li> <li><code>Eth1Data</code></li> <li><code>HistoricalBatch</code></li> <li><code>DepositMessage</code></li> <li><code>DepositData</code></li> <li><code>BeaconBlockHeader</code></li> <li><code>SigningData</code></li> </ul> </li> <li>Beacon operations<ul> <li><code>ProposerSlashing</code></li> <li><code>AttesterSlashing</code></li> <li><code>Attestation</code></li> <li><code>Deposit</code></li> <li><code>VoluntaryExit</code></li> </ul> </li> <li>Beacon blocks<ul> <li><code>BeaconBlockBody</code></li> <li><code>BeaconBlock</code></li> </ul> </li> <li>Beacon state<ul> <li><code>BeaconState</code></li> </ul> </li> <li>Signed envelopes<ul> <li><code>SignedVoluntaryExit</code></li> <li><code>SignedBeaconBlock</code></li> <li><code>SignedBeaconBlockHeader</code></li> </ul> </li> <li>Helper functions</li> <li>Math<ul> <li><code>integer_squareroot</code></li> <li><code>xor</code></li> <li><code>uint_to_bytes</code></li> <li><code>bytes_to_uint64</code></li> <li><code>saturating_sub</code></li> </ul> </li> <li>Crypto<ul> <li><code>hash</code></li> <li><code>hash_tree_root</code></li> <li>BLS signatures</li> </ul> </li> <li>Predicates<ul> <li><code>is_active_validator</code></li> <li><code>is_eligible_for_activation_queue</code></li> <li><code>is_eligible_for_activation</code></li> <li><code>is_slashable_validator</code></li> <li><code>is_slashable_attestation_data</code></li> <li><code>is_valid_indexed_attestation</code></li> <li><code>is_valid_merkle_branch</code></li> </ul> </li> <li>Misc<ul> <li><code>compute_shuffled_index</code></li> <li><code>compute_proposer_index</code></li> <li><code>compute_committee</code></li> <li><code>compute_time_at_slot</code></li> <li><code>compute_epoch_at_slot</code></li> <li><code>compute_start_slot_at_epoch</code></li> <li><code>compute_activation_exit_epoch</code></li> <li><code>compute_fork_data_root</code></li> <li><code>compute_domain</code></li> <li><code>compute_signing_root</code></li> </ul> </li> <li>Beacon state accessors<ul> <li><code>get_current_epoch</code></li> <li><code>get_previous_epoch</code></li> <li><code>get_block_root</code></li> <li><code>get_block_root_at_slot</code></li> <li><code>get_randao_mix</code></li> <li><code>get_active_validator_indices</code></li> <li><code>get_validator_churn_limit</code></li> <li><code>get_seed</code></li> <li><code>get_committee_count_per_slot</code></li> <li><code>get_beacon_committee</code></li> <li><code>get_beacon_proposer_index</code></li> <li><code>get_total_balance</code></li> <li><code>get_total_active_balance</code></li> <li><code>get_domain</code></li> <li><code>get_indexed_attestation</code></li> <li><code>get_attesting_indices</code></li> </ul> </li> <li>Beacon state mutators<ul> <li><code>increase_balance</code></li> <li><code>decrease_balance</code></li> <li><code>initiate_validator_exit</code></li> <li><code>slash_validator</code></li> </ul> </li> <li>Genesis</li> <li>Genesis state</li> <li>Genesis block</li> <li>Beacon chain state transition function</li> <li>Epoch processing<ul> <li>Helper functions</li> <li>Justification and finalization</li> <li>Rewards and penalties</li> <li>Helpers</li> <li>Components of attestation deltas</li> <li><code>get_attestation_deltas</code></li> <li><code>process_rewards_and_penalties</code></li> <li>Registry updates</li> <li>Slashings</li> <li>Eth1 data votes updates</li> <li>Effective balances updates</li> <li>Slashings balances updates</li> <li>Randao mixes updates</li> <li>Historical roots updates</li> <li>Participation records rotation</li> </ul> </li> <li>Block processing<ul> <li>Block header</li> <li>RANDAO</li> <li>Eth1 data</li> <li>Operations</li> <li>Proposer slashings</li> <li>Attester slashings</li> <li>Attestations</li> <li>Deposits</li> <li>Voluntary exits</li> </ul> </li> </ul>"},{"location":"specs/phase0/beacon-chain/#introduction","title":"Introduction","text":"<p>This document represents the specification for Phase 0 -- The Beacon Chain.</p> <p>At the core of Ethereum proof-of-stake is a system chain called the \"beacon chain\". The beacon chain stores and manages the registry of validators. In the initial deployment phases of proof-of-stake, the only mechanism to become a validator is to make a one-way ETH transaction to a deposit contract on the Ethereum proof-of-work chain. Activation as a validator happens when deposit receipts are processed by the beacon chain, the activation balance is reached, and a queuing process is completed. Exit is either voluntary or done forcibly as a penalty for misbehavior. The primary source of load on the beacon chain is \"attestations\". Attestations are simultaneously availability votes for a shard block (in a later upgrade) and proof-of-stake votes for a beacon block (Phase 0).</p>"},{"location":"specs/phase0/beacon-chain/#notation","title":"Notation","text":"<p>Code snippets appearing in <code>this style</code> are to be interpreted as Python 3 code.</p>"},{"location":"specs/phase0/beacon-chain/#custom-types","title":"Custom types","text":"<p>We define the following Python custom types for type hinting and readability:</p> Name SSZ equivalent Description <code>Slot</code> <code>uint64</code> a slot number <code>Epoch</code> <code>uint64</code> an epoch number <code>CommitteeIndex</code> <code>uint64</code> a committee index at a slot <code>ValidatorIndex</code> <code>uint64</code> a validator registry index <code>Gwei</code> <code>uint64</code> an amount in Gwei <code>Root</code> <code>Bytes32</code> a Merkle root <code>Hash32</code> <code>Bytes32</code> a 256-bit hash <code>Version</code> <code>Bytes4</code> a fork version number <code>DomainType</code> <code>Bytes4</code> a domain type <code>ForkDigest</code> <code>Bytes4</code> a digest of the current fork data <code>Domain</code> <code>Bytes32</code> a signature domain <code>BLSPubkey</code> <code>Bytes48</code> a BLS12-381 public key <code>BLSSignature</code> <code>Bytes96</code> a BLS12-381 signature"},{"location":"specs/phase0/beacon-chain/#constants","title":"Constants","text":"<p>The following values are (non-configurable) constants used throughout the specification.</p>"},{"location":"specs/phase0/beacon-chain/#misc","title":"Misc","text":"Name Value <code>UINT64_MAX</code> <code>uint64(2**64 - 1)</code> <code>UINT64_MAX_SQRT</code> <code>uint64(4294967295)</code> <code>GENESIS_SLOT</code> <code>Slot(0)</code> <code>GENESIS_EPOCH</code> <code>Epoch(0)</code> <code>FAR_FUTURE_EPOCH</code> <code>Epoch(2**64 - 1)</code> <code>BASE_REWARDS_PER_EPOCH</code> <code>uint64(4)</code> <code>DEPOSIT_CONTRACT_TREE_DEPTH</code> <code>uint64(2**5)</code> (= 32) <code>JUSTIFICATION_BITS_LENGTH</code> <code>uint64(4)</code> <code>ENDIANNESS</code> <code>'little'</code>"},{"location":"specs/phase0/beacon-chain/#withdrawal-prefixes","title":"Withdrawal prefixes","text":"Name Value <code>BLS_WITHDRAWAL_PREFIX</code> <code>Bytes1('0x00')</code> <code>ETH1_ADDRESS_WITHDRAWAL_PREFIX</code> <code>Bytes1('0x01')</code>"},{"location":"specs/phase0/beacon-chain/#domain-types","title":"Domain types","text":"Name Value <code>DOMAIN_BEACON_PROPOSER</code> <code>DomainType('0x00000000')</code> <code>DOMAIN_BEACON_ATTESTER</code> <code>DomainType('0x01000000')</code> <code>DOMAIN_RANDAO</code> <code>DomainType('0x02000000')</code> <code>DOMAIN_DEPOSIT</code> <code>DomainType('0x03000000')</code> <code>DOMAIN_VOLUNTARY_EXIT</code> <code>DomainType('0x04000000')</code> <code>DOMAIN_SELECTION_PROOF</code> <code>DomainType('0x05000000')</code> <code>DOMAIN_AGGREGATE_AND_PROOF</code> <code>DomainType('0x06000000')</code> <code>DOMAIN_APPLICATION_MASK</code> <code>DomainType('0x00000001')</code> <p>Note: <code>DOMAIN_APPLICATION_MASK</code> reserves the rest of the bitspace in <code>DomainType</code> for application usage. This means for some <code>DomainType</code> <code>DOMAIN_SOME_APPLICATION</code>, <code>DOMAIN_SOME_APPLICATION &amp; DOMAIN_APPLICATION_MASK</code> MUST be non-zero. This expression for any other <code>DomainType</code> in the consensus specs MUST be zero.</p>"},{"location":"specs/phase0/beacon-chain/#preset","title":"Preset","text":"<p>Note: The below configuration is bundled as a preset: a bundle of configuration variables which are expected to differ between different modes of operation, e.g. testing, but not generally between different networks. Additional preset configurations can be found in the <code>configs</code> directory.</p>"},{"location":"specs/phase0/beacon-chain/#misc_1","title":"Misc","text":"Name Value <code>MAX_COMMITTEES_PER_SLOT</code> <code>uint64(2**6)</code> (= 64) <code>TARGET_COMMITTEE_SIZE</code> <code>uint64(2**7)</code> (= 128) <code>MAX_VALIDATORS_PER_COMMITTEE</code> <code>uint64(2**11)</code> (= 2,048) <code>SHUFFLE_ROUND_COUNT</code> <code>uint64(90)</code> <code>HYSTERESIS_QUOTIENT</code> <code>uint64(4)</code> <code>HYSTERESIS_DOWNWARD_MULTIPLIER</code> <code>uint64(1)</code> <code>HYSTERESIS_UPWARD_MULTIPLIER</code> <code>uint64(5)</code> <ul> <li>For the safety of committees, <code>TARGET_COMMITTEE_SIZE</code> exceeds   the recommended minimum committee size of 111;   with sufficient active validators (at least   <code>SLOTS_PER_EPOCH * TARGET_COMMITTEE_SIZE</code>), the shuffling algorithm ensures   committee sizes of at least <code>TARGET_COMMITTEE_SIZE</code>. (Unbiasable randomness   with a Verifiable Delay Function (VDF) will improve committee robustness and   lower the safe minimum committee size.)</li> </ul>"},{"location":"specs/phase0/beacon-chain/#gwei-values","title":"Gwei values","text":"Name Value <code>MIN_DEPOSIT_AMOUNT</code> <code>Gwei(2**0 * 10**9)</code> (= 1,000,000,000) <code>MAX_EFFECTIVE_BALANCE</code> <code>Gwei(2**5 * 10**9)</code> (= 32,000,000,000) <code>EFFECTIVE_BALANCE_INCREMENT</code> <code>Gwei(2**0 * 10**9)</code> (= 1,000,000,000)"},{"location":"specs/phase0/beacon-chain/#time-parameters","title":"Time parameters","text":"Name Value Unit Duration <code>MIN_ATTESTATION_INCLUSION_DELAY</code> <code>uint64(2**0)</code> (= 1) slots 12 seconds <code>SLOTS_PER_EPOCH</code> <code>uint64(2**5)</code> (= 32) slots 6.4 minutes <code>MIN_SEED_LOOKAHEAD</code> <code>uint64(2**0)</code> (= 1) epochs 6.4 minutes <code>MAX_SEED_LOOKAHEAD</code> <code>uint64(2**2)</code> (= 4) epochs 25.6 minutes <code>MIN_EPOCHS_TO_INACTIVITY_PENALTY</code> <code>uint64(2**2)</code> (= 4) epochs 25.6 minutes <code>EPOCHS_PER_ETH1_VOTING_PERIOD</code> <code>uint64(2**6)</code> (= 64) epochs ~6.8 hours <code>SLOTS_PER_HISTORICAL_ROOT</code> <code>uint64(2**13)</code> (= 8,192) slots ~27 hours"},{"location":"specs/phase0/beacon-chain/#state-list-lengths","title":"State list lengths","text":"Name Value Unit Duration <code>EPOCHS_PER_HISTORICAL_VECTOR</code> <code>uint64(2**16)</code> (= 65,536) epochs ~0.8 years <code>EPOCHS_PER_SLASHINGS_VECTOR</code> <code>uint64(2**13)</code> (= 8,192) epochs ~36 days <code>HISTORICAL_ROOTS_LIMIT</code> <code>uint64(2**24)</code> (= 16,777,216) historical roots ~52,262 years <code>VALIDATOR_REGISTRY_LIMIT</code> <code>uint64(2**40)</code> (= 1,099,511,627,776) validators"},{"location":"specs/phase0/beacon-chain/#rewards-and-penalties","title":"Rewards and penalties","text":"Name Value <code>BASE_REWARD_FACTOR</code> <code>uint64(2**6)</code> (= 64) <code>WHISTLEBLOWER_REWARD_QUOTIENT</code> <code>uint64(2**9)</code> (= 512) <code>PROPOSER_REWARD_QUOTIENT</code> <code>uint64(2**3)</code> (= 8) <code>INACTIVITY_PENALTY_QUOTIENT</code> <code>uint64(2**26)</code> (= 67,108,864) <code>MIN_SLASHING_PENALTY_QUOTIENT</code> <code>uint64(2**7)</code> (= 128) <code>PROPORTIONAL_SLASHING_MULTIPLIER</code> <code>uint64(1)</code> <ul> <li>The <code>INACTIVITY_PENALTY_QUOTIENT</code> equals <code>INVERSE_SQRT_E_DROP_TIME**2</code> where   <code>INVERSE_SQRT_E_DROP_TIME := 2**13</code> epochs (about 36 days) is the time it   takes the inactivity penalty to reduce the balance of non-participating   validators to about <code>1/sqrt(e) ~= 60.6%</code>. Indeed, the balance retained by   offline validators after <code>n</code> epochs is about   <code>(1 - 1/INACTIVITY_PENALTY_QUOTIENT)**(n**2/2)</code>; so after   <code>INVERSE_SQRT_E_DROP_TIME</code> epochs, it is roughly   <code>(1 - 1/INACTIVITY_PENALTY_QUOTIENT)**(INACTIVITY_PENALTY_QUOTIENT/2) ~= 1/sqrt(e)</code>.   Note this value will be upgraded to <code>2**24</code> after Phase 0 mainnet stabilizes   to provide a faster recovery in the event of an inactivity leak.</li> </ul> <ul> <li>The <code>PROPORTIONAL_SLASHING_MULTIPLIER</code> is set to <code>1</code> at initial mainnet   launch, resulting in one-third of the minimum accountable safety margin in the   event of a finality attack. After Phase 0 mainnet stabilizes, this value will   be upgraded to <code>3</code> to provide the maximal minimum accountable safety margin.</li> </ul>"},{"location":"specs/phase0/beacon-chain/#max-operations-per-block","title":"Max operations per block","text":"Name Value <code>MAX_PROPOSER_SLASHINGS</code> <code>2**4</code> (= 16) <code>MAX_ATTESTER_SLASHINGS</code> <code>2**1</code> (= 2) <code>MAX_ATTESTATIONS</code> <code>2**7</code> (= 128) <code>MAX_DEPOSITS</code> <code>2**4</code> (= 16) <code>MAX_VOLUNTARY_EXITS</code> <code>2**4</code> (= 16)"},{"location":"specs/phase0/beacon-chain/#configuration","title":"Configuration","text":"<p>Note: The default mainnet configuration values are included here for illustrative purposes. Defaults for this more dynamic type of configuration are available with the presets in the <code>configs</code> directory. Testnets and other types of chain instances may use a different configuration.</p>"},{"location":"specs/phase0/beacon-chain/#genesis-settings","title":"Genesis settings","text":"Name Value <code>MIN_GENESIS_ACTIVE_VALIDATOR_COUNT</code> <code>uint64(2**14)</code> (= 16,384) <code>MIN_GENESIS_TIME</code> <code>uint64(1606824000)</code> (Dec 1, 2020, 12pm UTC) <code>GENESIS_FORK_VERSION</code> <code>Version('0x00000000')</code> <code>GENESIS_DELAY</code> <code>uint64(604800)</code> (7 days)"},{"location":"specs/phase0/beacon-chain/#time-parameters_1","title":"Time parameters","text":"Name Value Unit Duration <code>SECONDS_PER_SLOT</code> deprecated <code>uint64(12)</code> seconds 12 seconds <code>SLOT_DURATION_MS</code> <code>uint64(12000)</code> milliseconds 12 seconds <code>SECONDS_PER_ETH1_BLOCK</code> <code>uint64(14)</code> seconds 14 seconds <code>MIN_VALIDATOR_WITHDRAWABILITY_DELAY</code> <code>uint64(2**8)</code> (= 256) epochs ~27 hours <code>SHARD_COMMITTEE_PERIOD</code> <code>uint64(2**8)</code> (= 256) epochs ~27 hours <code>ETH1_FOLLOW_DISTANCE</code> <code>uint64(2**11)</code> (= 2,048) Eth1 blocks ~8 hours"},{"location":"specs/phase0/beacon-chain/#validator-cycle","title":"Validator cycle","text":"Name Value <code>EJECTION_BALANCE</code> <code>Gwei(2**4 * 10**9)</code> (= 16,000,000,000) <code>MIN_PER_EPOCH_CHURN_LIMIT</code> <code>uint64(2**2)</code> (= 4) <code>CHURN_LIMIT_QUOTIENT</code> <code>uint64(2**16)</code> (= 65,536)"},{"location":"specs/phase0/beacon-chain/#containers","title":"Containers","text":"<p>The following types are SimpleSerialize (SSZ) containers.</p> <p>Note: The definitions are ordered topologically to facilitate execution of the spec.</p> <p>Note: Fields missing in container instantiations default to their zero value.</p>"},{"location":"specs/phase0/beacon-chain/#misc-dependencies","title":"Misc dependencies","text":""},{"location":"specs/phase0/beacon-chain/#fork","title":"<code>Fork</code>","text":"<pre><code>class Fork(Container):\n    previous_version: Version\n    current_version: Version\n    epoch: Epoch\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#forkdata","title":"<code>ForkData</code>","text":"<pre><code>class ForkData(Container):\n    current_version: Version\n    genesis_validators_root: Root\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#checkpoint","title":"<code>Checkpoint</code>","text":"<pre><code>class Checkpoint(Container):\n    epoch: Epoch\n    root: Root\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#validator","title":"<code>Validator</code>","text":"<pre><code>class Validator(Container):\n    pubkey: BLSPubkey\n    withdrawal_credentials: Bytes32\n    effective_balance: Gwei\n    slashed: boolean\n    activation_eligibility_epoch: Epoch\n    activation_epoch: Epoch\n    exit_epoch: Epoch\n    withdrawable_epoch: Epoch\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#attestationdata","title":"<code>AttestationData</code>","text":"<pre><code>class AttestationData(Container):\n    slot: Slot\n    index: CommitteeIndex\n    beacon_block_root: Root\n    source: Checkpoint\n    target: Checkpoint\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#indexedattestation","title":"<code>IndexedAttestation</code>","text":"<pre><code>class IndexedAttestation(Container):\n    attesting_indices: List[ValidatorIndex, MAX_VALIDATORS_PER_COMMITTEE]\n    data: AttestationData\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#pendingattestation","title":"<code>PendingAttestation</code>","text":"<pre><code>class PendingAttestation(Container):\n    aggregation_bits: Bitlist[MAX_VALIDATORS_PER_COMMITTEE]\n    data: AttestationData\n    inclusion_delay: Slot\n    proposer_index: ValidatorIndex\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#eth1data","title":"<code>Eth1Data</code>","text":"<pre><code>class Eth1Data(Container):\n    deposit_root: Root\n    deposit_count: uint64\n    block_hash: Hash32\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#historicalbatch","title":"<code>HistoricalBatch</code>","text":"<pre><code>class HistoricalBatch(Container):\n    block_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    state_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#depositmessage","title":"<code>DepositMessage</code>","text":"<pre><code>class DepositMessage(Container):\n    pubkey: BLSPubkey\n    withdrawal_credentials: Bytes32\n    amount: Gwei\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#depositdata","title":"<code>DepositData</code>","text":"<p>Note: <code>signature</code> is over <code>DepositMessage</code>.</p> <pre><code>class DepositData(Container):\n    pubkey: BLSPubkey\n    withdrawal_credentials: Bytes32\n    amount: Gwei\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#beaconblockheader","title":"<code>BeaconBlockHeader</code>","text":"<pre><code>class BeaconBlockHeader(Container):\n    slot: Slot\n    proposer_index: ValidatorIndex\n    parent_root: Root\n    state_root: Root\n    body_root: Root\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#signingdata","title":"<code>SigningData</code>","text":"<pre><code>class SigningData(Container):\n    object_root: Root\n    domain: Domain\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#beacon-operations","title":"Beacon operations","text":""},{"location":"specs/phase0/beacon-chain/#proposerslashing","title":"<code>ProposerSlashing</code>","text":"<pre><code>class ProposerSlashing(Container):\n    signed_header_1: SignedBeaconBlockHeader\n    signed_header_2: SignedBeaconBlockHeader\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#attesterslashing","title":"<code>AttesterSlashing</code>","text":"<pre><code>class AttesterSlashing(Container):\n    attestation_1: IndexedAttestation\n    attestation_2: IndexedAttestation\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#attestation","title":"<code>Attestation</code>","text":"<pre><code>class Attestation(Container):\n    aggregation_bits: Bitlist[MAX_VALIDATORS_PER_COMMITTEE]\n    data: AttestationData\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#deposit","title":"<code>Deposit</code>","text":"<p>Note: <code>proof</code> is the Merkle path to the deposit root.</p> <pre><code>class Deposit(Container):\n    proof: Vector[Bytes32, DEPOSIT_CONTRACT_TREE_DEPTH + 1]\n    data: DepositData\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#voluntaryexit","title":"<code>VoluntaryExit</code>","text":"<pre><code>class VoluntaryExit(Container):\n    epoch: Epoch\n    validator_index: ValidatorIndex\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#beacon-blocks","title":"Beacon blocks","text":""},{"location":"specs/phase0/beacon-chain/#beaconblockbody","title":"<code>BeaconBlockBody</code>","text":"<pre><code>class BeaconBlockBody(Container):\n    randao_reveal: BLSSignature\n    eth1_data: Eth1Data\n    graffiti: Bytes32\n    proposer_slashings: List[ProposerSlashing, MAX_PROPOSER_SLASHINGS]\n    attester_slashings: List[AttesterSlashing, MAX_ATTESTER_SLASHINGS]\n    attestations: List[Attestation, MAX_ATTESTATIONS]\n    deposits: List[Deposit, MAX_DEPOSITS]\n    voluntary_exits: List[SignedVoluntaryExit, MAX_VOLUNTARY_EXITS]\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#beaconblock","title":"<code>BeaconBlock</code>","text":"<pre><code>class BeaconBlock(Container):\n    slot: Slot\n    proposer_index: ValidatorIndex\n    parent_root: Root\n    state_root: Root\n    body: BeaconBlockBody\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#beacon-state","title":"Beacon state","text":""},{"location":"specs/phase0/beacon-chain/#beaconstate","title":"<code>BeaconState</code>","text":"<pre><code>class BeaconState(Container):\n    genesis_time: uint64\n    genesis_validators_root: Root\n    slot: Slot\n    fork: Fork\n    latest_block_header: BeaconBlockHeader\n    block_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    state_roots: Vector[Root, SLOTS_PER_HISTORICAL_ROOT]\n    historical_roots: List[Root, HISTORICAL_ROOTS_LIMIT]\n    eth1_data: Eth1Data\n    eth1_data_votes: List[Eth1Data, EPOCHS_PER_ETH1_VOTING_PERIOD * SLOTS_PER_EPOCH]\n    eth1_deposit_index: uint64\n    validators: List[Validator, VALIDATOR_REGISTRY_LIMIT]\n    balances: List[Gwei, VALIDATOR_REGISTRY_LIMIT]\n    randao_mixes: Vector[Bytes32, EPOCHS_PER_HISTORICAL_VECTOR]\n    slashings: Vector[Gwei, EPOCHS_PER_SLASHINGS_VECTOR]\n    previous_epoch_attestations: List[PendingAttestation, MAX_ATTESTATIONS * SLOTS_PER_EPOCH]\n    current_epoch_attestations: List[PendingAttestation, MAX_ATTESTATIONS * SLOTS_PER_EPOCH]\n    justification_bits: Bitvector[JUSTIFICATION_BITS_LENGTH]\n    previous_justified_checkpoint: Checkpoint\n    current_justified_checkpoint: Checkpoint\n    finalized_checkpoint: Checkpoint\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#signed-envelopes","title":"Signed envelopes","text":""},{"location":"specs/phase0/beacon-chain/#signedvoluntaryexit","title":"<code>SignedVoluntaryExit</code>","text":"<pre><code>class SignedVoluntaryExit(Container):\n    message: VoluntaryExit\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#signedbeaconblock","title":"<code>SignedBeaconBlock</code>","text":"<pre><code>class SignedBeaconBlock(Container):\n    message: BeaconBlock\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#signedbeaconblockheader","title":"<code>SignedBeaconBlockHeader</code>","text":"<pre><code>class SignedBeaconBlockHeader(Container):\n    message: BeaconBlockHeader\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#helper-functions","title":"Helper functions","text":"<p>Note: The definitions below are for specification purposes and are not necessarily optimal implementations.</p>"},{"location":"specs/phase0/beacon-chain/#math","title":"Math","text":""},{"location":"specs/phase0/beacon-chain/#integer_squareroot","title":"<code>integer_squareroot</code>","text":"<pre><code>def integer_squareroot(n: uint64) -&gt; uint64:\n    \"\"\"\n    Return the largest integer ``x`` such that ``x**2 &lt;= n``.\n    \"\"\"\n    if n == UINT64_MAX:\n        return UINT64_MAX_SQRT\n    x = n\n    y = (x + 1) // 2\n    while y &lt; x:\n        x = y\n        y = (x + n // x) // 2\n    return x\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#xor","title":"<code>xor</code>","text":"<pre><code>def xor(bytes_1: Bytes32, bytes_2: Bytes32) -&gt; Bytes32:\n    \"\"\"\n    Return the exclusive-or of two 32-byte strings.\n    \"\"\"\n    return Bytes32(a ^ b for a, b in zip(bytes_1, bytes_2))\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#uint_to_bytes","title":"<code>uint_to_bytes</code>","text":"<p><code>def uint_to_bytes(n: uint) -&gt; bytes</code> is a function for serializing the <code>uint</code> type object to bytes in <code>ENDIANNESS</code>-endian. The expected length of the output is the byte-length of the <code>uint</code> type.</p>"},{"location":"specs/phase0/beacon-chain/#bytes_to_uint64","title":"<code>bytes_to_uint64</code>","text":"<pre><code>def bytes_to_uint64(data: bytes) -&gt; uint64:\n    \"\"\"\n    Return the integer deserialization of ``data`` interpreted as ``ENDIANNESS``-endian.\n    \"\"\"\n    return uint64(int.from_bytes(data, ENDIANNESS))\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#saturating_sub","title":"<code>saturating_sub</code>","text":"<pre><code>def saturating_sub(a: int, b: int) -&gt; int:\n    \"\"\"\n    Computes a - b, saturating at numeric bounds.\n    \"\"\"\n    return a - b if a &gt; b else 0\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#crypto","title":"Crypto","text":""},{"location":"specs/phase0/beacon-chain/#hash","title":"<code>hash</code>","text":"<p><code>def hash(data: bytes) -&gt; Bytes32</code> is SHA256.</p>"},{"location":"specs/phase0/beacon-chain/#hash_tree_root","title":"<code>hash_tree_root</code>","text":"<p><code>def hash_tree_root(object: SSZSerializable) -&gt; Root</code> is a function for hashing objects into a single root by utilizing a hash tree structure, as defined in the SSZ spec.</p>"},{"location":"specs/phase0/beacon-chain/#bls-signatures","title":"BLS signatures","text":"<p>The IETF BLS signature draft standard v4 with ciphersuite <code>BLS_SIG_BLS12381G2_XMD:SHA-256_SSWU_RO_POP_</code> defines the following functions:</p> <ul> <li><code>def Sign(privkey: int, message: Bytes) -&gt; BLSSignature</code></li> <li><code>def Verify(pubkey: BLSPubkey, message: Bytes, signature: BLSSignature) -&gt; bool</code></li> <li><code>def Aggregate(signatures: Sequence[BLSSignature]) -&gt; BLSSignature</code></li> <li><code>def FastAggregateVerify(pubkeys: Sequence[BLSPubkey], message: Bytes, signature: BLSSignature) -&gt; bool</code></li> <li><code>def AggregateVerify(pubkeys: Sequence[BLSPubkey], messages: Sequence[Bytes], signature: BLSSignature) -&gt; bool</code></li> <li><code>def KeyValidate(pubkey: BLSPubkey) -&gt; bool</code></li> </ul> <p>The above functions are accessed through the <code>bls</code> module, e.g. <code>bls.Verify</code>.</p>"},{"location":"specs/phase0/beacon-chain/#predicates","title":"Predicates","text":""},{"location":"specs/phase0/beacon-chain/#is_active_validator","title":"<code>is_active_validator</code>","text":"<pre><code>def is_active_validator(validator: Validator, epoch: Epoch) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` is active.\n    \"\"\"\n    return validator.activation_epoch &lt;= epoch &lt; validator.exit_epoch\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#is_eligible_for_activation_queue","title":"<code>is_eligible_for_activation_queue</code>","text":"<pre><code>def is_eligible_for_activation_queue(validator: Validator) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` is eligible to be placed into the activation queue.\n    \"\"\"\n    return (\n        validator.activation_eligibility_epoch == FAR_FUTURE_EPOCH\n        and validator.effective_balance == MAX_EFFECTIVE_BALANCE\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#is_eligible_for_activation","title":"<code>is_eligible_for_activation</code>","text":"<pre><code>def is_eligible_for_activation(state: BeaconState, validator: Validator) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` is eligible for activation.\n    \"\"\"\n    return (\n        # Placement in queue is finalized\n        validator.activation_eligibility_epoch &lt;= state.finalized_checkpoint.epoch\n        # Has not yet been activated\n        and validator.activation_epoch == FAR_FUTURE_EPOCH\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#is_slashable_validator","title":"<code>is_slashable_validator</code>","text":"<pre><code>def is_slashable_validator(validator: Validator, epoch: Epoch) -&gt; bool:\n    \"\"\"\n    Check if ``validator`` is slashable.\n    \"\"\"\n    return (not validator.slashed) and (\n        validator.activation_epoch &lt;= epoch &lt; validator.withdrawable_epoch\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#is_slashable_attestation_data","title":"<code>is_slashable_attestation_data</code>","text":"<pre><code>def is_slashable_attestation_data(data_1: AttestationData, data_2: AttestationData) -&gt; bool:\n    \"\"\"\n    Check if ``data_1`` and ``data_2`` are slashable according to Casper FFG rules.\n    \"\"\"\n    return (\n        # Double vote\n        (data_1 != data_2 and data_1.target.epoch == data_2.target.epoch)\n        or\n        # Surround vote\n        (data_1.source.epoch &lt; data_2.source.epoch and data_2.target.epoch &lt; data_1.target.epoch)\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#is_valid_indexed_attestation","title":"<code>is_valid_indexed_attestation</code>","text":"<pre><code>def is_valid_indexed_attestation(\n    state: BeaconState, indexed_attestation: IndexedAttestation\n) -&gt; bool:\n    \"\"\"\n    Check if ``indexed_attestation`` is not empty, has sorted and unique indices and has a valid aggregate signature.\n    \"\"\"\n    # Verify indices are sorted and unique\n    indices = indexed_attestation.attesting_indices\n    if len(indices) == 0 or not indices == sorted(set(indices)):\n        return False\n    # Verify aggregate signature\n    pubkeys = [state.validators[i].pubkey for i in indices]\n    domain = get_domain(state, DOMAIN_BEACON_ATTESTER, indexed_attestation.data.target.epoch)\n    signing_root = compute_signing_root(indexed_attestation.data, domain)\n    return bls.FastAggregateVerify(pubkeys, signing_root, indexed_attestation.signature)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#is_valid_merkle_branch","title":"<code>is_valid_merkle_branch</code>","text":"<pre><code>def is_valid_merkle_branch(\n    leaf: Bytes32, branch: Sequence[Bytes32], depth: uint64, index: uint64, root: Root\n) -&gt; bool:\n    \"\"\"\n    Check if ``leaf`` at ``index`` verifies against the Merkle ``root`` and ``branch``.\n    \"\"\"\n    value = leaf\n    for i in range(depth):\n        if index // (2**i) % 2:\n            value = hash(branch[i] + value)\n        else:\n            value = hash(value + branch[i])\n    return value == root\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#misc_2","title":"Misc","text":""},{"location":"specs/phase0/beacon-chain/#compute_shuffled_index","title":"<code>compute_shuffled_index</code>","text":"<pre><code>def compute_shuffled_index(index: uint64, index_count: uint64, seed: Bytes32) -&gt; uint64:\n    \"\"\"\n    Return the shuffled index corresponding to ``seed`` (and ``index_count``).\n    \"\"\"\n    assert index &lt; index_count\n\n    # Swap or not (https://link.springer.com/content/pdf/10.1007%2F978-3-642-32009-5_1.pdf)\n    # See the 'generalized domain' algorithm on page 3\n    for current_round in range(SHUFFLE_ROUND_COUNT):\n        pivot = bytes_to_uint64(hash(seed + uint_to_bytes(uint8(current_round)))[0:8]) % index_count\n        flip = (pivot + index_count - index) % index_count\n        position = max(index, flip)\n        source = hash(\n            seed + uint_to_bytes(uint8(current_round)) + uint_to_bytes(uint32(position // 256))\n        )\n        byte = uint8(source[(position % 256) // 8])\n        bit = (byte &gt;&gt; (position % 8)) % 2\n        index = flip if bit else index\n\n    return index\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#compute_proposer_index","title":"<code>compute_proposer_index</code>","text":"<pre><code>def compute_proposer_index(\n    state: BeaconState, indices: Sequence[ValidatorIndex], seed: Bytes32\n) -&gt; ValidatorIndex:\n    \"\"\"\n    Return from ``indices`` a random index sampled by effective balance.\n    \"\"\"\n    assert len(indices) &gt; 0\n    MAX_RANDOM_BYTE = 2**8 - 1\n    i = uint64(0)\n    total = uint64(len(indices))\n    while True:\n        candidate_index = indices[compute_shuffled_index(i % total, total, seed)]\n        random_byte = hash(seed + uint_to_bytes(uint64(i // 32)))[i % 32]\n        effective_balance = state.validators[candidate_index].effective_balance\n        if effective_balance * MAX_RANDOM_BYTE &gt;= MAX_EFFECTIVE_BALANCE * random_byte:\n            return candidate_index\n        i += 1\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#compute_committee","title":"<code>compute_committee</code>","text":"<pre><code>def compute_committee(\n    indices: Sequence[ValidatorIndex], seed: Bytes32, index: uint64, count: uint64\n) -&gt; Sequence[ValidatorIndex]:\n    \"\"\"\n    Return the committee corresponding to ``indices``, ``seed``, ``index``, and committee ``count``.\n    \"\"\"\n    start = (len(indices) * index) // count\n    end = (len(indices) * uint64(index + 1)) // count\n    return [\n        indices[compute_shuffled_index(uint64(i), uint64(len(indices)), seed)]\n        for i in range(start, end)\n    ]\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#compute_time_at_slot","title":"<code>compute_time_at_slot</code>","text":"<p>Note: This function is unsafe with respect to overflows and underflows.</p> <pre><code>def compute_time_at_slot(state: BeaconState, slot: Slot) -&gt; uint64:\n    slots_since_genesis = slot - GENESIS_SLOT\n    return uint64(state.genesis_time + slots_since_genesis * SECONDS_PER_SLOT)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#compute_epoch_at_slot","title":"<code>compute_epoch_at_slot</code>","text":"<pre><code>def compute_epoch_at_slot(slot: Slot) -&gt; Epoch:\n    \"\"\"\n    Return the epoch number at ``slot``.\n    \"\"\"\n    return Epoch(slot // SLOTS_PER_EPOCH)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#compute_start_slot_at_epoch","title":"<code>compute_start_slot_at_epoch</code>","text":"<pre><code>def compute_start_slot_at_epoch(epoch: Epoch) -&gt; Slot:\n    \"\"\"\n    Return the start slot of ``epoch``.\n    \"\"\"\n    return Slot(epoch * SLOTS_PER_EPOCH)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#compute_activation_exit_epoch","title":"<code>compute_activation_exit_epoch</code>","text":"<pre><code>def compute_activation_exit_epoch(epoch: Epoch) -&gt; Epoch:\n    \"\"\"\n    Return the epoch during which validator activations and exits initiated in ``epoch`` take effect.\n    \"\"\"\n    return Epoch(epoch + 1 + MAX_SEED_LOOKAHEAD)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#compute_fork_data_root","title":"<code>compute_fork_data_root</code>","text":"<pre><code>def compute_fork_data_root(current_version: Version, genesis_validators_root: Root) -&gt; Root:\n    \"\"\"\n    Return the 32-byte fork data root for the ``current_version`` and ``genesis_validators_root``.\n    This is used primarily in signature domains to avoid collisions across forks/chains.\n    \"\"\"\n    return hash_tree_root(\n        ForkData(\n            current_version=current_version,\n            genesis_validators_root=genesis_validators_root,\n        )\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#compute_domain","title":"<code>compute_domain</code>","text":"<pre><code>def compute_domain(\n    domain_type: DomainType, fork_version: Version = None, genesis_validators_root: Root = None\n) -&gt; Domain:\n    \"\"\"\n    Return the domain for the ``domain_type`` and ``fork_version``.\n    \"\"\"\n    if fork_version is None:\n        fork_version = GENESIS_FORK_VERSION\n    if genesis_validators_root is None:\n        genesis_validators_root = Root()  # all bytes zero by default\n    fork_data_root = compute_fork_data_root(fork_version, genesis_validators_root)\n    return Domain(domain_type + fork_data_root[:28])\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#compute_signing_root","title":"<code>compute_signing_root</code>","text":"<pre><code>def compute_signing_root(ssz_object: SSZObject, domain: Domain) -&gt; Root:\n    \"\"\"\n    Return the signing root for the corresponding signing data.\n    \"\"\"\n    return hash_tree_root(\n        SigningData(\n            object_root=hash_tree_root(ssz_object),\n            domain=domain,\n        )\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#beacon-state-accessors","title":"Beacon state accessors","text":""},{"location":"specs/phase0/beacon-chain/#get_current_epoch","title":"<code>get_current_epoch</code>","text":"<pre><code>def get_current_epoch(state: BeaconState) -&gt; Epoch:\n    \"\"\"\n    Return the current epoch.\n    \"\"\"\n    return compute_epoch_at_slot(state.slot)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_previous_epoch","title":"<code>get_previous_epoch</code>","text":"<pre><code>def get_previous_epoch(state: BeaconState) -&gt; Epoch:\n    \"\"\"`\n    Return the previous epoch (unless the current epoch is ``GENESIS_EPOCH``).\n    \"\"\"\n    current_epoch = get_current_epoch(state)\n    return GENESIS_EPOCH if current_epoch == GENESIS_EPOCH else Epoch(current_epoch - 1)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_block_root","title":"<code>get_block_root</code>","text":"<pre><code>def get_block_root(state: BeaconState, epoch: Epoch) -&gt; Root:\n    \"\"\"\n    Return the block root at the start of a recent ``epoch``.\n    \"\"\"\n    return get_block_root_at_slot(state, compute_start_slot_at_epoch(epoch))\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_block_root_at_slot","title":"<code>get_block_root_at_slot</code>","text":"<pre><code>def get_block_root_at_slot(state: BeaconState, slot: Slot) -&gt; Root:\n    \"\"\"\n    Return the block root at a recent ``slot``.\n    \"\"\"\n    assert slot &lt; state.slot &lt;= slot + SLOTS_PER_HISTORICAL_ROOT\n    return state.block_roots[slot % SLOTS_PER_HISTORICAL_ROOT]\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_randao_mix","title":"<code>get_randao_mix</code>","text":"<pre><code>def get_randao_mix(state: BeaconState, epoch: Epoch) -&gt; Bytes32:\n    \"\"\"\n    Return the randao mix at a recent ``epoch``.\n    \"\"\"\n    return state.randao_mixes[epoch % EPOCHS_PER_HISTORICAL_VECTOR]\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_active_validator_indices","title":"<code>get_active_validator_indices</code>","text":"<pre><code>def get_active_validator_indices(state: BeaconState, epoch: Epoch) -&gt; Sequence[ValidatorIndex]:\n    \"\"\"\n    Return the sequence of active validator indices at ``epoch``.\n    \"\"\"\n    return [\n        ValidatorIndex(i) for i, v in enumerate(state.validators) if is_active_validator(v, epoch)\n    ]\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_validator_churn_limit","title":"<code>get_validator_churn_limit</code>","text":"<pre><code>def get_validator_churn_limit(state: BeaconState) -&gt; uint64:\n    \"\"\"\n    Return the validator churn limit for the current epoch.\n    \"\"\"\n    active_validator_indices = get_active_validator_indices(state, get_current_epoch(state))\n    return max(\n        MIN_PER_EPOCH_CHURN_LIMIT, uint64(len(active_validator_indices)) // CHURN_LIMIT_QUOTIENT\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_seed","title":"<code>get_seed</code>","text":"<pre><code>def get_seed(state: BeaconState, epoch: Epoch, domain_type: DomainType) -&gt; Bytes32:\n    \"\"\"\n    Return the seed at ``epoch``.\n    \"\"\"\n    mix = get_randao_mix(\n        state, Epoch(epoch + EPOCHS_PER_HISTORICAL_VECTOR - MIN_SEED_LOOKAHEAD - 1)\n    )  # Avoid underflow\n    return hash(domain_type + uint_to_bytes(epoch) + mix)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_committee_count_per_slot","title":"<code>get_committee_count_per_slot</code>","text":"<pre><code>def get_committee_count_per_slot(state: BeaconState, epoch: Epoch) -&gt; uint64:\n    \"\"\"\n    Return the number of committees in each slot for the given ``epoch``.\n    \"\"\"\n    return max(\n        uint64(1),\n        min(\n            MAX_COMMITTEES_PER_SLOT,\n            uint64(len(get_active_validator_indices(state, epoch)))\n            // SLOTS_PER_EPOCH\n            // TARGET_COMMITTEE_SIZE,\n        ),\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_beacon_committee","title":"<code>get_beacon_committee</code>","text":"<pre><code>def get_beacon_committee(\n    state: BeaconState, slot: Slot, index: CommitteeIndex\n) -&gt; Sequence[ValidatorIndex]:\n    \"\"\"\n    Return the beacon committee at ``slot`` for ``index``.\n    \"\"\"\n    epoch = compute_epoch_at_slot(slot)\n    committees_per_slot = get_committee_count_per_slot(state, epoch)\n    return compute_committee(\n        indices=get_active_validator_indices(state, epoch),\n        seed=get_seed(state, epoch, DOMAIN_BEACON_ATTESTER),\n        index=(slot % SLOTS_PER_EPOCH) * committees_per_slot + index,\n        count=committees_per_slot * SLOTS_PER_EPOCH,\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_beacon_proposer_index","title":"<code>get_beacon_proposer_index</code>","text":"<pre><code>def get_beacon_proposer_index(state: BeaconState) -&gt; ValidatorIndex:\n    \"\"\"\n    Return the beacon proposer index at the current slot.\n    \"\"\"\n    epoch = get_current_epoch(state)\n    seed = hash(get_seed(state, epoch, DOMAIN_BEACON_PROPOSER) + uint_to_bytes(state.slot))\n    indices = get_active_validator_indices(state, epoch)\n    return compute_proposer_index(state, indices, seed)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_total_balance","title":"<code>get_total_balance</code>","text":"<pre><code>def get_total_balance(state: BeaconState, indices: Set[ValidatorIndex]) -&gt; Gwei:\n    \"\"\"\n    Return the combined effective balance of the ``indices``.\n    ``EFFECTIVE_BALANCE_INCREMENT`` Gwei minimum to avoid divisions by zero.\n    Math safe up to ~10B ETH, after which this overflows uint64.\n    \"\"\"\n    return Gwei(\n        max(\n            EFFECTIVE_BALANCE_INCREMENT,\n            sum([state.validators[index].effective_balance for index in indices]),\n        )\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_total_active_balance","title":"<code>get_total_active_balance</code>","text":"<pre><code>def get_total_active_balance(state: BeaconState) -&gt; Gwei:\n    \"\"\"\n    Return the combined effective balance of the active validators.\n    Note: ``get_total_balance`` returns ``EFFECTIVE_BALANCE_INCREMENT`` Gwei minimum to avoid divisions by zero.\n    \"\"\"\n    return get_total_balance(\n        state, set(get_active_validator_indices(state, get_current_epoch(state)))\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_domain","title":"<code>get_domain</code>","text":"<pre><code>def get_domain(state: BeaconState, domain_type: DomainType, epoch: Epoch = None) -&gt; Domain:\n    \"\"\"\n    Return the signature domain (fork version concatenated with domain type) of a message.\n    \"\"\"\n    epoch = get_current_epoch(state) if epoch is None else epoch\n    fork_version = (\n        state.fork.previous_version if epoch &lt; state.fork.epoch else state.fork.current_version\n    )\n    return compute_domain(domain_type, fork_version, state.genesis_validators_root)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_indexed_attestation","title":"<code>get_indexed_attestation</code>","text":"<pre><code>def get_indexed_attestation(state: BeaconState, attestation: Attestation) -&gt; IndexedAttestation:\n    \"\"\"\n    Return the indexed attestation corresponding to ``attestation``.\n    \"\"\"\n    attesting_indices = get_attesting_indices(state, attestation)\n\n    return IndexedAttestation(\n        attesting_indices=sorted(attesting_indices),\n        data=attestation.data,\n        signature=attestation.signature,\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_attesting_indices","title":"<code>get_attesting_indices</code>","text":"<pre><code>def get_attesting_indices(state: BeaconState, attestation: Attestation) -&gt; Set[ValidatorIndex]:\n    \"\"\"\n    Return the set of attesting indices corresponding to ``data`` and ``bits``.\n    \"\"\"\n    committee = get_beacon_committee(state, attestation.data.slot, attestation.data.index)\n    return set(index for i, index in enumerate(committee) if attestation.aggregation_bits[i])\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#beacon-state-mutators","title":"Beacon state mutators","text":""},{"location":"specs/phase0/beacon-chain/#increase_balance","title":"<code>increase_balance</code>","text":"<pre><code>def increase_balance(state: BeaconState, index: ValidatorIndex, delta: Gwei) -&gt; None:\n    \"\"\"\n    Increase the validator balance at index ``index`` by ``delta``.\n    \"\"\"\n    state.balances[index] += delta\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#decrease_balance","title":"<code>decrease_balance</code>","text":"<pre><code>def decrease_balance(state: BeaconState, index: ValidatorIndex, delta: Gwei) -&gt; None:\n    \"\"\"\n    Decrease the validator balance at index ``index`` by ``delta``, with underflow protection.\n    \"\"\"\n    state.balances[index] = 0 if delta &gt; state.balances[index] else state.balances[index] - delta\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#initiate_validator_exit","title":"<code>initiate_validator_exit</code>","text":"<pre><code>def initiate_validator_exit(state: BeaconState, index: ValidatorIndex) -&gt; None:\n    \"\"\"\n    Initiate the exit of the validator with index ``index``.\n    \"\"\"\n    # Return if validator already initiated exit\n    validator = state.validators[index]\n    if validator.exit_epoch != FAR_FUTURE_EPOCH:\n        return\n\n    # Compute exit queue epoch\n    exit_epochs = [v.exit_epoch for v in state.validators if v.exit_epoch != FAR_FUTURE_EPOCH]\n    exit_queue_epoch = max(exit_epochs + [compute_activation_exit_epoch(get_current_epoch(state))])\n    exit_queue_churn = len([v for v in state.validators if v.exit_epoch == exit_queue_epoch])\n    if exit_queue_churn &gt;= get_validator_churn_limit(state):\n        exit_queue_epoch += Epoch(1)\n\n    # Set validator exit epoch and withdrawable epoch\n    validator.exit_epoch = exit_queue_epoch\n    validator.withdrawable_epoch = Epoch(validator.exit_epoch + MIN_VALIDATOR_WITHDRAWABILITY_DELAY)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#slash_validator","title":"<code>slash_validator</code>","text":"<pre><code>def slash_validator(\n    state: BeaconState, slashed_index: ValidatorIndex, whistleblower_index: ValidatorIndex = None\n) -&gt; None:\n    \"\"\"\n    Slash the validator with index ``slashed_index``.\n    \"\"\"\n    epoch = get_current_epoch(state)\n    initiate_validator_exit(state, slashed_index)\n    validator = state.validators[slashed_index]\n    validator.slashed = True\n    validator.withdrawable_epoch = max(\n        validator.withdrawable_epoch, Epoch(epoch + EPOCHS_PER_SLASHINGS_VECTOR)\n    )\n    state.slashings[epoch % EPOCHS_PER_SLASHINGS_VECTOR] += validator.effective_balance\n    decrease_balance(\n        state, slashed_index, validator.effective_balance // MIN_SLASHING_PENALTY_QUOTIENT\n    )\n\n    # Apply proposer and whistleblower rewards\n    proposer_index = get_beacon_proposer_index(state)\n    if whistleblower_index is None:\n        whistleblower_index = proposer_index\n    whistleblower_reward = Gwei(validator.effective_balance // WHISTLEBLOWER_REWARD_QUOTIENT)\n    proposer_reward = Gwei(whistleblower_reward // PROPOSER_REWARD_QUOTIENT)\n    increase_balance(state, proposer_index, proposer_reward)\n    increase_balance(state, whistleblower_index, Gwei(whistleblower_reward - proposer_reward))\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#genesis","title":"Genesis","text":"<p>Before the Ethereum beacon chain genesis has been triggered, and for every Ethereum proof-of-work block, let <code>candidate_state = initialize_beacon_state_from_eth1(eth1_block_hash, eth1_timestamp, deposits)</code> where:</p> <ul> <li><code>eth1_block_hash</code> is the hash of the Ethereum proof-of-work block</li> <li><code>eth1_timestamp</code> is the Unix timestamp corresponding to <code>eth1_block_hash</code></li> <li><code>deposits</code> is the sequence of all deposits, ordered chronologically, up to   (and including) the block with hash <code>eth1_block_hash</code></li> </ul> <p>Proof-of-work blocks must only be considered once they are at least <code>SECONDS_PER_ETH1_BLOCK * ETH1_FOLLOW_DISTANCE</code> seconds old (i.e. <code>eth1_timestamp + SECONDS_PER_ETH1_BLOCK * ETH1_FOLLOW_DISTANCE &lt;= current_unix_time</code>). Due to this constraint, if <code>GENESIS_DELAY &lt; SECONDS_PER_ETH1_BLOCK * ETH1_FOLLOW_DISTANCE</code>, then the <code>genesis_time</code> can happen before the time/state is first known. Values should be configured to avoid this case.</p> <pre><code>def initialize_beacon_state_from_eth1(\n    eth1_block_hash: Hash32, eth1_timestamp: uint64, deposits: Sequence[Deposit]\n) -&gt; BeaconState:\n    fork = Fork(\n        previous_version=GENESIS_FORK_VERSION,\n        current_version=GENESIS_FORK_VERSION,\n        epoch=GENESIS_EPOCH,\n    )\n    state = BeaconState(\n        genesis_time=eth1_timestamp + GENESIS_DELAY,\n        fork=fork,\n        eth1_data=Eth1Data(block_hash=eth1_block_hash, deposit_count=uint64(len(deposits))),\n        latest_block_header=BeaconBlockHeader(body_root=hash_tree_root(BeaconBlockBody())),\n        randao_mixes=[eth1_block_hash]\n        * EPOCHS_PER_HISTORICAL_VECTOR,  # Seed RANDAO with Eth1 entropy\n    )\n\n    # Process deposits\n    leaves = list(map(lambda deposit: deposit.data, deposits))\n    for index, deposit in enumerate(deposits):\n        deposit_data_list = List[DepositData, 2**DEPOSIT_CONTRACT_TREE_DEPTH](*leaves[: index + 1])\n        state.eth1_data.deposit_root = hash_tree_root(deposit_data_list)\n        process_deposit(state, deposit)\n\n    # Process activations\n    for index, validator in enumerate(state.validators):\n        balance = state.balances[index]\n        validator.effective_balance = min(\n            balance - balance % EFFECTIVE_BALANCE_INCREMENT, MAX_EFFECTIVE_BALANCE\n        )\n        if validator.effective_balance == MAX_EFFECTIVE_BALANCE:\n            validator.activation_eligibility_epoch = GENESIS_EPOCH\n            validator.activation_epoch = GENESIS_EPOCH\n\n    # Set genesis validators root for domain separation and chain versioning\n    state.genesis_validators_root = hash_tree_root(state.validators)\n\n    return state\n</code></pre> <p>Note: The ETH1 block with <code>eth1_timestamp</code> meeting the minimum genesis active validator count criteria can also occur before <code>MIN_GENESIS_TIME</code>.</p>"},{"location":"specs/phase0/beacon-chain/#genesis-state","title":"Genesis state","text":"<p>Let <code>genesis_state = candidate_state</code> whenever <code>is_valid_genesis_state(candidate_state) is True</code> for the first time.</p> <pre><code>def is_valid_genesis_state(state: BeaconState) -&gt; bool:\n    if state.genesis_time &lt; MIN_GENESIS_TIME:\n        return False\n    if len(get_active_validator_indices(state, GENESIS_EPOCH)) &lt; MIN_GENESIS_ACTIVE_VALIDATOR_COUNT:\n        return False\n    return True\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#genesis-block","title":"Genesis block","text":"<p>Let <code>genesis_block = BeaconBlock(state_root=hash_tree_root(genesis_state))</code>.</p>"},{"location":"specs/phase0/beacon-chain/#beacon-chain-state-transition-function","title":"Beacon chain state transition function","text":"<p>The post-state corresponding to a pre-state <code>state</code> and a signed block <code>signed_block</code> is defined as <code>state_transition(state, signed_block)</code>. State transitions that trigger an unhandled exception (e.g. a failed <code>assert</code> or an out-of-range list access) are considered invalid. State transitions that cause a <code>uint64</code> overflow or underflow are also considered invalid.</p> <pre><code>def state_transition(\n    state: BeaconState, signed_block: SignedBeaconBlock, validate_result: bool = True\n) -&gt; None:\n    block = signed_block.message\n    # Process slots (including those with no blocks) since block\n    process_slots(state, block.slot)\n    # Verify signature\n    if validate_result:\n        assert verify_block_signature(state, signed_block)\n    # Process block\n    process_block(state, block)\n    # Verify state root\n    if validate_result:\n        assert block.state_root == hash_tree_root(state)\n</code></pre> <pre><code>def verify_block_signature(state: BeaconState, signed_block: SignedBeaconBlock) -&gt; bool:\n    proposer = state.validators[signed_block.message.proposer_index]\n    signing_root = compute_signing_root(\n        signed_block.message, get_domain(state, DOMAIN_BEACON_PROPOSER)\n    )\n    return bls.Verify(proposer.pubkey, signing_root, signed_block.signature)\n</code></pre> <pre><code>def process_slots(state: BeaconState, slot: Slot) -&gt; None:\n    assert state.slot &lt; slot\n    while state.slot &lt; slot:\n        process_slot(state)\n        # Process epoch on the start slot of the next epoch\n        if (state.slot + 1) % SLOTS_PER_EPOCH == 0:\n            process_epoch(state)\n        state.slot = Slot(state.slot + 1)\n</code></pre> <pre><code>def process_slot(state: BeaconState) -&gt; None:\n    # Cache state root\n    previous_state_root = hash_tree_root(state)\n    state.state_roots[state.slot % SLOTS_PER_HISTORICAL_ROOT] = previous_state_root\n    # Cache latest block header state root\n    if state.latest_block_header.state_root == Bytes32():\n        state.latest_block_header.state_root = previous_state_root\n    # Cache block root\n    previous_block_root = hash_tree_root(state.latest_block_header)\n    state.block_roots[state.slot % SLOTS_PER_HISTORICAL_ROOT] = previous_block_root\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#epoch-processing","title":"Epoch processing","text":"<pre><code>def process_epoch(state: BeaconState) -&gt; None:\n    process_justification_and_finalization(state)\n    process_rewards_and_penalties(state)\n    process_registry_updates(state)\n    process_slashings(state)\n    process_eth1_data_reset(state)\n    process_effective_balance_updates(state)\n    process_slashings_reset(state)\n    process_randao_mixes_reset(state)\n    process_historical_roots_update(state)\n    process_participation_record_updates(state)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#helper-functions_1","title":"Helper functions","text":"<pre><code>def get_matching_source_attestations(\n    state: BeaconState, epoch: Epoch\n) -&gt; Sequence[PendingAttestation]:\n    assert epoch in (get_previous_epoch(state), get_current_epoch(state))\n    return (\n        state.current_epoch_attestations\n        if epoch == get_current_epoch(state)\n        else state.previous_epoch_attestations\n    )\n</code></pre> <pre><code>def get_matching_target_attestations(\n    state: BeaconState, epoch: Epoch\n) -&gt; Sequence[PendingAttestation]:\n    return [\n        a\n        for a in get_matching_source_attestations(state, epoch)\n        if a.data.target.root == get_block_root(state, epoch)\n    ]\n</code></pre> <pre><code>def get_matching_head_attestations(\n    state: BeaconState, epoch: Epoch\n) -&gt; Sequence[PendingAttestation]:\n    return [\n        a\n        for a in get_matching_target_attestations(state, epoch)\n        if a.data.beacon_block_root == get_block_root_at_slot(state, a.data.slot)\n    ]\n</code></pre> <pre><code>def get_unslashed_attesting_indices(\n    state: BeaconState, attestations: Sequence[PendingAttestation]\n) -&gt; Set[ValidatorIndex]:\n    output: Set[ValidatorIndex] = set()\n    for a in attestations:\n        output = output.union(get_attesting_indices(state, a))\n    return set(filter(lambda index: not state.validators[index].slashed, output))\n</code></pre> <pre><code>def get_attesting_balance(state: BeaconState, attestations: Sequence[PendingAttestation]) -&gt; Gwei:\n    \"\"\"\n    Return the combined effective balance of the set of unslashed validators participating in ``attestations``.\n    Note: ``get_total_balance`` returns ``EFFECTIVE_BALANCE_INCREMENT`` Gwei minimum to avoid divisions by zero.\n    \"\"\"\n    return get_total_balance(state, get_unslashed_attesting_indices(state, attestations))\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#justification-and-finalization","title":"Justification and finalization","text":"<pre><code>def process_justification_and_finalization(state: BeaconState) -&gt; None:\n    # Initial FFG checkpoint values have a `0x00` stub for `root`.\n    # Skip FFG updates in the first two epochs to avoid corner cases that might result in modifying this stub.\n    if get_current_epoch(state) &lt;= GENESIS_EPOCH + 1:\n        return\n    previous_attestations = get_matching_target_attestations(state, get_previous_epoch(state))\n    current_attestations = get_matching_target_attestations(state, get_current_epoch(state))\n    total_active_balance = get_total_active_balance(state)\n    previous_target_balance = get_attesting_balance(state, previous_attestations)\n    current_target_balance = get_attesting_balance(state, current_attestations)\n    weigh_justification_and_finalization(\n        state, total_active_balance, previous_target_balance, current_target_balance\n    )\n</code></pre> <pre><code>def weigh_justification_and_finalization(\n    state: BeaconState,\n    total_active_balance: Gwei,\n    previous_epoch_target_balance: Gwei,\n    current_epoch_target_balance: Gwei,\n) -&gt; None:\n    previous_epoch = get_previous_epoch(state)\n    current_epoch = get_current_epoch(state)\n    old_previous_justified_checkpoint = state.previous_justified_checkpoint\n    old_current_justified_checkpoint = state.current_justified_checkpoint\n\n    # Process justifications\n    state.previous_justified_checkpoint = state.current_justified_checkpoint\n    state.justification_bits[1:] = state.justification_bits[: JUSTIFICATION_BITS_LENGTH - 1]\n    state.justification_bits[0] = 0b0\n    if previous_epoch_target_balance * 3 &gt;= total_active_balance * 2:\n        state.current_justified_checkpoint = Checkpoint(\n            epoch=previous_epoch, root=get_block_root(state, previous_epoch)\n        )\n        state.justification_bits[1] = 0b1\n    if current_epoch_target_balance * 3 &gt;= total_active_balance * 2:\n        state.current_justified_checkpoint = Checkpoint(\n            epoch=current_epoch, root=get_block_root(state, current_epoch)\n        )\n        state.justification_bits[0] = 0b1\n\n    # Process finalizations\n    bits = state.justification_bits\n    # The 2nd/3rd/4th most recent epochs are justified, the 2nd using the 4th as source\n    if all(bits[1:4]) and old_previous_justified_checkpoint.epoch + 3 == current_epoch:\n        state.finalized_checkpoint = old_previous_justified_checkpoint\n    # The 2nd/3rd most recent epochs are justified, the 2nd using the 3rd as source\n    if all(bits[1:3]) and old_previous_justified_checkpoint.epoch + 2 == current_epoch:\n        state.finalized_checkpoint = old_previous_justified_checkpoint\n    # The 1st/2nd/3rd most recent epochs are justified, the 1st using the 3rd as source\n    if all(bits[0:3]) and old_current_justified_checkpoint.epoch + 2 == current_epoch:\n        state.finalized_checkpoint = old_current_justified_checkpoint\n    # The 1st/2nd most recent epochs are justified, the 1st using the 2nd as source\n    if all(bits[0:2]) and old_current_justified_checkpoint.epoch + 1 == current_epoch:\n        state.finalized_checkpoint = old_current_justified_checkpoint\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#rewards-and-penalties_1","title":"Rewards and penalties","text":""},{"location":"specs/phase0/beacon-chain/#helpers","title":"Helpers","text":"<pre><code>def get_base_reward(state: BeaconState, index: ValidatorIndex) -&gt; Gwei:\n    total_balance = get_total_active_balance(state)\n    effective_balance = state.validators[index].effective_balance\n    return Gwei(\n        effective_balance\n        * BASE_REWARD_FACTOR\n        // integer_squareroot(total_balance)\n        // BASE_REWARDS_PER_EPOCH\n    )\n</code></pre> <pre><code>def get_proposer_reward(state: BeaconState, attesting_index: ValidatorIndex) -&gt; Gwei:\n    return Gwei(get_base_reward(state, attesting_index) // PROPOSER_REWARD_QUOTIENT)\n</code></pre> <pre><code>def get_finality_delay(state: BeaconState) -&gt; uint64:\n    return get_previous_epoch(state) - state.finalized_checkpoint.epoch\n</code></pre> <pre><code>def is_in_inactivity_leak(state: BeaconState) -&gt; bool:\n    return get_finality_delay(state) &gt; MIN_EPOCHS_TO_INACTIVITY_PENALTY\n</code></pre> <pre><code>def get_eligible_validator_indices(state: BeaconState) -&gt; Sequence[ValidatorIndex]:\n    previous_epoch = get_previous_epoch(state)\n    return [\n        ValidatorIndex(index)\n        for index, v in enumerate(state.validators)\n        if is_active_validator(v, previous_epoch)\n        or (v.slashed and previous_epoch + 1 &lt; v.withdrawable_epoch)\n    ]\n</code></pre> <pre><code>def get_attestation_component_deltas(\n    state: BeaconState, attestations: Sequence[PendingAttestation]\n) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:\n    \"\"\"\n    Helper with shared logic for use by get source, target, and head deltas functions\n    \"\"\"\n    rewards = [Gwei(0)] * len(state.validators)\n    penalties = [Gwei(0)] * len(state.validators)\n    total_balance = get_total_active_balance(state)\n    unslashed_attesting_indices = get_unslashed_attesting_indices(state, attestations)\n    attesting_balance = get_total_balance(state, unslashed_attesting_indices)\n    for index in get_eligible_validator_indices(state):\n        if index in unslashed_attesting_indices:\n            increment = EFFECTIVE_BALANCE_INCREMENT  # Factored out from balance totals to avoid uint64 overflow\n            if is_in_inactivity_leak(state):\n                # Since full base reward will be canceled out by inactivity penalty deltas,\n                # optimal participation receives full base reward compensation here.\n                rewards[index] += get_base_reward(state, index)\n            else:\n                reward_numerator = get_base_reward(state, index) * (attesting_balance // increment)\n                rewards[index] += reward_numerator // (total_balance // increment)\n        else:\n            penalties[index] += get_base_reward(state, index)\n    return rewards, penalties\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#components-of-attestation-deltas","title":"Components of attestation deltas","text":"<pre><code>def get_source_deltas(state: BeaconState) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:\n    \"\"\"\n    Return attester micro-rewards/penalties for source-vote for each validator.\n    \"\"\"\n    matching_source_attestations = get_matching_source_attestations(\n        state, get_previous_epoch(state)\n    )\n    return get_attestation_component_deltas(state, matching_source_attestations)\n</code></pre> <pre><code>def get_target_deltas(state: BeaconState) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:\n    \"\"\"\n    Return attester micro-rewards/penalties for target-vote for each validator.\n    \"\"\"\n    matching_target_attestations = get_matching_target_attestations(\n        state, get_previous_epoch(state)\n    )\n    return get_attestation_component_deltas(state, matching_target_attestations)\n</code></pre> <pre><code>def get_head_deltas(state: BeaconState) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:\n    \"\"\"\n    Return attester micro-rewards/penalties for head-vote for each validator.\n    \"\"\"\n    matching_head_attestations = get_matching_head_attestations(state, get_previous_epoch(state))\n    return get_attestation_component_deltas(state, matching_head_attestations)\n</code></pre> <pre><code>def get_inclusion_delay_deltas(state: BeaconState) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:\n    \"\"\"\n    Return proposer and inclusion delay micro-rewards/penalties for each validator.\n    \"\"\"\n    rewards = [Gwei(0) for _ in range(len(state.validators))]\n    matching_source_attestations = get_matching_source_attestations(\n        state, get_previous_epoch(state)\n    )\n    for index in get_unslashed_attesting_indices(state, matching_source_attestations):\n        attestation = min(\n            [a for a in matching_source_attestations if index in get_attesting_indices(state, a)],\n            key=lambda a: a.inclusion_delay,\n        )\n        rewards[attestation.proposer_index] += get_proposer_reward(state, index)\n        max_attester_reward = Gwei(\n            get_base_reward(state, index) - get_proposer_reward(state, index)\n        )\n        rewards[index] += Gwei(max_attester_reward // attestation.inclusion_delay)\n\n    # No penalties associated with inclusion delay\n    penalties = [Gwei(0) for _ in range(len(state.validators))]\n    return rewards, penalties\n</code></pre> <pre><code>def get_inactivity_penalty_deltas(state: BeaconState) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:\n    \"\"\"\n    Return inactivity reward/penalty deltas for each validator.\n    \"\"\"\n    penalties = [Gwei(0) for _ in range(len(state.validators))]\n    if is_in_inactivity_leak(state):\n        matching_target_attestations = get_matching_target_attestations(\n            state, get_previous_epoch(state)\n        )\n        matching_target_attesting_indices = get_unslashed_attesting_indices(\n            state, matching_target_attestations\n        )\n        for index in get_eligible_validator_indices(state):\n            # If validator is performing optimally this cancels all rewards for a neutral balance\n            base_reward = get_base_reward(state, index)\n            penalties[index] += Gwei(\n                BASE_REWARDS_PER_EPOCH * base_reward - get_proposer_reward(state, index)\n            )\n            if index not in matching_target_attesting_indices:\n                effective_balance = state.validators[index].effective_balance\n                penalties[index] += Gwei(\n                    effective_balance * get_finality_delay(state) // INACTIVITY_PENALTY_QUOTIENT\n                )\n\n    # No rewards associated with inactivity penalties\n    rewards = [Gwei(0) for _ in range(len(state.validators))]\n    return rewards, penalties\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#get_attestation_deltas","title":"<code>get_attestation_deltas</code>","text":"<pre><code>def get_attestation_deltas(state: BeaconState) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:\n    \"\"\"\n    Return attestation reward/penalty deltas for each validator.\n    \"\"\"\n    source_rewards, source_penalties = get_source_deltas(state)\n    target_rewards, target_penalties = get_target_deltas(state)\n    head_rewards, head_penalties = get_head_deltas(state)\n    inclusion_delay_rewards, _ = get_inclusion_delay_deltas(state)\n    _, inactivity_penalties = get_inactivity_penalty_deltas(state)\n\n    rewards = [\n        source_rewards[i] + target_rewards[i] + head_rewards[i] + inclusion_delay_rewards[i]\n        for i in range(len(state.validators))\n    ]\n\n    penalties = [\n        source_penalties[i] + target_penalties[i] + head_penalties[i] + inactivity_penalties[i]\n        for i in range(len(state.validators))\n    ]\n\n    return rewards, penalties\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#process_rewards_and_penalties","title":"<code>process_rewards_and_penalties</code>","text":"<pre><code>def process_rewards_and_penalties(state: BeaconState) -&gt; None:\n    # No rewards are applied at the end of `GENESIS_EPOCH` because rewards are for work done in the previous epoch\n    if get_current_epoch(state) == GENESIS_EPOCH:\n        return\n\n    rewards, penalties = get_attestation_deltas(state)\n    for index in range(len(state.validators)):\n        increase_balance(state, ValidatorIndex(index), rewards[index])\n        decrease_balance(state, ValidatorIndex(index), penalties[index])\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#registry-updates","title":"Registry updates","text":"<pre><code>def process_registry_updates(state: BeaconState) -&gt; None:\n    # Process activation eligibility and ejections\n    for index, validator in enumerate(state.validators):\n        if is_eligible_for_activation_queue(validator):\n            validator.activation_eligibility_epoch = get_current_epoch(state) + 1\n\n        if (\n            is_active_validator(validator, get_current_epoch(state))\n            and validator.effective_balance &lt;= EJECTION_BALANCE\n        ):\n            initiate_validator_exit(state, ValidatorIndex(index))\n\n    # Queue validators eligible for activation and not yet dequeued for activation\n    activation_queue = sorted(\n        [\n            index\n            for index, validator in enumerate(state.validators)\n            if is_eligible_for_activation(state, validator)\n        ],\n        # Order by the sequence of activation_eligibility_epoch setting and then index\n        key=lambda index: (state.validators[index].activation_eligibility_epoch, index),\n    )\n    # Dequeued validators for activation up to churn limit\n    for index in activation_queue[: get_validator_churn_limit(state)]:\n        validator = state.validators[index]\n        validator.activation_epoch = compute_activation_exit_epoch(get_current_epoch(state))\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#slashings","title":"Slashings","text":"<pre><code>def process_slashings(state: BeaconState) -&gt; None:\n    epoch = get_current_epoch(state)\n    total_balance = get_total_active_balance(state)\n    adjusted_total_slashing_balance = min(\n        sum(state.slashings) * PROPORTIONAL_SLASHING_MULTIPLIER, total_balance\n    )\n    for index, validator in enumerate(state.validators):\n        if (\n            validator.slashed\n            and epoch + EPOCHS_PER_SLASHINGS_VECTOR // 2 == validator.withdrawable_epoch\n        ):\n            increment = EFFECTIVE_BALANCE_INCREMENT  # Factored out from penalty numerator to avoid uint64 overflow\n            penalty_numerator = (\n                validator.effective_balance // increment * adjusted_total_slashing_balance\n            )\n            penalty = penalty_numerator // total_balance * increment\n            decrease_balance(state, ValidatorIndex(index), penalty)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#eth1-data-votes-updates","title":"Eth1 data votes updates","text":"<pre><code>def process_eth1_data_reset(state: BeaconState) -&gt; None:\n    next_epoch = Epoch(get_current_epoch(state) + 1)\n    # Reset eth1 data votes\n    if next_epoch % EPOCHS_PER_ETH1_VOTING_PERIOD == 0:\n        state.eth1_data_votes = []\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#effective-balances-updates","title":"Effective balances updates","text":"<pre><code>def process_effective_balance_updates(state: BeaconState) -&gt; None:\n    # Update effective balances with hysteresis\n    for index, validator in enumerate(state.validators):\n        balance = state.balances[index]\n        HYSTERESIS_INCREMENT = uint64(EFFECTIVE_BALANCE_INCREMENT // HYSTERESIS_QUOTIENT)\n        DOWNWARD_THRESHOLD = HYSTERESIS_INCREMENT * HYSTERESIS_DOWNWARD_MULTIPLIER\n        UPWARD_THRESHOLD = HYSTERESIS_INCREMENT * HYSTERESIS_UPWARD_MULTIPLIER\n        if (\n            balance + DOWNWARD_THRESHOLD &lt; validator.effective_balance\n            or validator.effective_balance + UPWARD_THRESHOLD &lt; balance\n        ):\n            validator.effective_balance = min(\n                balance - balance % EFFECTIVE_BALANCE_INCREMENT, MAX_EFFECTIVE_BALANCE\n            )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#slashings-balances-updates","title":"Slashings balances updates","text":"<pre><code>def process_slashings_reset(state: BeaconState) -&gt; None:\n    next_epoch = Epoch(get_current_epoch(state) + 1)\n    # Reset slashings\n    state.slashings[next_epoch % EPOCHS_PER_SLASHINGS_VECTOR] = Gwei(0)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#randao-mixes-updates","title":"Randao mixes updates","text":"<pre><code>def process_randao_mixes_reset(state: BeaconState) -&gt; None:\n    current_epoch = get_current_epoch(state)\n    next_epoch = Epoch(current_epoch + 1)\n    # Set randao mix\n    state.randao_mixes[next_epoch % EPOCHS_PER_HISTORICAL_VECTOR] = get_randao_mix(\n        state, current_epoch\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#historical-roots-updates","title":"Historical roots updates","text":"<pre><code>def process_historical_roots_update(state: BeaconState) -&gt; None:\n    # Set historical root accumulator\n    next_epoch = Epoch(get_current_epoch(state) + 1)\n    if next_epoch % (SLOTS_PER_HISTORICAL_ROOT // SLOTS_PER_EPOCH) == 0:\n        historical_batch = HistoricalBatch(\n            block_roots=state.block_roots, state_roots=state.state_roots\n        )\n        state.historical_roots.append(hash_tree_root(historical_batch))\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#participation-records-rotation","title":"Participation records rotation","text":"<pre><code>def process_participation_record_updates(state: BeaconState) -&gt; None:\n    # Rotate current/previous epoch attestations\n    state.previous_epoch_attestations = state.current_epoch_attestations\n    state.current_epoch_attestations = []\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#block-processing","title":"Block processing","text":"<pre><code>def process_block(state: BeaconState, block: BeaconBlock) -&gt; None:\n    process_block_header(state, block)\n    process_randao(state, block.body)\n    process_eth1_data(state, block.body)\n    process_operations(state, block.body)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#block-header","title":"Block header","text":"<pre><code>def process_block_header(state: BeaconState, block: BeaconBlock) -&gt; None:\n    # Verify that the slots match\n    assert block.slot == state.slot\n    # Verify that the block is newer than latest block header\n    assert block.slot &gt; state.latest_block_header.slot\n    # Verify that proposer index is the correct index\n    assert block.proposer_index == get_beacon_proposer_index(state)\n    # Verify that the parent matches\n    assert block.parent_root == hash_tree_root(state.latest_block_header)\n    # Cache current block as the new latest block\n    state.latest_block_header = BeaconBlockHeader(\n        slot=block.slot,\n        proposer_index=block.proposer_index,\n        parent_root=block.parent_root,\n        state_root=Bytes32(),  # Overwritten in the next process_slot call\n        body_root=hash_tree_root(block.body),\n    )\n\n    # Verify proposer is not slashed\n    proposer = state.validators[block.proposer_index]\n    assert not proposer.slashed\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#randao","title":"RANDAO","text":"<pre><code>def process_randao(state: BeaconState, body: BeaconBlockBody) -&gt; None:\n    epoch = get_current_epoch(state)\n    # Verify RANDAO reveal\n    proposer = state.validators[get_beacon_proposer_index(state)]\n    signing_root = compute_signing_root(epoch, get_domain(state, DOMAIN_RANDAO))\n    assert bls.Verify(proposer.pubkey, signing_root, body.randao_reveal)\n    # Mix in RANDAO reveal\n    mix = xor(get_randao_mix(state, epoch), hash(body.randao_reveal))\n    state.randao_mixes[epoch % EPOCHS_PER_HISTORICAL_VECTOR] = mix\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#eth1-data","title":"Eth1 data","text":"<pre><code>def process_eth1_data(state: BeaconState, body: BeaconBlockBody) -&gt; None:\n    state.eth1_data_votes.append(body.eth1_data)\n    if (\n        state.eth1_data_votes.count(body.eth1_data) * 2\n        &gt; EPOCHS_PER_ETH1_VOTING_PERIOD * SLOTS_PER_EPOCH\n    ):\n        state.eth1_data = body.eth1_data\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#operations","title":"Operations","text":"<pre><code>def process_operations(state: BeaconState, body: BeaconBlockBody) -&gt; None:\n    # Verify that outstanding deposits are processed up to the maximum number of deposits\n    assert len(body.deposits) == min(\n        MAX_DEPOSITS, state.eth1_data.deposit_count - state.eth1_deposit_index\n    )\n\n    def for_ops(operations: Sequence[Any], fn: Callable[[BeaconState, Any], None]) -&gt; None:\n        for operation in operations:\n            fn(state, operation)\n\n    for_ops(body.proposer_slashings, process_proposer_slashing)\n    for_ops(body.attester_slashings, process_attester_slashing)\n    for_ops(body.attestations, process_attestation)\n    for_ops(body.deposits, process_deposit)\n    for_ops(body.voluntary_exits, process_voluntary_exit)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#proposer-slashings","title":"Proposer slashings","text":"<pre><code>def process_proposer_slashing(state: BeaconState, proposer_slashing: ProposerSlashing) -&gt; None:\n    header_1 = proposer_slashing.signed_header_1.message\n    header_2 = proposer_slashing.signed_header_2.message\n\n    # Verify header slots match\n    assert header_1.slot == header_2.slot\n    # Verify header proposer indices match\n    assert header_1.proposer_index == header_2.proposer_index\n    # Verify the headers are different\n    assert header_1 != header_2\n    # Verify the proposer is slashable\n    proposer = state.validators[header_1.proposer_index]\n    assert is_slashable_validator(proposer, get_current_epoch(state))\n    # Verify signatures\n    for signed_header in (proposer_slashing.signed_header_1, proposer_slashing.signed_header_2):\n        domain = get_domain(\n            state, DOMAIN_BEACON_PROPOSER, compute_epoch_at_slot(signed_header.message.slot)\n        )\n        signing_root = compute_signing_root(signed_header.message, domain)\n        assert bls.Verify(proposer.pubkey, signing_root, signed_header.signature)\n\n    slash_validator(state, header_1.proposer_index)\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#attester-slashings","title":"Attester slashings","text":"<pre><code>def process_attester_slashing(state: BeaconState, attester_slashing: AttesterSlashing) -&gt; None:\n    attestation_1 = attester_slashing.attestation_1\n    attestation_2 = attester_slashing.attestation_2\n    assert is_slashable_attestation_data(attestation_1.data, attestation_2.data)\n    assert is_valid_indexed_attestation(state, attestation_1)\n    assert is_valid_indexed_attestation(state, attestation_2)\n\n    slashed_any = False\n    indices = set(attestation_1.attesting_indices).intersection(attestation_2.attesting_indices)\n    for index in sorted(indices):\n        if is_slashable_validator(state.validators[index], get_current_epoch(state)):\n            slash_validator(state, index)\n            slashed_any = True\n    assert slashed_any\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#attestations","title":"Attestations","text":"<pre><code>def process_attestation(state: BeaconState, attestation: Attestation) -&gt; None:\n    data = attestation.data\n    assert data.target.epoch in (get_previous_epoch(state), get_current_epoch(state))\n    assert data.target.epoch == compute_epoch_at_slot(data.slot)\n    assert data.slot + MIN_ATTESTATION_INCLUSION_DELAY &lt;= state.slot &lt;= data.slot + SLOTS_PER_EPOCH\n    assert data.index &lt; get_committee_count_per_slot(state, data.target.epoch)\n\n    committee = get_beacon_committee(state, data.slot, data.index)\n    assert len(attestation.aggregation_bits) == len(committee)\n\n    pending_attestation = PendingAttestation(\n        data=data,\n        aggregation_bits=attestation.aggregation_bits,\n        inclusion_delay=state.slot - data.slot,\n        proposer_index=get_beacon_proposer_index(state),\n    )\n\n    if data.target.epoch == get_current_epoch(state):\n        assert data.source == state.current_justified_checkpoint\n        state.current_epoch_attestations.append(pending_attestation)\n    else:\n        assert data.source == state.previous_justified_checkpoint\n        state.previous_epoch_attestations.append(pending_attestation)\n\n    # Verify signature\n    assert is_valid_indexed_attestation(state, get_indexed_attestation(state, attestation))\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#deposits","title":"Deposits","text":"<pre><code>def get_validator_from_deposit(\n    pubkey: BLSPubkey, withdrawal_credentials: Bytes32, amount: uint64\n) -&gt; Validator:\n    effective_balance = min(amount - amount % EFFECTIVE_BALANCE_INCREMENT, MAX_EFFECTIVE_BALANCE)\n\n    return Validator(\n        pubkey=pubkey,\n        withdrawal_credentials=withdrawal_credentials,\n        effective_balance=effective_balance,\n        slashed=False,\n        activation_eligibility_epoch=FAR_FUTURE_EPOCH,\n        activation_epoch=FAR_FUTURE_EPOCH,\n        exit_epoch=FAR_FUTURE_EPOCH,\n        withdrawable_epoch=FAR_FUTURE_EPOCH,\n    )\n</code></pre> <pre><code>def add_validator_to_registry(\n    state: BeaconState, pubkey: BLSPubkey, withdrawal_credentials: Bytes32, amount: uint64\n) -&gt; None:\n    state.validators.append(get_validator_from_deposit(pubkey, withdrawal_credentials, amount))\n    state.balances.append(amount)\n</code></pre> <pre><code>def apply_deposit(\n    state: BeaconState,\n    pubkey: BLSPubkey,\n    withdrawal_credentials: Bytes32,\n    amount: uint64,\n    signature: BLSSignature,\n) -&gt; None:\n    validator_pubkeys = [v.pubkey for v in state.validators]\n    if pubkey not in validator_pubkeys:\n        # Verify the deposit signature (proof of possession) which is not checked by the deposit contract\n        deposit_message = DepositMessage(\n            pubkey=pubkey,\n            withdrawal_credentials=withdrawal_credentials,\n            amount=amount,\n        )\n        # Fork-agnostic domain since deposits are valid across forks\n        domain = compute_domain(DOMAIN_DEPOSIT)\n        signing_root = compute_signing_root(deposit_message, domain)\n        if bls.Verify(pubkey, signing_root, signature):\n            add_validator_to_registry(state, pubkey, withdrawal_credentials, amount)\n    else:\n        # Increase balance by deposit amount\n        index = ValidatorIndex(validator_pubkeys.index(pubkey))\n        increase_balance(state, index, amount)\n</code></pre> <pre><code>def process_deposit(state: BeaconState, deposit: Deposit) -&gt; None:\n    # Verify the Merkle branch\n    assert is_valid_merkle_branch(\n        leaf=hash_tree_root(deposit.data),\n        branch=deposit.proof,\n        # Add 1 for the List length mix-in\n        depth=DEPOSIT_CONTRACT_TREE_DEPTH + 1,\n        index=state.eth1_deposit_index,\n        root=state.eth1_data.deposit_root,\n    )\n\n    # Deposits must be processed in order\n    state.eth1_deposit_index += 1\n\n    apply_deposit(\n        state=state,\n        pubkey=deposit.data.pubkey,\n        withdrawal_credentials=deposit.data.withdrawal_credentials,\n        amount=deposit.data.amount,\n        signature=deposit.data.signature,\n    )\n</code></pre>"},{"location":"specs/phase0/beacon-chain/#voluntary-exits","title":"Voluntary exits","text":"<pre><code>def process_voluntary_exit(state: BeaconState, signed_voluntary_exit: SignedVoluntaryExit) -&gt; None:\n    voluntary_exit = signed_voluntary_exit.message\n    validator = state.validators[voluntary_exit.validator_index]\n    # Verify the validator is active\n    assert is_active_validator(validator, get_current_epoch(state))\n    # Verify exit has not been initiated\n    assert validator.exit_epoch == FAR_FUTURE_EPOCH\n    # Exits must specify an epoch when they become valid; they are not valid before then\n    assert get_current_epoch(state) &gt;= voluntary_exit.epoch\n    # Verify the validator has been active long enough\n    assert get_current_epoch(state) &gt;= validator.activation_epoch + SHARD_COMMITTEE_PERIOD\n    # Verify signature\n    domain = get_domain(state, DOMAIN_VOLUNTARY_EXIT, voluntary_exit.epoch)\n    signing_root = compute_signing_root(voluntary_exit, domain)\n    assert bls.Verify(validator.pubkey, signing_root, signed_voluntary_exit.signature)\n    # Initiate exit\n    initiate_validator_exit(state, voluntary_exit.validator_index)\n</code></pre>"},{"location":"specs/phase0/deposit-contract/","title":"Phase 0 -- Deposit Contract","text":"<ul> <li>Introduction</li> <li>Constants</li> <li>Configuration</li> <li>Staking deposit contract</li> <li><code>deposit</code> function<ul> <li>Deposit amount</li> <li>Withdrawal credentials</li> <li><code>DepositEvent</code> log</li> </ul> </li> <li>Solidity code</li> </ul>"},{"location":"specs/phase0/deposit-contract/#introduction","title":"Introduction","text":"<p>This document represents the specification for the beacon chain deposit contract, part of Phase 0.</p>"},{"location":"specs/phase0/deposit-contract/#constants","title":"Constants","text":"<p>The following values are (non-configurable) constants used throughout the specification.</p> Name Value <code>DEPOSIT_CONTRACT_TREE_DEPTH</code> <code>2**5</code> (= 32)"},{"location":"specs/phase0/deposit-contract/#configuration","title":"Configuration","text":"<p>Note: The default mainnet configuration values are included here for spec-design purposes. The different configurations for mainnet, testnets, and YAML-based testing can be found in the <code>configs/constant_presets</code> directory. These configurations are updated for releases and may be out of sync during <code>dev</code> changes.</p> Name Value <code>DEPOSIT_CHAIN_ID</code> <code>1</code> <code>DEPOSIT_NETWORK_ID</code> <code>1</code> <code>DEPOSIT_CONTRACT_ADDRESS</code> <code>0x00000000219ab540356cBB839Cbe05303d7705Fa</code>"},{"location":"specs/phase0/deposit-contract/#staking-deposit-contract","title":"Staking deposit contract","text":"<p>The initial deployment phases of Ethereum proof-of-stake are implemented without consensus changes to the existing Ethereum proof-of-work chain. A deposit contract at address <code>DEPOSIT_CONTRACT_ADDRESS</code> is added to the Ethereum proof-of-work chain defined by the chain-id -- <code>DEPOSIT_CHAIN_ID</code> -- and the network-id -- <code>DEPOSIT_NETWORK_ID</code> -- for deposits of ETH to the beacon chain. Validator balances will be withdrawable to the execution-layer in a followup fork after Bellatrix upgrade.</p> <p>Note: See here for a comprehensive list of public Ethereum chain chain-id's and network-id's.</p>"},{"location":"specs/phase0/deposit-contract/#deposit-function","title":"<code>deposit</code> function","text":"<p>The deposit contract has a public <code>deposit</code> function to make deposits. It takes as arguments <code>bytes calldata pubkey, bytes calldata withdrawal_credentials, bytes calldata signature, bytes32 deposit_data_root</code>. The first three arguments populate a <code>DepositData</code> object, and <code>deposit_data_root</code> is the expected <code>DepositData</code> root as a protection against malformed calldata.</p>"},{"location":"specs/phase0/deposit-contract/#deposit-amount","title":"Deposit amount","text":"<p>The amount of ETH (rounded down to the closest Gwei) sent to the deposit contract is the deposit amount, which must be of size at least <code>MIN_DEPOSIT_AMOUNT</code> Gwei. Note that ETH consumed by the deposit contract is no longer usable on the execution-layer until sometime after Bellatrix upgrade.</p>"},{"location":"specs/phase0/deposit-contract/#withdrawal-credentials","title":"Withdrawal credentials","text":"<p>One of the <code>DepositData</code> fields is <code>withdrawal_credentials</code> which constrains validator withdrawals. The first byte of this 32-byte field is a withdrawal prefix which defines the semantics of the remaining 31 bytes. The withdrawal prefixes currently supported are <code>BLS_WITHDRAWAL_PREFIX</code> and <code>ETH1_ADDRESS_WITHDRAWAL_PREFIX</code>. Read more in the validator guide.</p> <p>Note: The deposit contract does not validate the <code>withdrawal_credentials</code> field. Support for new withdrawal prefixes can be added without modifying the deposit contract.</p>"},{"location":"specs/phase0/deposit-contract/#depositevent-log","title":"<code>DepositEvent</code> log","text":"<p>Every deposit emits a <code>DepositEvent</code> log for consumption by the beacon chain. The deposit contract does little validation, pushing most of the validator onboarding logic to the beacon chain. In particular, the proof of possession (a BLS12-381 signature) is not verified by the deposit contract.</p>"},{"location":"specs/phase0/deposit-contract/#solidity-code","title":"Solidity code","text":"<p>The deposit contract source code, written in Solidity, is available here.</p> <p>Note: To save on gas, the deposit contract uses a progressive Merkle root calculation algorithm that requires only O(log(n)) storage. See here for a Python implementation, and here for a formal correctness proof.</p>"},{"location":"specs/phase0/fork-choice/","title":"Phase 0 -- Beacon Chain Fork Choice","text":"<ul> <li>Introduction</li> <li>Fork choice</li> <li>Constant</li> <li>Configuration<ul> <li>Time parameters</li> </ul> </li> <li>Helpers<ul> <li><code>LatestMessage</code></li> <li><code>Store</code></li> <li><code>get_forkchoice_store</code></li> <li><code>get_slots_since_genesis</code></li> <li><code>get_current_slot</code></li> <li><code>get_current_store_epoch</code></li> <li><code>compute_slots_since_epoch_start</code></li> <li><code>get_ancestor</code></li> <li><code>calculate_committee_fraction</code></li> <li><code>get_checkpoint_block</code></li> <li><code>get_proposer_score</code></li> <li><code>get_weight</code></li> <li><code>get_voting_source</code></li> <li><code>filter_block_tree</code></li> <li><code>get_filtered_block_tree</code></li> <li><code>get_head</code></li> <li><code>update_checkpoints</code></li> <li><code>update_unrealized_checkpoints</code></li> <li><code>seconds_to_milliseconds</code></li> <li><code>get_slot_component_duration_ms</code></li> <li>Proposer head and reorg helpers</li> <li><code>is_head_late</code></li> <li><code>is_shuffling_stable</code></li> <li><code>is_ffg_competitive</code></li> <li><code>is_finalization_ok</code></li> <li><code>is_proposing_on_time</code></li> <li><code>is_head_weak</code></li> <li><code>is_parent_strong</code></li> <li><code>get_proposer_head</code></li> <li>Pull-up tip helpers</li> <li><code>compute_pulled_up_tip</code></li> <li><code>on_tick</code> helpers</li> <li><code>on_tick_per_slot</code></li> <li><code>on_attestation</code> helpers</li> <li><code>validate_target_epoch_against_current_time</code></li> <li><code>validate_on_attestation</code></li> <li><code>store_target_checkpoint_state</code></li> <li><code>update_latest_messages</code></li> </ul> </li> <li>Handlers<ul> <li><code>on_tick</code></li> <li><code>on_block</code></li> <li><code>on_attestation</code></li> <li><code>on_attester_slashing</code></li> </ul> </li> </ul>"},{"location":"specs/phase0/fork-choice/#introduction","title":"Introduction","text":"<p>This document is the beacon chain fork choice spec, part of Phase 0. It assumes the beacon chain state transition function spec.</p>"},{"location":"specs/phase0/fork-choice/#fork-choice","title":"Fork choice","text":"<p>The head block root associated with a <code>store</code> is defined as <code>get_head(store)</code>. At genesis, let <code>store = get_forkchoice_store(genesis_state, genesis_block)</code> and update <code>store</code> by running:</p> <ul> <li><code>on_tick(store, time)</code> whenever <code>time &gt; store.time</code> where <code>time</code> is the   current Unix time</li> <li><code>on_block(store, block)</code> whenever a block <code>block: SignedBeaconBlock</code> is   received</li> <li><code>on_attestation(store, attestation)</code> whenever an attestation <code>attestation</code> is   received</li> <li><code>on_attester_slashing(store, attester_slashing)</code> whenever an attester slashing   <code>attester_slashing</code> is received</li> </ul> <p>Any of the above handlers that trigger an unhandled exception (e.g. a failed assert or an out-of-range list access) are considered invalid. Invalid calls to handlers must not modify <code>store</code>.</p> <p>Notes:</p> <ol> <li>Leap seconds: Slots will last <code>SECONDS_PER_SLOT + 1</code> or    <code>SECONDS_PER_SLOT - 1</code> seconds around leap seconds. This is automatically    handled by UNIX time.</li> <li>Honest clocks: Honest nodes are assumed to have clocks synchronized    within <code>SECONDS_PER_SLOT</code> seconds of each other.</li> <li>Eth1 data: The large <code>ETH1_FOLLOW_DISTANCE</code> specified in the    honest validator document should ensure that    <code>state.latest_eth1_data</code> of the canonical beacon chain remains consistent    with the canonical Ethereum proof-of-work chain. If not, emergency manual    intervention will be required.</li> <li>Manual forks: Manual forks may arbitrarily change the fork choice rule    but are expected to be enacted at epoch transitions, with the fork details    reflected in <code>state.fork</code>.</li> <li>Implementation: The implementation found in this specification is    constructed for ease of understanding rather than for optimization in    computation, space, or any other resource. A number of optimized alternatives    can be found here.</li> </ol>"},{"location":"specs/phase0/fork-choice/#constant","title":"Constant","text":"Name Value <code>INTERVALS_PER_SLOT</code> deprecated <code>uint64(3)</code> <code>BASIS_POINTS</code> <code>uint64(10000)</code>"},{"location":"specs/phase0/fork-choice/#configuration","title":"Configuration","text":"Name Value <code>PROPOSER_SCORE_BOOST</code> <code>uint64(40)</code> <code>REORG_HEAD_WEIGHT_THRESHOLD</code> <code>uint64(20)</code> <code>REORG_PARENT_WEIGHT_THRESHOLD</code> <code>uint64(160)</code> <code>REORG_MAX_EPOCHS_SINCE_FINALIZATION</code> <code>Epoch(2)</code> <ul> <li>The proposer score boost and re-org weight threshold are percentage values   that are measured with respect to the weight of a single committee. See   <code>calculate_committee_fraction</code>.</li> </ul>"},{"location":"specs/phase0/fork-choice/#time-parameters","title":"Time parameters","text":"Name Value Unit Duration <code>PROPOSER_REORG_CUTOFF_BPS</code> <code>uint64(1667)</code> basis points ~17% of <code>SLOT_DURATION_MS</code>"},{"location":"specs/phase0/fork-choice/#helpers","title":"Helpers","text":""},{"location":"specs/phase0/fork-choice/#latestmessage","title":"<code>LatestMessage</code>","text":"<pre><code>@dataclass(eq=True, frozen=True)\nclass LatestMessage(object):\n    epoch: Epoch\n    root: Root\n</code></pre>"},{"location":"specs/phase0/fork-choice/#store","title":"<code>Store</code>","text":"<p>The <code>Store</code> is responsible for tracking information required for the fork choice algorithm. The important fields being tracked are described below:</p> <ul> <li><code>justified_checkpoint</code>: the justified checkpoint used as the starting point   for the LMD GHOST fork choice algorithm.</li> <li><code>finalized_checkpoint</code>: the highest known finalized checkpoint. The fork   choice only considers blocks that are not conflicting with this checkpoint.</li> <li><code>unrealized_justified_checkpoint</code> &amp; <code>unrealized_finalized_checkpoint</code>: these   track the highest justified &amp; finalized checkpoints resp., without regard to   whether on-chain realization has occurred, i.e. FFG processing of new   attestations within the state transition function. This is an important   distinction from <code>justified_checkpoint</code> &amp; <code>finalized_checkpoint</code>, because they   will only track the checkpoints that are realized on-chain. Note that on-chain   processing of FFG information only happens at epoch boundaries.</li> <li><code>unrealized_justifications</code>: stores a map of block root to the unrealized   justified checkpoint observed in that block.</li> </ul> <pre><code>@dataclass\nclass Store(object):\n    time: uint64\n    genesis_time: uint64\n    justified_checkpoint: Checkpoint\n    finalized_checkpoint: Checkpoint\n    unrealized_justified_checkpoint: Checkpoint\n    unrealized_finalized_checkpoint: Checkpoint\n    proposer_boost_root: Root\n    equivocating_indices: Set[ValidatorIndex]\n    blocks: Dict[Root, BeaconBlock] = field(default_factory=dict)\n    block_states: Dict[Root, BeaconState] = field(default_factory=dict)\n    block_timeliness: Dict[Root, boolean] = field(default_factory=dict)\n    checkpoint_states: Dict[Checkpoint, BeaconState] = field(default_factory=dict)\n    latest_messages: Dict[ValidatorIndex, LatestMessage] = field(default_factory=dict)\n    unrealized_justifications: Dict[Root, Checkpoint] = field(default_factory=dict)\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_forkchoice_store","title":"<code>get_forkchoice_store</code>","text":"<p>The provided anchor-state will be regarded as a trusted state, to not roll back beyond. This should be the genesis state for a full client.</p> <p>Note With regards to fork choice, block headers are interchangeable with blocks. The spec is likely to move to headers for reduced overhead in test vectors and better encapsulation. Full implementations store blocks as part of their database and will often use full blocks when dealing with production fork choice.</p> <pre><code>def get_forkchoice_store(anchor_state: BeaconState, anchor_block: BeaconBlock) -&gt; Store:\n    assert anchor_block.state_root == hash_tree_root(anchor_state)\n    anchor_root = hash_tree_root(anchor_block)\n    anchor_epoch = get_current_epoch(anchor_state)\n    justified_checkpoint = Checkpoint(epoch=anchor_epoch, root=anchor_root)\n    finalized_checkpoint = Checkpoint(epoch=anchor_epoch, root=anchor_root)\n    proposer_boost_root = Root()\n    return Store(\n        time=uint64(anchor_state.genesis_time + SECONDS_PER_SLOT * anchor_state.slot),\n        genesis_time=anchor_state.genesis_time,\n        justified_checkpoint=justified_checkpoint,\n        finalized_checkpoint=finalized_checkpoint,\n        unrealized_justified_checkpoint=justified_checkpoint,\n        unrealized_finalized_checkpoint=finalized_checkpoint,\n        proposer_boost_root=proposer_boost_root,\n        equivocating_indices=set(),\n        blocks={anchor_root: copy(anchor_block)},\n        block_states={anchor_root: copy(anchor_state)},\n        checkpoint_states={justified_checkpoint: copy(anchor_state)},\n        unrealized_justifications={anchor_root: justified_checkpoint},\n    )\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_slots_since_genesis","title":"<code>get_slots_since_genesis</code>","text":"<pre><code>def get_slots_since_genesis(store: Store) -&gt; int:\n    return (store.time - store.genesis_time) // SECONDS_PER_SLOT\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_current_slot","title":"<code>get_current_slot</code>","text":"<pre><code>def get_current_slot(store: Store) -&gt; Slot:\n    return Slot(GENESIS_SLOT + get_slots_since_genesis(store))\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_current_store_epoch","title":"<code>get_current_store_epoch</code>","text":"<pre><code>def get_current_store_epoch(store: Store) -&gt; Epoch:\n    return compute_epoch_at_slot(get_current_slot(store))\n</code></pre>"},{"location":"specs/phase0/fork-choice/#compute_slots_since_epoch_start","title":"<code>compute_slots_since_epoch_start</code>","text":"<pre><code>def compute_slots_since_epoch_start(slot: Slot) -&gt; int:\n    return slot - compute_start_slot_at_epoch(compute_epoch_at_slot(slot))\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_ancestor","title":"<code>get_ancestor</code>","text":"<pre><code>def get_ancestor(store: Store, root: Root, slot: Slot) -&gt; Root:\n    block = store.blocks[root]\n    if block.slot &gt; slot:\n        return get_ancestor(store, block.parent_root, slot)\n    return root\n</code></pre>"},{"location":"specs/phase0/fork-choice/#calculate_committee_fraction","title":"<code>calculate_committee_fraction</code>","text":"<pre><code>def calculate_committee_fraction(state: BeaconState, committee_percent: uint64) -&gt; Gwei:\n    committee_weight = get_total_active_balance(state) // SLOTS_PER_EPOCH\n    return Gwei((committee_weight * committee_percent) // 100)\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_checkpoint_block","title":"<code>get_checkpoint_block</code>","text":"<pre><code>def get_checkpoint_block(store: Store, root: Root, epoch: Epoch) -&gt; Root:\n    \"\"\"\n    Compute the checkpoint block for epoch ``epoch`` in the chain of block ``root``\n    \"\"\"\n    epoch_first_slot = compute_start_slot_at_epoch(epoch)\n    return get_ancestor(store, root, epoch_first_slot)\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_proposer_score","title":"<code>get_proposer_score</code>","text":"<pre><code>def get_proposer_score(store: Store) -&gt; Gwei:\n    justified_checkpoint_state = store.checkpoint_states[store.justified_checkpoint]\n    committee_weight = get_total_active_balance(justified_checkpoint_state) // SLOTS_PER_EPOCH\n    return (committee_weight * PROPOSER_SCORE_BOOST) // 100\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_weight","title":"<code>get_weight</code>","text":"<pre><code>def get_weight(store: Store, root: Root) -&gt; Gwei:\n    state = store.checkpoint_states[store.justified_checkpoint]\n    unslashed_and_active_indices = [\n        i\n        for i in get_active_validator_indices(state, get_current_epoch(state))\n        if not state.validators[i].slashed\n    ]\n    attestation_score = Gwei(\n        sum(\n            state.validators[i].effective_balance\n            for i in unslashed_and_active_indices\n            if (\n                i in store.latest_messages\n                and i not in store.equivocating_indices\n                and get_ancestor(store, store.latest_messages[i].root, store.blocks[root].slot)\n                == root\n            )\n        )\n    )\n    if store.proposer_boost_root == Root():\n        # Return only attestation score if ``proposer_boost_root`` is not set\n        return attestation_score\n\n    # Calculate proposer score if ``proposer_boost_root`` is set\n    proposer_score = Gwei(0)\n    # Boost is applied if ``root`` is an ancestor of ``proposer_boost_root``\n    if get_ancestor(store, store.proposer_boost_root, store.blocks[root].slot) == root:\n        proposer_score = get_proposer_score(store)\n    return attestation_score + proposer_score\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_voting_source","title":"<code>get_voting_source</code>","text":"<pre><code>def get_voting_source(store: Store, block_root: Root) -&gt; Checkpoint:\n    \"\"\"\n    Compute the voting source checkpoint in event that block with root ``block_root`` is the head block\n    \"\"\"\n    block = store.blocks[block_root]\n    current_epoch = get_current_store_epoch(store)\n    block_epoch = compute_epoch_at_slot(block.slot)\n    if current_epoch &gt; block_epoch:\n        # The block is from a prior epoch, the voting source will be pulled-up\n        return store.unrealized_justifications[block_root]\n    else:\n        # The block is not from a prior epoch, therefore the voting source is not pulled up\n        head_state = store.block_states[block_root]\n        return head_state.current_justified_checkpoint\n</code></pre>"},{"location":"specs/phase0/fork-choice/#filter_block_tree","title":"<code>filter_block_tree</code>","text":"<p>Note: External calls to <code>filter_block_tree</code> (i.e., any calls that are not made by the recursive logic in this function) MUST set <code>block_root</code> to <code>store.justified_checkpoint</code>.</p> <pre><code>def filter_block_tree(store: Store, block_root: Root, blocks: Dict[Root, BeaconBlock]) -&gt; bool:\n    block = store.blocks[block_root]\n    children = [\n        root for root in store.blocks.keys() if store.blocks[root].parent_root == block_root\n    ]\n\n    # If any children branches contain expected finalized/justified checkpoints,\n    # add to filtered block-tree and signal viability to parent.\n    if any(children):\n        filter_block_tree_result = [filter_block_tree(store, child, blocks) for child in children]\n        if any(filter_block_tree_result):\n            blocks[block_root] = block\n            return True\n        return False\n\n    current_epoch = get_current_store_epoch(store)\n    voting_source = get_voting_source(store, block_root)\n\n    # The voting source should be either at the same height as the store's justified checkpoint or\n    # not more than two epochs ago\n    correct_justified = (\n        store.justified_checkpoint.epoch == GENESIS_EPOCH\n        or voting_source.epoch == store.justified_checkpoint.epoch\n        or voting_source.epoch + 2 &gt;= current_epoch\n    )\n\n    finalized_checkpoint_block = get_checkpoint_block(\n        store,\n        block_root,\n        store.finalized_checkpoint.epoch,\n    )\n\n    correct_finalized = (\n        store.finalized_checkpoint.epoch == GENESIS_EPOCH\n        or store.finalized_checkpoint.root == finalized_checkpoint_block\n    )\n\n    # If expected finalized/justified, add to viable block-tree and signal viability to parent.\n    if correct_justified and correct_finalized:\n        blocks[block_root] = block\n        return True\n\n    # Otherwise, branch not viable\n    return False\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_filtered_block_tree","title":"<code>get_filtered_block_tree</code>","text":"<pre><code>def get_filtered_block_tree(store: Store) -&gt; Dict[Root, BeaconBlock]:\n    \"\"\"\n    Retrieve a filtered block tree from ``store``, only returning branches\n    whose leaf state's justified/finalized info agrees with that in ``store``.\n    \"\"\"\n    base = store.justified_checkpoint.root\n    blocks: Dict[Root, BeaconBlock] = {}\n    filter_block_tree(store, base, blocks)\n    return blocks\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_head","title":"<code>get_head</code>","text":"<pre><code>def get_head(store: Store) -&gt; Root:\n    # Get filtered block tree that only includes viable branches\n    blocks = get_filtered_block_tree(store)\n    # Execute the LMD-GHOST fork choice\n    head = store.justified_checkpoint.root\n    while True:\n        children = [root for root in blocks.keys() if blocks[root].parent_root == head]\n        if len(children) == 0:\n            return head\n        # Sort by latest attesting balance with ties broken lexicographically\n        # Ties broken by favoring block with lexicographically higher root\n        head = max(children, key=lambda root: (get_weight(store, root), root))\n</code></pre>"},{"location":"specs/phase0/fork-choice/#update_checkpoints","title":"<code>update_checkpoints</code>","text":"<pre><code>def update_checkpoints(\n    store: Store, justified_checkpoint: Checkpoint, finalized_checkpoint: Checkpoint\n) -&gt; None:\n    \"\"\"\n    Update checkpoints in store if necessary\n    \"\"\"\n    # Update justified checkpoint\n    if justified_checkpoint.epoch &gt; store.justified_checkpoint.epoch:\n        store.justified_checkpoint = justified_checkpoint\n\n    # Update finalized checkpoint\n    if finalized_checkpoint.epoch &gt; store.finalized_checkpoint.epoch:\n        store.finalized_checkpoint = finalized_checkpoint\n</code></pre>"},{"location":"specs/phase0/fork-choice/#update_unrealized_checkpoints","title":"<code>update_unrealized_checkpoints</code>","text":"<pre><code>def update_unrealized_checkpoints(\n    store: Store,\n    unrealized_justified_checkpoint: Checkpoint,\n    unrealized_finalized_checkpoint: Checkpoint,\n) -&gt; None:\n    \"\"\"\n    Update unrealized checkpoints in store if necessary\n    \"\"\"\n    # Update unrealized justified checkpoint\n    if unrealized_justified_checkpoint.epoch &gt; store.unrealized_justified_checkpoint.epoch:\n        store.unrealized_justified_checkpoint = unrealized_justified_checkpoint\n\n    # Update unrealized finalized checkpoint\n    if unrealized_finalized_checkpoint.epoch &gt; store.unrealized_finalized_checkpoint.epoch:\n        store.unrealized_finalized_checkpoint = unrealized_finalized_checkpoint\n</code></pre>"},{"location":"specs/phase0/fork-choice/#seconds_to_milliseconds","title":"<code>seconds_to_milliseconds</code>","text":"<pre><code>def seconds_to_milliseconds(seconds: uint64) -&gt; uint64:\n    \"\"\"\n    Convert seconds to milliseconds with overflow protection.\n    Returns ``UINT64_MAX`` if the result would overflow.\n    \"\"\"\n    if seconds &gt; UINT64_MAX // 1000:\n        return UINT64_MAX\n    return seconds * 1000\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_slot_component_duration_ms","title":"<code>get_slot_component_duration_ms</code>","text":"<pre><code>def get_slot_component_duration_ms(basis_points: uint64) -&gt; uint64:\n    \"\"\"\n    Calculate the duration of a slot component in milliseconds.\n    \"\"\"\n    return basis_points * SLOT_DURATION_MS // BASIS_POINTS\n</code></pre>"},{"location":"specs/phase0/fork-choice/#proposer-head-and-reorg-helpers","title":"Proposer head and reorg helpers","text":"<p>Implementing these helpers is optional.</p>"},{"location":"specs/phase0/fork-choice/#is_head_late","title":"<code>is_head_late</code>","text":"<pre><code>def is_head_late(store: Store, head_root: Root) -&gt; bool:\n    return not store.block_timeliness[head_root]\n</code></pre>"},{"location":"specs/phase0/fork-choice/#is_shuffling_stable","title":"<code>is_shuffling_stable</code>","text":"<pre><code>def is_shuffling_stable(slot: Slot) -&gt; bool:\n    return slot % SLOTS_PER_EPOCH != 0\n</code></pre>"},{"location":"specs/phase0/fork-choice/#is_ffg_competitive","title":"<code>is_ffg_competitive</code>","text":"<pre><code>def is_ffg_competitive(store: Store, head_root: Root, parent_root: Root) -&gt; bool:\n    return (\n        store.unrealized_justifications[head_root] == store.unrealized_justifications[parent_root]\n    )\n</code></pre>"},{"location":"specs/phase0/fork-choice/#is_finalization_ok","title":"<code>is_finalization_ok</code>","text":"<pre><code>def is_finalization_ok(store: Store, slot: Slot) -&gt; bool:\n    epochs_since_finalization = compute_epoch_at_slot(slot) - store.finalized_checkpoint.epoch\n    return epochs_since_finalization &lt;= REORG_MAX_EPOCHS_SINCE_FINALIZATION\n</code></pre>"},{"location":"specs/phase0/fork-choice/#is_proposing_on_time","title":"<code>is_proposing_on_time</code>","text":"<pre><code>def is_proposing_on_time(store: Store) -&gt; bool:\n    seconds_since_genesis = store.time - store.genesis_time\n    time_into_slot_ms = seconds_to_milliseconds(seconds_since_genesis) % SLOT_DURATION_MS\n    proposer_reorg_cutoff_ms = get_slot_component_duration_ms(PROPOSER_REORG_CUTOFF_BPS)\n    return time_into_slot_ms &lt;= proposer_reorg_cutoff_ms\n</code></pre>"},{"location":"specs/phase0/fork-choice/#is_head_weak","title":"<code>is_head_weak</code>","text":"<pre><code>def is_head_weak(store: Store, head_root: Root) -&gt; bool:\n    justified_state = store.checkpoint_states[store.justified_checkpoint]\n    reorg_threshold = calculate_committee_fraction(justified_state, REORG_HEAD_WEIGHT_THRESHOLD)\n    head_weight = get_weight(store, head_root)\n    return head_weight &lt; reorg_threshold\n</code></pre>"},{"location":"specs/phase0/fork-choice/#is_parent_strong","title":"<code>is_parent_strong</code>","text":"<pre><code>def is_parent_strong(store: Store, parent_root: Root) -&gt; bool:\n    justified_state = store.checkpoint_states[store.justified_checkpoint]\n    parent_threshold = calculate_committee_fraction(justified_state, REORG_PARENT_WEIGHT_THRESHOLD)\n    parent_weight = get_weight(store, parent_root)\n    return parent_weight &gt; parent_threshold\n</code></pre>"},{"location":"specs/phase0/fork-choice/#get_proposer_head","title":"<code>get_proposer_head</code>","text":"<pre><code>def get_proposer_head(store: Store, head_root: Root, slot: Slot) -&gt; Root:\n    head_block = store.blocks[head_root]\n    parent_root = head_block.parent_root\n    parent_block = store.blocks[parent_root]\n\n    # Only re-org the head block if it arrived later than the attestation deadline.\n    head_late = is_head_late(store, head_root)\n\n    # Do not re-org on an epoch boundary where the proposer shuffling could change.\n    shuffling_stable = is_shuffling_stable(slot)\n\n    # Ensure that the FFG information of the new head will be competitive with the current head.\n    ffg_competitive = is_ffg_competitive(store, head_root, parent_root)\n\n    # Do not re-org if the chain is not finalizing with acceptable frequency.\n    finalization_ok = is_finalization_ok(store, slot)\n\n    # Only re-org if we are proposing on-time.\n    proposing_on_time = is_proposing_on_time(store)\n\n    # Only re-org a single slot at most.\n    parent_slot_ok = parent_block.slot + 1 == head_block.slot\n    current_time_ok = head_block.slot + 1 == slot\n    single_slot_reorg = parent_slot_ok and current_time_ok\n\n    # Check that the head has few enough votes to be overpowered by our proposer boost.\n    assert store.proposer_boost_root != head_root  # ensure boost has worn off\n    head_weak = is_head_weak(store, head_root)\n\n    # Check that the missing votes are assigned to the parent and not being hoarded.\n    parent_strong = is_parent_strong(store, parent_root)\n\n    if all(\n        [\n            head_late,\n            shuffling_stable,\n            ffg_competitive,\n            finalization_ok,\n            proposing_on_time,\n            single_slot_reorg,\n            head_weak,\n            parent_strong,\n        ]\n    ):\n        # We can re-org the current head by building upon its parent block.\n        return parent_root\n    else:\n        return head_root\n</code></pre> <p>Note: The ordering of conditions is a suggestion only. Implementations are free to optimize by re-ordering the conditions from least to most expensive and by returning early if any of the early conditions are <code>False</code>.</p>"},{"location":"specs/phase0/fork-choice/#pull-up-tip-helpers","title":"Pull-up tip helpers","text":""},{"location":"specs/phase0/fork-choice/#compute_pulled_up_tip","title":"<code>compute_pulled_up_tip</code>","text":"<pre><code>def compute_pulled_up_tip(store: Store, block_root: Root) -&gt; None:\n    state = store.block_states[block_root].copy()\n    # Pull up the post-state of the block to the next epoch boundary\n    process_justification_and_finalization(state)\n\n    store.unrealized_justifications[block_root] = state.current_justified_checkpoint\n    update_unrealized_checkpoints(\n        store, state.current_justified_checkpoint, state.finalized_checkpoint\n    )\n\n    # If the block is from a prior epoch, apply the realized values\n    block_epoch = compute_epoch_at_slot(store.blocks[block_root].slot)\n    current_epoch = get_current_store_epoch(store)\n    if block_epoch &lt; current_epoch:\n        update_checkpoints(store, state.current_justified_checkpoint, state.finalized_checkpoint)\n</code></pre>"},{"location":"specs/phase0/fork-choice/#on_tick-helpers","title":"<code>on_tick</code> helpers","text":""},{"location":"specs/phase0/fork-choice/#on_tick_per_slot","title":"<code>on_tick_per_slot</code>","text":"<pre><code>def on_tick_per_slot(store: Store, time: uint64) -&gt; None:\n    previous_slot = get_current_slot(store)\n\n    # Update store time\n    store.time = time\n\n    current_slot = get_current_slot(store)\n\n    # If this is a new slot, reset store.proposer_boost_root\n    if current_slot &gt; previous_slot:\n        store.proposer_boost_root = Root()\n\n    # If a new epoch, pull-up justification and finalization from previous epoch\n    if current_slot &gt; previous_slot and compute_slots_since_epoch_start(current_slot) == 0:\n        update_checkpoints(\n            store, store.unrealized_justified_checkpoint, store.unrealized_finalized_checkpoint\n        )\n</code></pre>"},{"location":"specs/phase0/fork-choice/#on_attestation-helpers","title":"<code>on_attestation</code> helpers","text":""},{"location":"specs/phase0/fork-choice/#validate_target_epoch_against_current_time","title":"<code>validate_target_epoch_against_current_time</code>","text":"<pre><code>def validate_target_epoch_against_current_time(store: Store, attestation: Attestation) -&gt; None:\n    target = attestation.data.target\n\n    # Attestations must be from the current or previous epoch\n    current_epoch = get_current_store_epoch(store)\n    # Use GENESIS_EPOCH for previous when genesis to avoid underflow\n    previous_epoch = current_epoch - 1 if current_epoch &gt; GENESIS_EPOCH else GENESIS_EPOCH\n    # If attestation target is from a future epoch, delay consideration until the epoch arrives\n    assert target.epoch in [current_epoch, previous_epoch]\n</code></pre>"},{"location":"specs/phase0/fork-choice/#validate_on_attestation","title":"<code>validate_on_attestation</code>","text":"<pre><code>def validate_on_attestation(store: Store, attestation: Attestation, is_from_block: bool) -&gt; None:\n    target = attestation.data.target\n\n    # If the given attestation is not from a beacon block message, we have to check the target epoch scope.\n    if not is_from_block:\n        validate_target_epoch_against_current_time(store, attestation)\n\n    # Check that the epoch number and slot number are matching\n    assert target.epoch == compute_epoch_at_slot(attestation.data.slot)\n\n    # Attestation target must be for a known block. If target block is unknown, delay consideration until block is found\n    assert target.root in store.blocks\n\n    # Attestations must be for a known block. If block is unknown, delay consideration until the block is found\n    assert attestation.data.beacon_block_root in store.blocks\n    # Attestations must not be for blocks in the future. If not, the attestation should not be considered\n    assert store.blocks[attestation.data.beacon_block_root].slot &lt;= attestation.data.slot\n\n    # LMD vote must be consistent with FFG vote target\n    assert target.root == get_checkpoint_block(\n        store, attestation.data.beacon_block_root, target.epoch\n    )\n\n    # Attestations can only affect the fork choice of subsequent slots.\n    # Delay consideration in the fork choice until their slot is in the past.\n    assert get_current_slot(store) &gt;= attestation.data.slot + 1\n</code></pre>"},{"location":"specs/phase0/fork-choice/#store_target_checkpoint_state","title":"<code>store_target_checkpoint_state</code>","text":"<pre><code>def store_target_checkpoint_state(store: Store, target: Checkpoint) -&gt; None:\n    # Store target checkpoint state if not yet seen\n    if target not in store.checkpoint_states:\n        base_state = copy(store.block_states[target.root])\n        if base_state.slot &lt; compute_start_slot_at_epoch(target.epoch):\n            process_slots(base_state, compute_start_slot_at_epoch(target.epoch))\n        store.checkpoint_states[target] = base_state\n</code></pre>"},{"location":"specs/phase0/fork-choice/#update_latest_messages","title":"<code>update_latest_messages</code>","text":"<pre><code>def update_latest_messages(\n    store: Store, attesting_indices: Sequence[ValidatorIndex], attestation: Attestation\n) -&gt; None:\n    target = attestation.data.target\n    beacon_block_root = attestation.data.beacon_block_root\n    non_equivocating_attesting_indices = [\n        i for i in attesting_indices if i not in store.equivocating_indices\n    ]\n    for i in non_equivocating_attesting_indices:\n        if i not in store.latest_messages or target.epoch &gt; store.latest_messages[i].epoch:\n            store.latest_messages[i] = LatestMessage(epoch=target.epoch, root=beacon_block_root)\n</code></pre>"},{"location":"specs/phase0/fork-choice/#handlers","title":"Handlers","text":""},{"location":"specs/phase0/fork-choice/#on_tick","title":"<code>on_tick</code>","text":"<pre><code>def on_tick(store: Store, time: uint64) -&gt; None:\n    # If the ``store.time`` falls behind, while loop catches up slot by slot\n    # to ensure that every previous slot is processed with ``on_tick_per_slot``\n    tick_slot = (time - store.genesis_time) // SECONDS_PER_SLOT\n    while get_current_slot(store) &lt; tick_slot:\n        previous_time = store.genesis_time + (get_current_slot(store) + 1) * SECONDS_PER_SLOT\n        on_tick_per_slot(store, previous_time)\n    on_tick_per_slot(store, time)\n</code></pre>"},{"location":"specs/phase0/fork-choice/#on_block","title":"<code>on_block</code>","text":"<pre><code>def on_block(store: Store, signed_block: SignedBeaconBlock) -&gt; None:\n    block = signed_block.message\n    # Parent block must be known\n    assert block.parent_root in store.block_states\n    # Make a copy of the state to avoid mutability issues\n    pre_state = copy(store.block_states[block.parent_root])\n    # Blocks cannot be in the future. If they are, their consideration must be delayed until they are in the past.\n    assert get_current_slot(store) &gt;= block.slot\n\n    # Check that block is later than the finalized epoch slot (optimization to reduce calls to get_ancestor)\n    finalized_slot = compute_start_slot_at_epoch(store.finalized_checkpoint.epoch)\n    assert block.slot &gt; finalized_slot\n    # Check block is a descendant of the finalized block at the checkpoint finalized slot\n    finalized_checkpoint_block = get_checkpoint_block(\n        store,\n        block.parent_root,\n        store.finalized_checkpoint.epoch,\n    )\n    assert store.finalized_checkpoint.root == finalized_checkpoint_block\n\n    # Check the block is valid and compute the post-state\n    state = pre_state.copy()\n    block_root = hash_tree_root(block)\n    state_transition(state, signed_block, True)\n    # Add new block to the store\n    store.blocks[block_root] = block\n    # Add new state for this block to the store\n    store.block_states[block_root] = state\n\n    # Add block timeliness to the store\n    seconds_since_genesis = store.time - store.genesis_time\n    time_into_slot_ms = seconds_to_milliseconds(seconds_since_genesis) % SLOT_DURATION_MS\n    attestation_threshold_ms = get_slot_component_duration_ms(ATTESTATION_DUE_BPS)\n    is_before_attesting_interval = time_into_slot_ms &lt; attestation_threshold_ms\n    is_timely = get_current_slot(store) == block.slot and is_before_attesting_interval\n    store.block_timeliness[hash_tree_root(block)] = is_timely\n\n    # Add proposer score boost if the block is timely and not conflicting with an existing block\n    is_first_block = store.proposer_boost_root == Root()\n    if is_timely and is_first_block:\n        store.proposer_boost_root = hash_tree_root(block)\n\n    # Update checkpoints in store if necessary\n    update_checkpoints(store, state.current_justified_checkpoint, state.finalized_checkpoint)\n\n    # Eagerly compute unrealized justification and finality\n    compute_pulled_up_tip(store, block_root)\n</code></pre>"},{"location":"specs/phase0/fork-choice/#on_attestation","title":"<code>on_attestation</code>","text":"<pre><code>def on_attestation(store: Store, attestation: Attestation, is_from_block: bool = False) -&gt; None:\n    \"\"\"\n    Run ``on_attestation`` upon receiving a new ``attestation`` from either within a block or directly on the wire.\n\n    An ``attestation`` that is asserted as invalid may be valid at a later time,\n    consider scheduling it for later processing in such case.\n    \"\"\"\n    validate_on_attestation(store, attestation, is_from_block)\n\n    store_target_checkpoint_state(store, attestation.data.target)\n\n    # Get state at the `target` to fully validate attestation\n    target_state = store.checkpoint_states[attestation.data.target]\n    indexed_attestation = get_indexed_attestation(target_state, attestation)\n    assert is_valid_indexed_attestation(target_state, indexed_attestation)\n\n    # Update latest messages for attesting indices\n    update_latest_messages(store, indexed_attestation.attesting_indices, attestation)\n</code></pre>"},{"location":"specs/phase0/fork-choice/#on_attester_slashing","title":"<code>on_attester_slashing</code>","text":"<p>Note: <code>on_attester_slashing</code> should be called while syncing and a client MUST maintain the equivocation set of <code>AttesterSlashing</code>s from at least the latest finalized checkpoint.</p> <pre><code>def on_attester_slashing(store: Store, attester_slashing: AttesterSlashing) -&gt; None:\n    \"\"\"\n    Run ``on_attester_slashing`` immediately upon receiving a new ``AttesterSlashing``\n    from either within a block or directly on the wire.\n    \"\"\"\n    attestation_1 = attester_slashing.attestation_1\n    attestation_2 = attester_slashing.attestation_2\n    assert is_slashable_attestation_data(attestation_1.data, attestation_2.data)\n    state = store.block_states[store.justified_checkpoint.root]\n    assert is_valid_indexed_attestation(state, attestation_1)\n    assert is_valid_indexed_attestation(state, attestation_2)\n\n    indices = set(attestation_1.attesting_indices).intersection(attestation_2.attesting_indices)\n    for index in indices:\n        store.equivocating_indices.add(index)\n</code></pre>"},{"location":"specs/phase0/p2p-interface/","title":"Phase 0 -- Networking","text":"<ul> <li>Introduction</li> <li>Network fundamentals</li> <li>Transport</li> <li>Encryption and identification</li> <li>Protocol Negotiation</li> <li>Multiplexing</li> <li>Consensus-layer network interaction domains</li> <li>Helper functions<ul> <li><code>compute_fork_version</code></li> <li><code>compute_fork_digest</code></li> </ul> </li> <li>Custom types</li> <li>Constants</li> <li>Configuration</li> <li>MetaData</li> <li>Maximum message sizes<ul> <li><code>max_compressed_len</code></li> <li><code>max_message_size</code></li> </ul> </li> <li>The gossip domain: gossipsub<ul> <li>Topics and messages</li> <li>Global topics<ul> <li><code>beacon_block</code></li> <li><code>beacon_aggregate_and_proof</code></li> <li><code>voluntary_exit</code></li> <li><code>proposer_slashing</code></li> <li><code>attester_slashing</code></li> </ul> </li> <li>Attestation subnets<ul> <li><code>beacon_attestation_{subnet_id}</code></li> </ul> </li> <li>Attestations and Aggregation</li> <li>Encodings</li> <li>Gossipsub size limits</li> </ul> </li> <li>The Req/Resp domain<ul> <li>Protocol identification</li> <li>Req/Resp interaction</li> <li>Requesting side</li> <li>Responding side</li> <li>Encoding strategies</li> <li>SSZ-snappy encoding strategy</li> <li>Messages</li> <li>Status v1</li> <li>Goodbye v1</li> <li>BeaconBlocksByRange v1</li> <li>BeaconBlocksByRoot v1</li> <li>Ping v1</li> <li>GetMetaData v1</li> </ul> </li> <li>The discovery domain: discv5<ul> <li>Integration into libp2p stacks</li> <li>ENR structure</li> <li>Attestation subnet bitfield</li> <li><code>eth2</code> field</li> </ul> </li> <li>Attestation subnet subscription</li> <li>Design decision rationale</li> <li>Transport<ul> <li>Why are we defining specific transports?</li> <li>Can clients support other transports/handshakes than the ones mandated by the spec?</li> <li>What are the advantages of using TCP/QUIC/Websockets?</li> <li>Why do we not just support a single transport?</li> <li>Why are we not using QUIC from the start?</li> </ul> </li> <li>Multiplexing<ul> <li>Why are we using mplex/yamux?</li> </ul> </li> <li>Protocol Negotiation<ul> <li>When is multiselect 2.0 due and why do we plan to migrate to it?</li> <li>What is the difference between connection-level and stream-level protocol negotiation?</li> </ul> </li> <li>Encryption<ul> <li>Why are we not supporting SecIO?</li> <li>Why are we using Noise?</li> <li>Why are we using encryption at all?</li> </ul> </li> <li>Gossipsub<ul> <li>Why are we using a pub/sub algorithm for block and attestation propagation?</li> <li>Why are we using topics to segregate encodings, yet only support one encoding?</li> <li>How do we upgrade gossip channels (e.g. changes in encoding, compression)?</li> <li>Why must all clients use the same gossip topic instead of one negotiated between each peer pair?</li> <li>Why are the topics strings and not hashes?</li> <li>Why are we using the <code>StrictNoSign</code> signature policy?</li> <li>Why are we overriding the default libp2p pubsub <code>message-id</code>?</li> <li>Why are these specific gossip parameters chosen?</li> <li>Why is there <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> when validating slot ranges of messages in gossip subnets?</li> <li>Why are there <code>ATTESTATION_SUBNET_COUNT</code> attestation subnets?</li> <li>Why are attestations limited to be broadcast on gossip channels within <code>SLOTS_PER_EPOCH</code> slots?</li> <li>Why are aggregate attestations broadcast to the global topic as <code>AggregateAndProof</code>s rather than just as <code>Attestation</code>s?</li> <li>Why are we sending entire objects in the pubsub and not just hashes?</li> <li>Should clients gossip blocks if they cannot validate the proposer signature due to not yet being synced, not knowing the head block, etc?</li> <li>How are we going to discover peers in a gossipsub topic?</li> <li>How should fork version be used in practice?</li> </ul> </li> <li>Req/Resp<ul> <li>Why segregate requests into dedicated protocol IDs?</li> <li>Why are messages length-prefixed with a protobuf varint in the SSZ-encoding?</li> <li>Why do we version protocol strings with ordinals instead of semver?</li> <li>Why is it called Req/Resp and not RPC?</li> <li>What is a typical rate limiting strategy?</li> <li>Why do we allow empty responses in block requests?</li> <li>Why does <code>BeaconBlocksByRange</code> let the server choose which branch to send blocks from?</li> <li>Why are <code>BlocksByRange</code> requests only required to be served for the latest <code>MIN_EPOCHS_FOR_BLOCK_REQUESTS</code> epochs?</li> <li>Why must the proposer signature be checked when backfilling blocks in the database?</li> <li>What's the effect of empty slots on the sync algorithm?</li> </ul> </li> <li>Discovery<ul> <li>Why are we using discv5 and not libp2p Kademlia DHT?</li> <li>What is the difference between an ENR and a multiaddr, and why are we using ENRs?</li> <li>Why do we not form ENRs and find peers until genesis block/state is known?</li> </ul> </li> <li>Compression/Encoding<ul> <li>Why are we using SSZ for encoding?</li> <li>Why are we compressing, and at which layers?</li> <li>Why are we using Snappy for compression?</li> <li>Can I get access to unencrypted bytes on the wire for debugging purposes?</li> <li>What are SSZ type size bounds?</li> <li>Why is the message size defined in terms of application payload?</li> <li>Why is there a limit on message sizes at all?</li> </ul> </li> <li>libp2p implementations matrix</li> </ul>"},{"location":"specs/phase0/p2p-interface/#introduction","title":"Introduction","text":"<p>This document contains the networking specification for Phase 0.</p> <p>It consists of four main sections:</p> <ol> <li>A specification of the network fundamentals.</li> <li>A specification of the three network interaction domains of the    proof-of-stake consensus layer: (a) the gossip domain, (b) the discovery    domain, and (c) the Req/Resp domain.</li> <li>The rationale and further explanation for the design choices made in the    previous two sections.</li> <li>An analysis of the maturity/state of the libp2p features required by this    spec across the languages in which clients are being developed.</li> </ol>"},{"location":"specs/phase0/p2p-interface/#network-fundamentals","title":"Network fundamentals","text":"<p>This section outlines the specification for the networking stack in Ethereum consensus-layer clients.</p>"},{"location":"specs/phase0/p2p-interface/#transport","title":"Transport","text":"<p>Even though libp2p is a multi-transport stack (designed to listen on multiple simultaneous transports and endpoints transparently), we hereby define a profile for basic interoperability.</p> <p>All implementations MUST support the TCP libp2p transport, MAY support the QUIC (UDP) libp2p transport, and MUST be enabled for both dialing and listening (i.e. outbound and inbound connections). The libp2p TCP and QUIC (UDP) transports support listening on IPv4 and IPv6 addresses (and on multiple simultaneously).</p> <p>Clients must support listening on at least one of IPv4 or IPv6. Clients that do not have support for listening on IPv4 SHOULD be cognizant of the potential disadvantages in terms of Internet-wide routability/support. Clients MAY choose to listen only on IPv6, but MUST be capable of dialing both IPv4 and IPv6 addresses.</p> <p>All listening endpoints must be publicly dialable, and thus not rely on libp2p circuit relay, AutoNAT, or AutoRelay facilities. (Usage of circuit relay, AutoNAT, or AutoRelay will be specifically re-examined soon.)</p> <p>Nodes operating behind a NAT, or otherwise undialable by default (e.g. container runtime, firewall, etc.), MUST have their infrastructure configured to enable inbound traffic on the announced public listening endpoint.</p>"},{"location":"specs/phase0/p2p-interface/#encryption-and-identification","title":"Encryption and identification","text":"<p>The Libp2p-noise secure channel handshake with <code>secp256k1</code> identities will be used for encryption.</p> <p>As specified in the libp2p specification, clients MUST support the <code>XX</code> handshake pattern.</p>"},{"location":"specs/phase0/p2p-interface/#protocol-negotiation","title":"Protocol Negotiation","text":"<p>Clients MUST use exact equality when negotiating protocol versions to use and MAY use the version to give priority to higher version numbers.</p> <p>Clients MUST support multistream-select 1.0 and MAY support multiselect 2.0 when the spec solidifies. Once all clients have implementations for multiselect 2.0, multistream-select 1.0 MAY be phased out.</p>"},{"location":"specs/phase0/p2p-interface/#multiplexing","title":"Multiplexing","text":"<p>During connection bootstrapping, libp2p dynamically negotiates a mutually supported multiplexing method to conduct parallel conversations. This applies to transports that are natively incapable of multiplexing (e.g. TCP, WebSockets, WebRTC), and is omitted for capable transports (e.g. QUIC).</p> <p>Two multiplexers are commonplace in libp2p implementations: mplex and yamux. Their protocol IDs are, respectively: <code>/mplex/6.7.0</code> and <code>/yamux/1.0.0</code>.</p> <p>Clients MUST support mplex and MAY support yamux. If both are supported by the client, yamux MUST take precedence during negotiation. See the Rationale section below for tradeoffs.</p>"},{"location":"specs/phase0/p2p-interface/#consensus-layer-network-interaction-domains","title":"Consensus-layer network interaction domains","text":""},{"location":"specs/phase0/p2p-interface/#helper-functions","title":"Helper functions","text":""},{"location":"specs/phase0/p2p-interface/#compute_fork_version","title":"<code>compute_fork_version</code>","text":"<pre><code>def compute_fork_version(epoch: Epoch) -&gt; Version:\n    \"\"\"\n    Return the fork version at the given ``epoch``.\n    \"\"\"\n    return GENESIS_FORK_VERSION\n</code></pre>"},{"location":"specs/phase0/p2p-interface/#compute_fork_digest","title":"<code>compute_fork_digest</code>","text":"<pre><code>def compute_fork_digest(\n    genesis_validators_root: Root,\n    epoch: Epoch,\n) -&gt; ForkDigest:\n    \"\"\"\n    Return the 4-byte fork digest for the ``genesis_validators_root`` at a given ``epoch``.\n\n    This is a digest primarily used for domain separation on the p2p layer.\n    4-bytes suffices for practical separation of forks/chains.\n    \"\"\"\n    fork_version = compute_fork_version(epoch)\n    base_digest = compute_fork_data_root(fork_version, genesis_validators_root)\n    return ForkDigest(base_digest[:4])\n</code></pre>"},{"location":"specs/phase0/p2p-interface/#custom-types","title":"Custom types","text":"<p>We define the following Python custom types for type hinting and readability:</p> Name SSZ equivalent Description <code>NodeID</code> <code>uint256</code> node identifier <code>SubnetID</code> <code>uint64</code> subnet identifier"},{"location":"specs/phase0/p2p-interface/#constants","title":"Constants","text":"Name Value Unit <code>NODE_ID_BITS</code> <code>256</code> The bit length of uint256 is 256"},{"location":"specs/phase0/p2p-interface/#configuration","title":"Configuration","text":"<p>This section outlines configurations that are used in this spec.</p> Name Value Description <code>MAX_PAYLOAD_SIZE</code> <code>10 * 2**20</code> (= 10485760, 10 MiB) The maximum allowed size of uncompressed payload in gossipsub messages and RPC chunks <code>MAX_REQUEST_BLOCKS</code> <code>2**10</code> (= 1024) Maximum number of blocks in a single request <code>EPOCHS_PER_SUBNET_SUBSCRIPTION</code> <code>2**8</code> (= 256) Number of epochs on a subnet subscription (~27 hours) <code>MIN_EPOCHS_FOR_BLOCK_REQUESTS</code> <code>MIN_VALIDATOR_WITHDRAWABILITY_DELAY + CHURN_LIMIT_QUOTIENT // 2</code> (= 33024, ~5 months) The minimum epoch range over which a node must serve blocks <code>ATTESTATION_PROPAGATION_SLOT_RANGE</code> <code>32</code> The maximum number of slots during which an attestation can be propagated <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> <code>500</code> The maximum milliseconds of clock disparity assumed between honest nodes <code>MESSAGE_DOMAIN_INVALID_SNAPPY</code> <code>DomainType('0x00000000')</code> 4-byte domain for gossip message-id isolation of invalid snappy messages <code>MESSAGE_DOMAIN_VALID_SNAPPY</code> <code>DomainType('0x01000000')</code> 4-byte domain for gossip message-id isolation of valid snappy messages <code>SUBNETS_PER_NODE</code> <code>2</code> The number of long-lived subnets a beacon node should be subscribed to <code>ATTESTATION_SUBNET_COUNT</code> <code>2**6</code> (= 64) The number of attestation subnets used in the gossipsub protocol. <code>ATTESTATION_SUBNET_EXTRA_BITS</code> <code>0</code> The number of extra bits of a NodeId to use when mapping to a subscribed subnet <code>ATTESTATION_SUBNET_PREFIX_BITS</code> <code>int(ceillog2(ATTESTATION_SUBNET_COUNT) + ATTESTATION_SUBNET_EXTRA_BITS)</code> <code>MAX_CONCURRENT_REQUESTS</code> <code>2</code> Maximum number of concurrent requests per protocol ID that a client may issue"},{"location":"specs/phase0/p2p-interface/#metadata","title":"MetaData","text":"<p>Clients MUST locally store the following <code>MetaData</code>:</p> <pre><code>(\n  seq_number: uint64\n  attnets: Bitvector[ATTESTATION_SUBNET_COUNT]\n)\n</code></pre> <p>Where</p> <ul> <li><code>seq_number</code> is a <code>uint64</code> starting at <code>0</code> used to version the node's   metadata. If any other field in the local <code>MetaData</code> changes, the node MUST   increment <code>seq_number</code> by 1.</li> <li><code>attnets</code> is a <code>Bitvector</code> representing the node's persistent attestation   subnet subscriptions.</li> </ul> <p>Note: <code>MetaData.seq_number</code> is used for versioning of the node's metadata, is entirely independent of the ENR sequence number, and will in most cases be out of sync with the ENR sequence number.</p>"},{"location":"specs/phase0/p2p-interface/#maximum-message-sizes","title":"Maximum message sizes","text":"<p>Maximum message sizes are derived from the maximum payload size that the network can carry according to the following functions:</p>"},{"location":"specs/phase0/p2p-interface/#max_compressed_len","title":"<code>max_compressed_len</code>","text":"<pre><code>def max_compressed_len(n: uint64) -&gt; uint64:\n    # Worst-case compressed length for a given payload of size n when using snappy:\n    # https://github.com/google/snappy/blob/32ded457c0b1fe78ceb8397632c416568d6714a0/snappy.cc#L218C1-L218C47\n    return uint64(32 + n + n / 6)\n</code></pre>"},{"location":"specs/phase0/p2p-interface/#max_message_size","title":"<code>max_message_size</code>","text":"<pre><code>def max_message_size() -&gt; uint64:\n    # Allow 1024 bytes for framing and encoding overhead but at least 1MiB in case MAX_PAYLOAD_SIZE is small.\n    return max(max_compressed_len(MAX_PAYLOAD_SIZE) + 1024, 1024 * 1024)\n</code></pre>"},{"location":"specs/phase0/p2p-interface/#the-gossip-domain-gossipsub","title":"The gossip domain: gossipsub","text":"<p>Clients MUST support the gossipsub v1 libp2p Protocol including the gossipsub v1.1 extension.</p> <p>Protocol ID: <code>/meshsub/1.1.0</code></p> <p>Gossipsub Parameters</p> <p>The following gossipsub parameters will be used:</p> <ul> <li><code>D</code> (topic stable mesh target count): 8</li> <li><code>D_low</code> (topic stable mesh low watermark): 6</li> <li><code>D_high</code> (topic stable mesh high watermark): 12</li> <li><code>D_lazy</code> (gossip target): 6</li> <li><code>heartbeat_interval</code> (frequency of heartbeat, seconds): 0.7</li> <li><code>fanout_ttl</code> (ttl for fanout maps for topics we are not subscribed to but have   published to, seconds): 60</li> <li><code>mcache_len</code> (number of windows to retain full messages in cache for <code>IWANT</code>   responses): 6</li> <li><code>mcache_gossip</code> (number of windows to gossip about): 3</li> <li><code>seen_ttl</code> (expiry time for cache of seen message ids, seconds):   SECONDS_PER_SLOT * SLOTS_PER_EPOCH * 2</li> </ul> <p>Note: Gossipsub v1.1 introduces a number of additional parameters for peer scoring and other attack mitigations. These are currently under investigation and will be spec'd and released to mainnet when they are ready.</p>"},{"location":"specs/phase0/p2p-interface/#topics-and-messages","title":"Topics and messages","text":"<p>Topics are plain UTF-8 strings and are encoded on the wire as determined by protobuf (gossipsub messages are enveloped in protobuf messages). Topic strings have form: <code>/eth2/ForkDigestValue/Name/Encoding</code>. This defines both the type of data being sent on the topic and how the data field of the message is encoded.</p> <ul> <li><code>ForkDigestValue</code> - the lowercase hex-encoded (no \"0x\" prefix) bytes of   <code>compute_fork_digest(genesis_validators_root, epoch)</code> where</li> <li><code>genesis_validators_root</code> is the static <code>Root</code> found in     <code>state.genesis_validators_root</code></li> <li><code>epoch</code> is the context epoch of the message to be sent on the topic</li> <li><code>Name</code> - see table below</li> <li><code>Encoding</code> - the encoding strategy describes a specific representation of   bytes that will be transmitted over the wire. See the Encodings   section for further details.</li> </ul> <p>Clients MUST reject messages with an unknown topic.</p> <p>Note: <code>ForkDigestValue</code> is composed of values that are not known until the genesis block/state are available. Due to this, clients SHOULD NOT subscribe to gossipsub topics until these genesis values are known.</p> <p>The optional <code>from</code> (1), <code>seqno</code> (3), <code>signature</code> (5) and <code>key</code> (6) protobuf fields are omitted from the message, since messages are identified by content, anonymous, and signed where necessary in the application layer. Starting from Gossipsub v1.1, clients MUST enforce this by applying the <code>StrictNoSign</code> signature policy.</p> <p>The <code>message-id</code> of a gossipsub message MUST be the following 20 byte value computed from the message data:</p> <ul> <li>If <code>message.data</code> has a valid snappy decompression, set <code>message-id</code> to the   first 20 bytes of the <code>SHA256</code> hash of the concatenation of   <code>MESSAGE_DOMAIN_VALID_SNAPPY</code> with the snappy decompressed message data, i.e.   <code>SHA256(MESSAGE_DOMAIN_VALID_SNAPPY + snappy_decompress(message.data))[:20]</code>.</li> <li>Otherwise, set <code>message-id</code> to the first 20 bytes of the <code>SHA256</code> hash of the   concatenation of <code>MESSAGE_DOMAIN_INVALID_SNAPPY</code> with the raw message data,   i.e. <code>SHA256(MESSAGE_DOMAIN_INVALID_SNAPPY + message.data)[:20]</code>.</li> </ul> <p>Where relevant, clients MUST reject messages with <code>message-id</code> sizes other than 20 bytes.</p> <p>Note: The above logic handles two exceptional cases: (1) multiple snappy <code>data</code> can decompress to the same value, and (2) some message <code>data</code> can fail to snappy decompress altogether.</p> <p>The payload is carried in the <code>data</code> field of a gossipsub message, and varies depending on the topic:</p> Name Message Type <code>beacon_block</code> <code>SignedBeaconBlock</code> <code>beacon_aggregate_and_proof</code> <code>SignedAggregateAndProof</code> <code>beacon_attestation_{subnet_id}</code> <code>Attestation</code> <code>voluntary_exit</code> <code>SignedVoluntaryExit</code> <code>proposer_slashing</code> <code>ProposerSlashing</code> <code>attester_slashing</code> <code>AttesterSlashing</code> <p>Clients MUST reject (fail validation) messages containing an incorrect type, or invalid payload.</p> <p>When processing incoming gossip, clients MAY descore or disconnect peers who fail to observe these constraints.</p> <p>For any optional queueing, clients SHOULD maintain maximum queue sizes to avoid DoS vectors.</p> <p>Gossipsub v1.1 introduces Extended Validators for the application to aid in the gossipsub peer-scoring scheme. We utilize <code>ACCEPT</code>, <code>REJECT</code>, and <code>IGNORE</code>. For each gossipsub topic, there are application specific validations. If all validations pass, return <code>ACCEPT</code>. If one or more validations fail while processing the items in order, return either <code>REJECT</code> or <code>IGNORE</code> as specified in the prefix of the particular condition.</p>"},{"location":"specs/phase0/p2p-interface/#global-topics","title":"Global topics","text":"<p>There are two primary global topics used to propagate beacon blocks (<code>beacon_block</code>) and aggregate attestations (<code>beacon_aggregate_and_proof</code>) to all nodes on the network.</p> <p>There are three additional global topics that are used to propagate lower frequency validator messages (<code>voluntary_exit</code>, <code>proposer_slashing</code>, and <code>attester_slashing</code>).</p>"},{"location":"specs/phase0/p2p-interface/#beacon_block","title":"<code>beacon_block</code>","text":"<p>The <code>beacon_block</code> topic is used solely for propagating new signed beacon blocks to all nodes on the networks. Signed blocks are sent in their entirety.</p> <p>The following validations MUST pass before forwarding the <code>signed_beacon_block</code> on the network.</p> <ul> <li>[IGNORE] The block is not from a future slot (with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e. validate that   <code>signed_beacon_block.message.slot &lt;= current_slot</code> (a client MAY queue future   blocks for processing at the appropriate slot).</li> <li>[IGNORE] The block is from a slot greater than the latest finalized slot --   i.e. validate that   <code>signed_beacon_block.message.slot &gt; compute_start_slot_at_epoch(store.finalized_checkpoint.epoch)</code>   (a client MAY choose to validate and store such blocks for additional purposes   -- e.g. slashing detection, archive nodes, etc).</li> <li>[IGNORE] The block is the first block with valid signature received for the   proposer for the slot, <code>signed_beacon_block.message.slot</code>.</li> <li>[REJECT] The proposer signature, <code>signed_beacon_block.signature</code>, is valid   with respect to the <code>proposer_index</code> pubkey.</li> <li>[IGNORE] The block's parent (defined by <code>block.parent_root</code>) has been seen   (via gossip or non-gossip sources) (a client MAY queue blocks for processing   once the parent block is retrieved).</li> <li>[REJECT] The block's parent (defined by <code>block.parent_root</code>) passes   validation.</li> <li>[REJECT] The block is from a higher slot than its parent.</li> <li>[REJECT] The current <code>finalized_checkpoint</code> is an ancestor of <code>block</code> --   i.e.   <code>get_checkpoint_block(store, block.parent_root, store.finalized_checkpoint.epoch) == store.finalized_checkpoint.root</code></li> <li>[REJECT] The block is proposed by the expected <code>proposer_index</code> for the   block's slot in the context of the current shuffling (defined by   <code>parent_root</code>/<code>slot</code>). If the <code>proposer_index</code> cannot immediately be verified   against the expected shuffling, the block MAY be queued for later processing   while proposers for the block's branch are calculated -- in such a case do   not <code>REJECT</code>, instead <code>IGNORE</code> this message.</li> </ul>"},{"location":"specs/phase0/p2p-interface/#beacon_aggregate_and_proof","title":"<code>beacon_aggregate_and_proof</code>","text":"<p>The <code>beacon_aggregate_and_proof</code> topic is used to propagate aggregated attestations (as <code>SignedAggregateAndProof</code>s) to subscribing nodes (typically validators) to be included in future blocks.</p> <p>We define the following variables for convenience:</p> <ul> <li><code>aggregate_and_proof = signed_aggregate_and_proof.message</code></li> <li><code>aggregate = aggregate_and_proof.aggregate</code></li> <li><code>index = aggregate.data.index</code></li> <li><code>aggregation_bits = attestation.aggregation_bits</code></li> </ul> <p>The following validations MUST pass before forwarding the <code>signed_aggregate_and_proof</code> on the network.</p> <ul> <li>[REJECT] The committee index is within the expected range -- i.e.   <code>index &lt; get_committee_count_per_slot(state, aggregate.data.target.epoch)</code>.</li> <li>[IGNORE] <code>aggregate.data.slot</code> is within the last   <code>ATTESTATION_PROPAGATION_SLOT_RANGE</code> slots (with a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e.   <code>aggregate.data.slot + ATTESTATION_PROPAGATION_SLOT_RANGE &gt;= current_slot &gt;= aggregate.data.slot</code>   (a client MAY queue future aggregates for processing at the appropriate slot).</li> <li>[REJECT] The aggregate attestation's epoch matches its target -- i.e.   <code>aggregate.data.target.epoch == compute_epoch_at_slot(aggregate.data.slot)</code></li> <li>[REJECT] The number of aggregation bits matches the committee size -- i.e.   <code>len(aggregation_bits) == len(get_beacon_committee(state, aggregate.data.slot, index))</code>.</li> <li>[REJECT] The aggregate attestation has participants -- that is,   <code>len(get_attesting_indices(state, aggregate)) &gt;= 1</code>.</li> <li>[IGNORE] A valid aggregate attestation defined by   <code>hash_tree_root(aggregate.data)</code> whose <code>aggregation_bits</code> is a non-strict   superset has not already been seen. (via aggregate gossip, within a verified   block, or through the creation of an equivalent aggregate locally).</li> <li>[IGNORE] The <code>aggregate</code> is the first valid aggregate received for the   aggregator with index <code>aggregate_and_proof.aggregator_index</code> for the epoch   <code>aggregate.data.target.epoch</code>.</li> <li>[REJECT] The attestation has participants -- that is,   <code>len(get_attesting_indices(state, aggregate)) &gt;= 1</code>.</li> <li>[REJECT] <code>aggregate_and_proof.selection_proof</code> selects the validator as an   aggregator for the slot -- i.e.   <code>is_aggregator(state, aggregate.data.slot, index, aggregate_and_proof.selection_proof)</code>   returns <code>True</code>.</li> <li>[REJECT] The aggregator's validator index is within the committee -- i.e.   <code>aggregate_and_proof.aggregator_index in get_beacon_committee(state, aggregate.data.slot, index)</code>.</li> <li>[REJECT] The <code>aggregate_and_proof.selection_proof</code> is a valid signature of   the <code>aggregate.data.slot</code> by the validator with index   <code>aggregate_and_proof.aggregator_index</code>.</li> <li>[REJECT] The aggregator signature, <code>signed_aggregate_and_proof.signature</code>,   is valid.</li> <li>[REJECT] The signature of <code>aggregate</code> is valid.</li> <li>[IGNORE] The block being voted for (<code>aggregate.data.beacon_block_root</code>) has   been seen (via gossip or non-gossip sources) (a client MAY queue aggregates   for processing once block is retrieved).</li> <li>[REJECT] The block being voted for (<code>aggregate.data.beacon_block_root</code>)   passes validation.</li> <li>[REJECT] The aggregate attestation's target block is an ancestor of the   block named in the LMD vote -- i.e.   <code>get_checkpoint_block(store, aggregate.data.beacon_block_root, aggregate.data.target.epoch) == aggregate.data.target.root</code></li> <li>[IGNORE] The current <code>finalized_checkpoint</code> is an ancestor of the <code>block</code>   defined by <code>aggregate.data.beacon_block_root</code> -- i.e.   <code>get_checkpoint_block(store, aggregate.data.beacon_block_root, finalized_checkpoint.epoch) == store.finalized_checkpoint.root</code></li> </ul>"},{"location":"specs/phase0/p2p-interface/#voluntary_exit","title":"<code>voluntary_exit</code>","text":"<p>The <code>voluntary_exit</code> topic is used solely for propagating signed voluntary validator exits to proposers on the network. Signed voluntary exits are sent in their entirety.</p> <p>The following validations MUST pass before forwarding the <code>signed_voluntary_exit</code> on to the network.</p> <ul> <li>[IGNORE] The voluntary exit is the first valid voluntary exit received for   the validator with index <code>signed_voluntary_exit.message.validator_index</code>.</li> <li>[REJECT] All of the conditions within <code>process_voluntary_exit</code> pass   validation.</li> </ul>"},{"location":"specs/phase0/p2p-interface/#proposer_slashing","title":"<code>proposer_slashing</code>","text":"<p>The <code>proposer_slashing</code> topic is used solely for propagating proposer slashings to proposers on the network. Proposer slashings are sent in their entirety.</p> <p>The following validations MUST pass before forwarding the <code>proposer_slashing</code> on to the network.</p> <ul> <li>[IGNORE] The proposer slashing is the first valid proposer slashing received   for the proposer with index   <code>proposer_slashing.signed_header_1.message.proposer_index</code>.</li> <li>[REJECT] All of the conditions within <code>process_proposer_slashing</code> pass   validation.</li> </ul>"},{"location":"specs/phase0/p2p-interface/#attester_slashing","title":"<code>attester_slashing</code>","text":"<p>The <code>attester_slashing</code> topic is used solely for propagating attester slashings to proposers on the network. Attester slashings are sent in their entirety.</p> <p>Clients who receive an attester slashing on this topic MUST validate the conditions within <code>process_attester_slashing</code> before forwarding it across the network.</p> <ul> <li>[IGNORE] At least one index in the intersection of the attesting indices of   each attestation has not yet been seen in any prior <code>attester_slashing</code> (i.e.   <code>attester_slashed_indices = set(attestation_1.attesting_indices).intersection(attestation_2.attesting_indices)</code>,   verify if   <code>any(attester_slashed_indices.difference(prior_seen_attester_slashed_indices))</code>).</li> <li>[REJECT] All of the conditions within <code>process_attester_slashing</code> pass   validation.</li> </ul>"},{"location":"specs/phase0/p2p-interface/#attestation-subnets","title":"Attestation subnets","text":"<p>Attestation subnets are used to propagate unaggregated attestations to subsections of the network.</p>"},{"location":"specs/phase0/p2p-interface/#beacon_attestation_subnet_id","title":"<code>beacon_attestation_{subnet_id}</code>","text":"<p>The <code>beacon_attestation_{subnet_id}</code> topics are used to propagate unaggregated attestations to the subnet <code>subnet_id</code> (typically beacon and persistent committees) to be aggregated before being gossiped to <code>beacon_aggregate_and_proof</code>.</p> <p>We define the following variables for convenience:</p> <ul> <li><code>index = attestation.data.index</code></li> <li><code>aggregation_bits = attestation.aggregation_bits</code></li> </ul> <p>The following validations MUST pass before forwarding the <code>attestation</code> on the subnet.</p> <ul> <li>[REJECT] The committee index is within the expected range -- i.e.   <code>index &lt; get_committee_count_per_slot(state, attestation.data.target.epoch)</code>.</li> <li>[REJECT] The attestation is for the correct subnet -- i.e.   <code>compute_subnet_for_attestation(committees_per_slot, attestation.data.slot, index) == subnet_id</code>,   where   <code>committees_per_slot = get_committee_count_per_slot(state, attestation.data.target.epoch)</code>,   which may be pre-computed along with the committee information for the   signature check.</li> <li>[IGNORE] <code>attestation.data.slot</code> is within the last   <code>ATTESTATION_PROPAGATION_SLOT_RANGE</code> slots (within a   <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> allowance) -- i.e.   <code>attestation.data.slot + ATTESTATION_PROPAGATION_SLOT_RANGE &gt;= current_slot &gt;= attestation.data.slot</code>   (a client MAY queue future attestations for processing at the appropriate   slot).</li> <li>[REJECT] The attestation's epoch matches its target -- i.e.   <code>attestation.data.target.epoch == compute_epoch_at_slot(attestation.data.slot)</code></li> <li>[REJECT] The attestation is unaggregated -- that is, it has exactly one   participating validator (<code>len([bit for bit in aggregation_bits if bit]) == 1</code>,   i.e. exactly 1 bit is set).</li> <li>[REJECT] The number of aggregation bits matches the committee size -- i.e.   <code>len(aggregation_bits) == len(get_beacon_committee(state, attestation.data.slot, index))</code>.</li> <li>[IGNORE] There has been no other valid attestation seen on an attestation   subnet that has an identical <code>attestation.data.target.epoch</code> and participating   validator index.</li> <li>[REJECT] The signature of <code>attestation</code> is valid.</li> <li>[IGNORE] The block being voted for (<code>attestation.data.beacon_block_root</code>)   has been seen (via gossip or non-gossip sources) (a client MAY queue   attestations for processing once block is retrieved).</li> <li>[REJECT] The block being voted for (<code>attestation.data.beacon_block_root</code>)   passes validation.</li> <li>[REJECT] The attestation's target block is an ancestor of the block named in   the LMD vote -- i.e.   <code>get_checkpoint_block(store, attestation.data.beacon_block_root, attestation.data.target.epoch) == attestation.data.target.root</code></li> <li>[IGNORE] The current <code>finalized_checkpoint</code> is an ancestor of the <code>block</code>   defined by <code>attestation.data.beacon_block_root</code> -- i.e.   <code>get_checkpoint_block(store, attestation.data.beacon_block_root, store.finalized_checkpoint.epoch) == store.finalized_checkpoint.root</code></li> </ul>"},{"location":"specs/phase0/p2p-interface/#attestations-and-aggregation","title":"Attestations and Aggregation","text":"<p>Attestation broadcasting is grouped into subnets defined by a topic. The number of subnets is defined via <code>ATTESTATION_SUBNET_COUNT</code>. The correct subnet for an attestation can be calculated with <code>compute_subnet_for_attestation</code>. <code>beacon_attestation_{subnet_id}</code> topics, are rotated through throughout the epoch in a similar fashion to rotating through shards in committees (future beacon chain upgrade). The subnets are rotated through with <code>committees_per_slot = get_committee_count_per_slot(state, attestation.data.target.epoch)</code> subnets per slot.</p> <p>Unaggregated attestations are sent as <code>Attestation</code>s to the subnet topic, <code>beacon_attestation_{compute_subnet_for_attestation(committees_per_slot, attestation.data.slot, attestation.data.index)}</code> as <code>Attestation</code>s.</p> <p>Aggregated attestations are sent to the <code>beacon_aggregate_and_proof</code> topic as <code>AggregateAndProof</code>s.</p>"},{"location":"specs/phase0/p2p-interface/#encodings","title":"Encodings","text":"<p>Topics are post-fixed with an encoding. Encodings define how the payload of a gossipsub message is encoded.</p> <ul> <li><code>ssz_snappy</code> - All objects are SSZ-encoded and then compressed with   Snappy block compression. Example: The   beacon aggregate attestation topic string is   <code>/eth2/446a7232/beacon_aggregate_and_proof/ssz_snappy</code>, the fork digest is   <code>446a7232</code> and the data field of a gossipsub message is an <code>AggregateAndProof</code>   that has been SSZ-encoded and then compressed with Snappy.</li> </ul> <p>Snappy has two formats: \"block\" and \"frames\" (streaming). Gossip messages remain relatively small (100s of bytes to 100s of kilobytes) so basic snappy block compression is used to avoid the additional overhead associated with snappy frames.</p> <p>Implementations MUST use a single encoding for gossip. Changing an encoding will require coordination between participating implementations.</p>"},{"location":"specs/phase0/p2p-interface/#gossipsub-size-limits","title":"Gossipsub size limits","text":"<p>Size limits are placed both on the <code>RPCMsg</code> frame as well as the encoded payload in each <code>Message</code>.</p> <p>Clients MUST reject and MUST NOT emit or propagate messages whose size exceed the following limits:</p> <ul> <li>The size of the encoded <code>RPCMsg</code> (including control messages, framing, topics,   etc) must not exceed <code>max_message_size()</code>.</li> <li>The size of the compressed payload in the <code>Message.data</code> field must not exceed   <code>max_compressed_len(MAX_PAYLOAD_SIZE)</code>.</li> <li>The size of the uncompressed payload must not exceed <code>MAX_PAYLOAD_SIZE</code> or the   type-specific SSZ bound, whichever is lower.</li> </ul>"},{"location":"specs/phase0/p2p-interface/#the-reqresp-domain","title":"The Req/Resp domain","text":""},{"location":"specs/phase0/p2p-interface/#protocol-identification","title":"Protocol identification","text":"<p>Each message type is segregated into its own libp2p protocol ID, which is a case-sensitive UTF-8 string of the form:</p> <pre><code>/ProtocolPrefix/MessageName/SchemaVersion/Encoding\n</code></pre> <p>With:</p> <ul> <li><code>ProtocolPrefix</code> - messages are grouped into families identified by a shared   libp2p protocol name prefix. In this case, we use <code>/eth2/beacon_chain/req</code>.</li> <li><code>MessageName</code> - each request is identified by a name consisting of English   alphabet, digits and underscores (<code>_</code>).</li> <li><code>SchemaVersion</code> - an ordinal version number (e.g. 1, 2, 3\u2026). Each schema is   versioned to facilitate backward and forward-compatibility when possible.</li> <li><code>Encoding</code> - while the schema defines the data types in more abstract terms,   the encoding strategy describes a specific representation of bytes that will   be transmitted over the wire. See the Encodings   section for further details.</li> </ul> <p>This protocol segregation allows libp2p <code>multistream-select 1.0</code> / <code>multiselect 2.0</code> to handle the request type, version, and encoding negotiation before establishing the underlying streams.</p>"},{"location":"specs/phase0/p2p-interface/#reqresp-interaction","title":"Req/Resp interaction","text":"<p>We use ONE stream PER request/response interaction. Streams are closed when the interaction finishes, whether in success or in error.</p> <p>Request/response messages MUST adhere to the encoding specified in the protocol name and follow this structure (relaxed BNF grammar):</p> <pre><code>request   ::= &lt;encoding-dependent-header&gt; | &lt;encoded-payload&gt;\nresponse  ::= &lt;response_chunk&gt;*\nresponse_chunk  ::= &lt;result&gt; | &lt;encoding-dependent-header&gt; | &lt;encoded-payload&gt;\nresult    ::= \u201c0\u201d | \u201c1\u201d | \u201c2\u201d | [\u201c128\u201d ... \u201d255\u201d]\n</code></pre> <p>The encoding-dependent header may carry metadata or assertions such as the encoded payload length, for integrity and attack proofing purposes. Because req/resp streams are single-use and stream closures implicitly delimit the boundaries, it is not strictly necessary to length-prefix payloads; however, certain encodings like SSZ do, for added security.</p> <p>A <code>response</code> is formed by zero or more <code>response_chunk</code>s. Responses that consist of a single SSZ-list (such as <code>BlocksByRange</code> and <code>BlocksByRoot</code>) send each list item as a <code>response_chunk</code>. All other response types (non-Lists) send a single <code>response_chunk</code>.</p> <p>For both <code>request</code>s and <code>response</code>s, the <code>encoding-dependent-header</code> MUST be valid, and the <code>encoded-payload</code> must be valid within the constraints of the <code>encoding-dependent-header</code>. This includes type-specific bounds on payload size for some encoding strategies. Regardless of these type specific bounds, a global maximum uncompressed byte size of <code>MAX_PAYLOAD_SIZE</code> MUST be applied to all method response chunks.</p> <p>Clients MUST ensure that lengths are within these bounds; if not, they SHOULD reset the stream immediately. Clients tracking peer reputation MAY decrement the score of the misbehaving peer under this circumstance.</p>"},{"location":"specs/phase0/p2p-interface/#requesting-side","title":"Requesting side","text":"<p>Once a new stream with the protocol ID for the request type has been negotiated, the full request message SHOULD be sent immediately. The request MUST be encoded according to the encoding strategy.</p> <p>The requester MUST close the write side of the stream once it finishes writing the request message. At this point, the stream will be half-closed.</p> <p>The requester MUST NOT make more than <code>MAX_CONCURRENT_REQUESTS</code> concurrent requests with the same protocol ID.</p> <p>If a timeout occurs or the response is no longer relevant, the requester SHOULD reset the stream.</p> <p>A requester SHOULD read from the stream until either:</p> <ol> <li>An error result is received in one of the chunks (the error payload MAY be    read before stopping).</li> <li>The responder closes the stream.</li> <li>Any part of the <code>response_chunk</code> fails validation.</li> <li>The maximum number of requested chunks are read.</li> </ol> <p>For requests consisting of a single valid <code>response_chunk</code>, the requester SHOULD read the chunk fully, as defined by the <code>encoding-dependent-header</code>, before closing the stream.</p>"},{"location":"specs/phase0/p2p-interface/#responding-side","title":"Responding side","text":"<p>Once a new stream with the protocol ID for the request type has been negotiated, the responder SHOULD process the incoming request and MUST validate it before processing it. Request processing and validation MUST be done according to the encoding strategy, until EOF (denoting stream half-closure by the requester).</p> <p>The responder MUST:</p> <ol> <li>Use the encoding strategy to read the optional header.</li> <li>If there are any length assertions for length <code>N</code>, it should read exactly <code>N</code>    bytes from the stream, at which point an EOF should arise (no more bytes).    Should this not be the case, it should be treated as a failure.</li> <li>Deserialize the expected type, and process the request.</li> <li>Write the response which may consist of zero or more <code>response_chunk</code>s    (result, optional header, payload).</li> <li>Close their write side of the stream. At this point, the stream will be fully    closed.</li> </ol> <p>If steps (1), (2), or (3) fail due to invalid, malformed, or inconsistent data, the responder MUST respond in error. Clients tracking peer reputation MAY record such failures, as well as unexpected events, e.g. early stream resets.</p> <p>The responder MAY rate-limit chunks by withholding each chunk until capacity is available. The responder MUST NOT respond with an error or close the stream when rate limiting.</p> <p>When rate limiting, the responder MUST send each <code>response_chunk</code> in full promptly but may introduce delays between each chunk.</p> <p>Chunks start with a single-byte response code which determines the contents of the <code>response_chunk</code> (<code>result</code> particle in the BNF grammar above). For multiple chunks, only the last chunk is allowed to have a non-zero error code (i.e. The chunk stream is terminated once an error occurs).</p> <p>The response code can have one of the following values, encoded as a single unsigned byte:</p> <ul> <li>0: Success -- a normal response follows, with contents matching the   expected message schema and encoding specified in the request.</li> <li>1: InvalidRequest -- the contents of the request are semantically invalid,   or the payload is malformed, or could not be understood. The response payload   adheres to the <code>ErrorMessage</code> schema (described below).</li> <li>2: ServerError -- the responder encountered an error while processing the   request. The response payload adheres to the <code>ErrorMessage</code> schema (described   below).</li> <li>3: ResourceUnavailable -- the responder does not have requested resource.   The response payload adheres to the <code>ErrorMessage</code> schema (described below).   Note: This response code is only valid as a response where specified.</li> </ul> <p>Clients MAY use response codes above <code>128</code> to indicate alternative, erroneous request-specific responses.</p> <p>The range <code>[4, 127]</code> is RESERVED for future usages, and should be treated as error if not recognized expressly.</p> <p>The <code>ErrorMessage</code> schema is:</p> <pre><code>(\n  error_message: List[byte, 256]\n)\n</code></pre> <p>Note: By convention, the <code>error_message</code> is a sequence of bytes that MAY be interpreted as a UTF-8 string (for debugging purposes). Clients MUST treat as valid any byte sequences.</p> <p>The responder MAY penalise peers that concurrently open more than <code>MAX_CONCURRENT_REQUESTS</code> streams for the same request type, for the protocol IDs defined in this specification.</p>"},{"location":"specs/phase0/p2p-interface/#encoding-strategies","title":"Encoding strategies","text":"<p>The token of the negotiated protocol ID specifies the type of encoding to be used for the req/resp interaction. Only one value is possible at this time:</p> <ul> <li><code>ssz_snappy</code>: The contents are first   SSZ-encoded and then compressed with   Snappy frames compression. For objects   containing a single field, only the field is SSZ-encoded not a container with   a single field. For example, the <code>BeaconBlocksByRoot</code> request is an   SSZ-encoded list of <code>Root</code>'s. This encoding type MUST be supported by all   clients.</li> </ul>"},{"location":"specs/phase0/p2p-interface/#ssz-snappy-encoding-strategy","title":"SSZ-snappy encoding strategy","text":"<p>The SimpleSerialize (SSZ) specification outlines how objects are SSZ-encoded.</p> <p>To achieve snappy encoding on top of SSZ, we feed the serialized form of the object to the Snappy compressor on encoding. The inverse happens on decoding.</p> <p>Snappy has two formats: \"block\" and \"frames\" (streaming). To support large requests and response chunks, snappy-framing is used.</p> <p>Since snappy frame contents have a maximum size of <code>65536</code> bytes and frame headers are just <code>identifier (1) + checksum (4)</code> bytes, the expected buffering of a single frame is acceptable.</p> <p>Encoding-dependent header: Req/Resp protocols using the <code>ssz_snappy</code> encoding strategy MUST encode the length of the raw SSZ bytes, encoded as an unsigned protobuf varint.</p> <p>Writing: By first computing and writing the SSZ byte length, the SSZ encoder can then directly write the chunk contents to the stream. When Snappy is applied, it can be passed through a buffered Snappy writer to compress frame by frame.</p> <p>Reading: After reading the expected SSZ byte length, the SSZ decoder can directly read the contents from the stream. When snappy is applied, it can be passed through a buffered Snappy reader to decompress frame by frame.</p> <p>Before reading the payload, the header MUST be validated:</p> <ul> <li>The length-prefix MUST be encoded as an unsigned protobuf varint. It SHOULD be   minimally encoded (i.e., without any redundant bytes) and MUST not exceed 10   bytes in length, which is sufficient to represent any <code>uint64</code> value. The   length-prefix MUST be decoded into a type which supports the full range of   <code>uint64</code> values.</li> <li>The length-prefix is within the expected   size bounds derived from the payload SSZ type   or <code>MAX_PAYLOAD_SIZE</code>, whichever is smaller.</li> </ul> <p>After reading a valid header, the payload MAY be read, while maintaining the size constraints from the header.</p> <p>A reader MUST NOT read more than <code>max_compressed_len(n)</code> bytes after reading the SSZ length-prefix <code>n</code> from the header.</p> <p>A reader MUST consider the following cases as invalid input:</p> <ul> <li>Any remaining bytes, after having read the <code>n</code> SSZ bytes. An EOF is expected   if more bytes are read than required.</li> <li>An early EOF, before fully reading the declared length-prefix worth of SSZ   bytes.</li> </ul> <p>In case of an invalid input (header or payload), a reader MUST:</p> <ul> <li>From requests: send back an error message, response code <code>InvalidRequest</code>. The   request itself is ignored.</li> <li>From responses: ignore the response, the response MUST be considered bad   server behavior.</li> </ul> <p>All messages that contain only a single field MUST be encoded directly as the type of that field and MUST NOT be encoded as an SSZ container.</p> <p>Responses that are SSZ-lists (for example <code>List[SignedBeaconBlock, ...]</code>) send their constituents individually as <code>response_chunk</code>s. For example, the <code>List[SignedBeaconBlock, ...]</code> response type sends zero or more <code>response_chunk</code>s. Each successful <code>response_chunk</code> contains a single <code>SignedBeaconBlock</code> payload.</p>"},{"location":"specs/phase0/p2p-interface/#messages","title":"Messages","text":""},{"location":"specs/phase0/p2p-interface/#status-v1","title":"Status v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/status/1/</code></p> <p>Request, Response Content:</p> <pre><code>(\n  fork_digest: ForkDigest\n  finalized_root: Root\n  finalized_epoch: Epoch\n  head_root: Root\n  head_slot: Slot\n)\n</code></pre> <p>As seen by the client at the time of sending the message:</p> <ul> <li><code>fork_digest</code>: The node's <code>ForkDigest</code>   (<code>compute_fork_digest(genesis_validators_root, epoch)</code>) where</li> <li><code>genesis_validators_root</code> is the static <code>Root</code> found in     <code>state.genesis_validators_root</code></li> <li><code>epoch</code> is the node's current epoch defined by the wall-clock time (not     necessarily the epoch to which the node is sync).</li> <li><code>finalized_root</code>: <code>store.finalized_checkpoint.root</code> according to   fork choice. (Note this defaults to <code>Root(b'\\x00' * 32)</code>   for the genesis finalized checkpoint).</li> <li><code>finalized_epoch</code>: <code>store.finalized_checkpoint.epoch</code> according to   fork choice.</li> <li><code>head_root</code>: The <code>hash_tree_root</code> root of the current head block   (<code>BeaconBlock</code>).</li> <li><code>head_slot</code>: The slot of the block corresponding to the <code>head_root</code>.</li> </ul> <p>The dialing client MUST send a <code>Status</code> request upon connection.</p> <p>The request/response MUST be encoded as an SSZ-container.</p> <p>The response MUST consist of a single <code>response_chunk</code>.</p> <p>Clients SHOULD immediately disconnect from one another following the handshake above under the following conditions:</p> <ol> <li>If <code>fork_digest</code> does not match the node's local <code>fork_digest</code>, since the    client\u2019s chain is on another fork.</li> <li>If the (<code>finalized_root</code>, <code>finalized_epoch</code>) shared by the peer is not in the    client's chain at the expected epoch. For example, if Peer 1 sends (root,    epoch) of (A, 5) and Peer 2 sends (B, 3) but Peer 1 has root C at epoch 3,    then Peer 1 would disconnect because it knows that their chains are    irreparably disjoint.</li> </ol> <p>Once the handshake completes, the client with the lower <code>finalized_epoch</code> or <code>head_slot</code> (if the clients have equal <code>finalized_epoch</code>s) SHOULD request beacon blocks from its counterparty via the <code>BeaconBlocksByRange</code> request.</p> <p>Note: Under abnormal network condition or after some rounds of <code>BeaconBlocksByRange</code> requests, the client might need to send <code>Status</code> request again to learn if the peer has a higher head. Implementers are free to implement such behavior in their own way.</p>"},{"location":"specs/phase0/p2p-interface/#goodbye-v1","title":"Goodbye v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/goodbye/1/</code></p> <p>Request, Response Content:</p> <pre><code>(\n  uint64\n)\n</code></pre> <p>Client MAY send goodbye messages upon disconnection. The reason field MAY be one of the following values:</p> <ul> <li>1: Client shut down.</li> <li>2: Irrelevant network.</li> <li>3: Fault/error.</li> </ul> <p>Clients MAY use reason codes above <code>128</code> to indicate alternative, erroneous request-specific responses.</p> <p>The range <code>[4, 127]</code> is RESERVED for future usage.</p> <p>The request/response MUST be encoded as a single SSZ-field.</p> <p>The response MUST consist of a single <code>response_chunk</code>.</p>"},{"location":"specs/phase0/p2p-interface/#beaconblocksbyrange-v1","title":"BeaconBlocksByRange v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_range/1/</code></p> <p>Request Content:</p> <pre><code>(\n  start_slot: Slot\n  count: uint64\n  step: uint64 # Deprecated, must be set to 1\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[SignedBeaconBlock, MAX_REQUEST_BLOCKS]\n)\n</code></pre> <p>Requests beacon blocks in the slot range <code>[start_slot, start_slot + count)</code>, leading up to the current head block as selected by fork choice. For example, requesting blocks starting at <code>start_slot=2</code> and <code>count=4</code> would return the blocks at slots <code>[2, 3, 4, 5]</code>. In cases where a slot is empty for a given slot number, no block is returned. For example, if slot 4 were empty in the previous example, the returned array would contain <code>[2, 3, 5]</code>.</p> <p><code>step</code> is deprecated and must be set to 1. Clients may respond with a single block if a larger step is returned during the deprecation transition period.</p> <p><code>/eth2/beacon_chain/req/beacon_blocks_by_range/1/</code> is deprecated. Clients MAY respond with an empty list during the deprecation transition period.</p> <p><code>BeaconBlocksByRange</code> is primarily used to sync historical blocks.</p> <p>The request MUST be encoded as an SSZ-container.</p> <p>The response MUST consist of zero or more <code>response_chunk</code>. Each successful <code>response_chunk</code> MUST contain a single <code>SignedBeaconBlock</code> payload.</p> <p>Clients MUST keep a record of signed blocks seen on the epoch range <code>[max(GENESIS_EPOCH, current_epoch - MIN_EPOCHS_FOR_BLOCK_REQUESTS), current_epoch]</code> where <code>current_epoch</code> is defined by the current wall-clock time, and clients MUST support serving requests of blocks on this range.</p> <p>Peers that are unable to reply to block requests within the <code>MIN_EPOCHS_FOR_BLOCK_REQUESTS</code> epoch range SHOULD respond with error code <code>3: ResourceUnavailable</code>. Such peers that are unable to successfully reply to this range of requests MAY get descored or disconnected at any time.</p> <p>Note: The above requirement implies that nodes that start from a recent weak subjectivity checkpoint MUST backfill the local block database to at least epoch <code>current_epoch - MIN_EPOCHS_FOR_BLOCK_REQUESTS</code> to be fully compliant with <code>BlocksByRange</code> requests. To safely perform such a backfill of blocks to the recent state, the node MUST validate both (1) the proposer signatures and (2) that the blocks form a valid chain up to the most recent block referenced in the weak subjectivity state.</p> <p>Note: Although clients that bootstrap from a weak subjectivity checkpoint can begin participating in the networking immediately, other peers MAY disconnect and/or temporarily ban such an un-synced or semi-synced client.</p> <p>Clients MUST respond with at least the first block that exists in the range, if they have it, and no more than <code>MAX_REQUEST_BLOCKS</code> blocks.</p> <p>The following blocks, where they exist, MUST be sent in consecutive order.</p> <p>Clients MAY limit the number of blocks in the response.</p> <p>The response MUST contain no more than <code>count</code> blocks.</p> <p>Clients MUST respond with blocks from their view of the current fork choice -- that is, blocks from the single chain defined by the current head. Of note, blocks from slots before the finalization MUST lead to the finalized block reported in the <code>Status</code> handshake.</p> <p>Clients MUST respond with blocks that are consistent from a single chain within the context of the request. This applies to any <code>step</code> value. In particular when <code>step == 1</code>, each <code>parent_root</code> MUST match the <code>hash_tree_root</code> of the preceding block.</p> <p>After the initial block, clients MAY stop in the process of responding if their fork choice changes the view of the chain in the context of the request.</p>"},{"location":"specs/phase0/p2p-interface/#beaconblocksbyroot-v1","title":"BeaconBlocksByRoot v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/beacon_blocks_by_root/1/</code></p> <p>Request Content:</p> <pre><code>(\n  List[Root, MAX_REQUEST_BLOCKS]\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  List[SignedBeaconBlock, MAX_REQUEST_BLOCKS]\n)\n</code></pre> <p>Requests blocks by block root (= <code>hash_tree_root(SignedBeaconBlock.message)</code>). The response is a list of <code>SignedBeaconBlock</code> whose length is less than or equal to the number of requested blocks. It may be less in the case that the responding peer is missing blocks.</p> <p>No more than <code>MAX_REQUEST_BLOCKS</code> may be requested at a time.</p> <p><code>BeaconBlocksByRoot</code> is primarily used to recover recent blocks (e.g. when receiving a block or attestation whose parent is unknown).</p> <p>The request MUST be encoded as an SSZ-field.</p> <p>The response MUST consist of zero or more <code>response_chunk</code>. Each successful <code>response_chunk</code> MUST contain a single <code>SignedBeaconBlock</code> payload.</p> <p>Clients MUST support requesting blocks since the latest finalized epoch.</p> <p>Clients MUST respond with at least one block, if they have it. Clients MAY limit the number of blocks in the response.</p> <p>Clients MAY include a block in the response as soon as it passes the gossip validation rules. Clients SHOULD NOT respond with blocks that fail the beacon chain state transition.</p> <p><code>/eth2/beacon_chain/req/beacon_blocks_by_root/1/</code> is deprecated. Clients MAY respond with an empty list during the deprecation transition period.</p>"},{"location":"specs/phase0/p2p-interface/#ping-v1","title":"Ping v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/ping/1/</code></p> <p>Request Content:</p> <pre><code>(\n  uint64\n)\n</code></pre> <p>Response Content:</p> <pre><code>(\n  uint64\n)\n</code></pre> <p>Sent intermittently, the <code>Ping</code> protocol checks liveness of connected peers. Peers request and respond with their local metadata sequence number (<code>MetaData.seq_number</code>).</p> <p>If the peer does not respond to the <code>Ping</code> request, the client MAY disconnect from the peer.</p> <p>A client can then determine if their local record of a peer's MetaData is up to date and MAY request an updated version via the <code>MetaData</code> RPC method if not.</p> <p>The request MUST be encoded as an SSZ-field.</p> <p>The response MUST consist of a single <code>response_chunk</code>.</p>"},{"location":"specs/phase0/p2p-interface/#getmetadata-v1","title":"GetMetaData v1","text":"<p>Protocol ID: <code>/eth2/beacon_chain/req/metadata/1/</code></p> <p>No Request Content.</p> <p>Response Content:</p> <pre><code>(\n  MetaData\n)\n</code></pre> <p>Requests the MetaData of a peer. The request opens and negotiates the stream without sending any request content. Once established the receiving peer responds with it's local most up-to-date MetaData.</p> <p>The response MUST be encoded as an SSZ-container.</p> <p>The response MUST consist of a single <code>response_chunk</code>.</p>"},{"location":"specs/phase0/p2p-interface/#the-discovery-domain-discv5","title":"The discovery domain: discv5","text":"<p>Discovery Version 5 (discv5) (Protocol version v5.1) is used for peer discovery.</p> <p><code>discv5</code> is a standalone protocol, running on UDP on a dedicated port, meant for peer discovery only. <code>discv5</code> supports self-certified, flexible peer records (ENRs) and topic-based advertisement, both of which are (or will be) requirements in this context.</p>"},{"location":"specs/phase0/p2p-interface/#integration-into-libp2p-stacks","title":"Integration into libp2p stacks","text":"<p><code>discv5</code> SHOULD be integrated into the client\u2019s libp2p stack by implementing an adaptor to make it conform to the service discovery and peer routing abstractions and interfaces (go-libp2p links provided).</p> <p>Inputs to operations include peer IDs (when locating a specific peer) or capabilities (when searching for peers with a specific capability), and the outputs will be multiaddrs converted from the ENR records returned by the discv5 backend.</p> <p>This integration enables the libp2p stack to subsequently form connections and streams with discovered peers.</p>"},{"location":"specs/phase0/p2p-interface/#enr-structure","title":"ENR structure","text":"<p>The Ethereum Node Record (ENR) for an Ethereum consensus client MUST contain the following entries (exclusive of the sequence number and signature, which MUST be present in an ENR):</p> <ul> <li>The compressed secp256k1 publickey, 33 bytes (<code>secp256k1</code> field).</li> </ul> <p>The ENR MAY contain the following entries:</p> <ul> <li>An IPv4 address (<code>ip</code> field) and/or IPv6 address (<code>ip6</code> field).</li> <li>An IPv4 TCP port (<code>tcp</code> field) representing the local libp2p TCP listening   port and/or the corresponding IPv6 port (<code>tcp6</code> field).</li> <li>An IPv4 QUIC port (<code>quic</code> field) representing the local libp2p QUIC (UDP)   listening port and/or the corresponding IPv6 port (<code>quic6</code> field).</li> <li>An IPv4 UDP port (<code>udp</code> field) representing the local discv5 listening port   and/or the corresponding IPv6 port (<code>udp6</code> field).</li> </ul> <p>Specifications of these parameters can be found in the ENR Specification.</p>"},{"location":"specs/phase0/p2p-interface/#attestation-subnet-bitfield","title":"Attestation subnet bitfield","text":"<p>The ENR <code>attnets</code> entry signifies the attestation subnet bitfield with the following form to more easily discover peers participating in particular attestation gossip subnets.</p> Key Value <code>attnets</code> SSZ <code>Bitvector[ATTESTATION_SUBNET_COUNT]</code> <p>If a node's <code>MetaData.attnets</code> has any non-zero bit, the ENR MUST include the <code>attnets</code> entry with the same value as <code>MetaData.attnets</code>.</p> <p>If a node's <code>MetaData.attnets</code> is composed of all zeros, the ENR MAY optionally include the <code>attnets</code> entry or leave it out entirely.</p>"},{"location":"specs/phase0/p2p-interface/#eth2-field","title":"<code>eth2</code> field","text":"<p>ENRs MUST carry a generic <code>eth2</code> key with an 16-byte value of the node's current fork digest, next fork version, and next fork epoch to ensure connections are made with peers on the intended Ethereum network.</p> Key Value <code>eth2</code> SSZ <code>ENRForkID</code> <p>Specifically, the value of the <code>eth2</code> key MUST be the following SSZ encoded object (<code>ENRForkID</code>)</p> <pre><code>(\n  fork_digest: ForkDigest\n  next_fork_version: Version\n  next_fork_epoch: Epoch\n)\n</code></pre> <p>The fields of <code>ENRForkID</code> are defined as</p> <ul> <li><code>fork_digest</code> is <code>compute_fork_digest(genesis_validators_root, epoch)</code> where:</li> <li><code>genesis_validators_root</code> is the static <code>Root</code> found in     <code>state.genesis_validators_root</code>.</li> <li><code>epoch</code> is the node's current epoch defined by the wall-clock time (not     necessarily the epoch to which the node is sync).</li> <li><code>next_fork_version</code> is the fork version corresponding to the next planned hard   fork at a future epoch. If no future fork is planned, set   <code>next_fork_version = current_fork_version</code> to signal this fact</li> <li><code>next_fork_epoch</code> is the epoch at which the next fork is planned and the   <code>current_fork_version</code> will be updated. If no future fork is planned, set   <code>next_fork_epoch = FAR_FUTURE_EPOCH</code> to signal this fact</li> </ul> <p>Note: <code>fork_digest</code> is composed of values that are not known until the genesis block/state are available. Due to this, clients SHOULD NOT form ENRs and begin peer discovery until genesis values are known. One notable exception to this rule is the distribution of bootnode ENRs prior to genesis. In this case, bootnode ENRs SHOULD be initially distributed with <code>eth2</code> field set as <code>ENRForkID(fork_digest=compute_fork_digest(b'\\x00'*32, GENESIS_EPOCH), next_fork_version=GENESIS_FORK_VERSION, next_fork_epoch=FAR_FUTURE_EPOCH)</code>. After genesis values are known, the bootnodes SHOULD update ENRs to participate in normal discovery operations.</p> <p>Clients SHOULD connect to peers with <code>fork_digest</code>, <code>next_fork_version</code>, and <code>next_fork_epoch</code> that match local values.</p> <p>Clients MAY connect to peers with the same <code>fork_digest</code> but a different <code>next_fork_version</code>/<code>next_fork_epoch</code>. Unless <code>ENRForkID</code> is manually updated to matching prior to the earlier <code>next_fork_epoch</code> of the two clients, these connecting clients will be unable to successfully interact starting at the earlier <code>next_fork_epoch</code>.</p>"},{"location":"specs/phase0/p2p-interface/#attestation-subnet-subscription","title":"Attestation subnet subscription","text":"<p>Because Phase 0 does not have shards and thus does not have Shard Committees, there is no stable backbone to the attestation subnets (<code>beacon_attestation_{subnet_id}</code>). To provide this stability, each beacon node should:</p> <ul> <li>Remain subscribed to <code>SUBNETS_PER_NODE</code> for <code>EPOCHS_PER_SUBNET_SUBSCRIPTION</code>   epochs.</li> <li>Maintain advertisement of the selected subnets in their node's ENR <code>attnets</code>   entry by setting the selected <code>subnet_id</code> bits to <code>True</code> (e.g.   <code>ENR[\"attnets\"][subnet_id] = True</code>) for all persistent attestation subnets.</li> <li>Select these subnets based on their node-id as specified by the following   <code>compute_subscribed_subnets(node_id, epoch)</code> function.</li> </ul> <pre><code>def compute_subscribed_subnet(node_id: NodeID, epoch: Epoch, index: int) -&gt; SubnetID:\n    node_id_prefix = node_id &gt;&gt; (NODE_ID_BITS - ATTESTATION_SUBNET_PREFIX_BITS)\n    node_offset = node_id % EPOCHS_PER_SUBNET_SUBSCRIPTION\n    permutation_seed = hash(\n        uint_to_bytes(uint64((epoch + node_offset) // EPOCHS_PER_SUBNET_SUBSCRIPTION))\n    )\n    permutated_prefix = compute_shuffled_index(\n        node_id_prefix,\n        1 &lt;&lt; ATTESTATION_SUBNET_PREFIX_BITS,\n        permutation_seed,\n    )\n    return SubnetID((permutated_prefix + index) % ATTESTATION_SUBNET_COUNT)\n</code></pre> <pre><code>def compute_subscribed_subnets(node_id: NodeID, epoch: Epoch) -&gt; Sequence[SubnetID]:\n    return [compute_subscribed_subnet(node_id, epoch, index) for index in range(SUBNETS_PER_NODE)]\n</code></pre> <p>Note: When preparing for a hard fork, a node must select and subscribe to subnets of the future fork versioning at least <code>EPOCHS_PER_SUBNET_SUBSCRIPTION</code> epochs in advance of the fork. These new subnets for the fork are maintained in addition to those for the current fork until the fork occurs. After the fork occurs, let the subnets from the previous fork reach the end of life with no replacements.</p>"},{"location":"specs/phase0/p2p-interface/#design-decision-rationale","title":"Design decision rationale","text":""},{"location":"specs/phase0/p2p-interface/#transport_1","title":"Transport","text":""},{"location":"specs/phase0/p2p-interface/#why-are-we-defining-specific-transports","title":"Why are we defining specific transports?","text":"<p>libp2p peers can listen on multiple transports concurrently, and these can change over time. Multiaddrs encode not only the address but also the transport to be used to dial.</p> <p>Due to this dynamic nature, agreeing on specific transports like TCP, QUIC, or WebSockets on paper becomes irrelevant.</p> <p>However, it is useful to define a minimum baseline for interoperability purposes.</p>"},{"location":"specs/phase0/p2p-interface/#can-clients-support-other-transportshandshakes-than-the-ones-mandated-by-the-spec","title":"Can clients support other transports/handshakes than the ones mandated by the spec?","text":"<p>Clients may support other transports such as libp2p QUIC, WebSockets, and WebRTC transports, if available in the language of choice. While interoperability shall not be harmed by lack of such support, the advantages are desirable:</p> <ul> <li>Better latency, performance, and other QoS characteristics (QUIC).</li> <li>Paving the way for interfacing with future light clients (WebSockets, WebRTC).</li> </ul> <p>The libp2p QUIC transport inherently relies on TLS 1.3 per requirement in section 7 of the QUIC protocol specification and the accompanying QUIC-TLS document.</p> <p>The usage of one handshake procedure or the other shall be transparent to the application layer, once the libp2p Host/Node object has been configured appropriately.</p>"},{"location":"specs/phase0/p2p-interface/#what-are-the-advantages-of-using-tcpquicwebsockets","title":"What are the advantages of using TCP/QUIC/Websockets?","text":"<p>TCP is a reliable, ordered, full-duplex, congestion-controlled network protocol that powers much of the Internet as we know it today. HTTP/1.1 and HTTP/2 run atop TCP.</p> <p>QUIC is a new protocol that\u2019s in the final stages of specification by the IETF QUIC WG. It emerged from Google\u2019s SPDY experiment. The QUIC transport is undoubtedly promising. It\u2019s UDP-based yet reliable, ordered, multiplexed, natively secure (TLS 1.3), reduces latency vs. TCP, and offers stream-level and connection-level congestion control (thus removing head-of-line blocking), 0-RTT connection establishment, and endpoint migration, amongst other features. UDP also has better NAT traversal properties than TCP\u2014something we desperately pursue in peer-to-peer networks.</p> <p>QUIC is being adopted as the underlying protocol for HTTP/3. This has the potential to award us censorship resistance via deep packet inspection for free. Provided that we use the same port numbers and encryption mechanisms as HTTP/3, our traffic may be indistinguishable from standard web traffic, and we may only become subject to standard IP-based firewall filtering\u2014something we can counteract via other mechanisms.</p> <p>WebSockets and/or WebRTC transports are necessary for interaction with browsers, and will become increasingly important as we incorporate browser-based light clients to the Ethereum network.</p>"},{"location":"specs/phase0/p2p-interface/#why-do-we-not-just-support-a-single-transport","title":"Why do we not just support a single transport?","text":"<p>Networks evolve. Hardcoding design decisions leads to ossification, preventing the evolution of networks alongside the state of the art. Introducing changes on an ossified protocol is very costly, and sometimes, downright impracticable without causing undesirable breakage.</p> <p>Modeling for upgradeability and dynamic transport selection from the get-go lays the foundation for a future-proof stack.</p> <p>Clients can adopt new transports without breaking old ones, and the multi-transport ability enables constrained and sandboxed environments (e.g. browsers, embedded devices) to interact with the network as first-class citizens via suitable/native transports (e.g. WSS), without the need for proxying or trust delegation to servers.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-we-not-using-quic-from-the-start","title":"Why are we not using QUIC from the start?","text":"<p>The QUIC standard is still not finalized (at working draft 22 at the time of writing), and not all mainstream runtimes/languages have mature, standard, and/or fully-interoperable QUIC support. One remarkable example is node.js, where the QUIC implementation is in early development.</p> <p>Note: TLS 1.3 is a prerequisite of the QUIC transport, although an experiment exists to integrate Noise as the QUIC crypto layer: nQUIC.</p> <p>On the other hand, TLS 1.3 is the newest, simplified iteration of TLS. Old, insecure, obsolete ciphers and algorithms have been removed, adopting Ed25519 as the sole ECDH key agreement function. Handshakes are faster, 1-RTT data is supported, and session resumption is a reality, amongst other features.</p>"},{"location":"specs/phase0/p2p-interface/#multiplexing_1","title":"Multiplexing","text":""},{"location":"specs/phase0/p2p-interface/#why-are-we-using-mplexyamux","title":"Why are we using mplex/yamux?","text":"<p>Yamux is a multiplexer invented by Hashicorp that supports stream-level congestion control. Implementations exist in a limited set of languages, and it\u2019s not a trivial piece to develop.</p> <p>Conscious of that, the libp2p community conceptualized mplex as a simple, minimal multiplexer for usage with libp2p. It does not support stream-level congestion control and is subject to head-of-line blocking.</p> <p>Overlay multiplexers are not necessary with QUIC since the protocol provides native multiplexing, but they need to be layered atop TCP, WebSockets, and other transports that lack such support.</p>"},{"location":"specs/phase0/p2p-interface/#protocol-negotiation_1","title":"Protocol Negotiation","text":""},{"location":"specs/phase0/p2p-interface/#when-is-multiselect-20-due-and-why-do-we-plan-to-migrate-to-it","title":"When is multiselect 2.0 due and why do we plan to migrate to it?","text":"<p>multiselect 2.0 is currently being conceptualized. The debate started on this issue, but it got overloaded\u2014as it tends to happen with large conceptual OSS discussions that touch the heart and core of a system.</p> <p>At some point in 2020, we expect a renewed initiative to first define the requirements, constraints, assumptions, and features, in order to lock in basic consensus upfront and subsequently build on that consensus by submitting a specification for implementation.</p> <p>We plan to eventually migrate to multiselect 2.0 because it will:</p> <ol> <li>Reduce round trips during connection bootstrapping and stream protocol    negotiation.</li> <li>Enable efficient one-stream-per-request interaction patterns.</li> <li>Leverage push data mechanisms of underlying protocols to expedite    negotiation.</li> <li>Provide the building blocks for enhanced censorship resistance.</li> </ol>"},{"location":"specs/phase0/p2p-interface/#what-is-the-difference-between-connection-level-and-stream-level-protocol-negotiation","title":"What is the difference between connection-level and stream-level protocol negotiation?","text":"<p>All libp2p connections must be authenticated, encrypted, and multiplexed. Connections using network transports unsupportive of native authentication/encryption and multiplexing (e.g. TCP) need to undergo protocol negotiation to agree on a mutually supported:</p> <ol> <li>authentication/encryption mechanism (such as SecIO, TLS 1.3, Noise).</li> <li>overlay multiplexer (such as mplex, Yamux, spdystream).</li> </ol> <p>In this specification, we refer to these two as connection-level negotiations. Transports supporting those features natively (such as QUIC) omit those negotiations.</p> <p>After successfully selecting a multiplexer, all subsequent I/O happens over streams. When opening streams, peers pin a protocol to that stream, by conducting stream-level protocol negotiation.</p> <p>At present, multistream-select 1.0 is used for both types of negotiation, but multiselect 2.0 will use dedicated mechanisms for connection bootstrapping process and stream protocol negotiation.</p>"},{"location":"specs/phase0/p2p-interface/#encryption","title":"Encryption","text":""},{"location":"specs/phase0/p2p-interface/#why-are-we-not-supporting-secio","title":"Why are we not supporting SecIO?","text":"<p>SecIO has been the default encryption layer for libp2p for years. It is used in IPFS and Filecoin. And although it will be superseded shortly, it is proven to work at scale.</p> <p>Although SecIO has wide language support, we won\u2019t be using it for mainnet because, amongst other things, it requires several round trips to be sound, and doesn\u2019t support early data (0-RTT data), a mechanism that multiselect 2.0 will leverage to reduce round trips during connection bootstrapping.</p> <p>SecIO is not considered secure for the purposes of this spec.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-we-using-noise","title":"Why are we using Noise?","text":"<p>Copied from the Noise Protocol Framework website:</p> <p>Noise is a framework for building crypto protocols. Noise protocols support mutual and optional authentication, identity hiding, forward secrecy, zero round-trip encryption, and other advanced features.</p> <p>Noise in itself does not specify a single handshake procedure, but provides a framework to build secure handshakes based on Diffie-Hellman key agreement with a variety of tradeoffs and guarantees.</p> <p>Noise handshakes are lightweight and simple to understand, and are used in major cryptographic-centric projects like WireGuard, I2P, and Lightning. Various studies have assessed the stated security goals of several Noise handshakes with positive results.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-we-using-encryption-at-all","title":"Why are we using encryption at all?","text":"<p>Transport level encryption secures message exchange and provides properties that are useful for privacy, safety, and censorship resistance. These properties are derived from the following security guarantees that apply to the entire communication between two peers:</p> <ul> <li>Peer authentication: the peer I\u2019m talking to is really who they claim to be   and who I expect them to be.</li> <li>Confidentiality: no observer can eavesdrop on the content of our messages.</li> <li>Integrity: the data has not been tampered with by a third-party while in   transit.</li> <li>Non-repudiation: the originating peer cannot dispute that they sent the   message.</li> <li>Depending on the chosen algorithms and mechanisms (e.g. continuous HMAC), we   may obtain additional guarantees, such as non-replayability (this byte   could\u2019ve only been sent now; e.g. by using continuous HMACs), or perfect   forward secrecy (in the case that a peer key is compromised, the content of a   past conversation will not be compromised).</li> </ul> <p>Note that transport-level encryption is not exclusive of application-level encryption or cryptography. Transport-level encryption secures the communication itself, while application-level cryptography is necessary for the application\u2019s use cases (e.g. signatures, randomness, etc.).</p>"},{"location":"specs/phase0/p2p-interface/#gossipsub","title":"Gossipsub","text":""},{"location":"specs/phase0/p2p-interface/#why-are-we-using-a-pubsub-algorithm-for-block-and-attestation-propagation","title":"Why are we using a pub/sub algorithm for block and attestation propagation?","text":"<p>Pubsub is a technique to broadcast/disseminate data across a network rapidly. Such data is packaged in fire-and-forget messages that do not require a response from every recipient. Peers subscribed to a topic participate in the propagation of messages in that topic.</p> <p>The alternative is to maintain a fully connected mesh (all peers connected to each other 1:1), which scales poorly (O(n^2)).</p>"},{"location":"specs/phase0/p2p-interface/#why-are-we-using-topics-to-segregate-encodings-yet-only-support-one-encoding","title":"Why are we using topics to segregate encodings, yet only support one encoding?","text":"<p>For future extensibility with almost zero overhead now (besides the extra bytes in the topic name).</p>"},{"location":"specs/phase0/p2p-interface/#how-do-we-upgrade-gossip-channels-eg-changes-in-encoding-compression","title":"How do we upgrade gossip channels (e.g. changes in encoding, compression)?","text":"<p>Changing gossipsub/broadcasts requires a coordinated upgrade where all clients start publishing to the new topic together, during a hard fork.</p> <p>When a node is preparing for upcoming tasks (e.g. validator duty lookahead) on a gossipsub topic, the node should join the topic of the future epoch in which the task is to occur in addition to listening to the topics for the current epoch.</p>"},{"location":"specs/phase0/p2p-interface/#why-must-all-clients-use-the-same-gossip-topic-instead-of-one-negotiated-between-each-peer-pair","title":"Why must all clients use the same gossip topic instead of one negotiated between each peer pair?","text":"<p>Supporting multiple topics/encodings would require the presence of relayers to translate between encodings and topics so as to avoid network fragmentation where participants have diverging views on the gossiped state, making the protocol more complicated and fragile.</p> <p>Gossip protocols typically remember what messages they've seen for a finite period of time-based on message identity -- if you publish the same message again after that time has passed, it will be re-broadcast\u2014adding a relay delay also makes this scenario more likely.</p> <p>One can imagine that in a complicated upgrade scenario, we might have peers publishing the same message on two topics/encodings, but the price here is pretty high in terms of overhead -- both computational and networking -- so we'd rather avoid that.</p> <p>It is permitted for clients to publish data on alternative topics as long as they also publish on the network-wide mandatory topic.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-the-topics-strings-and-not-hashes","title":"Why are the topics strings and not hashes?","text":"<p>Topic names have a hierarchical structure. In the future, gossipsub may support wildcard subscriptions (e.g. subscribe to all children topics under a root prefix) by way of prefix matching. Enforcing hashes for topic names would preclude us from leveraging such features going forward.</p> <p>No security or privacy guarantees are lost as a result of choosing plaintext topic names, since the domain is finite anyway, and calculating a digest's preimage would be trivial.</p> <p>Furthermore, the topic names are shorter than their digest equivalents (assuming SHA-256 hash), so hashing topics would bloat messages unnecessarily.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-we-using-the-strictnosign-signature-policy","title":"Why are we using the <code>StrictNoSign</code> signature policy?","text":"<p>The policy omits the <code>from</code> (1), <code>seqno</code> (3), <code>signature</code> (5) and <code>key</code> (6) fields. These fields would:</p> <ul> <li>Expose origin of sender (<code>from</code>), type of sender (based on <code>seqno</code>)</li> <li>Add extra unused data to the gossip, since message IDs are based on <code>data</code>,   not on the <code>from</code> and <code>seqno</code>.</li> <li>Introduce more message validation than necessary, e.g. no <code>signature</code>.</li> </ul>"},{"location":"specs/phase0/p2p-interface/#why-are-we-overriding-the-default-libp2p-pubsub-message-id","title":"Why are we overriding the default libp2p pubsub <code>message-id</code>?","text":"<p>For our current purposes, there is no need to address messages based on source peer, or track a message <code>seqno</code>. By overriding the default <code>message-id</code> to use content-addressing we can filter unnecessary duplicates before hitting the application layer.</p> <p>Some examples of where messages could be duplicated:</p> <ul> <li>A validator client connected to multiple beacon nodes publishing duplicate   gossip messages</li> <li>Attestation aggregation strategies where clients partially aggregate   attestations and propagate them. Partial aggregates could be duplicated</li> <li>Clients re-publishing seen messages</li> </ul>"},{"location":"specs/phase0/p2p-interface/#why-are-these-specific-gossip-parameters-chosen","title":"Why are these specific gossip parameters chosen?","text":"<ul> <li><code>D</code>, <code>D_low</code>, <code>D_high</code>, <code>D_lazy</code>: recommended defaults.</li> <li><code>heartbeat_interval</code>: 0.7 seconds, recommended for the beacon chain in the   GossipSub evaluation report by Protocol Labs.</li> <li><code>fanout_ttl</code>: 60 seconds, recommended default. Fanout is primarily used by   committees publishing attestations to subnets. This happens once per epoch per   validator and the subnet changes each epoch so there is little to gain in   having a <code>fanout_ttl</code> be increased from the recommended default.</li> <li><code>mcache_len</code>: 6, increase by one to ensure that mcache is around for long   enough for <code>IWANT</code>s to respond to <code>IHAVE</code>s in the context of the shorter   <code>heartbeat_interval</code>. If <code>mcache_gossip</code> is increased, this param should be   increased to be at least <code>3</code> (~2 seconds) more than <code>mcache_gossip</code>.</li> <li><code>mcache_gossip</code>: 3, recommended default. This can be increased to 5 or 6 (~4   seconds) if gossip times are longer than expected and the current window does   not provide enough responsiveness during adverse conditions.</li> <li><code>seen_ttl</code>:   <code>SLOTS_PER_EPOCH * SECONDS_PER_SLOT / heartbeat_interval = approx. 550</code>.   Attestation gossip validity is bounded by an epoch, so this is the safe max   bound.</li> </ul>"},{"location":"specs/phase0/p2p-interface/#why-is-there-maximum_gossip_clock_disparity-when-validating-slot-ranges-of-messages-in-gossip-subnets","title":"Why is there <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> when validating slot ranges of messages in gossip subnets?","text":"<p>For some gossip channels (e.g. those for Attestations and BeaconBlocks), there are designated ranges of slots during which particular messages can be sent, limiting messages gossiped to those that can be reasonably used in the consensus at the current time/slot. This is to reduce optionality in DoS attacks.</p> <p><code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> provides some leeway in validating slot ranges to prevent the gossip network from becoming overly brittle with respect to clock disparity. For minimum and maximum allowable slot broadcast times, <code>MAXIMUM_GOSSIP_CLOCK_DISPARITY</code> MUST be subtracted and added respectively, marginally extending the valid range. Although messages can at times be eagerly gossiped to the network, the node's fork choice prevents integration of these messages into the actual consensus until the actual local start of the designated slot.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-there-attestation_subnet_count-attestation-subnets","title":"Why are there <code>ATTESTATION_SUBNET_COUNT</code> attestation subnets?","text":"<p>Depending on the number of validators, it may be more efficient to group shard subnets and might provide better stability for the gossipsub channel. The exact grouping will be dependent on more involved network tests. This constant allows for more flexibility in setting up the network topology for attestation aggregation (as aggregation should happen on each subnet). The value is currently set to be equal to <code>MAX_COMMITTEES_PER_SLOT</code> if/until network tests indicate otherwise.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-attestations-limited-to-be-broadcast-on-gossip-channels-within-slots_per_epoch-slots","title":"Why are attestations limited to be broadcast on gossip channels within <code>SLOTS_PER_EPOCH</code> slots?","text":"<p>Attestations can only be included on chain within an epoch's worth of slots so this is the natural cutoff. There is no utility to the chain to broadcast attestations older than one epoch, and because validators have a chance to make a new attestation each epoch, there is minimal utility to the fork choice to relay old attestations as a new latest message can soon be created by each validator.</p> <p>In addition to this, relaying attestations requires validating the attestation in the context of the <code>state</code> during which it was created. Thus, validating arbitrarily old attestations would put additional requirements on which states need to be readily available to the node. This would result in a higher resource burden and could serve as a DoS vector.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-aggregate-attestations-broadcast-to-the-global-topic-as-aggregateandproofs-rather-than-just-as-attestations","title":"Why are aggregate attestations broadcast to the global topic as <code>AggregateAndProof</code>s rather than just as <code>Attestation</code>s?","text":"<p>The dominant strategy for an individual validator is to always broadcast an aggregate containing their own attestation to the global channel to ensure that proposers see their attestation for inclusion. Using a private selection criteria and providing this proof of selection alongside the gossiped aggregate ensures that this dominant strategy will not flood the global channel.</p> <p>Also, an attacker can create any number of honest-looking aggregates and broadcast them to the global pubsub channel. Thus without some sort of proof of selection as an aggregator, the global channel can trivially be spammed.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-we-sending-entire-objects-in-the-pubsub-and-not-just-hashes","title":"Why are we sending entire objects in the pubsub and not just hashes?","text":"<p>Entire objects should be sent to get the greatest propagation speeds. If only hashes are sent, then block and attestation propagation is dependent on recursive requests from each peer. In a hash-only scenario, peers could receive hashes without knowing who to download the actual contents from. Sending entire objects ensures that they get propagated through the entire network.</p>"},{"location":"specs/phase0/p2p-interface/#should-clients-gossip-blocks-if-they-cannot-validate-the-proposer-signature-due-to-not-yet-being-synced-not-knowing-the-head-block-etc","title":"Should clients gossip blocks if they cannot validate the proposer signature due to not yet being synced, not knowing the head block, etc?","text":"<p>The prohibition of unverified-block-gossiping extends to nodes that cannot verify a signature due to not being fully synced to ensure that such (amplified) DOS attacks are not possible.</p>"},{"location":"specs/phase0/p2p-interface/#how-are-we-going-to-discover-peers-in-a-gossipsub-topic","title":"How are we going to discover peers in a gossipsub topic?","text":"<p>In Phase 0, peers for attestation subnets will be found using the <code>attnets</code> entry in the ENR.</p> <p>Although this method will be sufficient for early upgrade of the beacon chain, we aim to use the more appropriate discv5 topics for this and other similar tasks in the future. ENRs should ultimately not be used for this purpose. They are best suited to store identity, location, and capability information, rather than more volatile advertisements.</p>"},{"location":"specs/phase0/p2p-interface/#how-should-fork-version-be-used-in-practice","title":"How should fork version be used in practice?","text":"<p>Fork versions are to be manually updated (likely via incrementing) at each hard fork. This is to provide native domain separation for signatures as well as to aid in usefulness for identifying peers (via ENRs) and versioning network protocols (e.g. using fork version to naturally version gossipsub topics).</p> <p><code>BeaconState.genesis_validators_root</code> is mixed into signature and ENR fork domains (<code>ForkDigest</code>) to aid in the ease of domain separation between chains. This allows fork versions to safely be reused across chains except for the case of contentious forks using the same genesis. In these cases, extra care should be taken to isolate fork versions (e.g. flip a high order bit in all future versions of one of the chains).</p> <p>A node locally stores all previous and future planned fork versions along with the each fork epoch. This allows for handling sync and processing messages starting from past forks/epochs.</p>"},{"location":"specs/phase0/p2p-interface/#reqresp","title":"Req/Resp","text":""},{"location":"specs/phase0/p2p-interface/#why-segregate-requests-into-dedicated-protocol-ids","title":"Why segregate requests into dedicated protocol IDs?","text":"<p>Requests are segregated by protocol ID to:</p> <ol> <li>Leverage protocol routing in libp2p, such that the libp2p stack will route    the incoming stream to the appropriate handler. This allows the handler    function for each request type to be self-contained. For an analogy, think    about how you attach HTTP handlers to a REST API server.</li> <li>Version requests independently. In a coarser-grained umbrella protocol, the    entire protocol would have to be versioned even if just one field in a single    message changed.</li> <li>Enable clients to select the individual requests/versions they support. It    would no longer be a strict requirement to support all requests, and clients,    in principle, could support a subset of requests and variety of versions.</li> <li>Enable flexibility and agility for clients adopting spec changes that impact    the request, by signalling to peers exactly which subset of new/old requests    they support.</li> <li>Enable clients to explicitly choose backwards compatibility at the request    granularity. Without this, clients would be forced to support entire versions    of the coarser request protocol.</li> <li>Parallelise RFCs (or EIPs). By decoupling requests from one another, each RFC    that affects the request protocol can be deployed/tested/debated    independently without relying on a synchronization point to version the    general top-level protocol.</li> <li>This has the benefit that clients can explicitly choose which RFCs to       deploy without buying into all other RFCs that may be included in that       top-level version.</li> <li>Affording this level of granularity with a top-level protocol would imply       creating as many variants (e.g. /protocol/43-{a,b,c,d,...}) as the       cartesian product of RFCs in-flight, O(n^2).</li> <li>Allow us to simplify the payload of requests. Request-id\u2019s and method-ids no    longer need to be sent. The encoding/request type and version can all be    handled by the framework.</li> </ol> <p>Caveat: The protocol negotiation component in the current version of libp2p is called multistream-select 1.0. It is somewhat na\u00efve and introduces overhead on every request when negotiating streams, although implementation-specific optimizations are possible to save this cost. Multiselect 2.0 will eventually remove this overhead by memoizing previously selected protocols, and modeling shared protocol tables. Fortunately, this req/resp protocol is not the expected network bottleneck in the protocol so the additional overhead is not expected to significantly hinder this domain.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-messages-length-prefixed-with-a-protobuf-varint-in-the-ssz-encoding","title":"Why are messages length-prefixed with a protobuf varint in the SSZ-encoding?","text":"<p>We are using single-use streams where each stream is closed at the end of the message. Thus, libp2p transparently handles message delimiting in the underlying stream. libp2p streams are full-duplex, and each party is responsible for closing their write side (like in TCP). We can therefore use stream closure to mark the end of the request and response independently.</p> <p>Nevertheless, in the case of <code>ssz_snappy</code>, messages are still length-prefixed with the length of the underlying data:</p> <ul> <li>A basic reader can prepare a correctly sized buffer before reading the message</li> <li>A more advanced reader can stream-decode SSZ given the length of the SSZ data.</li> <li>Alignment with protocols like gRPC over HTTP/2 that prefix with length</li> <li>Sanity checking of message length, and enabling much stricter message length   limiting based on SSZ type information, to provide even more DOS protection   than the global message length already does. E.g. a small <code>Status</code> message   does not nearly require <code>MAX_PAYLOAD_SIZE</code> bytes.</li> </ul> <p>Protobuf varint is an efficient technique to encode variable-length (unsigned here) ints. Instead of reserving a fixed-size field of as many bytes as necessary to convey the maximum possible value, this field is elastic in exchange for 1-bit overhead per byte.</p>"},{"location":"specs/phase0/p2p-interface/#why-do-we-version-protocol-strings-with-ordinals-instead-of-semver","title":"Why do we version protocol strings with ordinals instead of semver?","text":"<p>Using semver for network protocols is confusing. It is never clear what a change in a field, even if backwards compatible on deserialization, actually implies. Network protocol agreement should be explicit. Imagine two peers:</p> <ul> <li>Peer A supporting v1.1.1 of protocol X.</li> <li>Peer B supporting v1.1.2 of protocol X.</li> </ul> <p>These two peers should never speak to each other because the results can be unpredictable. This is an oversimplification: imagine the same problem with a set of 10 possible versions. We now have 10^2 (100) possible outcomes that peers need to model for. The resulting complexity is unwieldy.</p> <p>For this reason, we rely on negotiation of explicit, verbatim protocols. In the above case, peer B would provide backwards compatibility by supporting and advertising both v1.1.1 and v1.1.2 of the protocol.</p> <p>Therefore, semver would be relegated to convey expectations at the human level, and it wouldn't do a good job there either, because it's unclear if \"backwards compatibility\" and \"breaking change\" apply only to wire schema level, to behavior, etc.</p> <p>For this reason, we remove and replace semver with ordinals that require explicit agreement and do not mandate a specific policy for changes.</p>"},{"location":"specs/phase0/p2p-interface/#why-is-it-called-reqresp-and-not-rpc","title":"Why is it called Req/Resp and not RPC?","text":"<p>Req/Resp is used to avoid confusion with JSON-RPC and similar user-client interaction mechanisms.</p>"},{"location":"specs/phase0/p2p-interface/#what-is-a-typical-rate-limiting-strategy","title":"What is a typical rate limiting strategy?","text":"<p>The responder typically will want to rate limit requests to protect against spam and to manage resource consumption, while the requester will want to maximise performance based on its own resource allocation strategy. For the network, it is beneficial if available resources are used optimally.</p> <p>Broadly, the requester does not know the capacity / limit of each server but can derive it from the rate of responses for the purpose of selecting the next peer for a request.</p> <p>Because the server withholds the response until capacity is available, a client can optimistically send requests without risking running into negative scoring situations or sub-optimal rate polling.</p> <p>A typical approach for the requester is to implement a timeout on the request that depends on the nature of the request and on connectivity parameters in general - for example when requesting blocks, a peer might choose to send a request to a second peer if the first peer does not respond within a reasonable time, and to reset the request to the first peer if the second peer responds faster. Clients may use past response performance to reward fast peers when implementing peer scoring.</p> <p>A typical approach for the responder is to implement a two-level token/leaky bucket with a per-peer limit and a global limit. The granularity of rate limiting may be based either on full requests or individual chunks with the latter being preferable. A token cost may be assigned to the request itself and separately each chunk in the response so as to remain protected both against large and frequent requests.</p> <p>For requesters, rate limiting is not distinguishable from other conditions causing slow responses (slow peers, congestion etc) and since the latter conditions must be handled anyway, including rate limiting in this strategy keeps the implementation simple.</p>"},{"location":"specs/phase0/p2p-interface/#why-do-we-allow-empty-responses-in-block-requests","title":"Why do we allow empty responses in block requests?","text":"<p>When requesting blocks by range or root, it may happen that there are no blocks in the selected range or the responding node does not have the requested blocks.</p> <p>Thus, it may happen that we need to transmit an empty list - there are several ways to encode this:</p> <ol> <li>Close the stream without sending any data</li> <li>Add a <code>null</code> option to the <code>success</code> response, for example by introducing an    additional byte</li> <li>Respond with an error result, using a specific error code for \"No data\"</li> </ol> <p>Semantically, it is not an error that a block is missing during a slot making option 2 unnatural.</p> <p>Option 1 allows the responder to signal \"no block\", but this information may be wrong - for example in the case of a malicious node.</p> <p>Under option 0, there is no way for a client to distinguish between a slot without a block and an incomplete response, but given that it already must contain logic to handle the uncertainty of a malicious peer, option 0 was chosen. Clients should mark any slots missing blocks as unknown until they can be verified as not containing a block by successive blocks.</p> <p>Assuming option 0 with no special <code>null</code> encoding, consider a request for slots <code>2, 3, 4</code> -- if there was no block produced at slot 4, the response would be <code>2, 3, EOF</code>. Now consider the same situation, but where only <code>4</code> is requested -- closing the stream with only <code>EOF</code> (without any <code>response_chunk</code>) is consistent.</p> <p>Failing to provide blocks that nodes \"should\" have is reason to trust a peer less -- for example, if a particular peer gossips a block, it should have access to its parent. If a request for the parent fails, it's indicative of poor peer quality since peers should validate blocks before gossiping them.</p>"},{"location":"specs/phase0/p2p-interface/#why-does-beaconblocksbyrange-let-the-server-choose-which-branch-to-send-blocks-from","title":"Why does <code>BeaconBlocksByRange</code> let the server choose which branch to send blocks from?","text":"<p>When connecting, the <code>Status</code> message gives an idea about the sync status of a particular peer, but this changes over time. By the time a subsequent <code>BeaconBlockByRange</code> request is processed, the information may be stale, and the responder might have moved on to a new finalization point and pruned blocks around the previous head and finalized blocks.</p> <p>To avoid this race condition, we allow the responder to choose which branch to send to the requester. The requester then goes on to validate the blocks and incorporate them in their own database -- because they follow the same rules, they should at this point arrive at the same canonical chain.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-blocksbyrange-requests-only-required-to-be-served-for-the-latest-min_epochs_for_block_requests-epochs","title":"Why are <code>BlocksByRange</code> requests only required to be served for the latest <code>MIN_EPOCHS_FOR_BLOCK_REQUESTS</code> epochs?","text":"<p>Due to economic finality and weak subjectivity requirements of a proof-of-stake blockchain, for a new node to safely join the network the node must provide a recent checkpoint found out-of-band. This checkpoint can be in the form of a <code>root</code> &amp; <code>epoch</code> or it can be the entire beacon state and then a simple block sync from there to the head. We expect the latter to be the dominant UX strategy.</p> <p>These checkpoints in the worst case (i.e. very large validator set and maximal allowed safety decay) must be from the most recent <code>MIN_EPOCHS_FOR_BLOCK_REQUESTS</code> epochs, and thus a user must be able to block sync to the head from this starting point. Thus, this defines the epoch range outside which nodes may prune blocks, and the epoch range that a new node syncing from a checkpoint must backfill.</p> <p><code>MIN_EPOCHS_FOR_BLOCK_REQUESTS</code> is calculated using the arithmetic from <code>compute_weak_subjectivity_period</code> found in the weak subjectivity guide. Specifically to find this max epoch range, we use the worst case event of a very large validator size (<code>&gt;= MIN_PER_EPOCH_CHURN_LIMIT * CHURN_LIMIT_QUOTIENT</code>).</p> <pre><code>MIN_EPOCHS_FOR_BLOCK_REQUESTS = (\n    MIN_VALIDATOR_WITHDRAWABILITY_DELAY + MAX_SAFETY_DECAY * CHURN_LIMIT_QUOTIENT // (2 * 100)\n)\n</code></pre> <p>Where <code>MAX_SAFETY_DECAY = 100</code> and thus <code>MIN_EPOCHS_FOR_BLOCK_REQUESTS = 33024</code> (~5 months).</p>"},{"location":"specs/phase0/p2p-interface/#why-must-the-proposer-signature-be-checked-when-backfilling-blocks-in-the-database","title":"Why must the proposer signature be checked when backfilling blocks in the database?","text":"<p>When backfilling blocks in a database from a know safe block/state (e.g. when starting from a weak subjectivity state), the node not only must ensure the <code>BeaconBlock</code>s form a chain to the known safe block, but also must check that the proposer signature is valid in the <code>SignedBeaconBlock</code> wrapper.</p> <p>This is because the signature is not part of the <code>BeaconBlock</code> hash chain, and thus could be corrupted by an attacker serving valid <code>BeaconBlock</code>s but invalid signatures contained in <code>SignedBeaconBlock</code>.</p> <p>Although in this particular use case this does not represent a decay in safety (due to the assumptions of starting at a weak subjectivity checkpoint), it would represent invalid historic data and could be unwittingly transmitted to additional nodes.</p>"},{"location":"specs/phase0/p2p-interface/#whats-the-effect-of-empty-slots-on-the-sync-algorithm","title":"What's the effect of empty slots on the sync algorithm?","text":"<p>When syncing one can only tell that a slot has been skipped on a particular branch by examining subsequent blocks and analyzing the graph formed by the parent root. Because the server side may choose to omit blocks in the response for any reason, clients must validate the graph and be prepared to fill in gaps.</p> <p>For example, if a peer responds with blocks [2, 3] when asked for [2, 3, 4], clients may not assume that block 4 doesn't exist -- it merely means that the responding peer did not send it (they may not have it yet or may maliciously be trying to hide it) and successive blocks will be needed to determine if there exists a block at slot 4 in this particular branch.</p>"},{"location":"specs/phase0/p2p-interface/#discovery","title":"Discovery","text":""},{"location":"specs/phase0/p2p-interface/#why-are-we-using-discv5-and-not-libp2p-kademlia-dht","title":"Why are we using discv5 and not libp2p Kademlia DHT?","text":"<p>discv5 is a standalone protocol, running on UDP on a dedicated port, meant for peer and service discovery only. discv5 supports self-certified, flexible peer records (ENRs) and topic-based advertisement, both of which are, or will be, requirements in this context.</p> <p>On the other hand, libp2p Kademlia DHT is a fully-fledged DHT protocol/implementations with content routing and storage capabilities, both of which are irrelevant in this context.</p> <p>Ethereum execution-layer nodes will evolve to support discv5. By sharing the discovery network between Ethereum consensus-layer and execution-layer clients, we benefit from the additive effect on network size that enhances resilience and resistance against certain attacks, to which smaller networks are more vulnerable. It should also help light clients of both networks find nodes with specific capabilities.</p> <p>discv5 is in the process of being audited.</p>"},{"location":"specs/phase0/p2p-interface/#what-is-the-difference-between-an-enr-and-a-multiaddr-and-why-are-we-using-enrs","title":"What is the difference between an ENR and a multiaddr, and why are we using ENRs?","text":"<p>Ethereum Node Records are self-certified node records. Nodes craft and disseminate ENRs for themselves, proving authorship via a cryptographic signature. ENRs are sequentially indexed, enabling conflicts to be resolved.</p> <p>ENRs are key-value records with string-indexed ASCII keys. They can store arbitrary information, but EIP-778 specifies a pre-defined dictionary, including IPv4 and IPv6 addresses, secp256k1 public keys, etc.</p> <p>Comparing ENRs and multiaddrs is like comparing apples and oranges. ENRs are self-certified containers of identity, addresses, and metadata about a node. Multiaddrs are address strings with the peculiarity that they\u2019re self-describing, composable and future-proof. An ENR can contain multiaddrs, and multiaddrs can be derived securely from the fields of an authenticated ENR.</p> <p>discv5 uses ENRs and we will presumably need to:</p> <ol> <li>Add <code>multiaddr</code> to the dictionary, so that nodes can advertise their    multiaddr under a reserved namespace in ENRs. \u2013 and/or \u2013</li> <li>Define a bi-directional conversion function between multiaddrs and the    corresponding denormalized fields in an ENR (ip, ip6, tcp, tcp6, etc.), for    compatibility with nodes that do not support multiaddr natively (e.g.    Ethereum execution-layer nodes).</li> </ol>"},{"location":"specs/phase0/p2p-interface/#why-do-we-not-form-enrs-and-find-peers-until-genesis-blockstate-is-known","title":"Why do we not form ENRs and find peers until genesis block/state is known?","text":"<p>Although client software might very well be running locally prior to the solidification of the beacon chain genesis state and block, clients cannot form valid ENRs prior to this point. ENRs contain <code>fork_digest</code> which utilizes the <code>genesis_validators_root</code> for a cleaner separation between chains so prior to knowing genesis, we cannot use <code>fork_digest</code> to cleanly find peers on our intended chain. Once genesis data is known, we can then form ENRs and safely find peers.</p> <p>When using a proof-of-work deposit contract for deposits, <code>fork_digest</code> will be known <code>GENESIS_DELAY</code> (7 days in mainnet configuration) before <code>genesis_time</code>, providing ample time to find peers and form initial connections and gossip subnets prior to genesis.</p>"},{"location":"specs/phase0/p2p-interface/#compressionencoding","title":"Compression/Encoding","text":""},{"location":"specs/phase0/p2p-interface/#why-are-we-using-ssz-for-encoding","title":"Why are we using SSZ for encoding?","text":"<p>SSZ is used at the consensus layer, and all implementations should have support for SSZ-encoding/decoding, requiring no further dependencies to be added to client implementations. This is a natural choice for serializing objects to be sent across the wire. The actual data in most protocols will be further compressed for efficiency.</p> <p>SSZ has well-defined schemas for consensus objects (typically sent across the wire) reducing any serialization schema data that needs to be sent. It also has defined all required types that are required for this network specification.</p>"},{"location":"specs/phase0/p2p-interface/#why-are-we-compressing-and-at-which-layers","title":"Why are we compressing, and at which layers?","text":"<p>We compress on the wire to achieve smaller payloads per-message, which, in aggregate, result in higher efficiency, better utilization of available bandwidth, and overall reduction in network-wide traffic overhead.</p> <p>At this time, libp2p does not have an out-of-the-box compression feature that can be dynamically negotiated and layered atop connections and streams, but it is being considered.</p> <p>This is a non-trivial feature because the behavior of network IO loops, kernel buffers, chunking, and packet fragmentation, amongst others, need to be taken into account. libp2p streams are unbounded streams, whereas compression algorithms work best on bounded byte streams of which we have some prior knowledge.</p> <p>Compression tends not to be a one-size-fits-all problem. A lot of variables need careful evaluation, and generic approaches/choices lead to poor size shavings, which may even be counterproductive when factoring in the CPU and memory tradeoff.</p> <p>For all these reasons, generically negotiating compression algorithms may be treated as a research problem at the libp2p community, one we\u2019re happy to tackle in the medium-term.</p> <p>At this stage, the wisest choice is to consider libp2p a messenger of bytes, and to make application layer participate in compressing those bytes. This looks different depending on the interaction layer:</p> <ul> <li>Gossip domain: since gossipsub has a framing protocol and exposes an API, we   compress the payload (when dictated by the encoding token in the topic name)   prior to publishing the message via the API. No length-prefixing is necessary   because protobuf takes care of bounding the field in the serialized form.</li> <li>Req/Resp domain: since we define custom protocols that operate on byte   streams, implementers are encouraged to encapsulate the encoding and   compression logic behind MessageReader and MessageWriter components/strategies   that can be layered on top of the raw byte streams.</li> </ul>"},{"location":"specs/phase0/p2p-interface/#why-are-we-using-snappy-for-compression","title":"Why are we using Snappy for compression?","text":"<p>Snappy is used in Ethereum 1.0. It is well maintained by Google, has good benchmarks, and can calculate the size of the uncompressed object without inflating it in memory. This prevents DOS vectors where large uncompressed data is sent.</p>"},{"location":"specs/phase0/p2p-interface/#can-i-get-access-to-unencrypted-bytes-on-the-wire-for-debugging-purposes","title":"Can I get access to unencrypted bytes on the wire for debugging purposes?","text":"<p>Yes, you can add loggers in your libp2p protocol handlers to log incoming and outgoing messages. It is recommended to use programming design patterns to encapsulate the logging logic cleanly.</p> <p>If your libp2p library relies on frameworks/runtimes such as Netty (jvm) or Node.js (javascript), you can use logging facilities in those frameworks/runtimes to enable message tracing.</p> <p>For specific ad-hoc testing scenarios, you can use the plaintext/2.0.0 secure channel (which is essentially no-op encryption or message authentication), in combination with tcpdump or Wireshark to inspect the wire.</p>"},{"location":"specs/phase0/p2p-interface/#what-are-ssz-type-size-bounds","title":"What are SSZ type size bounds?","text":"<p>The SSZ encoding outputs of each type have size bounds: each dynamic type, such as a list, has a \"limit\", which can be used to compute the maximum valid output size. Note that for some more complex dynamic-length objects, element offsets (4 bytes each) may need to be included. Other types are static, they have a fixed size: no dynamic-length content is involved, and the minimum and maximum bounds are the same.</p> <p>For reference, the type bounds can be computed ahead of time, as per this example. It is advisable to derive these lengths from the SSZ type definitions in use, to ensure that version changes do not cause out-of-sync type bounds.</p>"},{"location":"specs/phase0/p2p-interface/#why-is-the-message-size-defined-in-terms-of-application-payload","title":"Why is the message size defined in terms of application payload?","text":"<p>When transmitting messages over gossipsub and/or the req/resp domain, we want to ensure that the same payload sizes are supported regardless of the underlying transport, decoupling the consensus layer from libp2p-induced overhead and the particular transmission strategy.</p> <p>To derive \"encoded size limits\" from desired application sizes, we take into account snappy compression and framing overhead.</p> <p>In the case of gossipsub, the protocol supports sending multiple application payloads as well as mixing application data with control messages in each gossipsub frame. The limit is set such that at least one max-sized application-level message together with a small amount (1 KiB) of gossipsub overhead is allowed. Implementations are free to pack multiple smaller application messages into a single gossipsub frame, and/or combine it with control messages as they see fit.</p> <p>The limit is set on the uncompressed payload size in particular to protect against decompression bombs.</p>"},{"location":"specs/phase0/p2p-interface/#why-is-there-a-limit-on-message-sizes-at-all","title":"Why is there a limit on message sizes at all?","text":"<p>The message size limit protects against several forms of DoS and network-based amplification attacks and provides upper bounds for resource (network, memory) usage in the client based on protocol requirements to decode, buffer, cache, store and re-transmit messages which in turn translate into performance and protection tradeoffs, ensuring capacity to handle worst cases during recovery from network instability.</p> <p>In particular, blocks\u2014-currently the only message type without a practical SSZ-derived upper bound on size\u2014-cannot be fully verified synchronously as part of gossipsub validity checks. This means that there exist cases where invalid messages signed by a validator may be amplified by the network.</p>"},{"location":"specs/phase0/p2p-interface/#libp2p-implementations-matrix","title":"libp2p implementations matrix","text":"<p>This section will soon contain a matrix showing the maturity/state of the libp2p features required by this spec across the languages in which clients are being developed.</p>"},{"location":"specs/phase0/validator/","title":"Phase 0 -- Honest Validator","text":"<p>This is an accompanying document to Phase 0 -- The Beacon Chain, which describes the expected actions of a \"validator\" participating in the Ethereum proof-of-stake protocol.</p> <ul> <li>Introduction</li> <li>Prerequisites</li> <li>Constants</li> <li>Misc</li> <li>Configuration</li> <li>Time parameters</li> <li>Containers</li> <li><code>Eth1Block</code></li> <li><code>AggregateAndProof</code></li> <li><code>SignedAggregateAndProof</code></li> <li>Becoming a validator</li> <li>Initialization<ul> <li>BLS public key</li> <li>Withdrawal credentials</li> <li><code>BLS_WITHDRAWAL_PREFIX</code></li> <li><code>ETH1_ADDRESS_WITHDRAWAL_PREFIX</code></li> </ul> </li> <li>Submit deposit</li> <li>Process deposit</li> <li>Validator index</li> <li>Activation</li> <li>Validator assignments</li> <li>Lookahead</li> <li>Beacon chain responsibilities</li> <li>Block proposal<ul> <li>Preparing for a <code>BeaconBlock</code></li> <li>Slot</li> <li>Proposer index</li> <li>Parent root</li> <li>Constructing the <code>BeaconBlockBody</code></li> <li>Randao reveal</li> <li>Eth1 Data<ul> <li><code>get_eth1_data</code></li> </ul> </li> <li>Proposer slashings</li> <li>Attester slashings</li> <li>Attestations</li> <li>Deposits</li> <li>Voluntary exits</li> <li>Packaging into a <code>SignedBeaconBlock</code></li> <li>State root</li> <li>Signature</li> </ul> </li> <li>Attesting<ul> <li>Attestation data</li> <li>General</li> <li>LMD GHOST vote</li> <li>FFG vote</li> <li>Construct attestation</li> <li>Data</li> <li>Aggregation bits</li> <li>Aggregate signature</li> <li>Broadcast attestation</li> </ul> </li> <li>Attestation aggregation<ul> <li>Aggregation selection</li> <li>Construct aggregate</li> <li>Data</li> <li>Aggregation bits</li> <li>Aggregate signature</li> <li>Broadcast aggregate</li> </ul> </li> <li>How to avoid slashing</li> <li>Proposer slashing</li> <li>Attester slashing</li> <li>Protection best practices</li> </ul>"},{"location":"specs/phase0/validator/#introduction","title":"Introduction","text":"<p>This document represents the expected behavior of an \"honest validator\" with respect to Phase 0 of the Ethereum proof-of-stake protocol. This document does not distinguish between a \"node\" (i.e. the functionality of following and reading the beacon chain) and a \"validator client\" (i.e. the functionality of actively participating in consensus). The separation of concerns between these (potentially) two pieces of software is left as a design decision that is out of scope.</p> <p>A validator is an entity that participates in the consensus of the Ethereum proof-of-stake protocol. This is an optional role for users in which they can post ETH as collateral and verify and attest to the validity of blocks to seek financial returns in exchange for building and securing the protocol. This is similar to proof-of-work networks in which miners provide collateral in the form of hardware/hash-power to seek returns in exchange for building and securing the protocol.</p>"},{"location":"specs/phase0/validator/#prerequisites","title":"Prerequisites","text":"<p>All terminology, constants, functions, and protocol mechanics defined in the Phase 0 -- The Beacon Chain and Phase 0 -- Deposit Contract doc are requisite for this document and used throughout. Please see the Phase 0 doc before continuing and use as a reference throughout.</p>"},{"location":"specs/phase0/validator/#constants","title":"Constants","text":""},{"location":"specs/phase0/validator/#misc","title":"Misc","text":"Name Value Unit <code>TARGET_AGGREGATORS_PER_COMMITTEE</code> <code>2**4</code> (= 16) validators"},{"location":"specs/phase0/validator/#configuration","title":"Configuration","text":""},{"location":"specs/phase0/validator/#time-parameters","title":"Time parameters","text":"Name Value Unit Duration <code>ATTESTATION_DUE_BPS</code> <code>uint64(3333)</code> basis points ~33% of <code>SLOT_DURATION_MS</code> <code>AGGREGATE_DUE_BPS</code> <code>uint64(6667)</code> basis points ~67% of <code>SLOT_DURATION_MS</code>"},{"location":"specs/phase0/validator/#containers","title":"Containers","text":""},{"location":"specs/phase0/validator/#eth1block","title":"<code>Eth1Block</code>","text":"<pre><code>class Eth1Block(Container):\n    timestamp: uint64\n    deposit_root: Root\n    deposit_count: uint64\n    # All other eth1 block fields\n</code></pre>"},{"location":"specs/phase0/validator/#aggregateandproof","title":"<code>AggregateAndProof</code>","text":"<pre><code>class AggregateAndProof(Container):\n    aggregator_index: ValidatorIndex\n    aggregate: Attestation\n    selection_proof: BLSSignature\n</code></pre>"},{"location":"specs/phase0/validator/#signedaggregateandproof","title":"<code>SignedAggregateAndProof</code>","text":"<pre><code>class SignedAggregateAndProof(Container):\n    message: AggregateAndProof\n    signature: BLSSignature\n</code></pre>"},{"location":"specs/phase0/validator/#becoming-a-validator","title":"Becoming a validator","text":""},{"location":"specs/phase0/validator/#initialization","title":"Initialization","text":"<p>A validator must initialize many parameters locally before submitting a deposit and joining the validator registry.</p>"},{"location":"specs/phase0/validator/#bls-public-key","title":"BLS public key","text":"<p>Validator public keys are G1 points on the BLS12-381 curve. A private key, <code>privkey</code>, must be securely generated along with the resultant <code>pubkey</code>. This <code>privkey</code> must be \"hot\", that is, constantly available to sign data throughout the lifetime of the validator.</p>"},{"location":"specs/phase0/validator/#withdrawal-credentials","title":"Withdrawal credentials","text":"<p>The <code>withdrawal_credentials</code> field constrains validator withdrawals. The first byte of this 32-byte field is a withdrawal prefix which defines the semantics of the remaining 31 bytes.</p> <p>The following withdrawal prefixes are currently supported.</p>"},{"location":"specs/phase0/validator/#bls_withdrawal_prefix","title":"<code>BLS_WITHDRAWAL_PREFIX</code>","text":"<p>Withdrawal credentials with the BLS withdrawal prefix allow a BLS key pair <code>(bls_withdrawal_privkey, bls_withdrawal_pubkey)</code> to trigger withdrawals. The <code>withdrawal_credentials</code> field must be such that:</p> <ul> <li><code>withdrawal_credentials[:1] == BLS_WITHDRAWAL_PREFIX</code></li> <li><code>withdrawal_credentials[1:] == hash(bls_withdrawal_pubkey)[1:]</code></li> </ul> <p>Note: The <code>bls_withdrawal_privkey</code> is not required for validating and can be kept in cold storage.</p>"},{"location":"specs/phase0/validator/#eth1_address_withdrawal_prefix","title":"<code>ETH1_ADDRESS_WITHDRAWAL_PREFIX</code>","text":"<p>Withdrawal credentials with the Eth1 address withdrawal prefix specify a 20-byte Eth1 address <code>eth1_withdrawal_address</code> as the recipient for all withdrawals. The <code>eth1_withdrawal_address</code> can be the address of either an externally owned account or of a contract.</p> <p>The <code>withdrawal_credentials</code> field must be such that:</p> <ul> <li><code>withdrawal_credentials[:1] == ETH1_ADDRESS_WITHDRAWAL_PREFIX</code></li> <li><code>withdrawal_credentials[1:12] == b'\\x00' * 11</code></li> <li><code>withdrawal_credentials[12:] == eth1_withdrawal_address</code></li> </ul> <p>After the merge of the current Ethereum execution layer into the Beacon Chain, withdrawals to <code>eth1_withdrawal_address</code> will simply be increases to the account's ETH balance that do NOT trigger any EVM execution.</p>"},{"location":"specs/phase0/validator/#submit-deposit","title":"Submit deposit","text":"<p>In Phase 0, all incoming validator deposits originate from the Ethereum proof-of-work chain defined by <code>DEPOSIT_CHAIN_ID</code> and <code>DEPOSIT_NETWORK_ID</code>. Deposits are made to the deposit contract located at <code>DEPOSIT_CONTRACT_ADDRESS</code>.</p> <p>To submit a deposit:</p> <ul> <li>Pack the validator's initialization parameters into   <code>deposit_data</code>, a <code>DepositData</code> SSZ object.</li> <li>Let <code>amount</code> be the amount in Gwei to be deposited by the validator where   <code>amount &gt;= MIN_DEPOSIT_AMOUNT</code>.</li> <li>Set <code>deposit_data.pubkey</code> to validator's <code>pubkey</code>.</li> <li>Set <code>deposit_data.withdrawal_credentials</code> to <code>withdrawal_credentials</code>.</li> <li>Set <code>deposit_data.amount</code> to <code>amount</code>.</li> <li>Let <code>deposit_message</code> be a <code>DepositMessage</code> with all the <code>DepositData</code>   contents except the <code>signature</code>.</li> <li>Let <code>signature</code> be the result of <code>bls.Sign</code> of the   <code>compute_signing_root(deposit_message, domain)</code> with   <code>domain=compute_domain(DOMAIN_DEPOSIT)</code>. (Warning: Deposits must be signed   with <code>GENESIS_FORK_VERSION</code>, calling <code>compute_domain</code> without a second   argument defaults to the correct version).</li> <li>Let <code>deposit_data_root</code> be <code>hash_tree_root(deposit_data)</code>.</li> <li>Send a transaction on the Ethereum proof-of-work chain to   <code>DEPOSIT_CONTRACT_ADDRESS</code> executing   <code>def deposit(pubkey: bytes[48], withdrawal_credentials: bytes[32], signature: bytes[96], deposit_data_root: bytes32)</code>   along with a deposit of <code>amount</code> Gwei.</li> </ul> <p>Note: Deposits made for the same <code>pubkey</code> are treated as for the same validator. A singular <code>Validator</code> will be added to <code>state.validators</code> with each additional deposit amount added to the validator's balance. A validator can only be activated when total deposits for the validator pubkey meet or exceed <code>MAX_EFFECTIVE_BALANCE</code>.</p>"},{"location":"specs/phase0/validator/#process-deposit","title":"Process deposit","text":"<p>Deposits cannot be processed into the beacon chain until the proof-of-work block in which they were deposited or any of its descendants is added to the beacon chain <code>state.eth1_data</code>. This takes a minimum of <code>ETH1_FOLLOW_DISTANCE</code> Eth1 blocks (~8 hours) plus <code>EPOCHS_PER_ETH1_VOTING_PERIOD</code> epochs (~6.8 hours). Once the requisite proof-of-work block data is added, the deposit will normally be added to a beacon chain block and processed into the <code>state.validators</code> within an epoch or two. The validator is then in a queue to be activated.</p>"},{"location":"specs/phase0/validator/#validator-index","title":"Validator index","text":"<p>Once a validator has been processed and added to the beacon state's <code>validators</code>, the validator's <code>validator_index</code> is defined by the index into the registry at which the <code>ValidatorRecord</code> contains the <code>pubkey</code> specified in the validator's deposit. A validator's <code>validator_index</code> is guaranteed to not change from the time of initial deposit until the validator exits and fully withdraws. This <code>validator_index</code> is used throughout the specification to dictate validator roles and responsibilities at any point and should be stored locally.</p>"},{"location":"specs/phase0/validator/#activation","title":"Activation","text":"<p>In normal operation, the validator is quickly activated, at which point the validator is added to the shuffling and begins validation after an additional <code>MAX_SEED_LOOKAHEAD</code> epochs (25.6 minutes).</p> <p>The function <code>is_active_validator</code> can be used to check if a validator is active during a given epoch. Usage is as follows:</p> <pre><code>def check_if_validator_active(state: BeaconState, validator_index: ValidatorIndex) -&gt; bool:\n    validator = state.validators[validator_index]\n    return is_active_validator(validator, get_current_epoch(state))\n</code></pre> <p>Once a validator is activated, the validator is assigned responsibilities until exited.</p> <p>Note: There is a maximum validator churn per finalized epoch, so the delay until activation is variable depending upon finality, total active validator balance, and the number of validators in the queue to be activated.</p>"},{"location":"specs/phase0/validator/#validator-assignments","title":"Validator assignments","text":"<p>A validator can get committee assignments for a given epoch using the following helper via <code>get_committee_assignment(state, epoch, validator_index)</code> where <code>epoch &lt;= next_epoch</code>.</p> <pre><code>def get_committee_assignment(\n    state: BeaconState, epoch: Epoch, validator_index: ValidatorIndex\n) -&gt; Optional[Tuple[Sequence[ValidatorIndex], CommitteeIndex, Slot]]:\n    \"\"\"\n    Return the committee assignment in the ``epoch`` for ``validator_index``.\n    ``assignment`` returned is a tuple of the following form:\n        * ``assignment[0]`` is the list of validators in the committee\n        * ``assignment[1]`` is the index to which the committee is assigned\n        * ``assignment[2]`` is the slot at which the committee is assigned\n    Return None if no assignment.\n    \"\"\"\n    next_epoch = Epoch(get_current_epoch(state) + 1)\n    assert epoch &lt;= next_epoch\n\n    start_slot = compute_start_slot_at_epoch(epoch)\n    committee_count_per_slot = get_committee_count_per_slot(state, epoch)\n    for slot in range(start_slot, start_slot + SLOTS_PER_EPOCH):\n        for index in range(committee_count_per_slot):\n            committee = get_beacon_committee(state, Slot(slot), CommitteeIndex(index))\n            if validator_index in committee:\n                return committee, CommitteeIndex(index), Slot(slot)\n    return None\n</code></pre> <p>A validator can use the following function to see if they are supposed to propose during a slot. This function can only be run with a <code>state</code> of the slot in question. Proposer selection is only stable within the context of the current epoch.</p> <pre><code>def is_proposer(state: BeaconState, validator_index: ValidatorIndex) -&gt; bool:\n    return get_beacon_proposer_index(state) == validator_index\n</code></pre> <p>Note: To see if a validator is assigned to propose during the slot, the beacon state must be in the epoch in question. At the epoch boundaries, the validator must run an epoch transition into the epoch to successfully check the proposal assignment of the first slot.</p> <p>Note: <code>BeaconBlock</code> proposal is distinct from beacon committee assignment, and in a given epoch each responsibility might occur at a different slot.</p>"},{"location":"specs/phase0/validator/#lookahead","title":"Lookahead","text":"<p>The beacon chain shufflings are designed to provide a minimum of 1 epoch lookahead on the validator's upcoming committee assignments for attesting dictated by the shuffling and slot. Note that this lookahead does not apply to proposing, which must be checked during the epoch in question.</p> <p><code>get_committee_assignment</code> should be called at the start of each epoch to get the assignment for the next epoch (<code>current_epoch + 1</code>). A validator should plan for future assignments by noting their assigned attestation slot and joining the committee index attestation subnet related to their committee assignment.</p> <p>Specifically a validator should:</p> <ul> <li>Call   <code>_, committee_index, _ = get_committee_assignment(state, next_epoch, validator_index)</code>   when checking for next epoch assignments.</li> <li>Calculate the committees per slot for the next epoch:   <code>committees_per_slot = get_committee_count_per_slot(state, next_epoch)</code></li> <li>Calculate the subnet index:   <code>subnet_id = compute_subnet_for_attestation(committees_per_slot, slot, committee_index)</code></li> <li>Find peers of the pubsub topic <code>beacon_attestation_{subnet_id}</code>.</li> <li>If an insufficient number of current peers are subscribed to the topic,     the validator must discover new peers on this topic. Via the discovery     protocol, find peers with an ENR containing the <code>attnets</code> entry such that     <code>ENR[\"attnets\"][subnet_id] == True</code>. Then validate that the peers are still     persisted on the desired topic by requesting <code>GetMetaData</code> and checking the     resulting <code>attnets</code> field.</li> <li>If the validator is assigned to be an aggregator for the slot (see     <code>is_aggregator()</code>), then subscribe to the topic.</li> </ul> <p>Note: If the validator is not assigned to be an aggregator, the validator only needs sufficient number of peers on the topic to be able to publish messages. The validator does not need to subscribe and listen to all messages on the topic.</p>"},{"location":"specs/phase0/validator/#beacon-chain-responsibilities","title":"Beacon chain responsibilities","text":"<p>A validator has two primary responsibilities to the beacon chain: proposing blocks and creating attestations. Proposals happen infrequently, whereas attestations should be created once per epoch.</p>"},{"location":"specs/phase0/validator/#block-proposal","title":"Block proposal","text":"<p>A validator is expected to propose a <code>SignedBeaconBlock</code> at the beginning of any <code>slot</code> during which <code>is_proposer(state, validator_index)</code> returns <code>True</code>.</p> <p>To propose, the validator selects a <code>BeaconBlock</code>, <code>parent</code> using this process:</p> <ol> <li>Compute fork choice's view of the head at the start of <code>slot</code>, after running    <code>on_tick</code> and applying any queued attestations from <code>slot - 1</code>. Set    <code>head_root = get_head(store)</code>.</li> <li>Compute the proposer head, which is the head upon which the proposer SHOULD    build in order to incentivise timely block propagation by other validators.    Set <code>parent_root = get_proposer_head(store, head_root, slot)</code>. A proposer may    set <code>parent_root == head_root</code> if proposer re-orgs are not implemented or    have been disabled.</li> <li>Let <code>parent</code> be the block with <code>parent_root</code>.</li> </ol> <p>The validator creates, signs, and broadcasts a <code>block</code> that is a child of <code>parent</code> and satisfies a valid beacon chain state transition. Note that the parent's slot must be strictly less than the slot of the block about to be proposed, i.e. <code>parent.slot &lt; slot</code>.</p> <p>There is one proposer per slot, so if there are N active validators any individual validator will on average be assigned to propose once per N slots (e.g. at 312,500 validators = 10 million ETH, that's once per ~6 weeks).</p> <p>Note: In this section, <code>state</code> is the state of the slot for the block proposal without the block yet applied. That is, <code>state</code> is the <code>previous_state</code> processed through any empty slots up to the assigned slot using <code>process_slots(previous_state, slot)</code>.</p>"},{"location":"specs/phase0/validator/#preparing-for-a-beaconblock","title":"Preparing for a <code>BeaconBlock</code>","text":"<p>To construct a <code>BeaconBlockBody</code>, a <code>block</code> (<code>BeaconBlock</code>) is defined with the necessary context for a block proposal:</p>"},{"location":"specs/phase0/validator/#slot","title":"Slot","text":"<p>Set <code>block.slot = slot</code> where <code>slot</code> is the current slot at which the validator has been selected to propose. The <code>parent</code> selected must satisfy that <code>parent.slot &lt; block.slot</code>.</p> <p>Note: There might be \"skipped\" slots between the <code>parent</code> and <code>block</code>. These skipped slots are processed in the state transition function without per-block processing.</p>"},{"location":"specs/phase0/validator/#proposer-index","title":"Proposer index","text":"<p>Set <code>block.proposer_index = validator_index</code> where <code>validator_index</code> is the validator chosen to propose at this slot. The private key mapping to <code>state.validators[validator_index].pubkey</code> is used to sign the block.</p>"},{"location":"specs/phase0/validator/#parent-root","title":"Parent root","text":"<p>Set <code>block.parent_root = hash_tree_root(parent)</code>.</p>"},{"location":"specs/phase0/validator/#constructing-the-beaconblockbody","title":"Constructing the <code>BeaconBlockBody</code>","text":""},{"location":"specs/phase0/validator/#randao-reveal","title":"Randao reveal","text":"<p>Set <code>block.body.randao_reveal = epoch_signature</code> where <code>epoch_signature</code> is obtained from:</p> <pre><code>def get_epoch_signature(state: BeaconState, block: BeaconBlock, privkey: int) -&gt; BLSSignature:\n    domain = get_domain(state, DOMAIN_RANDAO, compute_epoch_at_slot(block.slot))\n    signing_root = compute_signing_root(compute_epoch_at_slot(block.slot), domain)\n    return bls.Sign(privkey, signing_root)\n</code></pre>"},{"location":"specs/phase0/validator/#eth1-data","title":"Eth1 Data","text":"<p>The <code>block.body.eth1_data</code> field is for block proposers to vote on recent Eth1 data. This recent data contains an Eth1 block hash as well as the associated deposit root (as calculated by the <code>get_deposit_root()</code> method of the deposit contract) and deposit count after execution of the corresponding Eth1 block. If over half of the block proposers in the current Eth1 voting period vote for the same <code>eth1_data</code> then <code>state.eth1_data</code> updates immediately allowing new deposits to be processed. Each deposit in <code>block.body.deposits</code> must verify against <code>state.eth1_data.eth1_deposit_root</code>.</p>"},{"location":"specs/phase0/validator/#get_eth1_data","title":"<code>get_eth1_data</code>","text":"<p>Let <code>Eth1Block</code> be an abstract object representing Eth1 blocks with the <code>timestamp</code> and deposit contract data available.</p> <p>Let <code>get_eth1_data(block: Eth1Block) -&gt; Eth1Data</code> be the function that returns the Eth1 data for a given Eth1 block.</p> <p>An honest block proposer sets <code>block.body.eth1_data = get_eth1_vote(state, eth1_chain)</code> where:</p> <pre><code>def voting_period_start_time(state: BeaconState) -&gt; uint64:\n    eth1_voting_period_start_slot = Slot(\n        state.slot - state.slot % (EPOCHS_PER_ETH1_VOTING_PERIOD * SLOTS_PER_EPOCH)\n    )\n    return compute_time_at_slot(state, eth1_voting_period_start_slot)\n</code></pre> <pre><code>def is_candidate_block(block: Eth1Block, period_start: uint64) -&gt; bool:\n    return (\n        block.timestamp + SECONDS_PER_ETH1_BLOCK * ETH1_FOLLOW_DISTANCE &lt;= period_start\n        and block.timestamp + SECONDS_PER_ETH1_BLOCK * ETH1_FOLLOW_DISTANCE * 2 &gt;= period_start\n    )\n</code></pre> <pre><code>def get_eth1_vote(state: BeaconState, eth1_chain: Sequence[Eth1Block]) -&gt; Eth1Data:\n    period_start = voting_period_start_time(state)\n    # `eth1_chain` abstractly represents all blocks in the eth1 chain sorted by ascending block height\n    votes_to_consider = [\n        get_eth1_data(block)\n        for block in eth1_chain\n        if (\n            is_candidate_block(block, period_start)\n            # Ensure cannot move back to earlier deposit contract states\n            and get_eth1_data(block).deposit_count &gt;= state.eth1_data.deposit_count\n        )\n    ]\n\n    # Valid votes already cast during this period\n    valid_votes = [vote for vote in state.eth1_data_votes if vote in votes_to_consider]\n\n    # Default vote on latest eth1 block data in the period range unless eth1 chain is not live\n    # Non-substantive casting for linter\n    state_eth1_data: Eth1Data = state.eth1_data\n    default_vote = (\n        votes_to_consider[len(votes_to_consider) - 1] if any(votes_to_consider) else state_eth1_data\n    )\n\n    return max(\n        valid_votes,\n        # Tiebreak by smallest distance\n        key=lambda v: (\n            valid_votes.count(v),\n            -valid_votes.index(v),\n        ),\n        default=default_vote,\n    )\n</code></pre>"},{"location":"specs/phase0/validator/#proposer-slashings","title":"Proposer slashings","text":"<p>Up to <code>MAX_PROPOSER_SLASHINGS</code>, <code>ProposerSlashing</code> objects can be included in the <code>block</code>. The proposer slashings must satisfy the verification conditions found in proposer slashings processing. The validator receives a small \"whistleblower\" reward for each proposer slashing found and included.</p>"},{"location":"specs/phase0/validator/#attester-slashings","title":"Attester slashings","text":"<p>Up to <code>MAX_ATTESTER_SLASHINGS</code>, <code>AttesterSlashing</code> objects can be included in the <code>block</code>. The attester slashings must satisfy the verification conditions found in attester slashings processing. The validator receives a small \"whistleblower\" reward for each attester slashing found and included.</p>"},{"location":"specs/phase0/validator/#attestations","title":"Attestations","text":"<p>Up to <code>MAX_ATTESTATIONS</code>, aggregate attestations can be included in the <code>block</code>. The attestations added must satisfy the verification conditions found in attestation processing. To maximize profit, the validator should attempt to gather aggregate attestations that include singular attestations from the largest number of validators whose signatures from the same epoch have not previously been added on chain.</p>"},{"location":"specs/phase0/validator/#deposits","title":"Deposits","text":"<p>If there are any unprocessed deposits for the existing <code>state.eth1_data</code> (i.e. <code>state.eth1_data.deposit_count &gt; state.eth1_deposit_index</code>), then pending deposits must be added to the block. The expected number of deposits is exactly <code>min(MAX_DEPOSITS, eth1_data.deposit_count - state.eth1_deposit_index)</code>. These <code>deposits</code> are constructed from the <code>Deposit</code> logs from the deposit contract and must be processed in sequential order. The deposits included in the <code>block</code> must satisfy the verification conditions found in deposits processing.</p> <p>The <code>proof</code> for each deposit must be constructed against the deposit root contained in <code>state.eth1_data</code> rather than the deposit root at the time the deposit was initially logged from the proof-of-work chain. This entails storing a full deposit merkle tree locally and computing updated proofs against the <code>eth1_data.deposit_root</code> as needed. See <code>minimal_merkle.py</code> for a sample implementation.</p>"},{"location":"specs/phase0/validator/#voluntary-exits","title":"Voluntary exits","text":"<p>Up to <code>MAX_VOLUNTARY_EXITS</code>, <code>VoluntaryExit</code> objects can be included in the <code>block</code>. The exits must satisfy the verification conditions found in exits processing.</p> <p>Note: If a slashing for a validator is included in the same block as a voluntary exit, the voluntary exit will fail and cause the block to be invalid due to the slashing being processed first. Implementers must take heed of this operation interaction when packing blocks.</p>"},{"location":"specs/phase0/validator/#packaging-into-a-signedbeaconblock","title":"Packaging into a <code>SignedBeaconBlock</code>","text":""},{"location":"specs/phase0/validator/#state-root","title":"State root","text":"<p>Set <code>block.state_root = hash_tree_root(state)</code> of the resulting <code>state</code> of the <code>parent -&gt; block</code> state transition.</p> <p>Note: To calculate <code>state_root</code>, the validator should first run the state transition function on an unsigned <code>block</code> containing a stub for the <code>state_root</code>. It is useful to be able to run a state transition function (working on a copy of the state) that does not validate signatures or state root for this purpose:</p> <pre><code>def compute_new_state_root(state: BeaconState, block: BeaconBlock) -&gt; Root:\n    temp_state: BeaconState = state.copy()\n    signed_block = SignedBeaconBlock(message=block)\n    state_transition(temp_state, signed_block, validate_result=False)\n    return hash_tree_root(temp_state)\n</code></pre>"},{"location":"specs/phase0/validator/#signature","title":"Signature","text":"<p><code>signed_block = SignedBeaconBlock(message=block, signature=block_signature)</code>, where <code>block_signature</code> is obtained from:</p> <pre><code>def get_block_signature(state: BeaconState, block: BeaconBlock, privkey: int) -&gt; BLSSignature:\n    domain = get_domain(state, DOMAIN_BEACON_PROPOSER, compute_epoch_at_slot(block.slot))\n    signing_root = compute_signing_root(block, domain)\n    return bls.Sign(privkey, signing_root)\n</code></pre>"},{"location":"specs/phase0/validator/#attesting","title":"Attesting","text":"<p>A validator is expected to create, sign, and broadcast an attestation during each epoch. The <code>committee</code>, assigned <code>index</code>, and assigned <code>slot</code> for which the validator performs this role during an epoch are defined by <code>get_committee_assignment(state, epoch, validator_index)</code>.</p> <p>A validator should create and broadcast the <code>attestation</code> to the associated attestation subnet when either (a) the validator has received a valid block from the expected block proposer for the assigned <code>slot</code> or (b) <code>get_slot_component_duration_ms(ATTESTATION_DUE_BPS)</code> milliseconds has transpired since the start of the slot -- whichever comes first.</p> <p>Note: Although attestations during <code>GENESIS_EPOCH</code> do not count toward FFG finality, these initial attestations do give weight to the fork choice, are rewarded, and should be made.</p>"},{"location":"specs/phase0/validator/#attestation-data","title":"Attestation data","text":"<p>First, the validator should construct <code>attestation_data</code>, an <code>AttestationData</code> object based upon the state at the assigned slot.</p> <ul> <li>Let <code>head_block</code> be the result of running the fork choice during the assigned   slot.</li> <li>Let <code>head_state</code> be the state of <code>head_block</code> processed through any empty   slots up to the assigned slot using <code>process_slots(state, slot)</code>.</li> </ul>"},{"location":"specs/phase0/validator/#general","title":"General","text":"<ul> <li>Set <code>attestation_data.slot = slot</code> where <code>slot</code> is the assigned slot.</li> <li>Set <code>attestation_data.index = index</code> where <code>index</code> is the index associated   with the validator's committee.</li> </ul>"},{"location":"specs/phase0/validator/#lmd-ghost-vote","title":"LMD GHOST vote","text":"<p>Set <code>attestation_data.beacon_block_root = hash_tree_root(head_block)</code>.</p>"},{"location":"specs/phase0/validator/#ffg-vote","title":"FFG vote","text":"<ul> <li>Set <code>attestation_data.source = head_state.current_justified_checkpoint</code>.</li> <li>Set   <code>attestation_data.target = Checkpoint(epoch=get_current_epoch(head_state), root=epoch_boundary_block_root)</code>   where <code>epoch_boundary_block_root</code> is the root of block at the most recent   epoch boundary.</li> </ul> <p>Note: <code>epoch_boundary_block_root</code> can be looked up in the state using:</p> <ul> <li>Let <code>start_slot = compute_start_slot_at_epoch(get_current_epoch(head_state))</code>.</li> <li>Let   <code>epoch_boundary_block_root = hash_tree_root(head_block) if start_slot == head_state.slot else get_block_root(state, get_current_epoch(head_state))</code>.</li> </ul>"},{"location":"specs/phase0/validator/#construct-attestation","title":"Construct attestation","text":"<p>Next, the validator creates <code>attestation</code>, an <code>Attestation</code> object.</p>"},{"location":"specs/phase0/validator/#data","title":"Data","text":"<p>Set <code>attestation.data = attestation_data</code> where <code>attestation_data</code> is the <code>AttestationData</code> object defined in the previous section, attestation data.</p>"},{"location":"specs/phase0/validator/#aggregation-bits","title":"Aggregation bits","text":"<ul> <li>Let <code>attestation.aggregation_bits</code> be a   <code>Bitlist[MAX_VALIDATORS_PER_COMMITTEE]</code> of length <code>len(committee)</code>, where the   bit of the index of the validator in the <code>committee</code> is set to <code>0b1</code>.</li> </ul> <p>Note: Calling <code>get_attesting_indices(state, attestation)</code> should return a list of length equal to 1, containing <code>validator_index</code>.</p>"},{"location":"specs/phase0/validator/#aggregate-signature","title":"Aggregate signature","text":"<p>Set <code>attestation.signature = attestation_signature</code> where <code>attestation_signature</code> is obtained from:</p> <pre><code>def get_attestation_signature(\n    state: BeaconState, attestation_data: AttestationData, privkey: int\n) -&gt; BLSSignature:\n    domain = get_domain(state, DOMAIN_BEACON_ATTESTER, attestation_data.target.epoch)\n    signing_root = compute_signing_root(attestation_data, domain)\n    return bls.Sign(privkey, signing_root)\n</code></pre>"},{"location":"specs/phase0/validator/#broadcast-attestation","title":"Broadcast attestation","text":"<p>Finally, the validator broadcasts <code>attestation</code> to the associated attestation subnet, the <code>beacon_attestation_{subnet_id}</code> pubsub topic.</p> <p>The <code>subnet_id</code> for the <code>attestation</code> is calculated with:</p> <ul> <li>Let   <code>committees_per_slot = get_committee_count_per_slot(state, attestation.data.target.epoch)</code>.</li> <li>Let   <code>subnet_id = compute_subnet_for_attestation(committees_per_slot, attestation.data.slot, attestation.data.index)</code>.</li> </ul> <pre><code>def compute_subnet_for_attestation(\n    committees_per_slot: uint64, slot: Slot, committee_index: CommitteeIndex\n) -&gt; SubnetID:\n    \"\"\"\n    Compute the correct subnet for an attestation for Phase 0.\n    Note, this mimics expected future behavior where attestations will be mapped to their shard subnet.\n    \"\"\"\n    slots_since_epoch_start = uint64(slot % SLOTS_PER_EPOCH)\n    committees_since_epoch_start = committees_per_slot * slots_since_epoch_start\n\n    return SubnetID((committees_since_epoch_start + committee_index) % ATTESTATION_SUBNET_COUNT)\n</code></pre>"},{"location":"specs/phase0/validator/#attestation-aggregation","title":"Attestation aggregation","text":"<p>Some validators are selected to locally aggregate attestations with a similar <code>attestation_data</code> to their constructed <code>attestation</code> for the assigned <code>slot</code>.</p>"},{"location":"specs/phase0/validator/#aggregation-selection","title":"Aggregation selection","text":"<p>A validator is selected to aggregate based upon the return value of <code>is_aggregator()</code>.</p> <pre><code>def get_slot_signature(state: BeaconState, slot: Slot, privkey: int) -&gt; BLSSignature:\n    domain = get_domain(state, DOMAIN_SELECTION_PROOF, compute_epoch_at_slot(slot))\n    signing_root = compute_signing_root(slot, domain)\n    return bls.Sign(privkey, signing_root)\n</code></pre> <pre><code>def is_aggregator(\n    state: BeaconState, slot: Slot, index: CommitteeIndex, slot_signature: BLSSignature\n) -&gt; bool:\n    committee = get_beacon_committee(state, slot, index)\n    modulo = max(1, len(committee) // TARGET_AGGREGATORS_PER_COMMITTEE)\n    return bytes_to_uint64(hash(slot_signature)[0:8]) % modulo == 0\n</code></pre>"},{"location":"specs/phase0/validator/#construct-aggregate","title":"Construct aggregate","text":"<p>If the validator is selected to aggregate (<code>is_aggregator()</code>), they construct an aggregate attestation via the following.</p> <p>Collect <code>attestations</code> seen via gossip during the <code>slot</code> that have an equivalent <code>attestation_data</code> to that constructed by the validator. If <code>len(attestations) &gt; 0</code>, create an <code>aggregate_attestation: Attestation</code> with the following fields.</p>"},{"location":"specs/phase0/validator/#data_1","title":"Data","text":"<p>Set <code>aggregate_attestation.data = attestation_data</code> where <code>attestation_data</code> is the <code>AttestationData</code> object that is the same for each individual attestation being aggregated.</p>"},{"location":"specs/phase0/validator/#aggregation-bits_1","title":"Aggregation bits","text":"<p>Let <code>aggregate_attestation.aggregation_bits</code> be a <code>Bitlist[MAX_VALIDATORS_PER_COMMITTEE]</code> of length <code>len(committee)</code>, where each bit set from each individual attestation is set to <code>0b1</code>.</p>"},{"location":"specs/phase0/validator/#aggregate-signature_1","title":"Aggregate signature","text":"<p>Set <code>aggregate_attestation.signature = aggregate_signature</code> where <code>aggregate_signature</code> is obtained from:</p> <pre><code>def get_aggregate_signature(attestations: Sequence[Attestation]) -&gt; BLSSignature:\n    signatures = [attestation.signature for attestation in attestations]\n    return bls.Aggregate(signatures)\n</code></pre>"},{"location":"specs/phase0/validator/#broadcast-aggregate","title":"Broadcast aggregate","text":"<p>If the validator is selected to aggregate (<code>is_aggregator</code>), then they broadcast their best aggregate as a <code>SignedAggregateAndProof</code> to the global aggregate channel (<code>beacon_aggregate_and_proof</code>) <code>get_slot_component_duration_ms(AGGREGATE_DUE_BPS)</code> milliseconds into the slot.</p> <p>Selection proofs are provided in <code>AggregateAndProof</code> to prove to the gossip channel that the validator has been selected as an aggregator.</p> <p><code>AggregateAndProof</code> messages are signed by the aggregator and broadcast inside of <code>SignedAggregateAndProof</code> objects to prevent a class of DoS attacks and message forgeries.</p> <p>First, <code>aggregate_and_proof = get_aggregate_and_proof(state, validator_index, aggregate_attestation, privkey)</code> is constructed.</p> <pre><code>def get_aggregate_and_proof(\n    state: BeaconState, aggregator_index: ValidatorIndex, aggregate: Attestation, privkey: int\n) -&gt; AggregateAndProof:\n    return AggregateAndProof(\n        aggregator_index=aggregator_index,\n        aggregate=aggregate,\n        selection_proof=get_slot_signature(state, aggregate.data.slot, privkey),\n    )\n</code></pre> <p>Then <code>signed_aggregate_and_proof = SignedAggregateAndProof(message=aggregate_and_proof, signature=signature)</code> is constructed and broadcast. Where <code>signature</code> is obtained from:</p> <pre><code>def get_aggregate_and_proof_signature(\n    state: BeaconState, aggregate_and_proof: AggregateAndProof, privkey: int\n) -&gt; BLSSignature:\n    aggregate = aggregate_and_proof.aggregate\n    domain = get_domain(\n        state, DOMAIN_AGGREGATE_AND_PROOF, compute_epoch_at_slot(aggregate.data.slot)\n    )\n    signing_root = compute_signing_root(aggregate_and_proof, domain)\n    return bls.Sign(privkey, signing_root)\n</code></pre>"},{"location":"specs/phase0/validator/#how-to-avoid-slashing","title":"How to avoid slashing","text":"<p>\"Slashing\" is the burning of some amount of validator funds and immediate ejection from the active validator set. In Phase 0, there are two ways in which funds can be slashed: proposer slashing and attester slashing. Although being slashed has serious repercussions, it is simple enough to avoid being slashed all together by remaining consistent with respect to the messages a validator has previously signed.</p> <p>Note: Signed data must be within a sequential <code>Fork</code> context to conflict. Messages cannot be slashed across diverging forks. If the previous fork version is 1 and the chain splits into fork 2 and 102, messages from 1 can be slashable against messages in forks 1, 2, and 102. Messages in 2 cannot be slashable against messages in 102, and vice versa.</p>"},{"location":"specs/phase0/validator/#proposer-slashing","title":"Proposer slashing","text":"<p>To avoid \"proposer slashings\", a validator must not sign two conflicting <code>BeaconBlock</code> where conflicting is defined as two distinct blocks within the same slot.</p> <p>In Phase 0, as long as the validator does not sign two different beacon blocks for the same slot, the validator is safe against proposer slashings.</p> <p>Specifically, when signing a <code>BeaconBlock</code>, a validator should perform the following steps in the following order:</p> <ol> <li>Save a record to hard disk that a beacon block has been signed for the    <code>slot=block.slot</code>.</li> <li>Generate and broadcast the block.</li> </ol> <p>If the software crashes at some point within this routine, then when the validator comes back online, the hard disk has the record of the potentially signed/broadcast block and can effectively avoid slashing.</p>"},{"location":"specs/phase0/validator/#attester-slashing","title":"Attester slashing","text":"<p>To avoid \"attester slashings\", a validator must not sign two conflicting <code>AttestationData</code> objects, i.e. two attestations that satisfy <code>is_slashable_attestation_data</code>.</p> <p>Specifically, when signing an <code>Attestation</code>, a validator should perform the following steps in the following order:</p> <ol> <li>Save a record to hard disk that an attestation has been signed for source    (i.e. <code>attestation_data.source.epoch</code>) and target (i.e.    <code>attestation_data.target.epoch</code>).</li> <li>Generate and broadcast attestation.</li> </ol> <p>If the software crashes at some point within this routine, then when the validator comes back online, the hard disk has the record of the potentially signed/broadcast attestation and can effectively avoid slashing.</p>"},{"location":"specs/phase0/validator/#protection-best-practices","title":"Protection best practices","text":"<p>A validator client should be considered standalone and should consider the beacon node as untrusted. This means that the validator client should protect:</p> <ol> <li>Private keys -- private keys should be protected from being exported    accidentally or by an attacker.</li> <li>Slashing -- before a validator client signs a message it should validate the    data, check it against a local slashing database (do not sign a slashable    attestation or block) and update its internal slashing database with the    newly signed object.</li> <li>Recovered validator -- Recovering a validator from a private key will result    in an empty local slashing db. Best practice is to import (from a trusted    source) that validator's attestation history. See    EIP 3076 for a standard    slashing interchange format.</li> <li>Far future signing requests -- A validator client can be requested to sign a    far into the future attestation, resulting in a valid non-slashable request.    If the validator client signs this message, it will result in it blocking    itself from attesting any other attestation until the beacon-chain reaches    that far into the future epoch. This will result in an inactivity penalty and    potential ejection due to low balance. A validator client should prevent    itself from signing such requests by: a) keeping a local time clock if    possible and following best practices to stop time server attacks and b)    refusing to sign, by default, any message that has a large (&gt;6h) gap from the    current slashing protection database indicated a time \"jump\" or a long    offline event. The administrator can manually override this protection to    restart the validator after a genuine long offline event.</li> </ol>"},{"location":"specs/phase0/weak-subjectivity/","title":"Phase 0 -- Weak Subjectivity Guide","text":"<ul> <li>Introduction</li> <li>Prerequisites</li> <li>Custom Types</li> <li>Constants</li> <li>Configuration</li> <li>Weak Subjectivity Checkpoint</li> <li>Weak Subjectivity Period</li> <li>Calculating the Weak Subjectivity Period<ul> <li><code>compute_weak_subjectivity_period</code></li> </ul> </li> <li>Weak Subjectivity Sync</li> <li>Weak Subjectivity Sync Procedure</li> <li>Checking for Stale Weak Subjectivity Checkpoint<ul> <li><code>is_within_weak_subjectivity_period</code></li> </ul> </li> <li>Distributing Weak Subjectivity Checkpoints</li> </ul>"},{"location":"specs/phase0/weak-subjectivity/#introduction","title":"Introduction","text":"<p>This document is a guide for implementing the Weak Subjectivity protections in Phase 0. This document is still a work-in-progress, and is subject to large changes. For more information about weak subjectivity and why it is required, please refer to:</p> <ul> <li>Weak Subjectivity in Ethereum Proof-of-Stake</li> <li>Proof of Stake: How I Learned to Love Weak Subjectivity</li> </ul>"},{"location":"specs/phase0/weak-subjectivity/#prerequisites","title":"Prerequisites","text":"<p>This document uses data structures, constants, functions, and terminology from Phase 0 -- The Beacon Chain and Phase 0 -- Beacon Chain Fork Choice.</p>"},{"location":"specs/phase0/weak-subjectivity/#custom-types","title":"Custom Types","text":"Name SSZ Equivalent Description <code>Ether</code> <code>uint64</code> an amount in Ether"},{"location":"specs/phase0/weak-subjectivity/#constants","title":"Constants","text":"Name Value <code>ETH_TO_GWEI</code> <code>uint64(10**9)</code>"},{"location":"specs/phase0/weak-subjectivity/#configuration","title":"Configuration","text":"Name Value <code>SAFETY_DECAY</code> <code>uint64(10)</code>"},{"location":"specs/phase0/weak-subjectivity/#weak-subjectivity-checkpoint","title":"Weak Subjectivity Checkpoint","text":"<p>Any <code>Checkpoint</code> object can be used as a Weak Subjectivity Checkpoint. These Weak Subjectivity Checkpoints are distributed by providers, downloaded by users and/or distributed as a part of clients, and used as input while syncing a client.</p>"},{"location":"specs/phase0/weak-subjectivity/#weak-subjectivity-period","title":"Weak Subjectivity Period","text":"<p>The Weak Subjectivity Period is the number of recent epochs within which there must be a Weak Subjectivity Checkpoint to ensure that an attacker who takes control of the validator set at the beginning of the period is slashed at least a minimum threshold in the event that a conflicting <code>Checkpoint</code> is finalized.</p> <p><code>SAFETY_DECAY</code> is defined as the maximum percentage tolerable loss in the one-third safety margin of FFG finality. Thus, any attack exploiting the Weak Subjectivity Period has a safety margin of at least <code>1/3 - SAFETY_DECAY/100</code>.</p>"},{"location":"specs/phase0/weak-subjectivity/#calculating-the-weak-subjectivity-period","title":"Calculating the Weak Subjectivity Period","text":"<p>A detailed analysis of the calculation of the weak subjectivity period is made in this report.</p> <p>Note: The expressions in the report use fractions, whereas the consensus-specs only use <code>uint64</code> arithmetic. The expressions have been simplified to avoid computing fractions, and more details can be found here.</p> <p>Note: The calculations here use <code>Ether</code> instead of <code>Gwei</code>, because the large magnitude of balances in <code>Gwei</code> can cause an overflow while computing using <code>uint64</code> arithmetic operations. Using <code>Ether</code> reduces the magnitude of the multiplicative factors by an order of <code>ETH_TO_GWEI</code> (<code>= 10**9</code>) and avoid the scope for overflows in <code>uint64</code>.</p>"},{"location":"specs/phase0/weak-subjectivity/#compute_weak_subjectivity_period","title":"<code>compute_weak_subjectivity_period</code>","text":"<pre><code>def compute_weak_subjectivity_period(state: BeaconState) -&gt; uint64:\n    \"\"\"\n    Returns the weak subjectivity period for the current ``state``.\n    This computation takes into account the effect of:\n        - validator set churn (bounded by ``get_validator_churn_limit()`` per epoch), and\n        - validator balance top-ups (bounded by ``MAX_DEPOSITS * SLOTS_PER_EPOCH`` per epoch).\n    A detailed calculation can be found at:\n    https://github.com/runtimeverification/beacon-chain-verification/blob/master/weak-subjectivity/weak-subjectivity-analysis.pdf\n    \"\"\"\n    ws_period = MIN_VALIDATOR_WITHDRAWABILITY_DELAY\n    N = len(get_active_validator_indices(state, get_current_epoch(state)))\n    t = get_total_active_balance(state) // N // ETH_TO_GWEI\n    T = MAX_EFFECTIVE_BALANCE // ETH_TO_GWEI\n    delta = get_validator_churn_limit(state)\n    Delta = MAX_DEPOSITS * SLOTS_PER_EPOCH\n    D = SAFETY_DECAY\n\n    if T * (200 + 3 * D) &lt; t * (200 + 12 * D):\n        epochs_for_validator_set_churn = (\n            N * (t * (200 + 12 * D) - T * (200 + 3 * D)) // (600 * delta * (2 * t + T))\n        )\n        epochs_for_balance_top_ups = N * (200 + 3 * D) // (600 * Delta)\n        ws_period += max(epochs_for_validator_set_churn, epochs_for_balance_top_ups)\n    else:\n        ws_period += 3 * N * D * t // (200 * Delta * (T - t))\n\n    return ws_period\n</code></pre> <p>A brief reference for what these values look like in practice (reference script):</p> Safety Decay Avg. Val. Balance (ETH) Val. Count Weak Sub. Period (Epochs) 10 28 32768 504 10 28 65536 752 10 28 131072 1248 10 28 262144 2241 10 28 524288 2241 10 28 1048576 2241 10 32 32768 665 10 32 65536 1075 10 32 131072 1894 10 32 262144 3532 10 32 524288 3532 10 32 1048576 3532"},{"location":"specs/phase0/weak-subjectivity/#weak-subjectivity-sync","title":"Weak Subjectivity Sync","text":"<p>Clients should allow users to input a Weak Subjectivity Checkpoint at startup, and guarantee that any successful sync leads to the given Weak Subjectivity Checkpoint along the canonical chain. If such a sync is not possible, the client should treat this as a critical and irrecoverable failure.</p>"},{"location":"specs/phase0/weak-subjectivity/#weak-subjectivity-sync-procedure","title":"Weak Subjectivity Sync Procedure","text":"<ol> <li>Input a Weak Subjectivity Checkpoint as a CLI parameter in    <code>block_root:epoch_number</code> format, where <code>block_root</code> (an \"0x\" prefixed    32-byte hex string) and <code>epoch_number</code> (an integer) represent a valid    <code>Checkpoint</code>. Example of the format:</li> </ol> <pre><code>0x8584188b86a9296932785cc2827b925f9deebacce6d72ad8d53171fa046b43d9:9544\n</code></pre> <ol> <li>Check the weak subjectivity requirements:</li> </ol> <ul> <li>IF <code>epoch_number &gt; store.finalized_checkpoint.epoch</code>, then ASSERT      during block sync that block with root <code>block_root</code> is in the sync path at      epoch <code>epoch_number</code>. Emit descriptive critical error if this assert fails,      then exit client process.</li> <li>IF <code>epoch_number &lt;= store.finalized_checkpoint.epoch</code>, then ASSERT that      the block in the canonical chain at epoch <code>epoch_number</code> has root      <code>block_root</code>. Emit descriptive critical error if this assert fails, then      exit client process.</li> </ul>"},{"location":"specs/phase0/weak-subjectivity/#checking-for-stale-weak-subjectivity-checkpoint","title":"Checking for Stale Weak Subjectivity Checkpoint","text":"<p>Clients may choose to validate that the input Weak Subjectivity Checkpoint is not stale at the time of startup. To support this mechanism, the client needs to take the state at the Weak Subjectivity Checkpoint as a CLI parameter input (or fetch the state associated with the input Weak Subjectivity Checkpoint from some source). The check can be implemented in the following way:</p>"},{"location":"specs/phase0/weak-subjectivity/#is_within_weak_subjectivity_period","title":"<code>is_within_weak_subjectivity_period</code>","text":"<pre><code>def is_within_weak_subjectivity_period(\n    store: Store, ws_state: BeaconState, ws_checkpoint: Checkpoint\n) -&gt; bool:\n    # Clients may choose to validate the input state against the input Weak Subjectivity Checkpoint\n    assert ws_state.latest_block_header.state_root == ws_checkpoint.root\n    assert compute_epoch_at_slot(ws_state.slot) == ws_checkpoint.epoch\n\n    ws_period = compute_weak_subjectivity_period(ws_state)\n    ws_state_epoch = compute_epoch_at_slot(ws_state.slot)\n    current_epoch = compute_epoch_at_slot(get_current_slot(store))\n    return current_epoch &lt;= ws_state_epoch + ws_period\n</code></pre>"},{"location":"specs/phase0/weak-subjectivity/#distributing-weak-subjectivity-checkpoints","title":"Distributing Weak Subjectivity Checkpoints","text":"<p>This section will be updated soon.</p>"},{"location":"ssz/merkle-proofs/","title":"Merkle proof formats","text":"<ul> <li>Helper functions</li> <li>Generalized Merkle tree index</li> <li>SSZ object to index</li> <li>Helpers for generalized indices<ul> <li><code>get_generalized_index_length</code></li> <li><code>get_generalized_index_bit</code></li> <li><code>generalized_index_sibling</code></li> <li><code>generalized_index_child</code></li> <li><code>generalized_index_parent</code></li> </ul> </li> <li>Merkle multiproofs</li> </ul>"},{"location":"ssz/merkle-proofs/#helper-functions","title":"Helper functions","text":"<pre><code>def get_power_of_two_ceil(x: int) -&gt; int:\n    \"\"\"\n    Get the power of 2 for given input, or the closest higher power of 2 if the input is not a power of 2.\n    Commonly used for \"how many nodes do I need for a bottom tree layer fitting x elements?\"\n    Example: 0-&gt;1, 1-&gt;1, 2-&gt;2, 3-&gt;4, 4-&gt;4, 5-&gt;8, 6-&gt;8, 7-&gt;8, 8-&gt;8, 9-&gt;16.\n    \"\"\"\n    if x &lt;= 1:\n        return 1\n    elif x == 2:\n        return 2\n    else:\n        return 2 * get_power_of_two_ceil((x + 1) // 2)\n</code></pre>"},{"location":"ssz/merkle-proofs/#generalized-merkle-tree-index","title":"Generalized Merkle tree index","text":"<p>In a binary Merkle tree, we define a \"generalized index\" of a node as <code>2**depth + index</code>. Visually, this looks as follows:</p> <pre><code>    1\n 2     3\n4 5   6 7\n   ...\n</code></pre> <p>Note that the generalized index has the convenient property that the two children of node <code>k</code> are <code>2k</code> and <code>2k+1</code>, and also that it equals the position of a node in the linear representation of the Merkle tree that's computed by this function:</p> <pre><code>def merkle_tree(leaves: Sequence[Bytes32]) -&gt; Sequence[Bytes32]:\n    \"\"\"\n    Return an array representing the tree nodes by generalized index:\n    [0, 1, 2, 3, 4, 5, 6, 7], where each layer is a power of 2. The 0 index is ignored. The 1 index is the root.\n    The result will be twice the size as the padded bottom layer for the input leaves.\n    \"\"\"\n    bottom_length = get_power_of_two_ceil(len(leaves))\n    o = [Bytes32()] * bottom_length + list(leaves) + [Bytes32()] * (bottom_length - len(leaves))\n    for i in range(bottom_length - 1, 0, -1):\n        o[i] = hash(o[i * 2] + o[i * 2 + 1])\n    return o\n</code></pre> <p>We define a custom type <code>GeneralizedIndex</code> as a Python integer type in this document. It can be represented as a Bitvector/Bitlist object as well.</p> <p>We will define Merkle proofs in terms of generalized indices.</p>"},{"location":"ssz/merkle-proofs/#ssz-object-to-index","title":"SSZ object to index","text":"<p>We can describe the hash tree of any SSZ object, rooted in <code>hash_tree_root(object)</code>, as a binary Merkle tree whose depth may vary. For example, an object <code>{x: bytes32, y: List[uint64]}</code> would look as follows:</p> <pre><code>     root\n    /    \\\n   x    y_root\n        /    \\\ny_data_root  len(y)\n    / \\\n   /\\ /\\\n  .......\n</code></pre> <p>We can now define a concept of a \"path\", a way of describing a function that takes as input an SSZ object and outputs some specific (possibly deeply nested) member. For example, <code>foo -&gt; foo.x</code> is a path, as are <code>foo -&gt; len(foo.y)</code> and <code>foo -&gt; foo.y[5].w</code>. We'll describe paths as lists, which can have two representations. In \"human-readable form\", they are <code>[\"x\"]</code>, <code>[\"y\", \"__len__\"]</code> and <code>[\"y\", 5, \"w\"]</code> respectively. In \"encoded form\", they are lists of <code>uint64</code> values, in these cases (assuming the fields of <code>foo</code> in order are <code>x</code> then <code>y</code>, and <code>w</code> is the first field of <code>y[i]</code>) <code>[0]</code>, <code>[1, 2**64-1]</code>, <code>[1, 5, 0]</code>. We define <code>SSZVariableName</code> as the member variable name string, i.e., a path is presented as a sequence of integers and <code>SSZVariableName</code>.</p> <pre><code>def item_length(typ: SSZType) -&gt; int:\n    \"\"\"\n    Return the number of bytes in a basic type, or 32 (a full hash) for compound types.\n    \"\"\"\n    if issubclass(typ, BasicValue):\n        return typ.byte_len\n    else:\n        return 32\n</code></pre> <pre><code>def get_elem_type(\n    typ: Union[BaseBytes, BaseList, Container], index_or_variable_name: Union[int, SSZVariableName]\n) -&gt; SSZType:\n    \"\"\"\n    Return the type of the element of an object of the given type with the given index\n    or member variable name (eg. `7` for `x[7]`, `\"foo\"` for `x.foo`)\n    \"\"\"\n    return typ.get_fields()[index_or_variable_name] if issubclass(typ, Container) else typ.elem_type\n</code></pre> <pre><code>def chunk_count(typ: SSZType) -&gt; int:\n    \"\"\"\n    Return the number of hashes needed to represent the top-level elements in the given type\n    (eg. `x.foo` or `x[7]` but not `x[7].bar` or `x.foo.baz`). In all cases except lists/vectors\n    of basic types, this is simply the number of top-level elements, as each element gets one\n    hash. For lists/vectors of basic types, it is often fewer because multiple basic elements\n    can be packed into one 32-byte chunk.\n    \"\"\"\n    # typ.length describes the limit for list types, or the length for vector types.\n    if issubclass(typ, BasicValue):\n        return 1\n    elif issubclass(typ, Bits):\n        return (typ.length + 255) // 256\n    elif issubclass(typ, Elements):\n        return (typ.length * item_length(typ.elem_type) + 31) // 32\n    elif issubclass(typ, Container):\n        return len(typ.get_fields())\n    else:\n        raise Exception(f\"Type not supported: {typ}\")\n</code></pre> <pre><code>def get_item_position(\n    typ: SSZType, index_or_variable_name: Union[int, SSZVariableName]\n) -&gt; Tuple[int, int, int]:\n    \"\"\"\n    Return three variables:\n        (i) the index of the chunk in which the given element of the item is represented;\n        (ii) the starting byte position within the chunk;\n        (iii) the ending byte position within the chunk.\n    For example: for a 6-item list of uint64 values, index=2 will return (0, 16, 24), index=5 will return (1, 8, 16)\n    \"\"\"\n    if issubclass(typ, Elements):\n        index = int(index_or_variable_name)\n        start = index * item_length(typ.elem_type)\n        return start // 32, start % 32, start % 32 + item_length(typ.elem_type)\n    elif issubclass(typ, Container):\n        variable_name = index_or_variable_name\n        return (\n            typ.get_field_names().index(variable_name),\n            0,\n            item_length(get_elem_type(typ, variable_name)),\n        )\n    else:\n        raise Exception(\"Only lists/vectors/containers supported\")\n</code></pre> <pre><code>def get_generalized_index(typ: SSZType, *path: PyUnion[int, SSZVariableName]) -&gt; GeneralizedIndex:\n    \"\"\"\n    Converts a path (eg. `[7, \"foo\", 3]` for `x[7].foo[3]`, `[12, \"bar\", \"__len__\"]` for\n    `len(x[12].bar)`) into the generalized index representing its position in the Merkle tree.\n    \"\"\"\n    root = GeneralizedIndex(1)\n    for p in path:\n        # If we descend to a basic type, the path cannot continue further\n        assert not issubclass(typ, BasicValue)\n        if p == \"__len__\":\n            assert issubclass(typ, (List, ByteList))\n            typ = uint64\n            root = GeneralizedIndex(root * 2 + 1)\n        else:\n            pos, _, _ = get_item_position(typ, p)\n            base_index = (\n                GeneralizedIndex(2) if issubclass(typ, (List, ByteList)) else GeneralizedIndex(1)\n            )\n            root = GeneralizedIndex(\n                root * base_index * get_power_of_two_ceil(chunk_count(typ)) + pos\n            )\n            typ = get_elem_type(typ, p)\n    return root\n</code></pre>"},{"location":"ssz/merkle-proofs/#helpers-for-generalized-indices","title":"Helpers for generalized indices","text":"<p>Usage note: functions outside this section should manipulate generalized indices using only functions inside this section. This is to make it easier for developers to implement generalized indices with underlying representations other than bigints.</p>"},{"location":"ssz/merkle-proofs/#get_generalized_index_length","title":"<code>get_generalized_index_length</code>","text":"<pre><code>def get_generalized_index_length(index: GeneralizedIndex) -&gt; int:\n    \"\"\"\n    Return the length of a path represented by a generalized index.\n    \"\"\"\n    return int(log2(index))\n</code></pre>"},{"location":"ssz/merkle-proofs/#get_generalized_index_bit","title":"<code>get_generalized_index_bit</code>","text":"<pre><code>def get_generalized_index_bit(index: GeneralizedIndex, position: int) -&gt; bool:\n    \"\"\"\n    Return the given bit of a generalized index.\n    \"\"\"\n    return (index &amp; (1 &lt;&lt; position)) &gt; 0\n</code></pre>"},{"location":"ssz/merkle-proofs/#generalized_index_sibling","title":"<code>generalized_index_sibling</code>","text":"<pre><code>def generalized_index_sibling(index: GeneralizedIndex) -&gt; GeneralizedIndex:\n    return GeneralizedIndex(index ^ 1)\n</code></pre>"},{"location":"ssz/merkle-proofs/#generalized_index_child","title":"<code>generalized_index_child</code>","text":"<pre><code>def generalized_index_child(index: GeneralizedIndex, right_side: bool) -&gt; GeneralizedIndex:\n    return GeneralizedIndex(index * 2 + right_side)\n</code></pre>"},{"location":"ssz/merkle-proofs/#generalized_index_parent","title":"<code>generalized_index_parent</code>","text":"<pre><code>def generalized_index_parent(index: GeneralizedIndex) -&gt; GeneralizedIndex:\n    return GeneralizedIndex(index // 2)\n</code></pre>"},{"location":"ssz/merkle-proofs/#merkle-multiproofs","title":"Merkle multiproofs","text":"<p>We define a Merkle multiproof as a minimal subset of nodes in a Merkle tree needed to fully authenticate that a set of nodes actually are part of a Merkle tree with some specified root, at a particular set of generalized indices. For example, here is the Merkle multiproof for positions 0, 1, 6 in an 8-node Merkle tree (i.e. generalized indices 8, 9, 14):</p> <pre><code>       .\n   .       .\n .   *   *   .\nx x . . . . x *\n</code></pre> <p>. are unused nodes, * are used nodes, x are the values we are trying to prove. Notice how despite being a multiproof for 3 values, it requires only 3 auxiliary nodes, the same amount required to prove a single value. Normally the efficiency gains are not quite that extreme, but the savings relative to individual Merkle proofs are still significant. As a rule of thumb, a multiproof for k nodes at the same level of an n-node tree has size <code>k * (n/k + log(n/k))</code>.</p> <p>First, we provide a method for computing the generalized indices of the auxiliary tree nodes that a proof of a given set of generalized indices will require:</p> <pre><code>def get_branch_indices(tree_index: GeneralizedIndex) -&gt; Sequence[GeneralizedIndex]:\n    \"\"\"\n    Get the generalized indices of the sister chunks along the path from the chunk with the\n    given tree index to the root.\n    \"\"\"\n    o = [generalized_index_sibling(tree_index)]\n    while o[-1] &gt; 1:\n        o.append(generalized_index_sibling(generalized_index_parent(o[-1])))\n    return o[:-1]\n</code></pre> <pre><code>def get_path_indices(tree_index: GeneralizedIndex) -&gt; Sequence[GeneralizedIndex]:\n    \"\"\"\n    Get the generalized indices of the chunks along the path from the chunk with the\n    given tree index to the root.\n    \"\"\"\n    o = [tree_index]\n    while o[-1] &gt; 1:\n        o.append(generalized_index_parent(o[-1]))\n    return o[:-1]\n</code></pre> <pre><code>def get_helper_indices(indices: Sequence[GeneralizedIndex]) -&gt; Sequence[GeneralizedIndex]:\n    \"\"\"\n    Get the generalized indices of all \"extra\" chunks in the tree needed to prove the chunks with the given\n    generalized indices. Note that the decreasing order is chosen deliberately to ensure equivalence to the\n    order of hashes in a regular single-item Merkle proof in the single-item case.\n    \"\"\"\n    all_helper_indices: Set[GeneralizedIndex] = set()\n    all_path_indices: Set[GeneralizedIndex] = set()\n    for index in indices:\n        all_helper_indices = all_helper_indices.union(set(get_branch_indices(index)))\n        all_path_indices = all_path_indices.union(set(get_path_indices(index)))\n\n    return sorted(all_helper_indices.difference(all_path_indices), reverse=True)\n</code></pre> <p>Now we provide the Merkle proof verification functions. First, for single item proofs:</p> <pre><code>def calculate_merkle_root(leaf: Bytes32, proof: Sequence[Bytes32], index: GeneralizedIndex) -&gt; Root:\n    assert len(proof) == get_generalized_index_length(index)\n    for i, h in enumerate(proof):\n        if get_generalized_index_bit(index, i):\n            leaf = hash(h + leaf)\n        else:\n            leaf = hash(leaf + h)\n    return leaf\n</code></pre> <pre><code>def verify_merkle_proof(\n    leaf: Bytes32, proof: Sequence[Bytes32], index: GeneralizedIndex, root: Root\n) -&gt; bool:\n    return calculate_merkle_root(leaf, proof, index) == root\n</code></pre> <p>Now for multi-item proofs:</p> <pre><code>def calculate_multi_merkle_root(\n    leaves: Sequence[Bytes32], proof: Sequence[Bytes32], indices: Sequence[GeneralizedIndex]\n) -&gt; Root:\n    assert len(leaves) == len(indices)\n    helper_indices = get_helper_indices(indices)\n    assert len(proof) == len(helper_indices)\n    objects = {\n        **{index: node for index, node in zip(indices, leaves)},\n        **{index: node for index, node in zip(helper_indices, proof)},\n    }\n    keys = sorted(objects.keys(), reverse=True)\n    pos = 0\n    while pos &lt; len(keys):\n        k = keys[pos]\n        if k in objects and k ^ 1 in objects and k // 2 not in objects:\n            objects[GeneralizedIndex(k // 2)] = hash(\n                objects[GeneralizedIndex((k | 1) ^ 1)] + objects[GeneralizedIndex(k | 1)]\n            )\n            keys.append(GeneralizedIndex(k // 2))\n        pos += 1\n    return objects[GeneralizedIndex(1)]\n</code></pre> <pre><code>def verify_merkle_multiproof(\n    leaves: Sequence[Bytes32],\n    proof: Sequence[Bytes32],\n    indices: Sequence[GeneralizedIndex],\n    root: Root,\n) -&gt; bool:\n    return calculate_multi_merkle_root(leaves, proof, indices) == root\n</code></pre> <p>Note that the single-item proof is a special case of a multi-item proof; a valid single-item proof verifies correctly when put into the multi-item verification function (making the natural trivial changes to input arguments, <code>index -&gt; [index]</code> and <code>leaf -&gt; [leaf]</code>). Note also that <code>calculate_merkle_root</code> and <code>calculate_multi_merkle_root</code> can be used independently to compute the new Merkle root of a proof with leaves updated.</p>"},{"location":"ssz/simple-serialize/","title":"SimpleSerialize (SSZ)","text":"<ul> <li>Constants</li> <li>Typing</li> <li>Basic types</li> <li>Composite types</li> <li>Variable-size and fixed-size</li> <li>Byte</li> <li>Aliases</li> <li>Default values<ul> <li><code>is_zero</code></li> </ul> </li> <li>Illegal types</li> <li>Serialization</li> <li><code>uintN</code></li> <li><code>boolean</code></li> <li><code>Bitvector[N]</code></li> <li><code>Bitlist[N]</code>, <code>ProgressiveBitlist</code></li> <li>Vectors, containers, progressive containers, lists, progressive lists</li> <li>Union</li> <li>Deserialization</li> <li>Merkleization</li> <li>Summaries and expansions</li> <li>Implementations</li> <li>JSON mapping</li> </ul>"},{"location":"ssz/simple-serialize/#constants","title":"Constants","text":"Name Value Description <code>BYTES_PER_CHUNK</code> <code>32</code> Number of bytes per chunk. <code>BYTES_PER_LENGTH_OFFSET</code> <code>4</code> Number of bytes per serialized length offset. <code>BITS_PER_BYTE</code> <code>8</code> Number of bits per byte."},{"location":"ssz/simple-serialize/#typing","title":"Typing","text":""},{"location":"ssz/simple-serialize/#basic-types","title":"Basic types","text":"<ul> <li><code>uintN</code>: <code>N</code>-bit unsigned integer (where <code>N in [8, 16, 32, 64, 128, 256]</code>)</li> <li><code>byte</code>: 8-bit opaque data container, equivalent in serialization and hashing   to <code>uint8</code></li> <li><code>boolean</code>: <code>True</code> or <code>False</code></li> </ul>"},{"location":"ssz/simple-serialize/#composite-types","title":"Composite types","text":"<ul> <li>container: ordered heterogeneous collection of values</li> <li>python dataclass notation with key-type pairs, e.g.   <pre><code>class ContainerExample(Container):\n    foo: uint64\n    bar: boolean\n</code></pre></li> <li>progressive container [EIP-7495, currently unused]: ordered   heterogeneous collection of values with stable Merkleization</li> <li>python dataclass notation with key-type pairs, e.g.   <pre><code>class Square(ProgressiveContainer(active_fields=[1, 0, 1])):\n    side: uint16  # Merkleized at field index #0 (location of first 1 in `active_fields`)\n    color: uint8  # Merkleized at field index #2 (location of second 1 in `active_fields`)\n\n\nclass Circle(ProgressiveContainer(active_fields=[0, 1, 1])):\n    radius: uint16  # Merkleized at field index #1 (location of first 1 in `active_fields`)\n    color: uint8  # Merkleized at field index #2 (location of second 1 in `active_fields`)\n</code></pre></li> <li>vector: ordered fixed-length homogeneous collection, with <code>N</code> values</li> <li>notation <code>Vector[type, N]</code>, e.g. <code>Vector[uint64, N]</code></li> <li>list: ordered variable-length homogeneous collection, limited to <code>N</code>   values</li> <li>notation <code>List[type, N]</code>, e.g. <code>List[uint64, N]</code></li> <li>progressive list [EIP-7916, currently unused]: ordered variable-length   homogeneous collection, without limit</li> <li>notation <code>ProgressiveList[type]</code>, e.g. <code>ProgressiveList[uint64]</code></li> <li>bitvector: ordered fixed-length collection of <code>boolean</code> values, with <code>N</code>   bits</li> <li>notation <code>Bitvector[N]</code></li> <li>bitlist: ordered variable-length collection of <code>boolean</code> values, limited   to <code>N</code> bits</li> <li>notation <code>Bitlist[N]</code></li> <li>progressive bitlist [EIP-7916, currently unused]: ordered   variable-length collection of <code>boolean</code> values, without limit</li> <li>notation <code>ProgressiveBitlist</code></li> <li>union: union type containing one of the given subtypes</li> <li>notation <code>Union[type_0, type_1, ...]</code>, e.g. <code>union[None, uint64, uint32]</code></li> </ul> <p>Note: Both <code>Vector[boolean, N]</code> and <code>Bitvector[N]</code> are valid, yet distinct due to their different serialization requirements. Similarly, both <code>List[boolean, N]</code> and <code>Bitlist[N]</code> are valid, yet distinct. Generally <code>Bitvector[N]</code>/<code>Bitlist[N]</code> are preferred because of their serialization efficiencies.</p>"},{"location":"ssz/simple-serialize/#variable-size-and-fixed-size","title":"Variable-size and fixed-size","text":"<p>We recursively define \"variable-size\" types to be lists, progressive lists, unions, bitlists, progressive bitlists, and all composite types that contain a variable-size type. All other types are said to be \"fixed-size\".</p>"},{"location":"ssz/simple-serialize/#byte","title":"Byte","text":"<p>Although the SSZ serialization of <code>byte</code> is equivalent to that of <code>uint8</code>, the former is used for opaque data while the latter is intended as a number.</p>"},{"location":"ssz/simple-serialize/#aliases","title":"Aliases","text":"<p>For convenience we alias:</p> <ul> <li><code>bit</code> to <code>boolean</code></li> <li><code>BytesN</code> and <code>ByteVector[N]</code> to <code>Vector[byte, N]</code> (this is not a basic type)</li> <li><code>ByteList[N]</code> to <code>List[byte, N]</code></li> <li><code>ProgressiveByteList</code> to <code>ProgressiveList[byte]</code></li> </ul> <p>Aliases are semantically equivalent to their underlying type and therefore share canonical representations both in SSZ and in related formats.</p>"},{"location":"ssz/simple-serialize/#default-values","title":"Default values","text":"<p>Assuming a helper function <code>default(type)</code> which returns the default value for <code>type</code>, we can recursively define the default value for all types.</p> Type Default Value <code>uintN</code> <code>0</code> <code>boolean</code> <code>False</code> <code>Container</code> <code>[default(type) for type in container]</code> <code>ProgressiveContainer(active_fields)</code> <code>[default(type) for type in progressive_container]</code> <code>Vector[type, N]</code> <code>[default(type)] * N</code> <code>Bitvector[N]</code> <code>[False] * N</code> <code>List[type, N]</code> <code>[]</code> <code>ProgressiveList[type]</code> <code>[]</code> <code>Bitlist[N]</code> <code>[]</code> <code>ProgressiveBitlist</code> <code>[]</code> <code>Union[type_0, type_1, ...]</code> <code>default(type_0)</code>"},{"location":"ssz/simple-serialize/#is_zero","title":"<code>is_zero</code>","text":"<p>An SSZ object is called zeroed (and thus, <code>is_zero(object)</code> returns true) if it is equal to the default value for that type.</p>"},{"location":"ssz/simple-serialize/#illegal-types","title":"Illegal types","text":"<ul> <li>Empty vector types (<code>Vector[type, 0]</code>, <code>Bitvector[0]</code>) are illegal.</li> <li>Containers with no fields are illegal.</li> <li><code>ProgressiveContainer</code> with no fields are illegal.</li> <li><code>ProgressiveContainer</code> with an <code>active_fields</code> configuration of more than 256   entries are illegal.</li> <li><code>ProgressiveContainer</code> with an <code>active_fields</code> configuration ending in <code>0</code> are   illegal.</li> <li><code>ProgressiveContainer</code> with an <code>active_fields</code> configuration with a different   count of <code>1</code> than fields are illegal.</li> <li>The <code>None</code> type option in a <code>Union</code> type is only legal as the first option   (i.e. with index zero).</li> </ul>"},{"location":"ssz/simple-serialize/#serialization","title":"Serialization","text":"<p>We recursively define the <code>serialize</code> function which consumes an object <code>value</code> (of the type specified) and returns a bytestring of type <code>bytes</code>.</p> <p>Note: In the function definitions below (<code>serialize</code>, <code>hash_tree_root</code>, <code>is_variable_size</code>, etc.) objects implicitly carry their type.</p>"},{"location":"ssz/simple-serialize/#uintn","title":"<code>uintN</code>","text":"<pre><code>assert N in [8, 16, 32, 64, 128, 256]\nreturn value.to_bytes(N // BITS_PER_BYTE, \"little\")\n</code></pre>"},{"location":"ssz/simple-serialize/#boolean","title":"<code>boolean</code>","text":"<pre><code>assert value in (True, False)\nreturn b\"\\x01\" if value is True else b\"\\x00\"\n</code></pre>"},{"location":"ssz/simple-serialize/#bitvectorn","title":"<code>Bitvector[N]</code>","text":"<pre><code>array = [0] * ((N + 7) // 8)\nfor i in range(N):\n    array[i // 8] |= value[i] &lt;&lt; (i % 8)\nreturn bytes(array)\n</code></pre>"},{"location":"ssz/simple-serialize/#bitlistn-progressivebitlist","title":"<code>Bitlist[N]</code>, <code>ProgressiveBitlist</code>","text":"<p>Note that from the offset coding, the length (in bytes) of the bitlist is known. An additional <code>1</code> bit is added to the end, at index <code>e</code> where <code>e</code> is the length of the bitlist (not the limit), so that the length in bits will also be known.</p> <pre><code>array = [0] * ((len(value) // 8) + 1)\nfor i in range(len(value)):\n    array[i // 8] |= value[i] &lt;&lt; (i % 8)\narray[len(value) // 8] |= 1 &lt;&lt; (len(value) % 8)\nreturn bytes(array)\n</code></pre>"},{"location":"ssz/simple-serialize/#vectors-containers-progressive-containers-lists-progressive-lists","title":"Vectors, containers, progressive containers, lists, progressive lists","text":"<pre><code># Recursively serialize\nfixed_parts = [serialize(element) if not is_variable_size(element) else None for element in value]\nvariable_parts = [serialize(element) if is_variable_size(element) else b\"\" for element in value]\n\n# Compute and check lengths\nfixed_lengths = [len(part) if part != None else BYTES_PER_LENGTH_OFFSET for part in fixed_parts]\nvariable_lengths = [len(part) for part in variable_parts]\nassert sum(fixed_lengths + variable_lengths) &lt; 2 ** (BYTES_PER_LENGTH_OFFSET * BITS_PER_BYTE)\n\n# Interleave offsets of variable-size parts with fixed-size parts\nvariable_offsets = [\n    serialize(uint32(sum(fixed_lengths + variable_lengths[:i]))) for i in range(len(value))\n]\nfixed_parts = [part if part != None else variable_offsets[i] for i, part in enumerate(fixed_parts)]\n\n# Return the concatenation of the fixed-size parts (offsets interleaved) with the variable-size parts\nreturn b\"\".join(fixed_parts + variable_parts)\n</code></pre>"},{"location":"ssz/simple-serialize/#union","title":"Union","text":"<p>A <code>value</code> as <code>Union[T...]</code> type has properties <code>value.value</code> with the contained value, and <code>value.selector</code> which indexes the selected <code>Union</code> type option <code>T</code>.</p> <p>A <code>Union</code>:</p> <ul> <li>May have multiple selectors with the same type.</li> <li>Should not use selectors above 127 (i.e. highest bit is set), these are   reserved for backwards compatible extensions.</li> <li>Must have at least 1 type option.</li> <li>May have <code>None</code> as first type option, i.e. <code>selector == 0</code></li> <li>Must have at least 2 type options if the first is <code>None</code></li> <li>Is always considered a variable-length type, even if all type options have an   equal fixed-length.</li> </ul> <pre><code>if value.value is None:\n    assert value.selector == 0\n    return b\"\\x00\"\nelse:\n    serialized_bytes = serialize(value.value)\n    serialized_selector_index = value.selector.to_bytes(1, \"little\")\n    return serialized_selector_index + serialized_bytes\n</code></pre>"},{"location":"ssz/simple-serialize/#deserialization","title":"Deserialization","text":"<p>Because serialization is an injective function (i.e. two distinct objects of the same type will serialize to different values) any bytestring has at most one object it could deserialize to.</p> <p>Deserialization can be implemented using a recursive algorithm. The deserialization of basic objects is easy, and from there we can find a simple recursive algorithm for all fixed-size objects. For variable-size objects we have to do one of the following depending on what kind of object it is:</p> <ul> <li>Vector/list/progressive list of a variable-size object: The serialized data   will start with offsets of all the serialized objects   (<code>BYTES_PER_LENGTH_OFFSET</code> bytes each).</li> <li>Using the first offset, we can compute the length of the list (divide by     <code>BYTES_PER_LENGTH_OFFSET</code>), as it gives us the total number of bytes in the     offset data.</li> <li>The size of each object in the vector/list/progressive list can be inferred     from the difference of two offsets. To get the size of the last object, the     total number of bytes has to be known (it is not generally possible to     deserialize an SSZ object of unknown length)</li> <li>Containers/progressive containers follow the same principles as vectors, with   the difference that there may be fixed-size objects in a container/progressive   container as well. This means the <code>fixed_parts</code> data will contain offsets as   well as fixed-size objects.</li> <li>In the case of bitlists/progressive bitlists, the length in bits cannot be   uniquely inferred from the number of bytes in the object. Because of this,   they have a bit at the end that is always set. This bit has to be used to   infer the size of the bitlist in bits.</li> <li>In the case of unions, the first byte of the deserialization scope is   deserialized as type selector, the remainder of the scope is deserialized as   the selected type.</li> </ul> <p>Note that deserialization requires hardening against invalid inputs. A non-exhaustive list:</p> <ul> <li>Offsets: out of order, out of range, mismatching minimum element size.</li> <li>Scope: Extra unused bytes, not aligned with element size.</li> <li>More elements than a list limit allows. Part of enforcing consensus.</li> <li>An out-of-bounds selected index in an <code>Union</code></li> </ul> <p>Efficient algorithms for computing this object can be found in the implementations.</p>"},{"location":"ssz/simple-serialize/#merkleization","title":"Merkleization","text":"<p>We first define helper functions:</p> <ul> <li><code>size_of(B)</code>, where <code>B</code> is a basic type: the length, in bytes, of the   serialized form of the basic type.</li> <li><code>chunk_count(type)</code>: calculate the amount of leaves for merkleization of the   type.</li> <li>all basic types: <code>1</code></li> <li><code>Bitlist[N]</code> and <code>Bitvector[N]</code>: <code>(N + 255) // 256</code> (dividing by chunk size,     rounding up)</li> <li><code>List[B, N]</code> and <code>Vector[B, N]</code>, where <code>B</code> is a basic type:     <code>(N * size_of(B) + 31) // 32</code> (dividing by chunk size, rounding up)</li> <li><code>List[C, N]</code> and <code>Vector[C, N]</code>, where <code>C</code> is a composite type: <code>N</code></li> <li>containers: <code>len(fields)</code></li> <li><code>get_active_fields(value)</code>, where <code>value</code> is of type   <code>ProgressiveContainer(active_fields)</code>: return <code>active_fields</code>.</li> <li><code>pack(values)</code>: Given ordered objects of the same basic type:   1. Serialize <code>values</code> into bytes.   2. If not aligned to a multiple of <code>BYTES_PER_CHUNK</code> bytes, right-pad with      zeroes to the next multiple.   3. Partition the bytes into <code>BYTES_PER_CHUNK</code>-byte chunks.   4. Return the chunks.</li> <li><code>pack_bits(bits)</code>: Given the bits of bitlist or bitvector, get   <code>bitfield_bytes</code> by packing them in bytes and aligning to the start. The   length-delimiting bit for bitlists is excluded. Then return   <code>pack(bitfield_bytes)</code>.</li> <li><code>next_pow_of_two(i)</code>: get the next power of 2 of <code>i</code>, if not already a power   of 2, with 0 mapping to 1. Examples:   <code>0-&gt;1, 1-&gt;1, 2-&gt;2, 3-&gt;4, 4-&gt;4, 6-&gt;8, 9-&gt;16</code></li> <li><code>merkleize(chunks, limit=None)</code>: Given ordered <code>BYTES_PER_CHUNK</code>-byte chunks,   merkleize the chunks, and return the root:</li> <li>The merkleization depends on the effective input, which must be     padded/limited:<ul> <li>if no limit: pad the <code>chunks</code> with zeroed chunks to   <code>next_pow_of_two(len(chunks))</code> (virtually for memory efficiency).</li> <li>if <code>limit &gt;= len(chunks)</code>, pad the <code>chunks</code> with zeroed chunks to   <code>next_pow_of_two(limit)</code> (virtually for memory efficiency).</li> <li>if <code>limit &lt; len(chunks)</code>: do not merkleize, input exceeds limit. Raise an   error instead.</li> </ul> </li> <li>Then, merkleize the chunks (empty input is padded to 1 zero chunk):<ul> <li>If <code>1</code> chunk: the root is the chunk itself.</li> <li>If <code>&gt; 1</code> chunks: merkleize as binary tree.</li> </ul> </li> <li><code>merkleize_progressive(chunks, num_leaves=1)</code>: Given ordered   <code>BYTES_PER_CHUNK</code>-byte chunks:</li> <li>The merkleization depends on the number of input chunks and is defined     recursively:<ul> <li>If <code>len(chunks) == 0</code>: the root is a zero value, <code>Bytes32()</code>.</li> <li>Otherwise: compute the root using <code>hash(a, b)</code></li> <li><code>a</code>: Recursively merkleize chunks beyond <code>num_leaves</code> using     <code>merkleize_progressive(chunks[num_leaves:], num_leaves * 4)</code>.</li> <li><code>b</code>: Merkleize the first up to <code>num_leaves</code> chunks as a binary tree     using <code>merkleize(chunks[:num_leaves], num_leaves)</code>.</li> </ul> </li> <li><code>mix_in_active_fields</code>: Given a Merkle root <code>root</code> and an <code>active_fields</code>   configuration return <code>hash(root, pack_bits(active_fields))</code>. Note that   <code>active_fields</code> is restricted to \u2264 256 bits.</li> <li><code>mix_in_length</code>: Given a Merkle root <code>root</code> and a length <code>length</code> (<code>\"uint256\"</code>   little-endian serialization) return <code>hash(root + length)</code>.</li> <li><code>mix_in_selector</code>: Given a Merkle root <code>root</code> and a type selector <code>selector</code>   (<code>\"uint256\"</code> little-endian serialization) return <code>hash(root + selector)</code>.</li> </ul> <p>We now define Merkleization <code>hash_tree_root(value)</code> of an object <code>value</code> recursively:</p> <ul> <li><code>merkleize(pack(value))</code> if <code>value</code> is a basic object or a vector of basic   objects.</li> <li><code>merkleize(pack_bits(value), limit=chunk_count(type))</code> if <code>value</code> is a   bitvector.</li> <li><code>mix_in_length(merkleize(pack(value), limit=chunk_count(type)), len(value))</code>   if <code>value</code> is a list of basic objects.</li> <li><code>mix_in_length(merkleize_progressive(pack(value)), len(value))</code> if <code>value</code> is   a progressive list of basic objects.</li> <li><code>mix_in_length(merkleize(pack_bits(value), limit=chunk_count(type)), len(value))</code>   if <code>value</code> is a bitlist.</li> <li><code>mix_in_length(merkleize_progressive(pack_bits(value)), len(value))</code> if   <code>value</code> is a progressive bitlist.</li> <li><code>merkleize([hash_tree_root(element) for element in value])</code> if <code>value</code> is a   vector of composite objects or a container.</li> <li><code>mix_in_active_fields(merkleize_progressive([hash_tree_root(element) for element in value]), get_active_fields(value))</code>   if <code>value</code> is a progressive container.</li> <li><code>mix_in_length(merkleize([hash_tree_root(element) for element in value], limit=chunk_count(type)), len(value))</code>   if <code>value</code> is a list of composite objects.</li> <li><code>mix_in_length(merkleize_progressive([hash_tree_root(element) for element in value]), len(value))</code>   if <code>value</code> is a progressive list of composite objects.</li> <li><code>mix_in_selector(hash_tree_root(value.value), value.selector)</code> if <code>value</code> is   of union type, and <code>value.value</code> is not <code>None</code></li> <li><code>mix_in_selector(Bytes32(), 0)</code> if <code>value</code> is of union type, and <code>value.value</code>   is <code>None</code></li> </ul>"},{"location":"ssz/simple-serialize/#summaries-and-expansions","title":"Summaries and expansions","text":"<p>Let <code>A</code> be an object derived from another object <code>B</code> by replacing some of the (possibly nested) values of <code>B</code> by their <code>hash_tree_root</code>. We say <code>A</code> is a \"summary\" of <code>B</code>, and that <code>B</code> is an \"expansion\" of <code>A</code>. Notice <code>hash_tree_root(A) == hash_tree_root(B)</code>.</p> <p>We similarly define \"summary types\" and \"expansion types\". For example, <code>BeaconBlock</code> is an expansion type of <code>BeaconBlockHeader</code>. Notice that objects expand to at most one object of a given expansion type. For example, <code>BeaconBlockHeader</code> objects uniquely expand to <code>BeaconBlock</code> objects.</p>"},{"location":"ssz/simple-serialize/#implementations","title":"Implementations","text":"<p>See https://github.com/ethereum/consensus-specs/issues/2138 for a list of current known implementations.</p>"},{"location":"ssz/simple-serialize/#json-mapping","title":"JSON mapping","text":"<p>The canonical JSON mapping assigns to each SSZ type a corresponding JSON encoding, enabling an SSZ schema to also define the JSON encoding.</p> <p>When decoding JSON data, all fields in the SSZ schema must be present with a value. Parsers may ignore additional JSON fields.</p> SSZ JSON Example <code>uintN</code> string <code>\"0\"</code> <code>byte</code> hex-byte-string <code>\"0x00\"</code> <code>boolean</code> bool <code>false</code> <code>Container</code> object <code>{ \"field\": ... }</code> <code>ProgressiveContainer(active_fields)</code> object <code>{ \"field\": ... }</code> <code>Vector[type, N]</code> array <code>[element, ...]</code> <code>Vector[byte, N]</code> hex-byte-string <code>\"0x1122\"</code> <code>Bitvector[N]</code> hex-byte-string <code>\"0x1122\"</code> <code>List[type, N]</code> array <code>[element, ...]</code> <code>List[byte, N]</code> hex-byte-string <code>\"0x1122\"</code> <code>ProgressiveList[type]</code> array <code>[element, ...]</code> <code>ProgressiveList[byte]</code> hex-byte-string <code>\"0x1122\"</code> <code>Bitlist[N]</code> hex-byte-string <code>\"0x1122\"</code> <code>ProgressiveBitlist</code> hex-byte-string <code>\"0x1122\"</code> <code>Union[type_0, type_1, ...]</code> selector-object <code>{ \"selector\": number, \"data\": type_N }</code> <p>Integers are encoded as strings to avoid loss of precision in 64-bit values.</p> <p>Aliases are encoded as their underlying type.</p> <p><code>hex-byte-string</code> is a <code>0x</code>-prefixed hex encoding of byte data, as it would appear in an SSZ stream.</p> <p><code>List</code>, <code>ProgressiveList</code>, and <code>Vector</code> of <code>byte</code> (and aliases thereof) are encoded as <code>hex-byte-string</code>. <code>Bitlist</code>, <code>ProgressiveBitlist</code>, and <code>Bitvector</code> similarly map their SSZ-byte encodings to a <code>hex-byte-string</code>.</p> <p><code>Union</code> is encoded as an object with a <code>selector</code> and <code>data</code> field, where the contents of <code>data</code> change according to the selector.</p>"},{"location":"sync/optimistic/","title":"Optimistic Sync","text":"<ul> <li>Introduction</li> <li>Constants</li> <li>Helpers</li> <li>Mechanisms</li> <li>When to optimistically import blocks</li> <li>How to optimistically import blocks</li> <li>How to apply <code>latestValidHash</code> when payload status is <code>INVALID</code></li> <li>Execution Engine Errors</li> <li>Assumptions about Execution Engine Behaviour</li> <li>Re-Orgs</li> <li>Fork Choice</li> <li>Fork Choice Poisoning</li> <li>Checkpoint Sync (Weak Subjectivity Sync)</li> <li>Validator assignments</li> <li>Block Production</li> <li>Attesting</li> <li>Participating in Sync Committees</li> <li>Ethereum Beacon APIs</li> <li>Design Decision Rationale</li> <li>Why sync optimistically?</li> <li>Why <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code>?</li> <li>Transitioning from VALID -&gt; INVALIDATED or INVALIDATED -&gt; VALID</li> <li>What about Light Clients?</li> <li>What if <code>TERMINAL_BLOCK_HASH</code> is used?</li> </ul>"},{"location":"sync/optimistic/#introduction","title":"Introduction","text":"<p>In order to provide a syncing execution engine with a partial view of the head of the chain, it may be desirable for a consensus engine to import beacon blocks without verifying the execution payloads. This partial sync is called an optimistic sync.</p> <p>Optimistic sync is designed to be opt-in and backwards compatible (i.e., non-optimistic nodes can tolerate optimistic nodes on the network and vice versa). Optimistic sync is not a fundamental requirement for consensus nodes. Rather, it's a stop-gap measure to allow execution nodes to sync via established methods until future Ethereum roadmap items are implemented (e.g., statelessness).</p>"},{"location":"sync/optimistic/#constants","title":"Constants","text":"Name Value Unit <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code> <code>128</code> slots <p>Note: the <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code> must be user-configurable. See Fork Choice Poisoning.</p>"},{"location":"sync/optimistic/#helpers","title":"Helpers","text":"<p>For brevity, we define two aliases for values of the <code>status</code> field on <code>PayloadStatusV1</code>:</p> <ul> <li>Alias <code>NOT_VALIDATED</code> to:</li> <li><code>SYNCING</code></li> <li><code>ACCEPTED</code></li> <li>Alias <code>INVALIDATED</code> to:</li> <li><code>INVALID</code></li> <li><code>INVALID_BLOCK_HASH</code></li> </ul> <p>Let <code>head: BeaconBlock</code> be the result of calling of the fork choice algorithm at the time of block production. Let <code>head_block_root: Root</code> be the root of that block.</p> <p>Let <code>blocks: Dict[Root, BeaconBlock]</code> and <code>block_states: Dict[Root, BeaconState]</code> be the blocks (and accompanying states) that have been verified either completely or optimistically.</p> <p>Let <code>optimistic_roots: Set[Root]</code> be the set of <code>hash_tree_root(block)</code> for all optimistically imported blocks which have only received a <code>NOT_VALIDATED</code> designation from an execution engine (i.e., they are not known to be <code>INVALIDATED</code> or <code>VALID</code>).</p> <p>Let <code>current_slot: Slot</code> be <code>(time - genesis_time) // SECONDS_PER_SLOT</code> where <code>time</code> is the UNIX time according to the local system clock.</p> <pre><code>@dataclass\nclass OptimisticStore(object):\n    optimistic_roots: Set[Root]\n    head_block_root: Root\n    blocks: Dict[Root, BeaconBlock] = field(default_factory=dict)\n    block_states: Dict[Root, BeaconState] = field(default_factory=dict)\n</code></pre> <pre><code>def is_optimistic(opt_store: OptimisticStore, block: BeaconBlock) -&gt; bool:\n    return hash_tree_root(block) in opt_store.optimistic_roots\n</code></pre> <pre><code>def latest_verified_ancestor(opt_store: OptimisticStore, block: BeaconBlock) -&gt; BeaconBlock:\n    # It is assumed that the `block` parameter is never an INVALIDATED block.\n    while True:\n        if not is_optimistic(opt_store, block) or block.parent_root == Root():\n            return block\n        block = opt_store.blocks[block.parent_root]\n</code></pre> <pre><code>def is_execution_block(block: BeaconBlock) -&gt; bool:\n    return block.body.execution_payload != ExecutionPayload()\n</code></pre> <pre><code>def is_optimistic_candidate_block(\n    opt_store: OptimisticStore, current_slot: Slot, block: BeaconBlock\n) -&gt; bool:\n    if is_execution_block(opt_store.blocks[block.parent_root]):\n        return True\n\n    if block.slot + SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY &lt;= current_slot:\n        return True\n\n    return False\n</code></pre> <p>Let a node be an optimistic node if its fork choice is in one of the following states:</p> <ol> <li><code>is_optimistic(opt_store, head) is True</code></li> <li>Blocks from every viable (with respect to FFG) branch have transitioned from    <code>NOT_VALIDATED</code> to <code>INVALIDATED</code> leaving the block tree without viable    branches</li> </ol> <p>Let only a validator on an optimistic node be an optimistic validator.</p> <p>When this specification only defines behaviour for an optimistic node/validator, but not for the non-optimistic case, assume default behaviours without regard for optimistic sync.</p>"},{"location":"sync/optimistic/#mechanisms","title":"Mechanisms","text":""},{"location":"sync/optimistic/#when-to-optimistically-import-blocks","title":"When to optimistically import blocks","text":"<p>A block MAY be optimistically imported when <code>is_optimistic_candidate_block(opt_store, current_slot, block)</code> returns <code>True</code>. This ensures that blocks are only optimistically imported if one or more of the following are true:</p> <ol> <li>The parent of the block has execution enabled.</li> <li>The current slot (as per the system clock) is at least    <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code> ahead of the slot of the block being    imported.</li> </ol> <p>In effect, there are restrictions on when a merge block can be optimistically imported. The merge block is the first block in any chain where <code>is_execution_block(block) == True</code>. Any descendant of a merge block may be imported optimistically at any time.</p> <p>See Fork Choice Poisoning for the motivations behind these conditions.</p>"},{"location":"sync/optimistic/#how-to-optimistically-import-blocks","title":"How to optimistically import blocks","text":"<p>To optimistically import a block:</p> <ul> <li>The   <code>verify_and_notify_new_payload</code>   function MUST return <code>True</code> if the execution engine returns <code>NOT_VALIDATED</code> or   <code>VALID</code>. An <code>INVALIDATED</code> response MUST return <code>False</code>.</li> <li>The   <code>validate_merge_block</code>   function MUST NOT raise an assertion if both the <code>pow_block</code> and <code>pow_parent</code>   are unknown to the execution engine.</li> <li>All other assertions in     <code>validate_merge_block</code>     (e.g., <code>TERMINAL_BLOCK_HASH</code>) MUST prevent an optimistic import.</li> <li>The parent of the block MUST NOT have an <code>INVALIDATED</code> execution payload.</li> </ul> <p>In addition to this change in validation, the consensus engine MUST track which blocks returned <code>NOT_VALIDATED</code> and which returned <code>VALID</code> for subsequent processing.</p> <p>Optimistically imported blocks MUST pass all verifications included in <code>process_block</code> (withstanding the modifications to <code>verify_and_notify_new_payload</code>).</p> <p>A consensus engine MUST be able to retrospectively (i.e., after import) modify the status of <code>NOT_VALIDATED</code> blocks to be either <code>VALID</code> or <code>INVALIDATED</code> based upon responses from an execution engine. I.e., perform the following transitions:</p> <ul> <li><code>NOT_VALIDATED</code> -&gt; <code>VALID</code></li> <li><code>NOT_VALIDATED</code> -&gt; <code>INVALIDATED</code></li> </ul> <p>When a block transitions from <code>NOT_VALIDATED</code> -&gt; <code>VALID</code>, all ancestors of the block MUST also transition from <code>NOT_VALIDATED</code> -&gt; <code>VALID</code>. Such a block and any previously <code>NOT_VALIDATED</code> ancestors are no longer considered \"optimistically imported\".</p> <p>When a block transitions from <code>NOT_VALIDATED</code> -&gt; <code>INVALIDATED</code>, all descendants of the block MUST also transition from <code>NOT_VALIDATED</code> -&gt; <code>INVALIDATED</code>.</p> <p>When a block transitions from the <code>NOT_VALIDATED</code> state, it is removed from the set of <code>opt_store.optimistic_roots</code>.</p> <p>When a \"merge block\" (i.e. the first block which enables execution in a chain) is declared to be <code>VALID</code> by an execution engine (either directly or indirectly), the full <code>validate_merge_block</code> MUST be run against the merge block. If the block fails <code>validate_merge_block</code>, the merge block MUST be treated the same as an <code>INVALIDATED</code> block (i.e., it and all its descendants are invalidated and removed from the block tree).</p>"},{"location":"sync/optimistic/#how-to-apply-latestvalidhash-when-payload-status-is-invalid","title":"How to apply <code>latestValidHash</code> when payload status is <code>INVALID</code>","text":"<p>Processing an <code>INVALID</code> payload status depends on the <code>latestValidHash</code> parameter. The general approach is as follows:</p> <ol> <li>Consensus engine MUST identify <code>invalidBlock</code> as per definition in the table    below.</li> <li><code>invalidBlock</code> and all of its descendants MUST be transitioned from    <code>NOT_VALIDATED</code> to <code>INVALIDATED</code>.</li> </ol> <code>latestValidHash</code> <code>invalidBlock</code> Execution block hash The child of a block with <code>body.execution_payload.block_hash == latestValidHash</code> in the chain containing the block with payload in question <code>0x00..00</code> (all zeroes) The first block with <code>body.execution_payload != ExecutionPayload()</code> in the chain containing a block with payload in question <code>null</code> Block with payload in question <p>When <code>latestValidHash</code> is a meaningful execution block hash but consensus engine cannot find a block satisfying <code>body.execution_payload.block_hash == latestValidHash</code>, consensus engine SHOULD behave the same as if <code>latestValidHash</code> was <code>null</code>.</p>"},{"location":"sync/optimistic/#execution-engine-errors","title":"Execution Engine Errors","text":"<p>When an execution engine returns an error or fails to respond to a payload validity request for some block, a consensus engine:</p> <ul> <li>MUST NOT optimistically import the block.</li> <li>MUST NOT apply the block to the fork choice store.</li> <li>MAY queue the block for later processing.</li> </ul>"},{"location":"sync/optimistic/#assumptions-about-execution-engine-behaviour","title":"Assumptions about Execution Engine Behaviour","text":"<p>This specification assumes execution engines will only return <code>NOT_VALIDATED</code> when there is insufficient information available to make a <code>VALID</code> or <code>INVALIDATED</code> determination on the given <code>ExecutionPayload</code> (e.g., the parent payload is unknown). Specifically, <code>NOT_VALIDATED</code> responses should be fork-specific, in that the search for a block on one chain MUST NOT trigger a <code>NOT_VALIDATED</code> response for another chain.</p>"},{"location":"sync/optimistic/#re-orgs","title":"Re-Orgs","text":"<p>The consensus engine MUST support any chain reorganisation which does not affect the justified checkpoint.</p> <p>If the justified checkpoint transitions from <code>NOT_VALIDATED</code> -&gt; <code>INVALIDATED</code>, a consensus engine MAY choose to alert the user and force the application to exit.</p>"},{"location":"sync/optimistic/#fork-choice","title":"Fork Choice","text":"<p>Consensus engines MUST support removing blocks from fork choice that transition from <code>NOT_VALIDATED</code> to <code>INVALIDATED</code>. Specifically, a block deemed <code>INVALIDATED</code> at any point MUST NOT be included in the canonical chain and the weights from those <code>INVALIDATED</code> blocks MUST NOT be applied to any <code>VALID</code> or <code>NOT_VALIDATED</code> ancestors.</p>"},{"location":"sync/optimistic/#fork-choice-poisoning","title":"Fork Choice Poisoning","text":"<p>During the merge transition it is possible for an attacker to craft a <code>BeaconBlock</code> with an execution payload that references an eternally-unavailable <code>body.execution_payload.parent_hash</code> (i.e., the parent hash is random bytes). In rare circumstances, it is possible that an attacker can build atop such a block to trigger justification. If an optimistic node imports this malicious chain, that node will have a \"poisoned\" fork choice store, such that the node is unable to produce a block that descends from the head (due to the invalid chain of payloads) and the node is unable to produce a block that forks around the head (due to the justification of the malicious chain).</p> <p>If an honest chain exists which justifies a higher epoch than the malicious chain, that chain will take precedence and revive any poisoned store. Such a chain, if imported before the malicious chain, will prevent the store from being poisoned. Therefore, the poisoning attack is temporary if &gt;= 2/3rds of the network is honest and non-faulty.</p> <p>The <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code> parameter assumes that the network will justify a honest chain within some number of slots. With this assumption, it is acceptable to optimistically import transition blocks during the sync process. Since there is an assumption that an honest chain with a higher justified checkpoint exists, any fork choice poisoning will be short-lived and resolved before that node is required to produce a block.</p> <p>However, the assumption that the honest, canonical chain will always justify within <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code> slots is dubious. Therefore, clients MUST provide the following command line flag to assist with manual disaster recovery:</p> <ul> <li><code>--safe-slots-to-import-optimistically</code>: modifies the   <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code>.</li> </ul>"},{"location":"sync/optimistic/#checkpoint-sync-weak-subjectivity-sync","title":"Checkpoint Sync (Weak Subjectivity Sync)","text":"<p>A consensus engine MAY assume that the <code>ExecutionPayload</code> of a block used as an anchor for checkpoint sync is <code>VALID</code> without necessarily providing that payload to an execution engine.</p>"},{"location":"sync/optimistic/#validator-assignments","title":"Validator assignments","text":"<p>An optimistic node is not a full node. It is unable to produce blocks, since an execution engine cannot produce a payload upon an unknown parent. It cannot faithfully attest to the head block of the chain, since it has not fully verified that block.</p>"},{"location":"sync/optimistic/#block-production","title":"Block Production","text":"<p>An optimistic validator MUST NOT produce a block (i.e., sign across the <code>DOMAIN_BEACON_PROPOSER</code> domain).</p>"},{"location":"sync/optimistic/#attesting","title":"Attesting","text":"<p>An optimistic validator MUST NOT participate in attestation (i.e., sign across the <code>DOMAIN_BEACON_ATTESTER</code>, <code>DOMAIN_SELECTION_PROOF</code> or <code>DOMAIN_AGGREGATE_AND_PROOF</code> domains).</p>"},{"location":"sync/optimistic/#participating-in-sync-committees","title":"Participating in Sync Committees","text":"<p>An optimistic validator MUST NOT participate in sync committees (i.e., sign across the <code>DOMAIN_SYNC_COMMITTEE</code>, <code>DOMAIN_SYNC_COMMITTEE_SELECTION_PROOF</code> or <code>DOMAIN_CONTRIBUTION_AND_PROOF</code> domains).</p>"},{"location":"sync/optimistic/#ethereum-beacon-apis","title":"Ethereum Beacon APIs","text":"<p>Consensus engines which provide an implementation of the Ethereum Beacon APIs must take care to ensure the <code>execution_optimistic</code> value is set to <code>True</code> whenever the request references optimistic blocks (and vice-versa).</p>"},{"location":"sync/optimistic/#design-decision-rationale","title":"Design Decision Rationale","text":""},{"location":"sync/optimistic/#why-sync-optimistically","title":"Why sync optimistically?","text":"<p>Most execution engines use state sync as a default sync mechanism on Ethereum Mainnet because executing blocks from genesis takes several weeks on commodity hardware.</p> <p>State sync requires the knowledge of the current head of the chain to converge eventually. If not constantly fed with the most recent head, state sync won't be able to complete because the recent state soon becomes unavailable due to state trie pruning.</p> <p>Optimistic block import (i.e. import when the execution engine cannot currently validate the payload) breaks a deadlock between the execution layer sync process and importing beacon blocks while the execution engine is syncing.</p> <p>Optimistic sync is also an optimal strategy for execution engines using block execution as a default sync mechanism (e.g. Erigon). Alternatively, a consensus engine may inform the execution engine with a payload obtained from a checkpoint block, then wait until the execution layer catches up with it and proceed in lock step after that. This alternative approach would keep user in limbo for several hours and would increase time of the sync process as batch sync has more opportunities for optimisation than the lock step.</p> <p>Aforementioned premises make optimistic sync a generalized solution for interaction between consensus and execution engines during the sync process.</p>"},{"location":"sync/optimistic/#why-safe_slots_to_import_optimistically","title":"Why <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code>?","text":"<p>Nodes can only import an optimistic block if their justified checkpoint is verified or the block is older than <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code>.</p> <p>These restraints are applied in order to mitigate an attack where a block which enables execution (a transition block) can reference a junk parent hash. This makes it impossible for honest nodes to build atop that block. If an attacker exploits a nuance in fork choice <code>filter_block_tree</code>, they can, in some rare cases, produce a junk block that out-competes all locally produced blocks for the head. This prevents a node from producing a chain of blocks, therefore breaking liveness.</p> <p>Thankfully, if 2/3rds of validators are not poisoned, they can justify an honest chain which will un-poison all other nodes.</p> <p>Notably, this attack only exists for optimistic nodes. Nodes which fully verify the transition block will reject a block with a junk parent hash. Therefore, liveness is unaffected if a vast majority of nodes have fully synced execution and consensus clients before and during the transition.</p> <p>Given all of this, we can say two things:</p> <ol> <li>BNs which are following the head during the transition shouldn't    optimistically import the transition block. If 1/3rd of validators    optimistically import the poison block, there will be no remaining nodes to    justify an honest chain.</li> <li>BNs which are syncing can optimistically import transition blocks. In    this case a justified chain already exists blocks. The poison block would be    quickly reverted and would have no effect on liveness.</li> </ol> <p>Astute readers will notice that (2) contains a glaring assumption about network liveness. This is necessary because a node cannot feasibly ascertain that the transition block is justified without importing that block and risking poisoning. Therefore, we use <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code> to say something along the lines of: \"if the transition block is sufficiently old enough, then we can just assume that block is honest or there exists an honest justified chain to out-compete it.\"</p> <p>Note the use of \"feasibly\" in the previous paragraph. One can imagine mechanisms to check that a block is justified before importing it. For example, just keep processing blocks without adding them to fork choice. However, there are still edge-cases here (e.g., when to halt and declare there was no justification?) and how to mitigate implementation complexity. At this point, it's important to reflect on the attack and how likely it is to happen. It requires some rather contrived circumstances and it seems very unlikely to occur. Therefore, we need to consider if adding complexity to avoid an unlikely attack increases or decreases our total risk. Presently, it appears that <code>SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY</code> sits in a sweet spot for this trade-off.</p>"},{"location":"sync/optimistic/#transitioning-from-valid-invalidated-or-invalidated-valid","title":"Transitioning from VALID -&gt; INVALIDATED or INVALIDATED -&gt; VALID","text":"<p>These operations are purposefully omitted. It is outside of the scope of the specification since it's only possible with a faulty EE.</p> <p>Such a scenario requires manual intervention.</p>"},{"location":"sync/optimistic/#what-about-light-clients","title":"What about Light Clients?","text":"<p>An alternative to optimistic sync is to run a light client inside/alongside beacon nodes that mitigates the need for optimistic sync by providing tip-of-chain blocks to the execution engine. However, light clients come with their own set of complexities. Relying on light clients may also restrict nodes from syncing from genesis, if they so desire.</p> <p>A notable thing about optimistic sync is that it's optional. Should an implementation decide to go the light-client route, then they can just ignore optimistic sync altogether.</p>"},{"location":"sync/optimistic/#what-if-terminal_block_hash-is-used","title":"What if <code>TERMINAL_BLOCK_HASH</code> is used?","text":"<p>If the terminal block hash override is used (i.e., <code>TERMINAL_BLOCK_HASH != Hash32()</code>), the <code>validate_merge_block</code> function will deterministically return <code>True</code> or <code>False</code>. Whilst it's not technically required retrospectively call <code>validate_merge_block</code> on a transition block that matches <code>TERMINAL_BLOCK_HASH</code> after an optimistic sync, doing so will have no effect. For simplicity, the optimistic sync specification does not define edge-case behaviour for when <code>TERMINAL_BLOCK_HASH</code> is used.</p>"}]}